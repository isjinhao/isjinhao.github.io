<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[07-中间件]]></title>
    <url>%2F2019%2F07-%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[消息队列的作用削峰：当大量请求到来时，先存入消息队列中，在异步的去消费，可以防止系统的崩溃。解耦：消费者无需关注消息是从哪个生产者发出的，它只需要监听自己的队列接收消息即可。异步：用户的请求将消息提交到队列中然后就可以返回，剩下的只需要等待消费被消费，如发送验证码。RabbitMQ消息模型测试的配置pom文件123456789101112131415161718192021222324252627282930&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.itcast.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;itcast-rabbitmq&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;RabbitMQ连接的工具类1234567891011121314151617public class ConnectionUtil &#123; public static Connection getConnection() throws Exception &#123; //定义连接工厂 ConnectionFactory factory = new ConnectionFactory(); //设置服务地址 factory.setHost("192.168.56.101"); //端口 factory.setPort(5672); //设置账号信息，用户名、密码、vhost factory.setVirtualHost("/leyou"); factory.setUsername("leyou"); factory.setPassword("leyou"); // 通过工程获取连接 Connection connection = factory.newConnection(); return connection; &#125;&#125;消息模型类别基本消息模型- P（producer/ publisher）：生产者，一个发送消息的用户应用程序。- C（consumer）：消费者，消费和接收有类似的意思，消费者是一个主要用来等待接收消息的用户应用程序- 队列（红色区域）：rabbitmq内部类似于邮箱的一个概念。虽然消息流经rabbitmq和你的应用程序，但是它们只能存储在队列中。队列只受主机的内存和磁盘限制，实质上是一个大的消息缓冲区。许多生产者可以发送消息到一个队列，许多消费者可以尝试从一个队列接收数据。生产者将消息发送到队列，消费者从队列中获取消息，队列是存储消息的缓冲区。##### 生产者123456789101112131415161718192021222324public class Send &#123; private final static String QUEUE_NAME = "simple_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); // 从连接中创建通道，这是完成大部分API的地方。 Channel channel = connection.createChannel(); // 声明（创建）队列，必须声明队列才能够发送消息，我们可以把消息发送到队列中。 // 声明一个队列是幂等的 - 只有当它不存在时才会被创建 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 消息内容 String message = "Hello World!"; channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); //关闭通道和连接 channel.close(); connection.close(); &#125;&#125;##### 消费者123456789101112131415161718192021222324public class Send &#123; private final static String QUEUE_NAME = "simple_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); // 从连接中创建通道，这是完成大部分API的地方。 Channel channel = connection.createChannel(); // 声明（创建）队列，必须声明队列才能够发送消息，我们可以把消息发送到队列中。 // 声明一个队列是幂等的 - 只有当它不存在时才会被创建 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 消息内容 String message = "Hello World!"; channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); //关闭通道和连接 channel.close(); connection.close(); &#125;&#125;#### work消息模型工作队列，又称任务队列。主要思想就是避免执行资源密集型任务时，必须等待它执行完成。相反我们稍后完成任务，我们将任务封装为消息并将其发送到队列。 在后台运行的工作进程将获取任务并最终执行作业。当你运行许多消费者时，任务将在他们之间共享，但是一个消息只能被一个消费者获取。##### 生产者123456789101112131415161718192021222324public class Send &#123; private final static String QUEUE_NAME = "test_work_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 循环发布任务 for (int i = 0; i &lt; 50; i++) &#123; // 消息内容 String message = "task .. " + i; channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); Thread.sleep(i * 2); &#125; // 关闭通道和连接 channel.close(); connection.close(); &#125;&#125;##### 消费者- 性能差的消费者1234567891011121314151617181920212223242526272829303132public class Recv &#123; private final static String QUEUE_NAME = "test_work_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 final Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者1] received : " + msg + "!"); try &#123; // 模拟完成任务的耗时：1000ms Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; // 手动ACK channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; // 监听队列。 channel.basicConsume(QUEUE_NAME, false, consumer); &#125;&#125;- 性能好的消费者123456789101112131415161718192021222324252627public class Recv2 &#123; private final static String QUEUE_NAME = "test_work_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 final Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者2] received : " + msg + "!"); // 手动ACK channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; // 监听队列。 channel.basicConsume(QUEUE_NAME, false, consumer); &#125;&#125;##### 结果可以发现，两个消费者各自消费了25条消息，而且各不相同，这就实现了任务的分发。##### 能者多劳我们可以使用basicQos方法和prefetchCount = 1设置。 这告诉RabbitMQ一次不要向工作人员发送多于一条消息。 或者换句话说，不要向工作人员发送新消息，直到它处理并确认了前一个消息。 相反，它会将其分派给不是仍然忙碌的下一个工作人员。再次测试：#### 订阅模型-FanoutFanout，也称为广播。在广播模式下，消息发送流程是这样的：- 可以有多个消费者- 每个消费者有自己的queue（队列）- 每个队列都要绑定到Exchange（交换机）- 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定。- 交换机把消息发送给绑定过的所有队列- 队列的消费者都能拿到消息。实现一条消息被多个消费者消费##### 生产者12345678910111213141516171819202122public class Send &#123; private final static String EXCHANGE_NAME = "fanout_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为fanout channel.exchangeDeclare(EXCHANGE_NAME, "fanout"); // 消息内容 String message = "Hello everyone"; // 发布消息到Exchange channel.basicPublish(EXCHANGE_NAME, "", null, message.getBytes()); System.out.println(" [生产者] Sent '" + message + "'"); channel.close(); connection.close(); &#125;&#125;##### 消费者12345678910111213141516171819202122232425262728public class Recv &#123; private final static String QUEUE_NAME = "fanout_exchange_queue_1"; private final static String EXCHANGE_NAME = "fanout_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者1] received : " + msg + "!"); &#125; &#125;; // 监听队列，自动返回完成 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;123456789101112131415161718192021222324252627282930public class Recv2 &#123; private final static String QUEUE_NAME = "fanout_exchange_queue_2"; private final static String EXCHANGE_NAME = "fanout_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者2] received : " + msg + "!"); &#125; &#125;; // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;#### 订阅模型-Direct在路由模式中，我们将添加一个功能 - 我们将只能订阅一部分消息。 例如，我们只能将重要的错误消息引导到日志文件（以节省磁盘空间），同时仍然能够在控制台上打印所有日志消息。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。在Direct模型下，队列与交换机的绑定，不能是任意绑定了，而是要指定一个RoutingKey（路由key）。消息的发送方在向Exchange发送消息时，也必须指定消息的routing key。- P：生产者，向Exchange发送消息，发送消息时，会指定一个routing key。- X：Exchange（交换机），接收生产者的消息，然后把消息递交给 与routing key完全匹配的队列- C1：消费者，其所在队列指定了需要routing key 为 error 的消息- C2：消费者，其所在队列指定了需要routing key 为 info、error、warning 的消息##### 生产者此处我们模拟商品的增删改，发送消息的RoutingKey分别是：insert、update、delete1234567891011121314151617181920public class Send &#123; private final static String EXCHANGE_NAME = "direct_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为direct channel.exchangeDeclare(EXCHANGE_NAME, "direct"); // 消息内容 String message = "商品新增了， id = 1001"; // 发送消息，并且指定routing key 为：insert ,代表新增商品 channel.basicPublish(EXCHANGE_NAME, "insert", null, message.getBytes()); System.out.println(" [商品服务：] Sent '" + message + "'"); channel.close(); connection.close(); &#125;&#125;##### 消费者- 只接收两种类型的消息：更新商品和删除商品。12345678910111213141516171819202122232425262728293031public class Recv &#123; private final static String QUEUE_NAME = "direct_exchange_queue_1"; private final static String EXCHANGE_NAME = "direct_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。假设此处需要update和delete消息 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "delete"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者1] received : " + msg + "!"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;- 接收所有类型的消息：新增商品，更新商品和删除商品。1234567891011121314151617181920212223242526272829303132public class Recv2 &#123; private final static String QUEUE_NAME = "direct_exchange_queue_2"; private final static String EXCHANGE_NAME = "direct_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。订阅 insert、update、delete channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "insert"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "delete"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者2] received : " + msg + "!"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;#### 订阅模型-TopicTopic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符！Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert通配符规则：123`#`：匹配一个或多个词`*`：匹配不多不少恰好1个词举例：123`audit.#`：能够匹配`audit.irs.corporate` 或者 `audit.irs``audit.*`：只能匹配`audit.irs`在这个例子中，我们将发送所有描述动物的消息。消息将使用由三个字（两个点）组成的routing key发送。路由关键字中的第一个单词将描述速度，第二个颜色和第三个种类：&lt;speed&gt;.&lt;color&gt;.&lt;species&gt;。我们创建了三个绑定：Q1绑定了绑定键“ .orange.”，Q2绑定了“..rabbit”和“lazy.＃”。Q1匹配所有的橙色动物。Q2匹配关于兔子以及懒惰动物的消息。##### 生产者使用topic类型的Exchange，发送消息的routing key有3种： item.isnert、item.update、item.delete：1234567891011121314151617181920public class Send &#123; private final static String EXCHANGE_NAME = "topic_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明exchange，指定类型为topic channel.exchangeDeclare(EXCHANGE_NAME, "topic"); // 消息内容 String message = "新增商品 : id = 1001"; // 发送消息，并且指定routing key 为：insert ,代表新增商品 channel.basicPublish(EXCHANGE_NAME, "item.insert", null, message.getBytes()); System.out.println(" [商品服务：] Sent '" + message + "'"); channel.close(); connection.close(); &#125;&#125;##### 消费者我们此处假设消费者1只接收两种类型的消息：更新商品和删除商品12345678910111213141516171819202122232425262728293031public class Recv &#123; private final static String QUEUE_NAME = "topic_exchange_queue_1"; private final static String EXCHANGE_NAME = "topic_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。需要 update、delete channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.delete"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者1] received : " + msg + "!"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;接收所有类型的消息：新增商品，更新商品和删除商品。123456789101112131415161718192021222324252627282930public class Recv2 &#123; private final static String QUEUE_NAME = "topic_exchange_queue_2"; private final static String EXCHANGE_NAME = "topic_exchange_test"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connection = ConnectionUtil.getConnection(); // 获取通道 Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机，同时指定需要订阅的routing key。订阅 insert、update、delete channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.*"); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [消费者2] received : " + msg + "!"); &#125; &#125;; // 监听队列，自动ACK channel.basicConsume(QUEUE_NAME, true, consumer); &#125;&#125;## 消息确认机制### 消费者消息一旦被消费者接收，队列中的消息就会被删除。那么问题来了：RabbitMQ怎么知道消息被接收了呢？如果消费者领取消息后，还没执行操作就挂掉了呢？或者抛出了异常？消息消费失败，但是RabbitMQ无从得知，这样消息就丢失了！因此，RabbitMQ有一个ACK机制。当消费者获取消息后，会向RabbitMQ发送回执ACK，告知消息已经被接收。不过这种回执ACK分两种情况：- 自动ACK：消息一旦被接收，消费者自动发送ACK- 手动ACK：消息接收后，不会发送ACK，需要手动调用大家觉得哪种更好呢？这需要看消息的重要性：- 如果消息不太重要，丢失也没有影响，那么自动ACK会比较方便- 如果消息非常重要，不容丢失。那么最好在消费完成后手动ACK，否则接收消息后就自动ACK，RabbitMQ就会把消息从队列中删除。如果此时消费者宕机，那么消息就丢失了。如果要手动ACK，需要改动我们的代码：123456789101112131415161718192021222324252627public class Recv2 &#123; private final static String QUEUE_NAME = "simple_queue"; public static void main(String[] argv) throws Exception &#123; // 获取到连接 Connection connecti on = ConnectionUtil.getConnection(); // 创建通道 final Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 定义队列的消费者 DefaultConsumer consumer = new DefaultConsumer(channel) &#123; // 获取消息，并且处理，这个方法类似事件监听，如果有消息的时候，会被自动调用 @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; // body 即消息体 String msg = new String(body); System.out.println(" [x] received : " + msg + "!"); // 手动进行ACK channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; // 监听队列，第二个参数false，手动进行ACK channel.basicConsume(QUEUE_NAME, false, consumer); &#125;&#125;手动拒绝或不成功主要使用以下方法：- basicRecover：是路由不成功的消息可以使用recovery重新发送到队列中。- basicReject：是接收端告诉服务器这个消息我拒绝接收，不处理，可以设置是否放回到队列中还是丢掉，而且只能一次拒绝一个消息，官网中有明确说明不能批量拒绝消息，为解决批量拒绝消息才有了basicNack。- basicNack：可以一次拒绝N条消息，客户端可以设置basicNack方法的multiple参数为true，服务器会拒绝指定了delivery_tag的所有未确认的消息(tag是一个64位的long值，最大值是9223372036854775807)。### 生产者#### 事务机制RabbitMQ中与事务机制有关的方法有三个：txSelect()、txCommit()以及txRollback()、txSelect用于将当前channel设置成transaction模式，txCommit用于提交事务，txRollback用于回滚事务，在通过txSelect开启事务之后，我们便可以发布消息给broker代理服务器了，如果txCommit提交成功了，则消息一定到达了broker了，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务了。关键代码：123channel.txSelect();channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());channel.txCommit();通过wirkshark抓包（ip.addr==xxx.xxx.xxx.xxx &amp;&amp; amqp）：可以看到：带事务的多了四个步骤：- client发送Tx.Select- broker发送Tx.Select-Ok(之后publish)- client发送Tx.Commit- broker发送Tx.Commit-Ok下面我们来看下事务回滚是什么样子的。关键代码如下：123456789try &#123; channel.txSelect(); channel.basicPublish(exchange, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes()); int result = 1 / 0; channel.txCommit();&#125; catch (Exception e) &#123; e.printStackTrace(); channel.txRollback();&#125;同样通过wireshark抓包可以看到：代码中先是发送了消息至broker中但是这时候发生了异常，之后在捕获异常的过程中进行事务回滚。事务确实能够解决producer与broker之间消息确认的问题，只有消息成功被broker接受，事务提交才能成功，否则我们便可以在捕获异常进行事务回滚操作同时进行消息重发，但是使用事务机制的话会降低RabbitMQ的性能，那么有没有更好的方法既能保障producer知道消息已经正确送到，又能基本上不带来性能上的损失呢？从AMQP协议的层面看是没有更好的方法，但是RabbitMQ提供了一个更好的方案，即将channel信道设置成confirm模式。#### 信道确认机制生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。confirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。##### 开启confirm模式的方法生产者通过调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式。从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的，注：已经在transaction事务模式的channel是不能再设置成confirm模式的，即这两种模式是不能共存的。##### confirm实现对于固定消息体大小和线程数，如果消息持久化，生产者confirm(或者采用事务机制)，消费者ack那么对性能有很大的影响。消息持久化的优化没有太好方法，用更好的物理存储（SAS, SSD, RAID卡）总会带来改善。生产者confirm这一环节的优化则主要在于客户端程序的优化之上。归纳起来，客户端实现生产者confirm有三种编程方式：- 普通confirm模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm。实际上是一种串行confirm了。- 批量confirm模式：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。- 异步confirm模式：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法。###### 普通模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 这是java原生类支持RabbitMQ，直接运行该类 */public class ConfirmSender1 &#123; private final static String QUEUE_NAME = "confirm"; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; /** * 创建连接连接到RabbitMQ */ ConnectionFactory factory = new ConnectionFactory(); // 设置RabbitMQ所在主机ip或者主机名 factory.setUsername("guest"); factory.setPassword("guest"); factory.setHost("127.0.0.1"); factory.setVirtualHost("/"); factory.setPort(5672); // 创建一个连接 Connection connection = factory.newConnection(); // 创建一个频道 Channel channel = connection.createChannel(); // 指定一个队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 发送的消息 String message = "This is a confirm message！"; channel.confirmSelect(); final long start = System.currentTimeMillis(); //发送持久化消息 for (int i = 0; i &lt; 5; i++) &#123; //第一个参数是exchangeName(默认情况下代理服务器端是存在一个""名字的exchange的, //因此如果不创建exchange的话我们可以直接将该参数设置成"",如果创建了exchange的话 //我们需要将该参数设置成创建的exchange的名字),第二个参数是路由键 channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_BASIC, (" Confirm模式， 第" + (i + 1) + "条消息").getBytes()); if (channel.waitForConfirms()) &#123; System.out.println("发送成功"); &#125;else&#123; // 进行消息重发 &#125; &#125; System.out.println("执行waitForConfirms耗费时间: " + (System.currentTimeMillis() - start) + "ms"); // 关闭频道和连接 channel.close(); connection.close(); &#125;&#125;###### 批量confirm模式客户端程序需要定期（每隔多少秒）或者定量（达到多少条）或者两则结合起来publish消息，然后等待服务器端confirm, 相比普通confirm模式，批量极大提升confirm效率，但是问题在于一旦出现confirm返回false或者超时的情况时，客户端需要将这一批次的消息全部重发，这会带来明显的重复消息数量，并且，当消息经常丢失时，批量confirm性能应该是不升反降的。123456789channel.confirmSelect();for(int i = 0; i &lt; 5;i++)&#123; channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_BASIC, (" Confirm模式， 第" + (i + 1) + "条消息").getBytes());&#125;if(channel.waitForConfirms())&#123; System.out.println("发送成功");&#125;else&#123; // 进行消息重发&#125;###### 异步confirm模式Channel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。123456789101112131415161718192021222324SortedSet&lt;Long&gt; confirmSet = Collections.synchronizedSortedSet(new TreeSet&lt;Long&gt;());channel.confirmSelect();channel.addConfirmListener(new ConfirmListener() &#123; public void handleAck(long deliveryTag, boolean multiple) throws IOException &#123; if (multiple) &#123; confirmSet.headSet(deliveryTag + 1L).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125; public void handleNack(long deliveryTag, boolean multiple) throws IOException &#123; System.out.println("Nack, SeqNo: " + deliveryTag + ", multiple: " + multiple); if (multiple) &#123; confirmSet.headSet(deliveryTag + 1L).clear(); &#125; else &#123; confirmSet.remove(deliveryTag); &#125; &#125;&#125;);for(int i=0;i&lt;5;i++)&#123; long nextSeqNo = channel.getNextPublishSeqNo(); channel.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_BASIC, (" Confirm模式， 第" + (i + 1) + "条消息").getBytes()); confirmSet.add(nextSeqNo);&#125;## 消息持久化### queue的持久化queue的持久化是通过durable=true来实现的。一般程序中这么使用：123Connection connection = connectionFactory.newConnection();Channel channel = connection.createChannel();channel.queueDeclare("queue.persistent.name", true, false, false, null);Channel类中queueDeclare的完整定义如下：12345678910111213/** * Declare a queue * @see com.rabbitmq.client.AMQP.Queue.Declare * @see com.rabbitmq.client.AMQP.Queue.DeclareOk * @param queue the name of the queue * @param durable true if we are declaring a durable queue (the queue will survive a server restart) * @param exclusive true if we are declaring an exclusive queue (restricted to this connection) * @param autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use) * @param arguments other properties (construction arguments) for the queue * @return a declaration-confirm method to indicate the queue was successfully declared * @throws java.io.IOException if an error is encountered */Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException;参数说明：- queue：queue的名称- exclusive：排他队列，如果一个队列被声明为排他队列，该队列仅对首次申明它的连接可见，并在连接断开时自动删除。这里需要注意三点：1. 排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一连接创建的排他队列；2.“首次”，如果一个连接已经声明了一个排他队列，其他连接是不允许建立同名的排他队列的，这个与普通队列不同；3.即使该队列是持久化的，一旦连接关闭或者客户端退出，该排他队列都会被自动删除的，这种队列适用于一个客户端发送读取消息的应用场景。- autoDelete：自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除。这种队列适用于临时队列。queueDeclare相关的有4种方法，分别是：1234567Queue.DeclareOk queueDeclare() throws IOException;Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException;void queueDeclareNoWait(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException;Queue.DeclareOk queueDeclarePassive(String queue) throws IOException;其中需要说明的是queueDeclarePassive(String queue)可以用来检测一个queue是否已经存在。如果该队列存在，则会返回true；如果不存在，就会返回异常，但是不会创建新的队列。### 持久化设置如过将queue的持久化标识durable设置为true,则代表是一个持久的队列，那么在服务重启之后，也会存在，因为服务会把持久化的queue存放在硬盘上，当服务重启的时候，会重新什么之前被持久化的queue。队列是可以被持久化，但是里面的消息是否为持久化那还要看消息的持久化设置。也就是说，重启之前那个queue里面还没有发出去的消息的话，重启之后那队列里面是不是还存在原来的消息，这个就要取决于发生着在发送消息时对消息的设置了。如果要在重启后保持消息的持久化必须设置消息是持久化的标识。设置消息的持久化：1channel.basicPublish("exchange.persistent", "persistent", MessageProperties.PERSISTENT_TEXT_PLAIN, "persistent_test_message".getBytes());这里的关键是：MessageProperties.PERSISTENT_TEXT_PLAIN，首先看一下basicPublish的方法：12345void basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException;void basicPublish(String exchange, String routingKey, boolean mandatory, BasicProperties props, byte[] body) throws IOException;void basicPublish(String exchange, String routingKey, boolean mandatory, boolean immediate, BasicProperties props, byte[] body) throws IOException;- exchange表示exchange的名称- routingKey表示routingKey的名称- body代表发送的消息体这里关键的是BasicProperties props这个参数了，这里看下BasicProperties的定义：123456789101112131415public BasicProperties( String contentType,//消息类型如：text/plain String contentEncoding,//编码 Map&lt;String,Object&gt; headers, Integer deliveryMode,//1:nonpersistent 2:persistent Integer priority,//优先级 String correlationId, String replyTo,//反馈队列 String expiration,//expiration到期时间 String messageId, Date timestamp, String type, String userId, String appId, String clusterId)这里的deliveryMode=1代表不持久化，deliveryMode=2代表持久化。上面的实现代码使用的是MessageProperties.PERSISTENT_TEXT_PLAIN，那么这个又是什么呢？12345678public static final BasicProperties PERSISTENT_TEXT_PLAIN = new BasicProperties("text/plain", null, null, 2, 0, null, null, null, null, null, null, null, null, null);可以看到这其实就是讲deliveryMode设置为2的BasicProperties的对象，为了方便编程而出现的一个东东。换一种实现方式：1234AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();builder.deliveryMode(2);AMQP.BasicProperties properties = builder.build();channel.basicPublish("exchange.persistent", "persistent",properties, "persistent_test_message".getBytes());设置了队列和消息的持久化之后，当broker服务重启的之后，消息依旧存在。单只设置队列持久化，重启之后消息会丢失；单只设置消息的持久化，重启之后队列消失，既而消息也丢失。单单设置消息持久化而不设置队列的持久化显得毫无意义。### exchange的持久化上面阐述了队列的持久化和消息的持久化，如果不设置exchange的持久化对消息的可靠性来说没有什么影响，但是同样如果exchange不设置持久化，那么当broker服务重启之后，exchange将不复存在，那么既而发送方rabbitmq producer就无法正常发送消息。这里博主建议，同样设置exchange的持久化。exchange的持久化设置也特别简单，方法如下：1234567891011121314151617Exchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable) throws IOException;Exchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException;Exchange.DeclareOk exchangeDeclare(String exchange, String type) throws IOException;Exchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable, boolean autoDelete, boolean internal, Map&lt;String, Object&gt; arguments) throws IOException;void exchangeDeclareNoWait(String exchange, String type, boolean durable, boolean autoDelete, boolean internal, Map&lt;String, Object&gt; arguments) throws IOException;Exchange.DeclareOk exchangeDeclarePassive(String name) throws IOException;一般只需要：channel.exchangeDeclare(exchangeName, “direct/topic/header/fanout”, true);即在声明的时候讲durable字段设置为true即可。### 进一步讨论#### 手动确认将queue，exchange, message等都设置了持久化之后就能保证100%保证数据不丢失了嚒？答案是否定的。首先，从consumer端来说，如果这时autoAck=true，那么当consumer接收到相关消息之后，还没来得及处理就crash掉了，那么这样也算数据丢失，这种情况也好处理，只需将autoAck设置为false（方法定义如下），然后在正确处理完消息之后进行手动ack（channel.basicAck）。1String basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;#### 同步到磁盘其次，关键的问题是消息在正确存入RabbitMQ之后，还需要有一段时间（这个时间很短，但不可忽视）才能存入磁盘之中，RabbitMQ并不是为每条消息都做fsync（同步到磁盘）的处理，可能仅仅保存到cache中而不是物理磁盘上，在这段时间内RabbitMQ broker发生crash，消息保存到cache但是还没来得及落盘，那么这些消息将会丢失。那么这个怎么解决呢？首先可以引入RabbitMQ的mirrored-queue即镜像队列，这个相当于配置了副本，当master在此特殊时间内crash掉，可以自动切换到slave，这样有效的保障了HA, 除非整个集群都挂掉，这样也不能完全的100%保障RabbitMQ不丢消息，但比没有mirrored-queue的要好很多，很多现实生产环境下都是配置了mirrored-queue的。还有要在producer引入事务机制或者Confirm机制来确保消息已经正确的发送至broker端，有关RabbitMQ的事务机制或者Confirm机制可以参考：RabbitMQ之消息确认机制（事务+Confirm）。幸亏本文的主题是讨论RabbitMQ的持久化而不是可靠性，不然就一发不可收拾了。RabbitMQ的可靠性涉及producer端的确认机制、broker端的镜像队列的配置以及consumer端的确认机制，要想确保消息的可靠性越高，那么性能也会随之而降，鱼和熊掌不可兼得，关键在于选择和取舍。##### 消息什么时候刷到磁盘？写入文件前会有一个Buffer，大小为1M，数据在写入文件时，首先会写入到这个Buffer，如果Buffer已满，则会将Buffer写入到文件（未必刷到磁盘）。有个固定的刷盘时间：25ms，也就是不管Buffer满不满，每个25ms，Buffer里的数据及未刷新到磁盘的文件内容必定会刷到磁盘。每次消息写入后，如果没有后续写入请求，则会直接将已写入的消息刷到磁盘：使用Erlang的receive x after 0实现，只要进程的信箱里没有消息，则产生一个timeout消息，而timeout会触发刷盘操作。## Redis数据类型及基本操作### 存储stringkey最好不要超过1024字节，value最大可支持512M。- 设置：set key value。设定key持有指定的字符串value，如果该key存在则进行覆盖操作。总是返回”OK”。- 取值：get key。获取key的value，如果与该key关联的value不是String类型，redis将返回错误信息，因为get命令只能用于获取String value；如果该key不存在，返回（nil）。- getset key value：先获取该key的值，然后在设置该key的值。- 删除：del username。- 数值相加减- 加一：incr key。将指定的key的value原子性的递增1，如果该key不存在，其初始值为0，在incr之后其值为1。如果value的值不能转成整型，如hello，该操作将执行失败并返回相应的错误信息。- 减一：decr key。将指定的key的value原子性的递减1，如果该key个存在，其初始值为0，在incr之后其值为-1。如果value的值不能转成整型，如hello，该操作将执行失败并返回相应的错误信息。- 加x：incrby key x。将指定的key的value原子性增加increment，如果该key不存在，器初始值为0，在incrby之后，该值为increment。如果该值不能转成整型，如hello则失败并返回错误信息- 减x：decrby key x。将指定的key的value原子性减少decrement，如果该key不存在，器初始值为0，在decrby之后，该值为decrement。如果该值不能转成整型，如hello则失败并返回错误信息- 字符串拼接：append key value，拼凑字符串。如果该key存在，则在原有的value后追加该值；如果该key不存在，则重新创建一个key/value。### 存储Map最多可支持4294967295键值对。- 赋值：- 赋多值：取值：取多个值：取所有的值：删除字段：删除map：判断字段存在：hexists key field获取全部entry：获取全部key：获取全部value：存储listredis的list是双向链表。头部添加：尾部添加：查看列表：获取链表中从start到end的元素的值，start、end从0开始计数；也可为负数，若为-1则表示链表尾部的元素，-2则表示倒数第二个，依次类推…头部弹出：尾部弹出：lpushx key value：仅当参数中指定的key存在时，向关联的list的头部插入value。如果不存在，将不进行插入。rpush key value：仅当key存在时才向尾部插入。如果不存在，将不进行插入。删除：irem key count value：count&gt;0时从头部开始删除|count|个值为value的元素；count&lt;0时从尾部开始删除|count|个值为value的元素；count=0时删除全部的值为|value|的元素。设置：lset key index value：设置链表中索引值为index的元素，0是链表头，-1是链表尾。索引值不存在抛异常。lindex key index：通过索引获取列表中的元素linsert key before|after pivot value：在列表的元素前或者后插入元素rpoplpush source destination：移除列表的最后一个元素，并将该元素添加到另一个列表并返回### 存储set- SADD key member1 member2...：向集合添加一个或多个成员- SREM key member1 member2...：移除集合中一个或多个成员- SISMEMBER key member：判断 member 元素是否是集合 key 的成员- 1：存在- 0：key不存在或member不存在- sdiff key1 key2：返回集合key1-key2的数据- sinter key1 key2 ...：返回集合key1,key2,...的交集- sunion key1 key2 ...：返回集合key1,key2,...的并集- scard key：返回集合的数量- srandmember key：随机返回集合中的一个数据- 集合运算拓展存储sortedset有序集合和集合一样也是string类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的，但分数(score)却可以重复。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。序号命令及描述1ZADD key score1 member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数2ZCARD key 获取有序集合的成员数3ZCOUNT key min max 计算在有序集合中指定区间分数的成员数4ZINCRBY key increment member 有序集合中对指定成员的分数加上增量 increment5ZINTERSTORE destination numkeys key [key …] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中6ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量7ZRANGE key start stop [WITHSCORES] 通过索引区间返回有序集合成指定区间内的成员8ZRANGEBYLEX key min max [LIMIT offset count] 通过字典区间返回有序集合的成员9ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] 通过分数返回有序集合指定区间内的成员10ZRANK key member 返回有序集合中指定成员的索引11ZREM key member [member …] 移除有序集合中的一个或多个成员12ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员13ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员14ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员15ZREVRANGE key start stop [WITHSCORES] 返回有序集中指定区间内的成员，通过索引，分数从高到底16ZREVRANGEBYSCORE key max min [WITHSCORES] 返回有序集中指定分数区间内的成员，分数从高到低排序17ZREVRANK key member 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序18ZSCORE key member 返回有序集中，成员的分数值19ZUNIONSTORE destination numkeys key [key …] 计算给定的一个或多个有序集的并集，并存储在新的 key 中20ZSCAN key cursor [MATCH pattern] [COUNT count] 迭代有序集合中的元素（包括元素成员和元素分值）keys的通用操作keys pattern：获取所有和pattern匹配的key。del key1, key2, ...：删除指定key。exists key：key是否存在。rename key newkey：为当前的key重命名。expire key：为key设置过期时间，单位：秒。ttl key：获取key所剩的时间，如果没有设置超时，返回-1，key不存在返回-2。type key：以字符串形式返回key的类型。key不存在返回none。Redis的持久化Redis支持两种不同的持久化操作。Redis的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file,AOF）。这两种方法各有千秋。快照（snapshotting）持久化（RDB）Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。快照持久化是Redis默认采用的持久化方式，在redis.conf的140多行有如下配置是RDB配置：- save 900 1：每900秒至少有1个key发生变化，则备份内存快照。- save 300 10：每300秒至少有10个key发生变化，则备份内存快照。- save 60 10000：每60秒至少有10000个key发生变化，则备份内存快照。快照存储的位置：### AOF（append-only file）持久化与快照持久化相比，AOF持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：1appendonly yes开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。在Redis的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：123appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘appendfsync no #让操作系统决定何时进行同步为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec选项 ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。Redis 4.0 对于持久化机制的优化Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 aof-use-rdb-preamble 开启）。如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。## 设置过期时间Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？定期删除+惰性删除。通过名字大概就能猜出这两个删除方式的意思了。- 定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！- 惰性删除 ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ redis 内存淘汰机制。如果有大量的key需要设置同一时间过期，一般需要注意什么？如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。### 内存淘汰机制MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据?redis 配置文件 redis.conf 中有相关注释，我这里就不贴了，大家可以自行查阅或者通过这个网址查看： http://download.redis.io/redis-stable/redis.conf。redis 提供 6种数据淘汰策略：1. volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰2. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰3. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰4. allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰6. no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！4.0版本后增加以下两种：1. volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰2. allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key## 如何防止缓存穿透有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。### 布隆过滤器问题：不安全网页的黑名单里有100亿个URL，每一个网页的URL最多占用64B。要求实现一种过滤系统，可以根据网页的URL判断是否在这个黑名单中。布隆过滤器本质上是一个bit数组，可以用极少的空间解决“判断在不在”这种问题。以这道题为例，思路是将所有的URL整个都存储起来，但是这个题目其实只需要我们判断在不在，我们根本无需存整个URL，甚至无需在意一个URL是多少字节，只需要存这个URL是“在”还是“不在”这两种状态就好了。重头戏来了，当我们需要判断一个URL在不在黑名单里，只需要判断URL在经过hash函数后对应的bit数组下标的位置是“0”还是“1”。如果对应位置是0，意味这个位置仍是初始化状态，没有被标记过，所以这个URL不在黑名单里。如果对应位置是1，意味这个位置已经被标记过，所以这个URL在黑名单里。#### hash函数上面所提到的“100亿个URL每一个都做hash运算”，这里的hash运算在现实中不只是一个hash函数，而是一组hash函数。顺便说一句hash函数不需要自己实现，经典的哈希函数已经有很多了，比如MD5、SHAI。但为什么URL经过hash函数的出来的值一定会是bit数组下标？打个比方，一个最简单的hash运算：%3。集合里的数经过%3的hash运算后，是只可能得出0或1或2，这三种情况。也就是说hash运算得出的输出域是固定的。这是hash函数的一个重要性质：哈希函数有无限的输入域，但只有固定有限输出域。#### 布隆过滤器误判类型布隆过滤器是有一定失误率。它的误判类型是——宁可错杀一百，也不能放过一个。也就是说如果URL在黑名单，判断结果一定会表示在。可能失误的情况是：某个URL不在黑名单里，也被判断在。为什么布隆过滤器会失误？并且只会“冤枉”，不会“漏判”？这是因为hash函数的另一个性质：不同的输入值hash运算后得到的散列输出值可能不同，也可能相同。但是不同的散列输出值对应的输入值一定不同。假如要判断的两个URLhash运算得到了相同的结果，但一个在黑名单里，一个不在黑名单里，对应的数组下标位置已经被描黑，那么两个URL都会被判为在黑名单里。#### 计算误判率误判率与数组长度、哈希函数的个数成负相关，与样本量成正相关。举一个极端的例子，如果样本量很大而bit数组太小，经过100亿和URL的标记后，数组里的所有元素都被“描黑”。此时任意一个URL都会被判断在黑名单里。想要减少失误率就需根据三个公式设计一个长度合适的bit数组。还是上面那道题为例，n是样本量，即100亿；p预期失误率，即0.0001，m是数组元素个数。##### 公式一：计算布隆过滤器的大小$m=-\frac{nlnp}{(ln2)^2}$把p和n代入公式match，lnp等于-9.21，（ln2）的平方是0.7，n是100亿。计算出来m等于19.19n，转为GB,等于bit数组大小要开25G。##### 公式二：我们还得确定hash函数的个数，哈希函数的个数k公式：$k=ln2\frac{m}{n}$算出k为14，需要14个hash函数##### 公式三：计算失误率，p公式：$p=(1-e^{-\frac{nk}{m}})^k$算出失误率是0.006%。#### 用布隆过滤器着手解决缓冲穿透请求过来，先调用布隆过滤器判断数据是否存在。如果不存在的数据，就不要把请求引向数据库。直接过滤掉了大量不存在的数据攻击。总的来说，当数据量比较大并且重复率不高的时候，布隆过滤器的成本比一般解决方案成本更低。#### 布隆过滤器的题32位无符号整数的范围是0 - 4294967295，现在有一个正好包含40亿个无符号整数的文件，所以在整个范围中必然有没出现过的数。可以使用最多1GB的内存，怎么找到所有出现过两次的数？Redis分布式锁先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！对方这时会显露笑容，心里开始默念：嗯，这小子还不错。scanRedis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？使用keys指令可以扫出指定模式的key列表。 但如果这个redis正在给线上的业务提供服务，由于redis是单线程的，keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。用法SCAN cursor MATCH pattern COUNT count。其中cursor为游标，MATCH和COUNT为可选参数。SCAN命令和SSCAN、HSCAN、ZSCAN命令都用于增量的迭代元素集，它每次返回小部分数据，不会像KEYS那样阻塞Redis。SCAN命令是基于游标的，每次调用后，都会返回一个游标，用于下一次迭代。当游标返回0时，表示迭代结束。SCAN每次返回的数量并不固定，也有可能返回数据为空。另外，SCAN命令和KEYS命令一样支持匹配。我们在Redis里存入10000个key用于测试。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134127.0.0.1:6379&gt; scan 0 match key24* count 10001) "1688"2) 1) "key2411" 2) "key2475" 3) "key2494" 4) "key2406" 5) "key2478"127.0.0.1:6379&gt; scan 1688 match key24* count 10001) "2444"2) 1) "key2458" 2) "key249" 3) "key2407" 4) "key2434" 5) "key241" 6) "key2497" 7) "key2435" 8) "key2413" 9) "key2421" 10) "key248"127.0.0.1:6379&gt; scan 2444 match key24* count 10001) "818"2) 1) "key2459" 2) "key2462" 3) "key2409" 4) "key2454" 5) "key2431" 6) "key2423" 7) "key2476" 8) "key2428" 9) "key2493" 10) "key2420"127.0.0.1:6379&gt; scan 818 match key24* count 10001) "9190"2) 1) "key2402" 2) "key2415" 3) "key2429" 4) "key2424" 5) "key2425" 6) "key2400" 7) "key2472" 8) "key2479" 9) "key2448" 10) "key245" 11) "key2487" 12) "key2430" 13) "key2405"127.0.0.1:6379&gt; scan 9190 match key24* count 10001) "12161"2) 1) "key2488" 2) "key2437" 3) "key2404" 4) "key2440" 5) "key2461" 6) "key2416" 7) "key2436" 8) "key2403" 9) "key2460" 10) "key2452" 11) "key2449" 12) "key2482"127.0.0.1:6379&gt; scan 12161 match key24* count 10001) "11993"2) 1) "key2483" 2) "key2491" 3) "key242" 4) "key2466" 5) "key2446" 6) "key2465" 7) "key243" 8) "key2438" 9) "key2457" 10) "key246" 11) "key2422" 12) "key2418"127.0.0.1:6379&gt; scan 11993 match key24* count 10001) "7853"2) 1) "key2498" 2) "key2451" 3) "key2439" 4) "key2495" 5) "key2408" 6) "key2410"127.0.0.1:6379&gt; scan 7853 match key24* count 10001) "5875"2) 1) "key2486" 2) "key2490" 3) "key244" 4) "key2401" 5) "key2463" 6) "key2481" 7) "key2477" 8) "key2468" 9) "key2433" 10) "key2489" 11) "key2455" 12) "key2426" 13) "key24" 14) "key2450" 15) "key2414" 16) "key2442" 17) "key2473" 18) "key2467" 19) "key2469" 20) "key2456"127.0.0.1:6379&gt; scan 5875 match key24* count 10001) "14311"2) 1) "key2453" 2) "key2492" 3) "key2480" 4) "key2427" 5) "key2443" 6) "key2417" 7) "key2432" 8) "key240" 9) "key2445" 10) "key2484" 11) "key2444" 12) "key247" 13) "key2485"127.0.0.1:6379&gt; scan 14311 match key24* count 10001) "16383"2) 1) "key2441" 2) "key2474" 3) "key2447" 4) "key2471" 5) "key2470" 6) "key2464" 7) "key2412" 8) "key2419" 9) "key2499" 10) "key2496"127.0.0.1:6379&gt; scan 16383 match key24* count 10001) "0"2) (empty list or set)可以看到虽然我们设置的count为1000，但Redis每次返回的数值只有10个左右。]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载和自定义类加载器]]></title>
    <url>%2F2019%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[介绍Java是一个纯面向对象的语言，Java的体系结构是由一个一个的类构成的。类加载是将.class文件定义为JVM中一个类的过程，也是使用一个类的前提条件。每一个类由：它的全限定名+它的类加载器唯一确定。类加载器是一个抽象类：abstract ClassLoader。JDK给我们实现了三个类加载器，BootStrapClassLoader、ExtClassLoader、AppClassLoader。双亲委派机制如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就加载后返回，否则交给子类加载器完成。特点安全，可避免用户自己编写的类动态替换Java的核心类，如java.lang.String避免全限定命名的类重复加载，使用了findLoadClass()判断当前类是否已加载代码分析loadClass123456789101112131415161718192021222324252627282930313233343536373839404142protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); // 如果没有被记载 if (c == null) &#123; long t0 = System.nanoTime(); try &#123; // 有爹就找他爹去加载 if (parent != null) &#123; c = parent.loadClass(name, false); // 没爹就找BootStrap加载器去加载 &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; // 父亲不能加载的情况下自己加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); // 一个满足双亲委派原则的自定义类加载器需要覆盖此方法 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125;findClass这个方法是上面第29行被调用的方法。如果想保持双亲委派机制，在自定义类加载器的时候不去覆盖loadClass，去覆盖findClass就可以了。自定义类加载器的例子12345package org.zzj;public class User &#123; &#125;1234567891011package org.zzj; public class UserService &#123; public void add() &#123; try &#123; System.out.println(Class.forName("org.zzj.User").getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package org.zzj;import java.io.IOException;import java.io.InputStream;import java.lang.reflect.Method;public class ClassForNameTest &#123; public static void main(String[] args) throws Exception &#123; // 当前调用者的加载器是 sun.misc.Launcher$AppClassLoader@18b4aac2 System.out.println(Class.forName("org.zzj.User").getClassLoader()); MyClassLoader classLoader = new MyClassLoader(); // clazz是 org.zzj.MyClassLoader@5b2133b1 加载的 Class&lt;?&gt; clazz = classLoader.loadClass("org.zzj.UserService"); System.out.println("aaa -&gt; " + clazz.getClassLoader()); Method method = clazz.getMethod("add"); method.invoke(clazz.newInstance()); &#125;&#125;class MyClassLoader extends ClassLoader &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; System.out.println(name); String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream in = getClass().getResourceAsStream(fileName); if (in == null) &#123; return super.loadClass(name); &#125; byte[] b = null; try &#123; b = new byte[in.available()]; in.read(b); in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; // 将 字节数组 转为 类 return defineClass(name, b, 0, b.length); &#125;&#125;Class.forName和ClassLoader.loadClass的区别Class.forName加载的类会进行初始化，而ClassLoader.loadClass加载的类不会进行初始化：12345public static Class&lt;?&gt; forName(String className) throws ClassNotFoundException &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); return forName0(className, true, ClassLoader.getClassLoader(caller), caller);&#125;需要注意的是这个使用这个方法加载得到的类默认是调用者的类加载器。123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;线程上下文类加载器Java 提供了很多服务提供者接口（Service Provider Interface，SPI），允许第三方为这些接口提供实现。常见的 SPI 有 JDBC、JCE、JNDI、JAXP 和 JBI 等。这些 SPI 的接口由 Java 核心库来提供，而这些 SPI 的实现代码则是作为 Java 应用所依赖的 jar 包被包含进类路径（CLASSPATH）里。SPI接口中的代码经常需要加载具体的实现类。那么问题来了，SPI的接口是Java核心库的一部分，是由启动类加载器(Bootstrap Classloader)来加载的；SPI的实现类是由系统类加载器(System ClassLoader)来加载的。引导类加载器是无法找到 SPI 的实现类的，因为依照双亲委派模型，BootstrapClassloader无法委派AppClassLoader来加载类。而线程上下文类加载器破坏了“双亲委派模型”，可以在执行线程中抛弃双亲委派加载链模式，使程序可以逆向使用类加载器。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven排除依赖]]></title>
    <url>%2F2019%2FMaven%E6%8E%92%E9%99%A4%E4%BE%9D%E8%B5%96%2F</url>
    <content type="text"><![CDATA[依赖重复时在启动项目的时候会报错，但大多数不影响使用。不过如果把Maven项目按普通方式打包时就会出现问题。所以依赖最好排除一下。排除依赖的写法在坐标里面（dependency）加入exclusions结点，exclusions里的exclusion是要排除的内容。1234567891011121314&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA的打包]]></title>
    <url>%2F2019%2FIDEA%E7%9A%84%E6%89%93%E5%8C%85%2F</url>
    <content type="text"><![CDATA[基本打包方式然后选择build。这样过后，我们能在classes文件夹下找到一个文件夹，文件夹里我们写的的包和第三方包。Maven打包Springboot项目pom.xml中加入插件：1234567891011&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includeSystemScope&gt;true&lt;/includeSystemScope&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;]]></content>
      <categories>
        <category>IDE</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jar包的动态加载及卸载]]></title>
    <url>%2F2019%2FJar%E5%8C%85%E7%9A%84%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8F%8A%E5%8D%B8%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[用springboot封装了一下。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115@RequestMapping("controller")@RestControllerpublic class Controller &#123; // 公司的一个调用dubbo服务的jar File innerServiceBus = new File(new File("").getCanonicalPath() + File.separator + "InnerServiceBus_4.3.0" + ".jar"); URLClassLoader loader = new URLClassLoader(new URL[]&#123;innerServiceBus.toURI().toURL()&#125;); public Controller() throws IOException &#123; &#125; @RequestMapping("invoke1") public Object invoke1( @RequestParam("service") String service, @RequestParam("method") String method, @RequestParam("jarName") String jarName) throws Exception &#123; // 加载传入的jar包 File file = new File(new File("").getCanonicalPath() + File.separator + jarName + ".jar"); URL url = file.toURI().toURL(); Class aClass1 = loader.getClass(); Method add = URLClassLoader.class.getDeclaredMethod("addURL", URL.class); add.setAccessible(true); add.invoke(loader, url); // 设置线程上下文类加载器 Thread.currentThread().setContextClassLoader(loader); // 加载 ServiceBus 类 Class&lt;?&gt; serviceBusClazz = loader.loadClass("dcloud.common.InnerServiceBus.ServiceBus"); // 构造serviceBus对象 Object serviceBus = serviceBusClazz.newInstance(); Method init = serviceBusClazz.getMethod("init"); init.invoke(serviceBus); // 获取dubbo传来的对象 Method locateService = serviceBusClazz.getMethod("locateService", String.class); Object serviceObject = locateService.invoke(serviceBus, service); Class clazz = serviceObject.getClass(); // 打印所有的方法 Method[] methods = clazz.getMethods(); for(Method m : methods)&#123; System.out.println(m); &#125; // 执行一个无参测试方法 // 如果是有参需要注意： // 如使用自己定义的类，必须使用同一类加载器进行加载。 // 比如有个cn.isjinhao.User类，在getDeclaredMethod的时候需要 // 传入：loader.loadClass("cn.isjinhao,User"). Method methoda = clazz.getDeclaredMethod(method); Object invoke = methoda.invoke(serviceObject); System.out.println(invoke); // 释放资源 loader.close(); ClassLoaderUtil.releaseLoader(loader); return null; &#125; @RequestMapping("invoke2") public Object invoke2( @RequestParam("service") String service, @RequestParam("method") String method, @RequestParam("jarName") String jarName) throws Exception &#123; // 重新创建一个 类加载器 loader = new URLClassLoader(new URL[]&#123;&#125;); //加载 两个jar包 File file = new File(new File("").getCanonicalPath() + File.separator + jarName + ".jar"); URL url = file.toURI().toURL(); Method add = URLClassLoader.class.getDeclaredMethod("addURL", URL.class); add.setAccessible(true); add.invoke(loader, url); add.invoke(loader, innerServiceBus.toURI().toURL()); // 设置线程上下文类加载器 Thread.currentThread().setContextClassLoader(loader); // 加载 ServiceBus 类 Class&lt;?&gt; serviceBusClazz = loader.loadClass("dcloud.common.InnerServiceBus.ServiceBus"); // 构造serviceBus对象 Object serviceBus = serviceBusClazz.newInstance(); Method init = serviceBusClazz.getMethod("init"); init.invoke(serviceBus); // 获取dubbo传来的对象 Method locateService = serviceBusClazz.getMethod("locateService", String.class); Object serviceObject = locateService.invoke(serviceBus, service); Class clazz = serviceObject.getClass(); // 打印所有的方法 Method[] methods = clazz.getMethods(); for(Method m : methods)&#123; System.out.println(m); &#125; // 执行一个无参测试方法 Method methoda = clazz.getDeclaredMethod(method); Object invoke = methoda.invoke(serviceObject); System.out.println(invoke); return null; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kettle的基本使用]]></title>
    <url>%2F2019%2Fkettle%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最近实习被公司安排用kettle处理数据，所以写一篇记录一下kettle的基本使用方法。SQL1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586SELECT K.EQUIP_ID AS STATIONIDX, K.NAME AS STATIONNAME, STA_DAY, ISNULL( STANUM, 0 ), ISNULL( SPACENUM, 0 ), ISNULL( SIGNALNUM, 0 ), FNUM FROM ( SELECT A.STATIONIDX, B.STATIONNAME, &#123;3&#125; AS STA_DAY, SUM( CASE WHEN RESTRAIN_FLAG = 0 OR RESTRAIN_FLAG IS NULL THEN 1 ELSE 0 END ) AS NNUM, SUM( CASE WHEN RESTRAIN_FLAG = 0 OR RESTRAIN_FLAG IS NULL THEN 0 ELSE 1 END ) AS FNUM FROM MONITORSIGNAL.TBSIGNALBASIS_SX_&#123;&#123;2&#125;&#125; A /* 变量参数 + 循环*/ JOIN MONITORSIGNAL.TBSTATION_SX B ON A.STATIONIDX = B.STATIONIDX WHERE SIGNAL_TIME &gt;= &#123; 3 &#125; /* 占位参数 */ AND SIGNAL_TIME &lt; &#123; 4 &#125; GROUP BY A.STATIONIDX, B.STATIONNAME ) M LEFT JOIN ( SELECT st_id, count( * ) AS SPACENUM FROM ESDC_ODS.D5000_HISDB_OP_DEV_SX A JOIN MONITORSIGNAL.TBSTATION_SX B ON A.st_id = B.STATIONIDX WHERE OCCUR_TIME &gt;= &#123; 3 &#125; AND OCCUR_TIME &lt; &#123; 4 &#125; AND STATUS = 1 GROUP BY st_id ) N ON M.stationidx = N.st_id LEFT JOIN ( SELECT st_id, SUM( CASE WHEN STATUS = 19 THEN 1 ELSE 0 END ) AS STANUM, SUM( CASE WHEN STATUS = 7 THEN 1 ELSE 0 END ) AS SIGNALNUM FROM ESDC_ODS.D5000_HISDB_OP_YX_SX WHERE OCCUR_TIME &gt;= &#123; 3 &#125; AND OCCUR_TIME &lt; &#123; 4 &#125; AND (STATUS = 7 OR STATUS = 19) GROUP BY st_id ) O ON M.STATIONIDX = O.st_id JOIN ( SELECT DISTINCT EMS_EQUIP_ID, EQUIP_ID, NAME FROM SG_THEME.D5000_EMS_EQUIP_MAPPING I JOIN SG_THEME.SG_CON_SUBSTATION_B D ON I.EQUIP_ID = D.ID WHERE I.LX = 'SG_CON_SUBSTATION_B' ) K ON K.EMS_EQUIP_ID = M.STATIONIDX这个sql是真实业务场景下的一句SQL，emmm，比较长，但是很有代表性。下面就以这个sql解释知识点。基本知识union、连接、分组的字段必须在连接之时是按照升序排序的。按字符串处理之前必须是String类型，如果不是可以使用字段选择进行转换类型。记录集连接是两个表之间的连接，如果需要多个表做一个条件的连接使用multiway merge join。数字类型和字符串类型做连接时可能会出错，需要将转换数据类型后再做连接。JS脚本有些需要使用到处理的语句需要使用JS进行处理，比如上面的1CASE WHEN RESTRAIN_FLAG = 0 OR RESTRAIN_FLAG IS NULL THEN 1 ELSE 0 END ) AS NNUM从上一步获得的输入可以在JS中直接使用，但是一定要注意数据类型对不对，虽然JS是弱类型，但是最好还是在使用时处理一下，比如使用&#39;&#39;+XXX进行转字符串，在做其他操作。在脚本中用var定义的变量可以在下方的字段中被获取，获取之后就能作为输出字段输出。记住：JS脚本的执行过程是将上一步输入的每一行都使用执行一遍JS，然后将每次执行后的结果合并。占位参数如果某个表（设为A）输入的SQL语句需要使用使用其他表的数据，我们可以在其之前加上一个表（设为B），将B表的数据输入到A表中。此时需要使用到占位参数。B表：1234SELECT *,? as d3,? as d4 FROM MONITORSIGNAL.TBSIGNALBASIS_SX_2019_01 A WHERE SIGNAL_TIME &gt;= ?AND SIGNAL_TIME &lt; ? ORDER BY STATIONIDX;A表：1234567select lastexectime as STA_DAY, lastexectime + numtodsinterval(intervalvalue, 'minute') as D41, lastexectime as D32, lastexectime + numtodsinterval(intervalvalue, 'minute') as D42 from monitorsignal.tbdataetlconfig占位参数是按顺序匹配。两者的执行关系是：B表拿出每一行带入A表，A表依次执行，得到的所有数据在做合并拼接。变量参数占位参数的弊端是使用完就没了，上面所示的A表获得的四个字段在B表使用之后丢失，B表再传出的是其处理后的数据。所以如果我们需要跨几个操作使用就需要用到变量参数。变量的设置方式：上图所示实在自定义常量数据中定义了一个数据，JS处理之后设置为变量，实际上不使用JS处理也可以直接设置为变量。循环我们有时候需要做循环，比如再使用子表的时候，我们会对每个月的子表的分别就进行操作。这样就需要做一个循环，循环中只改变子表名。设置一个转换来获取变量，比如从表中查一列。并且放在结果中，这个结果个人理解就是一个缓冲区，别的转换能从这个结果中拿数据。在处理的时候再一行一行的拿数据。转换中需要设置一个阻塞，保证再使用到变量的时候此变量已被初始化。]]></content>
      <categories>
        <category>kettle</category>
      </categories>
      <tags>
        <tag>kettle</tag>
        <tag>etl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11-面试题]]></title>
    <url>%2F2019%2F11-%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[并发控制某个方法允许并发访问线程的个数12345678910111213141516171819202122232425262728public class SemaphoreTest &#123; static Semaphore semaphore = new Semaphore(5, true); public static void main(String[] args) &#123; for (int i = 0; i &lt; 100; i++) &#123; new Thread(new Runnable() &#123; public void run() &#123; test(); &#125; &#125;).start(); &#125; &#125; public static void test() &#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "进来了"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "走了"); semaphore.release(); &#125;&#125;三个线程a、b、c并发运行，c、b需要a线程的数据怎么实现考虑到多线程的不确定性，因此我们不能确保 ThreadA 就一定先于 ThreadB 和 ThreadC 前执行，就算 ThreadA先执行了，我们也无法保证 ThreadA 什么时候才能将变量 num 给初始化完成。因此我们必须让 ThreadB 和 ThreadC去等待 ThreadA 完成任何后发出的消息。现在需要解决两个问题，一是让 ThreadB 和 ThreadC 等待ThreadA 先执行完，二是 ThreadA 执行完之后给ThreadB 和 ThreadC 发送消息。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ThreadCommunication &#123; private static int num; private static Semaphore semaphore = new Semaphore(0); public static void main(String[] args) &#123; Thread threadA = new Thread(new Runnable() &#123; public void run() &#123; try &#123; //模拟耗时操作之后初始化变量 num Thread.sleep(1000); num = 1; //初始化完参数后释放两个 permit semaphore.release(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Thread threadB = new Thread(new Runnable() &#123; public void run() &#123; try &#123; //获取 permit，如果 semaphore 没有可用的 permit 则等待，如果有则消耗一个 semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "获取到 num 的值为：" + num); &#125; &#125;); Thread threadC = new Thread(new Runnable() &#123; public void run() &#123; try &#123; //获取 permit，如果 semaphore 没有可用的 permit 则等待，如果有则消耗一个 semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "获取到 num 的值为：" + num); &#125; &#125;); //同时开启 3 个线程 threadA.start(); threadB.start(); threadC.start(); &#125;&#125;同一个类中的2个方法都加了同步锁，多个线程能同时访问同一个类中的这两个方法吗？多个线程不可访问同一个类中的 2 个加了锁的方法。12345678910111213141516171819202122232425262728293031323334353637383940public class TestA &#123; private int count = 0; private Lock lock = new ReentrantLock();//设置 lock 锁 public Runnable run1 = new Runnable() &#123; public void run() &#123; lock.lock(); //加锁 while (count &lt; 1000) &#123; try &#123; //打印是否执行该方法 System.out.println(Thread.currentThread().getName() + " run1: " + count++); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; lock.unlock(); &#125; &#125;; //方法 2 public Runnable run2 = new Runnable() &#123; public void run() &#123; lock.lock(); while (count &lt; 1000) &#123; try &#123; System.out.println(Thread.currentThread().getName() + " run2: " + count++); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; lock.unlock(); &#125; &#125;; public static void main(String[] args) throws InterruptedException &#123; TestA t = new TestA(); //创建一个对象 new Thread(t.run1).start();//获取该对象的方法 1 new Thread(t.run2).start();//获取该对象的方法 2 &#125;&#125;死锁产生的必要条件互斥条件：线程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个线程所占有。此时若有其他线程请求该资源，则请求线程只能等待。不剥夺条件：线程所获得的资源在未使用完毕之前，不能被其他线程强行夺走，即只能由获得该资源的线程自己来释放（只能是主动释放)。请求和保持条件：线程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他线程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。循环等待条件：存在一种线程资源的循环等待链，链中每一个线程已获得的资源同时被链中下一个线程所请求。即存在一个处于等待状态的线程集合{Pl, P2, …, pn}，其中 Pi 等待的资源被 P(i+1)占有（i=0, 1, …, n-1)，Pn 等待的资源被 P0 占有。产生死锁的例子12345678910111213141516171819202122232425262728293031323334353637383940414243public class DeadLock implements Runnable &#123; public int flag = 1; private static Object o1 = new Object(), o2 = new Object(); public void run() &#123; System.out.println("flag = " + flag); if (flag == 1) &#123; synchronized (o1) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o2) &#123; System.out.println("1"); &#125; &#125; &#125; if (flag == 0) &#123; synchronized (o2) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o1) &#123; System.out.println("0"); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; DeadLock td1 = new DeadLock(); DeadLock td2 = new DeadLock(); td1.flag = 1; td2.flag = 0; //td1,td2 都处于可执行状态，但 JVM 线程调度先执行哪个线程是不确定的。 //td2 的 run()可能在 td1 的 run()之前运行 new Thread(td1).start(); new Thread(td2).start(); &#125;&#125;HashMapHashMap的实现原理你看过HashMap源码嘛，知道原理嘛针对这个问题，嗯，当然是必须看过HashMap源码。至于原理：数组+链表+红黑树。HashMap采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体。为什么用数组+链表数组是用来确定桶的位置，利用元素的key的hash值对数组长度取模得到。链表是用来解决hash冲突问题，当出现hash值一样的情形，就在数组上的对应位置形成一条链表。hash冲突你还知道哪些解决办法比较出名的有四种：开放定址法、链地址法、再哈希法、公共溢出区域法我用LinkedList代替数组结构可以么这里我稍微说明一下，此题的意思是，源码中是这样的1Entry[] table = new Entry[capacity];那我用下面这样表示：1List&lt;Entry&gt; table = new LinkedList&lt;Entry&gt;();是否可行？答案很明显，必须是可以的。既然是可以的，为什么HashMap不用LinkedList，而选用数组？因为用数组效率最高！在HashMap中，定位桶的位置是利用元素的key的哈希值对数组长度取模得到。此时，我们已得到桶的位置。显然数组的查找效率比LinkedList大。那ArrayList，底层也是数组，查找也快啊，为啥不用ArrayList？因为采用基本数组结构，扩容机制可以自己定义，HashMap中数组扩容刚好是2的次幂，在做取模运算的效率高。而ArrayList的扩容机制是1.5倍扩容，那ArrayList为什么是1.5倍扩容这就不在本文说明了。HashMap在什么条件下扩容HashMap在什么条件下扩容如果bucket满了（超过load factor*current capacity），就要resize。默认load factor为0.75，为了最大程度避免哈希冲突。（current capacity为当前数组大小。为什么扩容是2的次幂减少碰撞HashMap为了存取高效，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法；这个算法实际就是取模，hash%length。但是，大家都知道这种运算不如位移运算快。因此，源码中做了优化hash &amp; (length-1)。也就是说hash%length==hash&amp;(length-1)。那为什么是2的n次方呢？因为2的n次方实际就是1后面n个0，2的n次方-1，实际就是n个1。如果length不为2的幂，比如15。那么length-1的2进制就会变成1110。在h为随机数的情况下，和1110做&amp;操作。尾数永远为0。那么0001、1001、1101等尾数为1的位置就永远不可能被entry占用。这样会造成浪费，不随机等问题。 length-1 二进制中为1的位数越多，那么分布就平均。扩容时减少消耗以下图为例，其中图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，n代表length。元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：resize过程中不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap“。hash方法为什么为什么要先高16位异或低16位再取模运算1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;hashmap这么做，只是为了降低hash冲突的几率。打个比方，当我们的length为16的时候，哈希码(字符串“abcabcabcabcabc”的key对应的哈希码)对(16-1)与操作，对于多个key生成的hashCode，只要哈希码的后4位为0，不论不论高位怎么变化，最终的结果均为0。而加上高16位异或低16位的“扰动函数”后，结果如下：可以看到: 扰动函数优化前：1954974080 % 16 = 1954974080 &amp; (16 - 1) = 0 扰动函数优化后：1955003654 % 16 = 1955003654 &amp; (16 - 1) = 6 很显然，减少了碰撞的几率。讲讲hashmap的get/put的过程知道hashmap中put元素的过程是什么样么对key的hashCode()做hash运算，计算index如果没碰撞直接放到bucket里；如果碰撞了，以链表的形式存在buckets后；如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树如果节点已经存在就替换old value(保证key的唯一性)如果bucket满了(超过load factor*current capacity)，就要resize。知道hashmap中get元素的过程是什么样么对key的hashCode()做hash运算，计算index;如果在bucket里的第一个节点里直接命中，则直接返回；如果有冲突，则通过key.equals(k)去查找对应的Entry;若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。你还知道哪些hash算法先说一下hash算法干嘛的，Hash函数是指把一个大范围映射到一个小范围。把大范围映射到一个小范围的目的往往是为了节省空间，使得数据容易保存。比较出名的有MurmurHash、MD4、MD5等等。说说String中hashcode的实现123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125;就是以31为权，每一位为字符的ASCII值进行运算。哈希计算公式可以计为s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]那为什么以31为质数呢？主要是因为31是一个奇质数，所以31*i=32*i-i=(i&lt;&lt;5)-i，这种位移与减法结合的计算相比一般的运算快很多。为什么hashmap的在链表元素数量超过8时改为红黑树知道jdk1.8中hashmap改了啥么由数组+链表的结构改为数组+链表+红黑树。优化了高位运算的hash算法：h ^ (h&gt;&gt;&gt;16)扩容后，元素要么是在原位置，要么是在原位置再移动2次幂的位置，且链表顺序不变。为什么在解决hash冲突的时候，不直接用红黑树?而选择先用链表，再转红黑树因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡，而单链表不需要。当元素小于8个当时候，此时做查询操作，链表结构已经能保证查询性能。当元素大于8个的时候，此时需要红黑树来加快查询速度，但是新增节点的效率变慢了。因此，如果一开始就用红黑树结构，元素太少，新增效率又比较慢，无疑这是浪费性能的。我不用红黑树，用二叉查找树可以么可以。但是二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。当链表转为红黑树后，什么时候退化为链表为6的时候退转为链表。中间有个差值7可以防止链表和树之间频繁的转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。你一般用什么作为HashMap的key健可以为Null值么必须可以，key为null的时候，hash算法最后的值以0来计算，也就是放在数组的第一个位置。1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;你一般用什么作为HashMap的key一般用Integer、String这种不可变类当HashMap当key，而且String最为常用。因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。因为获取对象的时候要用到equals()和hashCode()方法，那么键对象正确的重写这两个方法是非常重要的,这些类已经很规范的覆写了hashCode()以及equals()方法。我用可变类当HashMap的key有什么问题hashcode可能发生改变，导致put进去的值，无法get出，如下所示：如果让你实现一个自定义的class作为HashMap的key该如何实现针对问题一，记住下面四个原则即可两个对象相等，hashcode一定相等两个对象不等，hashcode不一定不等hashcode相等，两个对象不一定相等hashcode不等，两个对象一定不等针对问题二，记住如何写一个不可变类类添加final修饰符，保证类不被继承。如果类可以被继承会破坏类的不可变性机制，只要继承类覆盖父类的方法并且继承类可以改变成员变量值，那么一旦子类以父类的形式出现时，不能保证当前类是否可变。保证所有成员变量必须私有，并且加上final修饰。通过这种方式保证成员变量不可改变。但只做到这一步还不够，因为如果是对象成员变量有可能再外部改变其值。所以第4点弥补这个不足。不提供改变成员变量的方法，包括setter避免通过其他接口改变成员变量的值，破坏不可变特性。通过构造器初始化所有成员，进行深拷贝(deep copy)，如果构造器传入的对象直接赋值给成员变量，还是可以通过对传入对象的修改进而导致改变内部变量的值。例如：123456public final class ImmutableDemo &#123; private final int[] myArray; public ImmutableDemo(int[] array) &#123; this.myArray = array; // wrong &#125; &#125;这种方式不能保证不可变性，myArray和array指向同一块内存地址，用户可以在ImmutableDemo之外通过修改array对象的值来改变myArray内部的值。为了保证内部的值不被修改，可以采用深度copy来创建一个新内存保存传入的值。正确做法：123456public final class MyImmutableDemo &#123; private final int[] myArray; public MyImmutableDemo(int[] array) &#123; this.myArray = array.clone(); &#125; &#125;在getter方法中，不要直接返回对象本身，而是克隆对象，并返回对象的拷贝，这种做法也是防止对象外泄，防止通过getter获得内部可变成员对象后对成员变量直接操作，导致成员变量发生改变。类加载过程Class 文件需要加载到虚拟机中之后才能运行和使用，那么虚拟机是如何加载这些 Class 文件呢？系统加载 Class 类型的文件主要三步:加载-&gt;连接-&gt;初始化。连接过程又可分为三步:验证-&gt;准备-&gt;解析。加载类加载过程的第一步，主要完成下面3件事情：通过全类名获取定义此类的二进制字节流将字节流所代表的静态存储结构转换为方法区的运行时数据结构在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口虚拟机规范多上面这3点并不具体，因此是非常灵活的。比如：”通过全类名获取定义此类的二进制字节流” 并没有指明具体从哪里获取、怎样获取。比如：比较常见的就是从 ZIP 包中读取（日后出现的JAR、EAR、WAR格式的基础）、其他文件生成（典型应用就是JSP）等等。一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。连接验证准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意：这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在 Java 堆中。这里所设置的初始值”通常情况”下是数据类型默认的零值（如0、0L、null、false等），比如我们定义了public static int value = 111 ，那么 value 变量在准备阶段的初始值就是 0 而不是111（初始化阶段才会复制）。特殊情况：比如给 value 变量加上了 fianl 关键字public static final int value = 111 ，那么准备阶段 value 的值就被复制为 111。解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方发表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。初始化初始化是类加载的最后一步，也是真正执行类中定义的 Java 程序代码(字节码)，初始化阶段是执行类构造器 &lt;clinit&gt; ()方法的过程。（是类构造器，不是对象构造器）对于&lt;clinit&gt;() 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 &lt;clinit&gt;() 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起死锁，并且这种死锁很难被发现。对于初始化阶段，虚拟机严格规范了有且只有5中情况下，必须对类进行初始化：当遇到 new 、 getstatic、putstatic或invokestatic 这4条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。使用 java.lang.reflect 包的方法对类进行反射调用时 ，如果类没初始化，需要触发其初始化。初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。当使用 JDK1.7 的动态语言时，如果一个 MethodHandle 实例的最后解析结构为 REF_getStatic、REF_putStatic、REF_invokeStatic、的方法句柄，并且这个句柄没有初始化，则需要先触发器初始化。Java的引用无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）引用分类强引用Java中默认声明的就是强引用，比如：12Object obj = new Object(); //只要obj还指向Object对象，Object对象就不会被回收obj = null; //手动置null只要强引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足时，JVM也会直接抛出OutOfMemoryError，不会去回收。如果想中断强引用与对象之间的联系，可以显示的将强引用赋值为null，这样一来，JVM就可以适时的回收对象了。软引用软引用是用来描述一些非必需但仍有用的对象。在内存足够的时候，软引用对象不会被回收，只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常。这种特性常常被用来实现缓存技术，比如网页缓存，图片缓存等。在 JDK1.2 之后，用java.lang.ref.SoftReference类来表示软引用。下面以一个例子来进一步说明强引用和软引用的区别：在运行下面的Java代码之前，需要先配置参数 -Xms2M -Xmx3M，将 JVM 的初始内存设为2M，最大可用内存为 3M。首先先来测试一下强引用，在限制了 JVM 内存的前提下，下面的代码运行正常：12345678910public class TestOOM &#123; public static void main(String[] args) &#123; testStrongReference(); &#125; private static void testStrongReference() &#123; // 当 new byte为 1M 时，程序运行正常 // 当 new byte为 1M 时，程序报异常 OutOfMemoryError byte[] buff = new byte[1024 * 1024 * 3]; &#125;&#125;接着来看一下软引用会有什么不一样，在下面的示例中连续创建了 10 个大小为 1M 的字节数组，并赋值给了软引用，然后循环遍历将这些对象打印出来。123456789101112131415161718192021222324252627282930313233343536public class TestOOM &#123; private static List&lt;Object&gt; list = new ArrayList&lt;&gt;(); public static void main(String[] args) &#123; testSoftReference(); &#125; private static void testSoftReference() &#123; for (int i = 0; i &lt; 10; i++) &#123; SoftReference&lt;byte[]&gt; sr = new SoftReference&lt;&gt;(new byte[1024 * 1024]); list.add(sr); &#125; byte[] buff = null; System.gc(); //主动通知垃圾回收 for(int i=0; i &lt; list.size(); i++)&#123; Object obj = ((SoftReference) list.get(i)).get(); System.out.println(obj); &#125; &#125;&#125;/* null null null null null null null null null [B@12a3a380*/我们发现无论循环创建多少个软引用对象，打印结果总是只有最后一个对象被保留，其他的obj全都被置空回收了。这里就说明了在内存不足的情况下，软引用将会被自动回收。弱引用弱引用的引用强度比软引用要更弱一些，无论内存是否足够，只要 JVM 开始进行垃圾回收，那些被弱引用关联的对象都会被回收。1234567891011121314151617181920212223242526private static void testWeakReference() &#123; for (int i = 0; i &lt; 10; i++) &#123; byte[] buff = new byte[1024 * 1024]; WeakReference&lt;byte[]&gt; sr = new WeakReference&lt;&gt;(buff); list.add(sr); &#125; System.gc(); //主动通知垃圾回收 for(int i=0; i &lt; list.size(); i++)&#123; Object obj = ((WeakReference) list.get(i)).get(); System.out.println(obj); &#125;&#125;/* null null null null null null null null null null*/可以发现所有被弱引用关联的对象都被垃圾回收了。虚引用“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。判断一个常量是废弃常量运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？假如在常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。判断一个类是无用的类方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 “无用的类” ：该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。加载该类的 ClassLoader 已经被回收。该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。垃圾回收什么是垃圾回收垃圾回收（Garbage Collection，GC），顾名思义就是释放垃圾占用的空间，防止内存泄露。有效的使用可以使用的内存，对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收。Java 语言出来之前，大家都在拼命的写 C 或者 C++ 的程序，而此时存在一个很大的矛盾，C++ 等语言创建对象要不断的去开辟空间，不用的时候又需要不断的去释放控件，既要写构造函数，又要写析构函数，很多时候都在重复的 allocated，然后不停的析构。于是，有人就提出，能不能写一段程序实现这块功能，每次创建，释放控件的时候复用这段代码，而无需重复的书写呢？1960年，基于 MIT 的 Lisp 首先提出了垃圾回收的概念，而这时 Java 还没有出世呢！所以实际上 GC 并不是Java的专利，GC 的历史远远大于 Java 的历史！怎么定义垃圾既然我们要做垃圾回收，首先我们得搞清楚垃圾的定义是什么，哪些内存是需要回收的。引用计数算法引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。1String m = new String(&quot;jack&quot;);先创建一个字符串，这时候”jack”有一个引用，就是 m。然后将 m 设置为 null，这时候”jack”的引用次数就等于0了，在引用计数算法中，意味着这块内容就需要被回收了。1m = null;引用计数算法是将垃圾回收分摊到整个应用程序的运行当中了，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的”Stop-The-World”的垃圾收集机制。看似很美好，但我们知道JVM的垃圾回收就是”Stop-The-World”的，那是什么原因导致我们最终放弃了引用计数算法呢？看下面的例子。12345678910111213141516public class ReferenceCountingGC &#123; public Object instance; public ReferenceCountingGC(String name)&#123;&#125;&#125;public static void testGC()&#123; ReferenceCountingGC a = new ReferenceCountingGC("objA"); ReferenceCountingGC b = new ReferenceCountingGC("objB"); a.instance = b; b.instance = a; a = null; b = null;&#125;定义2个对象相互引用置空各自的声明引用我们可以看到，最后这2个对象已经不可能再被访问了，但由于他们相互引用着对方，导致它们的引用计数永远都不会为0，通过引用计数算法，也就永远无法通知GC收集器回收它们。可达性分析算法可达性分析算法（Reachability Analysis）的基本思路是，通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时（即从 GC Roots 节点到该节点不可达），则证明该对象是不可用的。通过可达性算法，成功解决了引用计数所无法解决的问题“循环依赖”，只要你无法与 GC Root 建立直接或间接的连接，系统就会判定你为可回收对象。那这样就引申出了另一个问题，哪些属于 GC Root。Java 内存区域在 Java 语言中，可作为 GC Root 的对象包括以下4种：虚拟机栈（栈帧中的本地变量表）中引用的对象方法区中类静态属性引用的对象方法区中常量引用的对象本地方法栈中 JNI（即一般说的 Native 方法）引用的对象虚拟机栈（栈帧中的本地变量表）中的引用此时的 s，即为 GC Root，当s置空时，localParameter 对象也断掉了与 GC Root 的引用链，将被回收。12345678public class StackLocalParameter &#123; public StackLocalParameter(String name)&#123;&#125;&#125;public static void testGC()&#123; StackLocalParameter s = new StackLocalParameter("localParameter"); s = null;&#125;方法区中类静态属性的引用s 为 GC Root，s 置为 null，经过 GC 后，s 所指向的 properties 对象由于无法与 GC Root 建立关系被回收。而 m 作为类的静态属性，也属于 GC Root，parameter 对象依然与 GC root 建立着连接，所以此时 parameter 对象并不会被回收。12345678910public class MethodAreaStaicProperties &#123; public static MethodAreaStaicProperties m; public MethodAreaStaicProperties(String name)&#123;&#125;&#125;public static void testGC()&#123; MethodAreaStaicProperties s = new MethodAreaStaicProperties("properties"); s.m = new MethodAreaStaicProperties("parameter"); s = null;&#125;方法区中常量的引用m 即为方法区中的常量引用，也为 GC Root，s 置为 null 后，final 对象也不会因没有与 GC Root 建立联系而被回收。123456789public class MethodAreaStaicProperties &#123; public static final MethodAreaStaicProperties m = MethodAreaStaicProperties("final"); public MethodAreaStaicProperties(String name)&#123;&#125;&#125;public static void testGC()&#123; MethodAreaStaicProperties s = new MethodAreaStaicProperties("staticProperties"); s = null;&#125;本地方法栈中的引用任何 Native 接口都会使用某种本地方法栈，实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法。怎么回收垃圾在确定了哪些垃圾可以被回收后，垃圾收集器要做的事情就是开始进行垃圾回收，但是这里面涉及到一个问题是：如何高效地进行垃圾回收。由于Java虚拟机规范并没有对如何实现垃圾收集器做出明确的规定，因此各个厂商的虚拟机可以采用不同的方式来实现垃圾收集器，这里我们讨论几种常见的垃圾收集算法的核心思想。标记清除算法标记清除算法（Mark-Sweep）是最基础的一种垃圾回收算法，它分为2部分，先把内存区域中的这些对象进行标记，哪些属于可回收标记出来，然后把这些垃圾拎出来清理掉。就像上图一样，清理掉的垃圾就变成未使用的内存区域，等待被再次使用。这逻辑再清晰不过了，并且也很好操作，但它存在一个很大的问题，那就是内存碎片。上图中等方块的假设是 2M，小一些的是 1M，大一些的是 4M。等我们回收完，内存就会切成了很多段。我们知道开辟内存空间时，需要的是连续的内存区域，这时候我们需要一个 2M的内存区域，其中有2个 1M 是没法用的。这样就导致，其实我们本身还有这么多的内存的，但却用不了。复制算法复制算法（Copying）是在标记清除算法上演化而来，解决标记清除算法的内存碎片问题。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。保证了内存的连续可用，内存分配时也就不用考虑内存碎片等复杂情况，逻辑清晰，运行高效。上面的图很清楚，也很明显的暴露了另一个问题，合着我这140平的大三房，只能当70平米的小两房来使？代价实在太高。标记整理算法标记整理算法（Mark-Compact）标记过程仍然与标记清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，再清理掉端边界以外的内存区域。标记整理算法一方面在标记-清除算法上做了升级，解决了内存碎片的问题，也规避了复制算法只能利用一半内存区域的弊端。看起来很美好，但从上图可以看到，它对内存变动更频繁，需要整理所有存活对象的引用地址，在效率上比复制算法要差很多。分代收集算法分代收集算法（Generational Collection）严格来说并不是一种思想或理论，而是融合上述3种基础的算法思想，而产生的针对不同情况所采用不同算法的一套组合拳。对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记-清理或者标记整理算法来进行回收。so，另一个问题来了，那内存区域到底被分为哪几块，每一块又有什么特别适合什么算法呢？内存模型与回收策略Java 堆（Java Heap）是JVM所管理的内存中最大的一块，堆又是垃圾收集器管理的主要区域，这里我们主要分析一下 Java 堆的结构。Java 堆主要分为2个区域：年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2个区。可能这时候大家会有疑问，为什么需要 Survivor 区，为什么Survivor 还要分2个区。不着急，我们从头到尾，看看对象到底是怎么来的，而它又是怎么没的。Eden 区IBM 公司的专业研究表明，有将近98%的对象是朝生夕死，所以针对这一现状，大多数情况下，对象会在新生代 Eden 区中进行分配，当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快。通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（若 From 区不够，则直接进入 Old 区）。Survivor 区Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，类似于我们交通灯中的黄灯。Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）。为啥需要？不就是新生代到老年代么，直接 Eden 到 Old 不好了吗，为啥要这么复杂。想想如果没有 Survivor 区，Eden 区每进行一次 Minor GC，存活的对象就会被送到老年代，老年代很快就会被填满。而有很多对象虽然一次 Minor GC 没有消灭，但其实也并不会蹦跶多久，或许第二次，第三次就需要被清除。这时候移入老年区，很明显不是一个明智的决定。所以，Survivor 的存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 的预筛选保证，只有经历16次 Minor GC 还能在新生代中存活的对象，才会被送到老年代。为啥需要俩？设置两个 Survivor 区最大的好处就是解决内存碎片化。我们先假设一下，Survivor 如果只有一个区域会怎样。Minor GC 执行后，Eden 区被清空了，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。问题来了，这时候我们怎么清除它们？在这种场景下，我们只能标记清除，而我们知道标记清除最大的问题就是内存碎片，在新生代这种经常会消亡的区域，采用标记清除必然会让内存产生严重的碎片化。因为 Survivor 有2个区域，所以每次 Minor GC，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，From 与 To 职责兑换，这时候会将 Eden 区和 To 区中的存活对象再复制到 From 区域，以此反复。这种机制最大的好处就是，整个过程中，永远有一个 Survivor space 是空的，另一个非空的 Survivor space 是无碎片的。那么，Survivor 为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果 Survivor 区再细分下去，每一块的空间就会比较小，容易导致 Survivor 区满，两块 Survivor 区可能是经过权衡之后的最佳方案。Old 区老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发“Stop-The-World”。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。由于复制算法在对象存活率较高的老年代会进行很多次的复制操作，效率很低，所以老年代这里采用的是标记——整理算法。除了上述所说，在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代。大对象：大对象指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及2个 Survivor 区之间发生大量的内存复制。当你的系统有非常多“朝生夕死”的大对象时，得注意了。长期存活对象：虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中每经历一次 Minor GC，年龄就增加1岁。当年龄增加到15岁时，这时候就会被转移到老年代。当然，这里的15，JVM 也支持进行特殊设置。动态对象年龄：虚拟机并不重视要求对象年龄必须到15岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的总合大于 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你“成年”。这其实有点类似于负载均衡，轮询是负载均衡的一种，保证每台机器都分得同样的请求。看似很均衡，但每台机的硬件不通，健康状况不同，我们还可以基于每台机接受的请求数，或每台机的响应时间等，来调整我们的负载均衡算法。空间分配担保在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于就尝试进程一次Minor GC（尽管此次GC是有风险的），如果小于或者不允许冒险，需要进行一次Full GC。GC分类老年代：major gc。新生代：minor gc。全清理：full gc。major gc+minor gc = full gc，如果是新生代不够了，会触发minor gc，如果minor gc将一部分移到老年代，老年代不够会触发major gc，所以一般major gc会伴随minor gc，进而形成full gc。但是像大对象直接进入major gc不会伴随minor gc。Java内存模型JVMJVM则是JRE中的核心组成部分，承担分析和执行Java字节码的工作。在Java历史上有很多发行的Java虚拟机，但目前一般都是HotSpot。查看本机JVM：java -version运行时数据区Java虚拟机在执行Java程序的时候会把它所管理的内存区域划分为若干个不同的数据区域。根据JVM规范，JVM 内存共分为虚拟机栈、堆、方法区、程序计数器、本地方法栈五个部分。运行时数据区划分线程私有程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完。另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。从上面的介绍中我们知道程序计数器主要有两个作用：字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。注意：程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。Java虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。Java 内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack)，其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。（实际上，Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息）局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向一条字节码指令的地址）。Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。StackOverFlowError： 若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。Java 虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。扩展：那么方法/函数如何调用？Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入Java栈，每一个函数调用结束后，都会有一个栈帧被弹出。Java方法有两种返回方式：return 语句。抛出异常。不管哪种返回方式都会导致栈帧被弹出。本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。线程共享Java堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。Java 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代。再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。上图所示的eden区、s0区、s1区都属于新生代，tentired区属于老年代。大部分情况，对象都会首先在Eden区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入s0或者s1，并且对象的年龄还会加 1（Eden区-&gt;Survivor 区后对象的初始年龄变为1），当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。运行时常量池运行时常量池在JDK8及以后存放在堆中。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）字面量就是指这个量本身，比如字面量3。也就是指3。再比如 string类型的字面量”ABC”, 这个”ABC” 通过字来描述。 可以理解成一眼就能知道的量。既然运行时常量池时方法区的一部分，自然受到堆内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。方法区存放在元空间中。元空间使用的是直接内存。我们可以使用参数： -XX:MetaspaceSize 来指定元数据区的大小。如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。类的各个部分分别在哪个位置字节码：方法区方法：方法区字节码对象：堆普通对象：大部分存在于堆。更多参考：https://blog.csdn.net/rickiyeat/article/details/76802085对象的属性：大部分存在于堆static属性：方法区方法中的局部变量：Java虚拟机栈String对象：堆或常量池对象的创建类加载检查： 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。分配内存： 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。内存分配的两种方式选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。指针碰撞：假设JAVA堆中的内存时绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式成为“指针碰撞”。空闲链表：如果JAVA堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式成为“空闲列表”。初始化零值： 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。设置对象头： 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。执行 init 方法： 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。内存分配并发问题在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，否则比如当虚拟机正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存就会引发严重的问题。通常来讲，虚拟机采用两种方式来保证线程安全：CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。TLAB： 为每一个线程预先在Eden区分配一块儿内存，称为本地线程分配缓存（Thread Local Allocation Buffer，TLAB），JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配。对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为3块区域：对象头、实例数据和对齐填充。Hotspot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的自身运行时数据（哈希码、GC分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为Hotspot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。对象的访问定位建立对象就是为了使用对象，我们的Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式有虚拟机实现而定，目前主流的访问方式有使用句柄和直接指针两种：句柄： 如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；直接指针：如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。初始化问题解析规则：静态先于普通父类先于子类创建对象必须先初始化类（初始化属性）获得子类对象必须先获得一份父类对象默认的加载方式和Class.forName执行：加载、链接、初始化。classloader.load仅执行加载。static在初始化的时候被执行（初始化的时候执行类构造器，即运行字节码）1234567891011121314151617181920212223242526272829303132333435363738public class Test &#123; Person person = new Person("Test"); static &#123; System.out.println("test static"); &#125; public Test() &#123; System.out.println("test constructor"); &#125; public static void main(String[] args) &#123; new MyClass(); &#125;&#125;class Person&#123; static &#123; System.out.println("person static"); &#125; public Person(String str) &#123; System.out.println("person " + str); &#125;&#125;class MyClass extends Test &#123; Person person = new Person("MyClass"); static &#123; System.out.println("myclass static"); &#125; public MyClass() &#123; System.out.println("myclass constructor"); &#125;&#125;/* test static myclass static person static person Test test constructor person MyClass myclass constructor*/加载MyClass，发现Test没被加载，先去加载Test，因此会执行Test类中的static块加载完Test，加载MyClass，因此执行MyClass中的static块初始化MyClass，先去初始化Test初始化Test，需要先加载Person类，因此执行Person的static块构造Person对象时执行构造方法构造Test对象时执行构造方法构造MyClass对象时初始化一个Person对象执行MyClass构造方法]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10-项目准备]]></title>
    <url>%2F2019%2F10-%E9%A1%B9%E7%9B%AE%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[人脸识别签到系统功能教师、社团等发布签到，学生等参与签到。分为两个端，发布方和参与方。人脸识别可以使用照片替代，所有识别成功的图片会被保存下来，可供发布方下载查看。数据库设计人脸识别流程浏览器每一秒提交N次图片到服务器，服务器收到请求后将图片保存在硬盘上，然后将图片的名称、活动号、是否启用组的标志态和用户集合发送到消息队列。监听消息队列的函数每秒接收10个请求。先将图片中的人脸切割出来，切割出来之后扩容。遍历人脸集合，提交到Face++认证，Face++返回最像的人脸，返回后检测置信度和阈值是不是符合系统要求。如果不符合，开启下一轮检测。如果符合，检查是否在用户集合中。如果不在，开启下一轮检测。如果在，将签到信息存储在数据库中。将原始图片复制一份，在相应位置打上标记，修改文件名。删除切割之后的图片。删除上传的图片航班管理系统功能管理员录入信息。用户查询信息。]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09-数据结构和编程能力]]></title>
    <url>%2F2019%2F09-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%BC%96%E7%A8%8B%E8%83%BD%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[红黑树二叉搜索树由于红黑树本质上就是一棵二叉查找树，所以在了解红黑树之前，咱们先来看下二叉查找树。二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树：若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；任意结点的左、右子树也分别为二叉查找树。没有键值相等的结点（no duplicate nodes）。因为，一棵由n个结点，随机构造的二叉查找树的高度为lgn，一般操作的执行时间为O（lgn）。但二叉树若退化成了一棵具有n个结点的线性链后，则此些操作最坏情况运行时间为O（n）。性质红黑树是一颗平衡二叉树，平衡二叉树的概念：每课树的左右子树高度差都不超过1。每个结点都有颜色，红色或者黑色根结点是黑色的每个叶结点是黑色的（设叶结点是NIL，但它不是一个空节点，是一个哨兵）如果一个结点是红色的，则它的两个子结点都是黑色的对每个结点，从该结点到其所有后代结点的简单路径上，均包含相同数目的黑色结点图中的NIL其实可以用一个哨兵（T.nil）替代，但在画图时往往其实不画NIL结点。### 旋转对红黑树的增加和删除会破坏红黑树原本的性质，旋转是用来使其恢复到红黑树的手段。#### 左旋1234567891011121314// LEFT-ROTATE(T, x) 设x是图中的pivoty = x.rightx.right = y.leftif y.left != T.nil y.left.p = xy.p = x.pif x.p == T.nil T.root = yelse if x == x.p.left // 判断应该放在P的左子树还是右子树上 x.p.left = yelse x.p.right = yy.left = xx.p = y#### 右旋1234567891011121314// RIGHT-ROTATE(T, x) 设x是图中的pivoty = x.leftx.left = y.rightif y.right != T.nil y.right.p = xy.p = x.pif x.p == T.nil T.root = yelse if x == x.p.right // 判断应该放在P的左子树还是右子树上 x.p.right = yelse x.p.lrft = yy.right = xx.p = y### 二叉查找树的插入如果要在二叉查找树中插入一个结点，首先要查找到结点插入的位置，然后进行插入，假设插入的结点为z的话，插入的伪代码如下：12345678910111213141516// TREE-INSERT(T, z)y = T.nilx = T.rootwhile x != NIL y = x if z.key &lt; x.key x = x.left else x = x.rightz.p = yif y == NIL T.root = z // Tree T was emptyelse if z.key &lt; y.key y.left = zelse y.right = z### 红黑树的插入如果我们插入的是黑色节点，会违反了性质五，需要进行大规模调整，如果我们插入的是红色节点，那就只有在要插入节点的父节点也是红色的时候违反性质四或者是当插入的节点是根节点时，违反性质二，所以，我们把要插入的节点的颜色变成红色。仍然设被插入结点是z：1234567891011121314151617181920// RB-INSERT(T, z)y = T.nilx = T.rootwhile x != T.nil y = x if z.key &lt; x.key x = x.left else x = x.rightz.p = yif y == T.nil T.root = zelse if z.key &lt; y.key y.left = zelse y.right = zz.left = T.nilz.right = T.nilz.color = REDRB-INSERT-FIXUP(T, z)我们把上面这段红黑树的插入代码，跟我们之前看到的二叉查找树的插入代码，可以看出，RB-INSERT(T, z)前面的16行代码基本就是二叉查找树的插入代码，然后第17-18行代码把z的左孩子、右孩子都赋为叶结点nil，第19行再把z结点着为红色，最后为保证红黑性质在插入操作后依然保持，调用一个辅助程序RB-INSERT-FIXUP来对结点进行重新着色，并旋转。 换言之：- 如果插入的是根结点，因为原树是空树，此情况只会违反性质2，所以直接把此结点涂为黑色。- 如果插入的结点的父结点是黑色，由于此不会违反性质2和性质4，红黑树没有被破坏，所以此时也是什么也不做。但当遇到下述3种情况时需要修复：- 插入修复情况1：如果当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色- 插入修复情况2：当前结点的父结点是红色，叔叔结点是黑色，当前结点是其父结点的右子- 插入修复情况3：当前结点的父结点是红色，叔叔结点是黑色，当前结点是其父结点的左子#### 修复1234567891011121314151617181920212223242526RB-INSERT-FIXUP(T, z)while z.p.color == RED if z.p == z.p.p.left y = z.p.p.right // 指向叔叔结点 if y.color == RED z.p.color = BLACK y.color = BLACK z.p.p.color = RED else if z == z.p.right z = z.p LEFT-ROTATE(T, z) z.p.color = BLACK z.p.p.color = RED RIGHT-ROTATE(T, z.p.p) else // 与 if 对称，等下只分析if，不分析else y = z.p.p.left if y.color == RED z.p.color = BLACK z.p.p.color = RED else if z == z.p.left z = z.p RIGHT-ROTATE(T, z) z.p.color = BLACK z.p.p.color = RED LEFT-ROTATE(T, z.p.p)T.root.color = BLACK下面，咱们来分别处理上述3种插入修复情况。插入修复情况1：当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色。上诉代码中第5行至第8行是处理这种情况：将父结点和叔叔结点涂黑，将爷爷结点涂红。插入修复情况2：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的右子上诉代码中第9行至第11行是处理这种情况：当前结点的父结点做为新的当前结点，以新当前结点为支点左旋。插入修复情况3：当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子上述代码中的12-14行处理此种情况：父结点变为黑色，祖父结点变为红色，在祖父结点为支点右旋。### 二叉查找树的后继12345678// TREE-SUCCESSOR(x)if x.right != T.nil return TREE-MINIMUM(x.right)y = x.pwhile y != T.nil and x == y.right x = y y = y.preturn y$x$是待查找结点，右子树不为空，右子树的最小值所在的节点是后继。解释第4-8行代码需要证明一个定理：&gt; 对于一棵二叉搜索树T，其关键字各不相同，如果T中一个节点$x$的右子树为空，且$x$有一个后继$y$，那么$y$一定是$x$的最底层祖先，并且其左孩子也是$x$的祖先。（每个结点都是其自身的祖先）#### 证明对于给定结点$x$，若其后继$y$存在，则$y &gt; x$。1. 考虑结点$x$，对于$x$的左子树，显然其中任意结点值都小于$x$，所以$y$必定不在其左子树中。2. $x$的右子树，其中任意结点值都大于$x$,但是根据题设，其右子树为空。所以，$y$必定为$x$的祖先或其祖先的右子树。又因为$y$是其中大于$x$且最小的一个，则$y$不可能是其祖先的右子树，那么我们可以将范围缩小至$y$必定为$x$的某一祖先，又根据$y&gt;x$，则$x$必定在$y$的左子树中，即$y$的左孩子也是$x$的祖先（$x$也是$x$的祖先）对于所有满足条件的，假设有$p_0,p_1 \dots p_n$共$n+1$个，且$p_0 &lt; p_1 &lt; p_2 &lt; \dots &lt; p_n$。显然，$x$的前驱结点$y$必定是其中的最小一个，即$y=p_0$。又因为$y$是$x$的祖先，则$y$必然是$x$的最底层祖先。#### 结论这个定理实际的意义是，对于二叉搜索树中的一个节点（$x$），如果其不存在右子树且还有后继（$y$），则$y$是$x$祖先节点中有左子树的最底层祖先。如下图中13的后继是15。### 二叉查找树的前驱前驱的代码和后继对应。12345678TREE-PREDECESSOR(x)if x.left != null return TREE-MAXNUM(x.left);y = x.pwhile y != null and x == y.left x = y y = y.preturn y3-7行代码的意思是，对于二叉搜索树中的一个节点（$x$），如果其不存在左子树且还有前驱（$y$），则$y$是$x$祖先节点中有右子树的最底层祖先。如图中17的前驱是15。### 二叉查找树的删除讨论删除之前需要证明一个定理：&gt; 如果一个二叉搜索树中的一个节点有两个孩子，那么它的后继没有左孩子，它的前驱没有右孩子。#### 证明如果一棵二叉搜索树中的一个结点有两个孩子，那么它的后继为它的右子树中的最小值，所以它的后继没有左孩子，它的前驱为它的左子树中的最大值，所以它的前驱没有右孩子。删除时有三种情况：1. 如果被删除节点（$z$）没有孩子节点，直接删除，修改父节点相应指针指向空。2. 如果$z$只有一个孩子，把孩子提到树中$z$所在的位置，并修改$z$的父节点，用$z$的孩子来替换。3. 如果$z$有两个孩子，那么找$z$的后继$y$（一定在$z$的右子树中）。1. 如果$y$是$z$的右孩子，用$y$替换$z$，同时留下$y$的右孩子。2. 如果$y$不是$z$的右孩子，有之上定理可知，$y$是没有左孩子的，此时用$y$的右孩子替换$y$，用$y$替换$z$，不留下$y$的右孩子。#### TRANSPLANT123456789// TRANSPLANT(T, u, v)if u.p == T.nil T.root = velse if u == u.p.left u.p.left = velse u.p.right = vif v != T.nil v.p = u.pTRANSPLANT的功能是在树$T$中用一棵以$v$为根的子树来替换一棵以$u$为根的子树。- 2-3行：当$u$是树根的时候，直接让$T$的根指向$v$。- 4-5行：当$u$是一个左孩子的时候，将$v$放在$u$的左孩子的位置。- 6行：当$u$是一个右孩子的时候，将$v$放在$u$的右孩子的位置。- 7-8行：更新$v$的父节点。#### TREE-DELETE1234567891011121314TREE-DELETE(T, z)if z.left == T.nil TRANSPLANT(T, z, z.right)else if z.right == T.nil TRANSPLANT(T, z, z.left)else y = TREE-MINIMUM(z.right) if y.p != z TRANSPLANT(T, y, y.right) y.right = z.right y.right.p = y TRANSPLANT(T, z, y) y.left = z.left y.left.p = y1. 2-5行：如果$z$没有左孩子，那么用其右孩子替换$z$。如果$z$没有右孩子，那么用其左孩子替换$z$。2. 12-14行：如果$y$是$z$的右孩子，用$y$替换$z$，同时留下$z$的左孩子。3. 7-11行：如果如果$z$有两个孩子，且$y$不是$z$的右孩子，用$y$的右孩子替换$y$，用$y$替换$z$。### 红黑树的删除红黑树的删除和二叉查找树的删除有类似的结构。#### RB-TRANSPLANT12345678// RB-TRANSPLANT(T, u, v)if u.p == T.nil T.root = velse if u == u.p.left u.p.left = velse u.p.right = vv.p = u.p过程RB-TRANSPLANT与TRANSPLANT有一点不同，即第8行无条件赋值，因为红黑树中的哨兵不是空。#### RB-DELETE12345678910111213141516171819202122232425// RB-DELETE(T, z)y = zy-original-color = y.color // 删除的结点的颜色if z.left == T.nil // 左子树为空，右子树直接上去 x = z.right // x指向被删除结点的右孩子 RB-TRANSPLANT(T, z, z.right)else if z.right == T.nil // 右子树为空，右子树直接上去 x = z.left RB-TRANSPLANT(T, z, z.left)else y = TREE-MINIMUM(z.right) // 右子树中最小的 y-original-color = y.color // 删除的节点的颜色 x = y.right if y.p == z x.p = y else RB-TRANSPLANT(T, y, y.right) // 和二叉搜索树删除时第2、3点一致 y.right = z.right y.right.p = y RB-TRANSPLANT(T, z, y) y.left = z.left y.left.p = y y.color = z.colorif y-original-color == BLACK //当删除的是黑色时需要调整，红色不需要 RB-DELETE-FIXUP(T, x)我们从被删结点后来顶替它的那个结点开始调整，并认为它有额外的一重黑色。这里额外一重黑色是什么意思呢，我们不是把红黑树的结点加上除红与黑的另一种颜色，这里只是一种假设，我们认为我们当前指向它，因此空有额外一种黑色，可以认为它的黑色是从它的父结点被删除后继承给它的，它现在可以容纳两种颜色，如果它原来是红色，那么现在是红+黑，如果原来是黑色，那么它现在的颜色是黑+黑。有了这重额外的黑色，原红黑树性质5就能保持不变。现在只要恢复其它性质就可以了，做法还是尽量向根移动和穷举所有可能性。12345678910111213141516171819202122232425// RB-DELETE-FIXUP(T, x)while x != T.root and x.color == BLACK if x == x.p.left w = x.p.right // 兄弟结点 if w.color == RED w.color = BLACK x.p.color = RED LEFT-ROTATE(T, x.p) w = x.p.right if w.left.color == BLACK and w.right.color == BLACK w.color = RED x = x.p else if w.right.color == BLACK w.left.color = BLACK w.color= RED RIGHT-RATATE(T, w) w = x.p.right w.color = x.p.color x.p.color = BLACK w.right.color = BLACK LEFT-ROTATE(T, x.p) x = T.root else same as then clause with "right" and "left" exchangedx.color = BLACK（y是被删除的结点，x是怼上去的结点，即x占据了y的位置）如果y的颜色是RED，则y不可能为红黑树的根，所以不管x的颜色是什么，都不会影响到红黑树的性质。所以只考虑y的颜色为BLACK的情况。在y的颜色是BLACK的情况下，如果x的颜色为RED的话，删除y之后，结点y所在的分支的黑高就会减1，所以，只需要将x的颜色变为BLACK，则该分支的黑高会加1，则会保持住红黑树的颜色性质。所以最终要考虑的情况就是：y颜色为BLACK，x的颜色为BLACK的情况。因把y删除后，x顶替y的位置，y所在分支的黑高减1，所以，假设x节点的颜色为BLACK-BLACK，简称BB，也就是原来y的BLACK增加到x上了，这样就保证了该分支的黑高不变，接下来要做的就是调整x所在的分支，使红黑树的性质保持不变，又分为下面的几种情况（只考虑x为左孩子的情况，右孩子的情况是对称的）删除修复情况1：当前结点是黑+黑且兄弟结点为红色(此时父结点和兄弟结点的子结点为黑)。解法：把父结点染成红色，把兄弟结点染成黑色，左旋，之后重新进入算法。此变换后原红黑树性质5不变，而把问题转化为兄弟结点为黑色的情况(注：变化前，原本就未违反性质5，只是为了把问题转化为兄弟结点为黑色的情况)。 即第5行至第9行。删除修复情况2：当前结点是黑加黑且兄弟是黑色且兄弟结点的两个子结点全为黑色。解法：把当前结点和兄弟结点中抽取一重黑色追加到父结点上，把父结点当成新的当前结点，重新进入算法。（此变换后性质5不变），即第10-12行代码操作。删除修复情况3：当前结点颜色是黑+黑，兄弟结点是黑色，兄弟的左子是红色，右子是黑色。解法：把兄弟结点染红，兄弟左子结点染黑，之后再以兄弟结点为支点解右旋，之后重新进入算法。此是把当前的情况转化为情况4，而性质5得以保持，即第13-17行代码：删除修复情况4：当前结点颜色是黑-黑色，它的兄弟结点是黑色，但是兄弟结点的右子是红色，兄弟结点左子的颜色任意。解法：把兄弟结点染成当前结点父结点的颜色，把当前结点父结点染成黑色，兄弟结点右子染成黑色，之后以当前结点的父结点为支点进行左旋，此时算法结束，红黑树所有性质调整正确，即第18-22行代码，如下所示：]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08-并发]]></title>
    <url>%2F2019%2F08-%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[线程的中断interrupt()interrupt()是一个线程中断的方法，本人只在Java网络编程这门课的实验里用过一次。其可以使得处于阻塞状态的线程抛出一个异常，也就说，它可以用来中断一个正处于阻塞状态的线程。123456789101112131415161718192021222324252627282930313233package test;import java.io.IOException;public class Test &#123; public static void main(String[] args) throws IOException &#123; Test test = new Test(); MyThread thread = test.new MyThread(); thread.start(); // 睡2秒，保证thread线程得到执行 try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; thread.interrupt(); &#125; class MyThread extends Thread&#123; @Override public void run() &#123; try &#123; System.out.println("进入睡眠状态"); Thread.currentThread().sleep(10000); System.out.println("睡眠完毕"); &#125; catch (InterruptedException e) &#123; System.out.println("得到中断异常"); &#125; System.out.println("run方法执行完毕"); &#125; &#125;&#125;isInterrupted()interrupt()配合isInterrupted()能够中断正在运行的线程，因为调用interrupt方法相当于将中断标志位置为true，那么可以通过调用isInterrupted()判断中断标志是否被置位来中断线程的执行。比如下面这段代码：12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) throws IOException &#123; Test test = new Test(); MyThread thread = test.new MyThread(); thread.start(); try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; thread.interrupt(); &#125; class MyThread extends Thread&#123; @Override public void run() &#123; int i = 0; while(!isInterrupted() &amp;&amp; i &lt; Integer.MAX_VALUE)&#123; System.out.println(i+" while循环"); i++; &#125; &#125; &#125;&#125;但是以上的暂停程序运行的方法可以被替换为如下代码：1234567891011121314class MyThread extends Thread&#123; private volatile boolean isStop = false; @Override public void run() &#123; int i = 0; while(!isStop)&#123; i++; &#125; &#125; public void setStop(boolean stop)&#123; this.isStop = stop; &#125;&#125;volatile的目的是禁止指令重排。参见：https://isjinhao.github.io/2019/volatile/#moreinterrupted()Tests whether the current thread has been interrupted. The interrupted status of the thread is cleared by this method. In other words, if this method were to be called twice in succession, the second call would return false (unless the current thread were interrupted again, after the first call had cleared its interrupted status and before the second call had examined it).A thread interruption ignored because a thread was not alive at the time of the interrupt will be reflected by this method returning false.每个线程都有一个中断状态位：private native boolean isInterrupted(boolean ClearInterrupted);：传入true重置状态位，传入false不重置状态位。返回此方法执行完成前线程中断状态位的状态。public void interrupt()：将中断状态位设置为true。public boolean isInterrupted()：查看当前状态位但是不影响状态位，内部实现原理isInterrupted(false)。public static boolean interrupted()：重置当前线程状态位（即如果状态位是true，则设置为false），内部实现原理isInterrupted(true)。synchronized按照时间发展呢的顺序，Java中是先出现了synchronized（since 1.0），再出现了Lock（since 5.0）。在Java中，每一个对象都拥有一个锁标记（monitor），也称为监视器，我们可以使用synchronized关键字来标记一个方法或者代码块，当某个线程调用该对象的synchronized方法或者访问synchronized代码块时，这个线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，这个线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。synchronized方法：123public synchronized void insert()&#123; &#125;普通方法获得当前对象的锁，即this的锁。静态方法获得类的字节码对象的锁。synchronized代码块123synchronized(synObject) &#123; &#125;对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。条件对象当一个线程进入临界区后却发现某一条件被满足之后它才能执行，比如在银行转账时，A向B账户转账，但是当A账户获得锁后，发现账户中没有钱，需要等待C账户给其转账之后其才能给B账户转账，这时它就需要释放锁，进入等待状态，并且当其的账户余额能保证向B转完账后不为负数这个条件时才能转账，同时当此条件被满足时其他线程需要通知等待的线程让其进入运行状态。方法如下：synchronized方法123456public synchronized void test()&#123; if(条件x不满足) wait(); if(条件x被满足) notify() or notifyAll() //唤醒等待在条件x上的线程&#125;synchronized代码块123456synchronized(synObject) &#123; if(条件x不满足) wait(); if(条件x被满足) notify() or notifyAll() //唤醒等待在条件x上的线程&#125;但是如果还有一个条件可以迫使线程进入等待状态，在编程时只能将其也等待在条件x上，这就是其不足之一。需要注意：对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。LockLock接口定义的方法如下：12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125;tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。Lock接口的典型使用方法如下：123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125;ReentrantLock翻译为是“可重入锁”，意思是如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。按不同的分类，还有一类锁是中断锁，顾名思义，就是可以相应中断的锁。在Java中，synchronized就不是可中断锁，而Lock是可中断锁。如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread0 = new MyThread(test); MyThread thread1 = new MyThread(test); thread0.start(); thread1.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread1.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+"得到了锁"); long startTime = System.currentTimeMillis(); for(;;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; /* * 插入数据 */ &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+"执行finally"); lock.unlock(); System.out.println(thread.getName()+"释放了锁"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+"被中断"); &#125; &#125;&#125;在这段代码中，如果线程1首先获得锁，其会一直运行下去，此时线程0得不到锁就会永远等待下去。但是如果线程0首先获得锁，其会一直运行下去，所以此时线程1得不到锁，但是在主线程中线程1启用了interrupt()方法，而lockInterruptibly()可以响应中断。thread的状态### yield()12// JDK原型public static native void yield();&gt; A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore this hint.当yield()成功的时候会自动放弃时间片，转入就绪状态，然后和其它线程进行CPU的争夺。### join()join方法有三个重载版本：123join()join(long millis) //参数为毫秒join(long millis,int nanoseconds) //第一参数为毫秒，第二个参数为纳秒假如在main线程中，调用thread.join方法，则main方法会等待thread线程执行完毕或者等待一定的时间。- 如果调用的是无参join方法，则等待thread执行完毕。- 如果调用的是指定了时间参数的join方法，则等待一定的时间。#### join的实现123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125;join是使用wait来实现的，如果线程仍然活着，则等待对应的时间。当调用线程（设为A）执行到其他线程（设为B）的join()方法时，A阻塞在线程B的this对象（线程B本身），如第12行或第20行所示。从代码上我们看不出来什么时候notify线程A，但是JDK注释上描述：&gt; As a thread terminates the this.notifyAll method is invoked.笔者也是在此知道，当一个线程结束时会通知所有在其上等待的线程。## ThreadLocal### ThreadLocal使用ThreadLocal是一个线程局部变量，我们都知道全局变量和局部变量的区别，拿Java举例就是定义在类中的是全局的变量，各个方法中都能访问得到（静态方法不能获得实例属性），而局部变量定义在方法中，只能在方法内访问。那线程局部变量（ThreadLocal）就是每个线程都会有一个局部变量，独立于变量的初始化副本，而各个副本是通过线程唯一标识相关联的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class TaskThread extends Thread &#123; private UniqueThreadIdGenerator t; public TaskThread(String threadName, UniqueThreadIdGenerator t) &#123; this.setName(threadName); this.t = t; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 4; i++) &#123; try &#123; int value = t.getUniqueId(); System.out.println("thread[ " + Thread.currentThread().getName() + " ] --&gt; uniqueId[ " + value + " ]"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; UniqueThreadIdGenerator uniqueThreadId = new UniqueThreadIdGenerator(); // 为每个线程生成一个唯一的局部标识 TaskThread t1 = new TaskThread("custom-thread-1", uniqueThreadId); TaskThread t2 = new TaskThread("custom-thread-2", uniqueThreadId); TaskThread t3 = new TaskThread("custom-thread-3", uniqueThreadId); t1.start(); t2.start(); t3.start(); &#125;&#125;class UniqueThreadIdGenerator &#123; // 线程局部整型变量 private final ThreadLocal&lt;Integer&gt; uniqueNum = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return 0; &#125; &#125;; // 变量值 public int getUniqueId() &#123; uniqueNum.set(uniqueNum.get() + 1); return uniqueNum.get(); &#125;&#125;// thread[ custom-thread-2 ] --&gt; uniqueId[ 1 ]// thread[ custom-thread-1 ] --&gt; uniqueId[ 1 ]// thread[ custom-thread-3 ] --&gt; uniqueId[ 1 ]// thread[ custom-thread-1 ] --&gt; uniqueId[ 2 ]// thread[ custom-thread-2 ] --&gt; uniqueId[ 2 ]// thread[ custom-thread-1 ] --&gt; uniqueId[ 3 ]// thread[ custom-thread-3 ] --&gt; uniqueId[ 2 ]// thread[ custom-thread-1 ] --&gt; uniqueId[ 4 ]// thread[ custom-thread-2 ] --&gt; uniqueId[ 3 ]// thread[ custom-thread-3 ] --&gt; uniqueId[ 3 ]// thread[ custom-thread-2 ] --&gt; uniqueId[ 4 ]// thread[ custom-thread-3 ] --&gt; uniqueId[ 4 ]// 每个线程之间的uniqueId是互不干扰的### ThreadLocal源码分析每个线程内部有一个ThreadLocalMap，get()的时候就是获得当前线程的ThreadLocalMap，并且将当前ThreadLocal对象传入map.getEntry(this);#### get()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// ThreadLocal.javapublic T get() &#123; Thread t = Thread.currentThread(); // 拿到每个线程内部的ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) &#123; // this指的是这个ThreadLocal对象，每个ThreadLocalMap可以有多个ThreadLocal对象 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;// 默认初始化为nullprotected T initialValue() &#123; return null;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;// ThreadLocalMap.javaThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125;#### set()12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;#### remove()123456// 从当前线程的ThreadLocalMap中删除当前的ThreadLocalpublic void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125;### ThreadLocalMapThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也独立实现。在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。但是Entry中key只能是ThreadLocal对象，这点被Entry的构造方法已经限定死了。Entry继承自WeakReference（弱引用，生命周期只能存活到下次GC前），但只有Key是弱引用类型的，Value并非弱引用。12345678910// Entry.javastatic class Entry extends WeakReference&lt;ThreadLocal&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) &#123; super(k); value = v; &#125;&#125;#### Hash冲突怎么解决和HashMap的最大的不同在于，ThreadLocalMap结构非常简单，没有next引用，也就是说ThreadLocalMap中解决Hash冲突的方式并非链表的方式，而是采用线性探测的方式，所谓线性探测，就是根据初始key的hashcode值确定元素在table数组中的位置，如果发现这个位置上已经有其他key值的元素被占用，则利用固定的算法寻找一定步长的下个位置，依次判断，直至找到能够存放的位置。ThreadLocalMap解决Hash冲突的方式就是简单的步长加1或减1，寻找下一个相邻的位置。12345678910111213/** * Increment i modulo len. */private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;/** * Decrement i modulo len. */private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125;显然ThreadLocalMap采用线性探测的方式解决Hash冲突的效率很低，如果有大量不同的ThreadLocal对象放入map中时发送冲突，或者发生二次冲突，则效率很低。所以这里引出的良好建议是：每个线程只存一个变量，需要多个变量 这个时候需要把这些对象封装成变量对象。### 内存泄漏ThreadLocal在ThreadLocalMap中是以一个弱引用身份被Entry中的Key引用的，因此如果ThreadLocal没有外部强引用来引用它，那么ThreadLocal会在下次JVM垃圾收集时被回收。这个时候就会出现Entry中Key已经被回收，出现一个null Key的情况，外部读取ThreadLocalMap中的元素是无法通过null Key来找到Value的。因此如果当前线程的生命周期很长，一直存在，那么其内部的ThreadLocalMap对象也一直生存下来，这些null key就存在一条强引用链的关系一直存在：Thread –&gt; ThreadLocalMap–&gt;Entry–&gt;Value，这条强引用链会导致Entry不会回收，Value也不会回收，但Entry中的Key却已经被回收的情况，造成内存泄漏。但是JVM团队已经考虑到这样的情况，并做了一些措施来保证ThreadLocal尽量不会内存泄漏：在ThreadLocal的get()、set()、remove()方法调用的时候会清除掉线程ThreadLocalMap中所有Entry中Key为null的Value，并将整个Entry设置为null，利于下次内存回收。ThreadLocal的get()方法在调用map.getEntry(this)时，内部会判断key是否为null1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162private Entry getEntry(ThreadLocal key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); // 清除空结点的方法 else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot（意思是，删除value，设置为null便于下次回收） tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null // 将当前Entry删除后，会继续循环往下检查是否有key为null的节点，如果有则一并删除，防止内存泄漏。 Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125;但这样也并不能保证ThreadLocal不会发生内存泄漏，例如：- 使用static的ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏。- 分配使用了ThreadLocal又不再调用get()、set()、remove()方法，那么就会导致内存泄漏#### 为什么使用弱引用？从表面上看，发生内存泄漏，是因为Key使用了弱引用类型。但其实是因为整个Entry的key为null后，没有主动清除value导致。为什么使用弱引用而不是强引用？官方文档的说法：&gt; To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.&gt; 为了处理非常大和生命周期非常长的线程，哈希表使用弱引用作为 key。下面我们分两种情况讨论：- key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。- key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set，get，remove的时候会被清除。比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set，get，remove的时候会被清除。因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key的value就会导致内存泄漏，而不是因为弱引用。所以：每次使用完ThreadLocal，都调用它的remove()方法，清除数据。尤其是在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。## Callable和Future和FutureTask### CallableCallable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个方法，只不过这个方法叫做call()：1`public` `interface` `Callable&lt;V&gt; &#123;`` ``/**`` ``* Computes a result, or throws an exception if unable to do so.`` ``*`` ``* @return computed result`` ``* @throws Exception if unable to compute a result`` ``*/`` ``V call() ``throws` `Exception;``&#125;`可以看到，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：1`&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);``&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);``Future&lt;?&gt; submit(Runnable task);`第一个submit方法里面的参数类型就是Callable。暂时只需要知道Callable一般是和ExecutorService配合来使用的，具体的使用方法讲在后面讲述。### FutureFuture就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。Future类位于java.util.concurrent包下，它是一个接口：1`public` `interface` `Future&lt;V&gt; &#123;`` ``boolean` `cancel(``boolean` `mayInterruptIfRunning);`` ``boolean` `isCancelled();`` ``boolean` `isDone();`` ``V get() ``throws` `InterruptedException, ExecutionException;`` ``V get(``long` `timeout, TimeUnit unit)`` ``throws` `InterruptedException, ExecutionException, TimeoutException;``&#125;`在Future接口中声明了5个方法，下面依次解释每个方法的作用：- cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。- isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。- isDone方法表示任务是否已经完成，若任务完成，则返回true；- get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回；- get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接抛出TimeoutException。也就是说Future提供了三种功能：- 判断任务是否完成；- 能够中断任务；- 能够获取任务执行结果。因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。### FutureTask我们先来看一下FutureTask的实现：1`public` `class` `FutureTask&lt;V&gt; ``implements` `RunnableFuture&lt;V&gt;`FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现：1`public` `interface` `RunnableFuture&lt;V&gt; ``extends` `Runnable, Future&lt;V&gt; &#123;`` ``void` `run();``&#125;`可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。FutureTask提供了2个构造器：1`public` `FutureTask(Callable&lt;V&gt; callable) &#123;``&#125;``public` `FutureTask(Runnable runnable, V result) &#123;``&#125;`### 使用示例#### 使用Callable+Future获取执行结果12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); Future&lt;Integer&gt; result = executor.submit(task); executor.shutdown(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+result.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125;#### 使用Callable+FutureTask获取执行结果123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test &#123; public static void main(String[] args) &#123; //第一种方式 ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); executor.submit(futureTask); executor.shutdown(); //第二种方式，注意这种方式和第一种方式效果是类似的，只不过一个使用的是ExecutorService，一个使用的是Thread /*Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); Thread thread = new Thread(futureTask); thread.start();*/ try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125;## 线程池### 线程池的分类并发库中，线程池创建线程大致可以分为下面三种：123456//创建固定大小的线程池ExecutorService fPool = Executors.newFixedThreadPool(3);//创建缓存大小的线程池ExecutorService cPool = Executors.newCachedThreadPool();//创建单一的线程池ExecutorService sPool = Executors.newSingleThreadExecutor();#### 固定大小连接池1234567891011121314151617181920212223242526272829303132333435public class TestExecutor &#123; public static void main(String[] args) &#123; //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newFixedThreadPool(2); //创建实现了 Runnable 接口对象，Thread 对象当然也实现了 Runnable 接口 Thread t1 = new MyThread(); Thread t2 = new MyThread(); Thread t3 = new MyThread(); Thread t4 = new MyThread(); Thread t5 = new MyThread(); //将线程放入池中进行执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); //关闭线程池 pool.shutdown(); &#125;&#125;class MyThread extends Thread&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + " 正在执行..."); &#125;&#125;/* 运行结果： pool-1-thread-2 正在执行... pool-1-thread-1 正在执行... pool-1-thread-1 正在执行... pool-1-thread-2 正在执行... pool-1-thread-1 正在执行...*/#### 单任务连接池123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TestExecutor &#123; public static void main(String[] args) &#123; //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newSingleThreadExecutor(); //创建实现了 Runnable 接口对象，Thread 对象当然也实现了 Runnable 接口 Thread t1 = new MyThread(); Thread t2 = new MyThread(); Thread t3 = new MyThread(); Thread t4 = new MyThread(); Thread t5 = new MyThread(); //将线程放入池中进行执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); // 可以重启一个执行结束的线程 try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; pool.execute(t1); //关闭线程池 pool.shutdown(); &#125;&#125;class MyThread extends Thread&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + " 正在执行..."); &#125;&#125;/* 运行结果： pool-1-thread-1 正在执行... pool-1-thread-1 正在执行... pool-1-thread-1 正在执行... pool-1-thread-1 正在执行... pool-1-thread-1 正在执行... pool-1-thread-1 正在执行...*/#### 可变连接池可变任务线程池在执行 execute 方法来执行 Thread 类中的 run 方法。这里 execute 执行多次，线程池就会创建出多个线程来处理 Thread 类中 run 方法。所有我们看到连接池会根据执行的情况，在程序运行时创建多个线程来处理。123456789101112131415161718192021222324252627282930313233343536public class TestExecutor &#123; public static void main(String[] args) &#123; //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newCachedThreadPool(); //创建实现了 Runnable 接口对象，Thread 对象当然也实现了 Runnable 接口 Thread t1 = new MyThread(); Thread t2 = new MyThread(); Thread t3 = new MyThread(); Thread t4 = new MyThread(); Thread t5 = new MyThread(); //将线程放入池中进行执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); pool.execute(t4); pool.execute(t5); //关闭线程池 pool.shutdown(); &#125;&#125;class MyThread extends Thread&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + " 正在执行..."); &#125;&#125;/* 运行结果： pool-1-thread-2 正在执行... pool-1-thread-3 正在执行... pool-1-thread-5 正在执行... pool-1-thread-4 正在执行... pool-1-thread-1 正在执行...*/#### 延迟连接池123456789101112131415161718192021222324252627282930313233343536373839public class TestExecutor &#123; public static void main(String[] args) &#123; //创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。 //ScheduledExecutorService 是 ExecutorService 的子接口 ScheduledExecutorService pool = Executors.newScheduledThreadPool(2); //创建实现了 Runnable 接口对象，Thread 对象当然也实现了 Runnable 接口 Thread t1 = new MyThread(); Thread t2 = new MyThread(); Thread t3 = new MyThread(); Thread t4 = new MyThread(); Thread t5 = new MyThread(); //将线程放入池中进行执行 pool.execute(t1); pool.execute(t2); pool.execute(t3); //使用定时执行风格的方法 pool.schedule(t4, 10, TimeUnit.SECONDS); //t4 和 t5 在 10 秒后执行 pool.schedule(t5, 10, TimeUnit.SECONDS); //关闭线程池 pool.shutdown(); &#125;&#125;class MyThread extends Thread&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + " 正在执行..."); &#125;&#125;/* 运行结果： pool-1-thread-2 正在执行... pool-1-thread-1 正在执行... pool-1-thread-2 正在执行... pool-1-thread-2 正在执行... pool-1-thread-1 正在执行...*/### ExecutorServicejava.util.concurrent.ExecutorService 接口表示一个异步执行机制，使我们能够在后台执行任务。ExecutorService 执行的线程不影响其本身的执行：123456789101112131415161718192021222324public class TestExecutor &#123; public static void main(String[] args) &#123; //创建一个可重用固定线程数的线程池 ExecutorService pool = Executors.newSingleThreadExecutor(); //创建实现了 Runnable 接口对象，Thread 对象当然也实现了 Runnable 接口 Thread t1 = new MyThread(); // 正常启动线程 t1.start(); //将线程放入池中进行执行 pool.execute(t1); //关闭线程池 pool.shutdown(); &#125;&#125;class MyThread extends Thread&#123; private int i = 10; public void run() &#123; System.out.println(Thread.currentThread().getName() + " 正在执行..." + (++i)); &#125;&#125;/* Thread-0 正在执行...11 pool-1-thread-1 正在执行...12*/#### 基本使用##### ExecutorService 实现既然 ExecutorService 是个接口，如果你想用它的话就得去使用它的实现类之一。java.util.concurrent 包提供了 ExecutorService 接口的以下实现类：- ThreadPoolExecutor- ScheduledThreadPoolExecutor##### ExecutorService 创建ExecutorService 的创建依赖于你使用的具体实现。但是你也可以使用 Executors 工厂类来创建ExecutorService 实例。代码示例：123ExecutorService executorService1 = Executors.newSingleThreadExecutor(); ExecutorService executorService2 = Executors.newFixedThreadPool(10);ExecutorService executorService3 = Executors.newScheduledThreadPool(10);##### ExecutorService 使用有几种不同的方式来将任务委托给 ExecutorService 去执行：- execute(Runnable)- submit(Runnable)submit(Runnable) 方法也要求一个 Runnable 实现类，但它返回一个 Future 对象。这个 Future 对象可以用来检查 Runnable 是否已经执行完毕。他无法得到返回值，因为Runnable接口没有返回值。123456789101112public class TestExecutor &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); Future future = executorService.submit(new Runnable() &#123; public void run() &#123; System.out.println("Asynchronous task"); &#125; &#125;); future.get(); //获得执行完 run 方法后的返回值，这里使用的 Runnable，所以这里没有返回值，返回的是 null。 executorService.shutdown(); &#125;&#125;- submit(Callable)12345678910111213public class TestExecutor &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); Future future = executorService.submit(new Callable()&#123; public Object call() throws Exception &#123; System.out.println("Asynchronous Callable"); return "Callable Result"; &#125; &#125;); System.out.println("future.get() = " + future.get()); executorService.shutdown(); &#125;&#125;- invokeAny(…)invokeAny() 方法要求一系列的 Callable 或者其子接口的实例对象。调用这个方法并不会返回一个 Future，但它返回其中一个 Callable 对象的结果。无法保证返回的是哪个 Callable 的结果 – 只能表明其中一个已执行结束。如果其中一个任务执行结束(或者抛了一个异常)，其他 Callable 将被取消。123456789101112131415161718192021222324252627public class TestExecutor &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; int times = 1000; while(times -- &gt; 0) &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); Set&lt;Callable&lt;String&gt;&gt; callables = new HashSet&lt;Callable&lt;String&gt;&gt;(); callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 1"; &#125; &#125;); callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 2"; &#125; &#125;); callables.add(new Callable&lt;String&gt;() &#123; public String call() throws Exception &#123; return "Task 3"; &#125; &#125;); String result = executorService.invokeAny(callables); System.out.println("result = " + result); executorService.shutdown(); &#125; &#125;&#125;- invokeAll(…)invokeAll() 方法将调用你在集合中传给 ExecutorService 的所有 Callable 对象。invokeAll() 返回一系列的 Future 对象，通过它们你可以获取每个 Callable 的执行结果。记住，一个任务可能会由于一个异常而结束，因此它可能没有 “成功”。无法通过一个 Future 对象来告知我们是两种结束中的哪一种。##### Executors 关闭使用 shutdown 和 shutdownNow 可以关闭线程池。两者的区别：- shutdown 只是将空闲的线程 interrupt() 了，shutdown() 之前提交的任务可以继续执行直到结束。- shutdownNow 是 interrupt 所有线程， 因此大部分线程将立刻被中断。之所以是大部分，而不是全部 ，是因为 interrupt()方法能力有限。#### ThreadPoolExecutor 线程池执行者java.util.concurrent.ThreadPoolExecutor 是 ExecutorService 接口的一个实现。ThreadPoolExecutor 使用其内部池中的线程执行给定任务(Callable 或者 Runnable)。ThreadPoolExecutor 包含的线程池能够包含不同数量的线程。池中线程的数量由以下变量决定：- corePoolSize- maximumPoolSize当一个任务委托给线程池时，如果池中线程数量低于 corePoolSize，一个新的线程将被创建，即使池中可能尚有空闲线程。如果内部任务队列已满，而且有 corePoolSize 个线程正在运行，但是运行线程的数量低于maximumPoolSize，一个新的线程将被创建去执行该任务。1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler);- corePoolSize：线程池核心线程数（平时保留的线程数）- maximumPoolSize：线程池最大线程数（当workQueue都放不下时，启动新线程，最大线程数）- keepAliveTime：超出corePoolSize数量的线程的保留时间。- unit：keepAliveTime单位- workQueue：阻塞队列，存放来不及执行的线程- ArrayBlockingQueue：构造函数一定要传大小- LinkedBlockingQueue：构造函数不传大小会默认为（Integer.MAX_VALUE ），当大量请求任务时，容易造成 内存耗尽。- SynchronousQueue：同步队列，一个没有存储空间的阻塞队列 ，将任务同步交付给工作线程。- PriorityBlockingQueue : 优先队列- threadFactory：线程工厂- handler：饱和策略- AbortPolicy（默认）：直接抛弃- CallerRunsPolicy：用调用者的线程执行任务- DiscardOldestPolicy：抛弃队列中最久的任务- DiscardPolicy：抛弃当前任务##### 阿里巴巴开发手册线程池不使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明： Executors 返回的线程池对象的弊端如下：1. FixedThreadPool 和 SingleThreadPool : 允许的请求队列长度为 Integer.MAX_VALUE ，可能会堆积大量的请求，从而导致 OOM 。2. CachedThreadPool 和 ScheduledThreadPool : 允许的创建线程数量为 Integer.MAX_VALUE ，可能会创建大量的线程，从而导致 OOM 。### ScheduledExecutorServicejava.util.concurrent.ScheduledExecutorService 是一个 ExecutorService， 它能够将任务延后执行，或者间隔固定时间多次执行。 任务由一个工作者线程异步执行，而不是由提交任务给 ScheduledExecutorService 的那个线程执行。1234567891011121314151617public class TestExecutor &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5); ScheduledFuture scheduledFuture = scheduledExecutorService.schedule( new Callable() &#123; public Object call() throws Exception &#123; System.out.println("Executed!"); return "Called!"; &#125; &#125;, 5, TimeUnit.SECONDS);//5 秒后执行 scheduledExecutorService.shutdown(); &#125;&#125;#### ScheduledExecutorService 的实现ScheduledExecutorService 是一个接口，你要用它的话就得使用 java.util.concurrent 包里对它的某个实现类。ScheduledExecutorService 具有以下实现类：ScheduledThreadPoolExecutor#### 创建一个 ScheduledExecutorService如何创建一个 ScheduledExecutorService 取决于你采用的它的实现类。但是你也可以使用 Executors 工厂类来创建一个 ScheduledExecutorService 实例。比如：1ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);#### ScheduledExecutorService 的使用一旦你创建了一个 ScheduledExecutorService，你可以通过调用它的以下方法：- schedule (Callable task, long delay, TimeUnit timeunit)123456789101112131415161718public class TestExecutor &#123; public static void main(String[] args) throws Exception &#123; ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5); ScheduledFuture scheduledFuture = scheduledExecutorService.schedule( new Callable() &#123; public Object call() throws Exception &#123; System.out.println("Executed!"); return "Called!"; &#125; &#125;, 5, TimeUnit.SECONDS); System.out.println("result = " + scheduledFuture.get()); scheduledExecutorService.shutdown(); &#125;&#125;- schedule (Runnable task, long delay, TimeUnit timeunit)- scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit)这一方法规划一个任务将被定期执行。该任务将会在首个 initialDelay 之后得到执行，然后每个 period 时间之后重复执行。如果给定任务的执行抛出了异常，该任务将不再执行。如果没有任何异常的话，这个任务将会持续循环执行到ScheduledExecutorService 被关闭。如果一个任务占用了比计划的时间间隔更长的时候，下一次执行将在当前执行结束执行才开始。计划任务在同一时间不会有多个线程同时执行。- scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)除了 period 有不同的解释之外这个方法和 scheduleAtFixedRate() 非常像。scheduleAtFixedRate() 方法中，period 被解释为前一个执行的开始和下一个执行的开始之间的间隔时间。而在本方法中，period 则被解释为前一个执行的结束和下一个执行的结束之间的间隔。因此这个延迟是执行结束之间的间隔，而不是执行开始之间的间隔。## Lock.lockInterruptiblyAPI文档的说法：- lock.lock()：尝试获取锁。当该函数返回时，处于已经获取锁的状态。如果当前有别的线程获取了锁，则睡眠。- lockInterruptibly()：尝试获取锁。如果当前有别的线程获取了锁，则睡眠。当该函数返回时，有两种可能：- 已经获取了锁。- 获取锁不成功，但是别的线程打断了它。则该线程会抛出 InterruptedException 异常而返回，同时该线程的中断标志会被清除。12345678910111213141516171819202122232425262728293031323334353637class Run implements Runnable &#123; private static Lock lock = new ReentrantLock(); public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + " trying to get lock"); lock.lock(); Thread.sleep(5000); System.out.println(Thread.currentThread().getName() + " finished"); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName() + " interrupted"); &#125; finally &#123; lock.unlock(); System.out.println("now lock is avalibale"); &#125; &#125;&#125;public class Test &#123; public static void main(String args[]) throws InterruptedException &#123; Thread i0 = new Thread(new Run()); Thread i1 = new Thread(new Run()); i0.start(); Thread.sleep(100); i1.start(); i1.interrupt(); &#125;&#125;/* Thread-0 trying to get lock Thread-1 trying to get lock Thread-0 finished now lock is avalibale Thread-1 interrupted now lock is avalibale*/在线程0获取了锁后，线程1去lock.lock().然后主线程里面去中断线程1，线程1并没有立马中断，而是要等到Thread0运行完后，释放了锁，Thread1在成功获取锁之后，才会被中断，抛出异常。如果我们使用的是lock.lockInterruptibly()，信息如下：1234567891011Thread-0 trying to get lockThread-1 trying to get lockThread-1 interruptedException in thread &quot;Thread-1&quot; java.lang.IllegalMonitorStateException at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151) at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261) at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457) at Run.run(Test.java:19) at java.lang.Thread.run(Thread.java:748)Thread-0 finishednow lock is avalibale在线程0获取了锁后，线程1去lock.lock().然后主线程里面去中断线程1。因为在中断时，线程1是没有拿到锁的（线程0获取了锁，在处于sleep状态），所以lock.lockInterruptibly()里面抛出了中断，此时并没有拿到锁！！而finally块就算是发生了中断也会执行lock.unlock()，这里就抛出异常了，因为你没有获取到锁啊，unlock啥！！同时如下的代码不能解决此问题：12345678finally&#123; //如果不是以中断方式返回，则应该是获取了锁，则释放锁！！ if(!Thread.currentThread().isInterrupted()) &#123; lock.unlock(); System.out.println("now lock is avalibale"); &#125; &#125;因为lock.lockInterruptibly()在抛出了异常后，是会清除中断标志位的，所以，finally 中的 if 永远会执行，又回到了之前的状态。比较好的方法是这样的：既然Thread自己的标志位会被清除，那自己设一个呗！123456789101112131415public void run()&#123; boolean flag = true; try&#123; lock.lockInterruptibly(); System.out.println(Thread.currentThread().getName() + " running"); Thread.sleep(1900); System.out.println(Thread.currentThread().getName() + " finished"); &#125; catch (InterruptedException e)&#123; System.out.println(Thread.currentThread().getName() + " interrupted"); flag = false; &#125; if(flag)&#123; lock.unlock(); &#125;&#125;## 阻塞队列阻塞队列 （BlockingQueue）是 Java util.concurrent 包下重要的数据结构，BlockingQueue 提供了线程安全的队列访问方式：当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。并发包下很多高级同步类的实现都是基于 BlockingQueue 实现的。### ArrayBlockingQueue一个有界的阻塞队列，其内部实现是将对象放到一个数组里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了。#### 构造函数123456789101112131415public ArrayBlockingQueue(int capacity) &#123; this(capacity, false);&#125;public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125;/*公平锁：就是在并发环境中，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程线程是等 待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照 FIFO 的规则从队列中取到自己。非公平锁：比较粗鲁，上来就直接尝试占有锁，如果尝试失败，就再采用类似公平锁那种方式*/#### offer12345678910111213141516171819202122public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) return false; else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;private void enqueue(E x) &#123; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125;#### put1234567891011public void put(E e) throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;这里需要思考一个问题为啥调用 lockInterruptibly 方法而不是 Lock 方法。我的理解是因为调用了条件变量的 await()方法，而 await()方法会在中断标志设置后抛出 InterruptedException 异常后退出，所以还不如在加锁时候先看中断标志是不是被设置了，如果设置了直接抛出 InterruptedException 异常，就不用再去获取锁了。然后看了其他并发类里面凡是调用了 await 的方法获取锁时候都是使用的 lockInterruptibly 方法而不是 Lock 也验证了这个想法。#### poll12345678910111213141516171819202122public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;private E dequeue() &#123; final Object[] items = this.items; @SuppressWarnings("unchecked") E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); notFull.signal(); return x;&#125;#### take1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;#### peek123456789public E peek() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return itemAt(takeIndex); // null when queue is empty &#125; finally &#123; lock.unlock(); &#125;&#125;#### size123456789public int size() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return count; &#125; finally &#123; lock.unlock(); &#125;&#125;#### 面试题在多线程操作下，一个数组中最多只能存入 3 个元素。多放入不可以存入数组，或等待某线程对数组中某个元素取走才能放入，要求使用 java 的多线程来实现。1234567891011121314151617181920212223242526272829303132333435363738public class BlockingQueueTest &#123; public static void main(String[] args) &#123; final BlockingQueue queue = new ArrayBlockingQueue(3); for (int i = 0; i &lt; 2; i++) &#123; // 生产者 new Thread() &#123; public void run() &#123; while (true) &#123; try &#123; Thread.sleep((long) (Math.random() * 1000)); queue.put(1); System.out.println(Thread.currentThread().getName() + " 放了数据，" + "队列目前有" + queue.size() + "个数据"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;.start(); &#125; // 消费者 new Thread() &#123; public void run() &#123; while (true) &#123; try &#123; Thread.sleep(1000); System.err.println(queue.take()); System.out.println(Thread.currentThread().getName() + " 取走数据，" + "队列目前有" + queue.size() + "个数据"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;.start(); &#125;&#125;### LinkedBlockingQueue内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。LinkedBlockingQueue 中也有两个 Node 分别用来存放首尾节点，并且里面有个初始值为 0 的原子变量 count用来记录队列元素个数，另外里面有两个 ReentrantLock 的独占锁，分别用来控制元素入队和出队加锁，其中 takeLock用来控制同时只有一个线程可以从队列获取元素，其他线程必须等待，putLock 控制同时只能有一个线程可以获取锁去添加元素，其他线程必须等待。另外 notEmpty 和 notFull 用来实现入队和出队的同步。 另外由于出入队是两个非公平独占锁，所以可以同时又一个线程入队和一个线程出队，其实这个是个生产者-消费者模型。1234567891011/** Lock held by take, poll, etc */private final ReentrantLock takeLock = new ReentrantLock();/** Wait queue for waiting takes */private final Condition notEmpty = takeLock.newCondition();/** Lock held by put, offer, etc */private final ReentrantLock putLock = new ReentrantLock();/** Wait queue for waiting puts */private final Condition notFull = putLock.newCondition();#### 带时间的 Offer 操作-生产者在 ArrayBlockingQueue 中已经简单介绍了 Offer()方法，LinkedBlocking 的 Offer 方法类似，在此就不过多去介绍。这次我们从介绍下带时间的 Offer 方法。123456789101112131415161718192021222324252627public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); &#125; enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return true;&#125;#### 带时间的 poll 操作-消费者123456789101112131415161718192021222324public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; E x = null; int c = -1; long nanos = unit.toNanos(timeout); final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x;&#125;#### size 操作当前队列元素个数，如代码直接使用原子变量 count 获取。123public int size() &#123; return count.get();&#125;#### remove1234567891011121314151617public boolean remove(Object o) &#123; if (o == null) return false; fullyLock(); try &#123; for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) &#123; if (o.equals(p.item)) &#123; unlink(p, trail); return true; &#125; &#125; return false; &#125; finally &#123; fullyUnlock(); &#125;&#125;### PriorityBlockingQueue一 个 无 界 的 并 发 队 列 。 它 使 用 了 和 类java.util.PriorityQueue 一 样 的 排 序 规 则 。 你 无 法 向 这 个 队 列 中 插 入 null 值 。 所 有 插 入 到PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。每次出队都返回优先级最高的元素，是二叉树最小堆的实现，直接遍历队列元素是无序的。1234567891011121314151617181920212223242526272829303132333435public class BlockingQueueTest &#123; public static PriorityBlockingQueue&lt;User&gt; queue = new PriorityBlockingQueue&lt;User&gt;(); public static void main(String[] args) &#123; queue.add(new User(1, "wu")); queue.add(new User(5, "wu5")); queue.add(new User(23, "wu23")); queue.add(new User(55, "wu55")); queue.add(new User(9, "wu9")); queue.add(new User(3, "wu3")); for (User user : queue) &#123; try &#123; System.out.println(queue.take().name); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; //静态内部类 static class User implements Comparable&lt;User&gt; &#123; public User(int age, String name) &#123; this.age = age; this.name = name; &#125; int age; String name; public int compareTo(User o) &#123; return this.age &gt; o.age ? -1 : 1; &#125; &#125;&#125;### 其他- SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。- DelayQueue：DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现java.util.concurrent.Delayed 接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * @Description * @Auther sty * @createTime 2018/9/18 下午2:52 */public class DelayQueueTest &#123; private static DelayQueue delayQueue = new DelayQueue(); public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; public void run() &#123; delayQueue.offer(new MyDelayedTask("task1",10000)); delayQueue.offer(new MyDelayedTask("task2",3900)); delayQueue.offer(new MyDelayedTask("task3",1900)); delayQueue.offer(new MyDelayedTask("task4",5900)); delayQueue.offer(new MyDelayedTask("task5",6900)); delayQueue.offer(new MyDelayedTask("task6",7900)); delayQueue.offer(new MyDelayedTask("task7",4900)); &#125; &#125;).start(); while (true) &#123; // 输出的时候有一定时间的延迟 Delayed take = delayQueue.take(); System.out.println(take); &#125; &#125;&#125;/** * compareTo 方法必须提供与 getDelay 方法一致的排序 */class MyDelayedTask implements Delayed&#123; private String name ; private long start = System.currentTimeMillis(); private long time ; public MyDelayedTask(String name,long time) &#123; this.name = name; this.time = time; &#125; /** * 需要实现的接口，获得延迟时间 用过期时间-当前时间 * @param unit * @return */ public long getDelay(TimeUnit unit) &#123; return unit.convert((start+time) - System.currentTimeMillis(),TimeUnit.MILLISECONDS); &#125; /** * 用于延迟队列内部比较排序 当前时间的延迟时间 - 比较对象的延迟时间 * @param o * @return */ public int compareTo(Delayed o) &#123; MyDelayedTask o1 = (MyDelayedTask) o; return (int) (this.getDelay(TimeUnit.MILLISECONDS) - o.getDelay(TimeUnit.MILLISECONDS)); &#125; @Override public String toString() &#123; return "MyDelayedTask&#123;" + "name='" + name + '\'' + ", time=" + time + '&#125;'; &#125;&#125;- LinkedTransferQueue：由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，多了tryTransfer和transfer方法- transfer方法，如果当前有消费者正在等待接收元素（take或者待时间限制的poll方法），transfer可以把生产者传入的元素立刻传给消费者。如果没有消费者等待接收元素，则将元素放在队列的tail节点，并等到该元素被消费者消费了才返回。- tryTransfer方法，用来试探生产者传入的元素能否直接传给消费者。，如果没有消费者在等待，则返回false。和上述方法的区别是该方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。- LinkedBlockingDeque：链表结构的双向阻塞队列，优势在于多线程入队时，减少一半的竞争。## volatile### 提升计算机工作能力在许多情况下，让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统速度的差距太大， 大量的时间都花费在磁盘I/O、网络通信或者数据库访问上。 如果不希望处理器在大部分时间里都处于等待其他资源的状态，就必须使用一些手段去把处理器的运算能力” 压榨” 出来， 否则就会造成很大的浪费，而计算机同时处理几项任务则是最容易想到、也被证明是非常有效的 “压榨” 手段。除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一个更具体的并发应用场景。衡量一个服务性能的高低好坏，每秒事务处理数（Transactions Per Second，TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序的并发能力。服务端是Java语言最擅长的领域之一，这个领域的应用占了Java应用中最大的一块份额，不过如何写好并发应用程序却又是服务端程序开发的难点之一，处理好并发方面的问题通常需要更多的编码经验来支持。幸好Java语言和虚拟机提供了许多工具，把并发编程的门槛降低了不少。并且各种中间件服务器、各类框架都努力地替程序员处理尽可能多的线程并发细节，使得程序员在编码时能更关注业务逻辑，而不是花费大部分时间去关注此服务会同时被多少人调用、如何协调硬件资源。无论语言、中间件和框架如何先进，开发人员都不能期望它们能独立完成所有并发处理的事情，了解并发的内幕也是成为一个高级程序员不可缺少的课程。### 真机的内存结构在正式讲解 Java 虚拟机并发相关的知识之前，我们先花费一点时间去了解一下物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。“让计算机并发执行若干个运算任务” 与 “更充分地利用计算机处理器的效能” 之间的因果关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的复杂性来源是绝大多数的运算任务都不可能只靠处理器 “计算” 就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个 I/O 操作是很难消除的（无法仅靠寄存器来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。基于高速缓存的存储交互很好地理解了处理器与内存的速度矛盾，但是也为计算机系统带来了更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），如图所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly 及 Dragon Protocol 等。其中最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。在本章中将会多次提到的 “内存模型” 一词，可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型，而 Java 虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件的缓存访问操作具有很高的可比性。除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果充足，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类型，Java 虚拟机的即时编译器中有有类似的指令重排序（Instruction Reorder）优化。### JVM的内存结构Java 虚拟机规范中试图定义一种 Java 内存模型（Java Memory Model，JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。Java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variables）与 Java 编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。为了获得较好的执行效能，Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。Java 内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。### volatile关键字 volatile 可以说是 Java 虚拟机提供的最轻量级的同步机制。当一个变量定义为 volatile 之后，它将具备两种特性：#### 保证此变量对所有线程的可见性这里的 “可见性” 是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成，例如，线程 A 修改一个普通变量的值，然后向主内存进行回写，另外一条线程 B 在线程 A 回写完成了之后再从主内存进行读取操作，新变量值才会对线程 B 可见。关于 volatile 变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile 变量对所有线程是立即可见的，对 volatile 变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出 “基于 volatile 变量的运算在并发下是安全的” 这个结论。比如以下代码：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125;运行它会发现每次运行结果都不一致，都是一个小于10000的数字。这便是由于volatile 不能保证原子性。同时自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：- 假如某个时刻变量inc的值为10。- 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；- 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。- 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。- 那么两个线程分别进行了一次自增操作后，inc只增加了1。#### 禁止指令重排序优化普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这也就是 Java 内存模型中描述的所谓的 “线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。volatile关键字禁止指令重排序有两层意思：- 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；- 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。可能上面说的比较绕，举个简单的例子：1234567//x、y为非volatile变量//flag为volatile变量x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5`由于 flag 变量为 volatile 变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。并且 volatile 关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。那么我们看一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep();&#125;doSomethingwithconfig(context);前在这个例子中，有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。### 并发编程的三个概念并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。#### 原子性（Atomicity）在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子，请分析以下哪些操作是原子性操作：1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4乍一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。所以上面4个语句只有语句1的操作具备原子性。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。#### 可见性（Visibility）当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。#### 有序性（Ordering）在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 先行发生原则（happens-before原则）。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。##### 先行发生原则1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作2. 锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。下面我们来解释一下前4条规则：1. 对于程序次序规则：一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。2. 锁定规则：也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。3. volatile变量规则：如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。4. 传递规则：实际上就是体现happens-before原则具备传递性。### volatile关键字的场景所以总结来说，volatile 变量在各个线程的工作内存中不存在一致性问题（在各个线程的工作内存中，volatile 变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在不一致性问题），但是 Java 里面的运算并非原子操作，导致 volatile 变量的运算在并发下一样是不安全的。由于 volatile 变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然需要通过加锁（使用 synchronized 或 java.util.concurrent 中的原子类）来保证原子性。通常来说，使用volatile必须具备以下2个条件：- 对变量的写操作不依赖于当前值- 该变量没有包含在具有其他变量的不变式中实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。下面列举几个Java中使用volatile的几个场景。#### 状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125;12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited)&#123; sleep()&#125;doSomethingwithconfig(context);#### double check12345678910111213141516171819class Singleton&#123; // 如果不加volatile可能拿到半个实例 private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; // 此层判断的目的是在instance初始化完成之后，直接返回 if(instance == null) &#123; // 可能会有多个线程到达此步，对字节码加锁的目的是使保证只能被构造一次 synchronized (Singleton.class) &#123; // 进入第10行的线程在正常情况下一定会进入到此步，再判断一次，如果被构造了则不再构造 if(instance == null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125;## CASCAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、 旧的预期值（用A表示）和新值（用B表示）。 CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供，虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程。### ABA问题尽管CAS看起来很美，但显然这种操作无法涵盖互斥同步的所有使用场景，并且CAS从语义上来说并不是完美的，存在这样的一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。 J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。 不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。以AtomicInteger为例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class AtomicIntegerDefectDemo &#123; public static void main(String[] args) &#123; defectOfABA(); &#125; static void defectOfABA() &#123; final AtomicInteger atomicInteger = new AtomicInteger(1); Thread coreThread = new Thread( () -&gt; &#123; final int currentValue = atomicInteger.get(); System.out.println(Thread.currentThread().getName() + " ------ currentValue=" + currentValue); // 这段目的：模拟处理其他业务花费的时间 try &#123; Thread.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean casResult = atomicInteger.compareAndSet(1, 2); System.out.println(Thread.currentThread().getName() + " ------ currentValue=" + currentValue + ", finalValue=" + atomicInteger.get() + ", compareAndSet Result=" + casResult); &#125; ); coreThread.start(); // 这段目的：为了让 coreThread 线程先跑起来 try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Thread amateurThread = new Thread( () -&gt; &#123; int currentValue = atomicInteger.get(); boolean casResult = atomicInteger.compareAndSet(1, 2); System.out.println(Thread.currentThread().getName() + " ------ currentValue=" + currentValue + ", finalValue=" + atomicInteger.get() + ", compareAndSet Result=" + casResult); currentValue = atomicInteger.get(); casResult = atomicInteger.compareAndSet(2, 1); System.out.println(Thread.currentThread().getName() + " ------ currentValue=" + currentValue + ", finalValue=" + atomicInteger.get() + ", compareAndSet Result=" + casResult); &#125; ); amateurThread.start(); &#125;&#125;## 原子类并发包 java.util.concurrent 的原子类都存放在java.util.concurrent.atomic。根据操作的数据类型，可以将JUC包中的原子类分为4类。### 基本类型使用原子的方式更新基本类型- AtomicInteger：整型原子类- AtomicLong：长整型原子类- AtomicBoolean ：布尔型原子类上面三个类提供的方法几乎相同，所以我们这里以 AtomicInteger 为例子来介绍。#### AtomicInteger 类常用方法1234567public final int get() //获取当前的值public final int getAndSet(int newValue)//获取当前的值，并设置新的值public final int getAndIncrement()//获取当前的值，并自增public final int getAndDecrement() //获取当前的值，并自减public final int getAndAdd(int delta) //获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。#### AtomicInteger 常见方法使用123456789101112131415public class AtomicIntegerTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int temvalue = 0; AtomicInteger i = new AtomicInteger(0); temvalue = i.getAndSet(3); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:0; i:3 temvalue = i.getAndIncrement(); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:3; i:4 temvalue = i.getAndAdd(5); System.out.println("temvalue:" + temvalue + "; i:" + i);//temvalue:4; i:9 &#125;&#125;#### AtomicInteger 线程安全原理简单分析123456789101112// setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value;AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。### 数组类型使用原子的方式更新数组里的某个元素- AtomicIntegerArray：整型数组原子类- AtomicLongArray：长整型数组原子类- AtomicReferenceArray ：引用类型数组原子类#### AtomicIntegerArray 类常用方法1234567public final int get(int i) //获取 index=i 位置元素的值public final int getAndSet(int i, int newValue)//返回 index=i 位置的当前的值，并将其设置为新值：newValuepublic final int getAndIncrement(int i)//获取 index=i 位置元素的值，并让该位置的元素自增public final int getAndDecrement(int i) //获取 index=i 位置元素的值，并让该位置的元素自减public final int getAndAdd(int delta) //获取 index=i 位置元素的值，并加上预期的值boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将 index=i 位置的元素值设置为输入值（update）public final void lazySet(int i, int newValue)//最终 将index=i 位置的元素设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。#### AtomicIntegerArray 常见方法使用1234567891011121314151617public class AtomicIntegerArrayTest &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int temvalue = 0; int[] nums = &#123; 1, 2, 3, 4, 5, 6 &#125;; AtomicIntegerArray i = new AtomicIntegerArray(nums); for (int j = 0; j &lt; nums.length; j++) &#123; System.out.println(i.get(j)); &#125; temvalue = i.getAndSet(0, 2); System.out.println("temvalue:" + temvalue + "; i:" + i); temvalue = i.getAndIncrement(0); System.out.println("temvalue:" + temvalue + "; i:" + i); temvalue = i.getAndAdd(0, 5); System.out.println("temvalue:" + temvalue + "; i:" + i); &#125;&#125;### 引用类型- AtomicReference：引用类型原子类- AtomicStampedReference：原子更新引用类型里的字段原子类- AtomicMarkableReference ：原子更新带有标记位的引用类型基本类型原子类只能更新一个变量，如果需要原子更新多个变量，需要使用引用类型原子类。#### AtomicReference 类使用示例123456789101112131415161718192021222324252627282930313233public class AtomicReferenceTest &#123; public static void main(String[] args) &#123; AtomicReference&lt;Person&gt; ar = new AtomicReference&lt;Person&gt;(); Person person = new Person("SnailClimb", 22); ar.set(person); Person updatePerson = new Person("Daisy", 20); ar.compareAndSet(person, updatePerson); System.out.println(ar.get().getName()); System.out.println(ar.get().getAge()); &#125;&#125;class Person &#123; private String name; private int age; public Person(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;上述代码首先创建了一个 Person 对象，然后把 Person 对象设置进 AtomicReference 对象中，然后调用 compareAndSet 方法，该方法就是通过通过 CAS 操作设置 ar。如果 ar 的值为 person 的话，则将其设置为 updatePerson。CAS操作中比较的是地址。#### AtomicStampedReference 类使用示例123456789101112131415161718192021222324252627282930313233343536373839public class AtomicStampedReferenceDemo &#123; public static void main(String[] args) &#123; // 实例化、取当前值和 stamp 值 final Integer initialRef = 0, initialStamp = 0; final AtomicStampedReference&lt;Integer&gt; asr = new AtomicStampedReference&lt;&gt;(initialRef, initialStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp()); // compare and set final Integer newReference = 666, newStamp = 999; final boolean casResult = asr.compareAndSet(initialRef, newReference, initialStamp, newStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp() + ", casResult=" + casResult); // 获取当前的值和当前的 stamp 值 int[] arr = new int[1]; final Integer currentValue = asr.get(arr); final int currentStamp = arr[0]; System.out.println("currentValue=" + currentValue + ", currentStamp=" + currentStamp); // 单独设置 stamp 值 final boolean attemptStampResult = asr.attemptStamp(newReference, 88); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp() + ", attemptStampResult=" + attemptStampResult); // 重新设置当前值和 stamp 值 asr.set(initialRef, initialStamp); System.out.println("currentValue=" + asr.getReference() + ", currentStamp=" + asr.getStamp()); &#125;&#125;/* currentValue=0, currentStamp=0 currentValue=666, currentStamp=999, casResult=true currentValue=666, currentStamp=999 currentValue=666, currentStamp=88, attemptStampResult=true currentValue=0, currentStamp=0*/### 对象的属性修改类型- AtomicIntegerFieldUpdater:原子更新整型字段的更新器- AtomicLongFieldUpdater：原子更新长整型字段的更新器- AtomicStampedReference ：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。- AtomicMarkableReference：原子更新带有标记的引用类型。该类将 boolean 标记与引用关联起来，也可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。要想原子地更新对象的属性需要两步。第一步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法 newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新的对象属性必须使用 public volatile 修饰符。上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerFieldUpdater为例子来介绍。#### 5.2 AtomicIntegerFieldUpdater 类使用示例12345678910111213141516171819202122232425262728293031public class AtomicIntegerFieldUpdaterTest &#123; public static void main(String[] args) &#123; AtomicIntegerFieldUpdater&lt;User&gt; a = AtomicIntegerFieldUpdater.newUpdater(User.class, "age"); User user = new User("Java", 22); System.out.println(a.getAndIncrement(user));// 22 System.out.println(a.get(user));// 23 &#125;&#125;class User &#123; private String name; public volatile int age; public User(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;## AQSJava并发包（JUC）中提供了很多并发工具，这其中，很多我们耳熟能详的并发工具，譬如ReentrangLock、Semaphore，它们的实现都用到了一个共同的基类–AbstractQueuedSynchronizer，简称AQS。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。AQS 原理概览AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。看个AQS(AbstractQueuedSynchronizer)原理图：AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。1private volatile int state;//共享变量，使用volatile修饰保证线程可见性状态信息通过protected类型的getState，setState，compareAndSetState进行操作123456789101112//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;AQS 对资源的共享方式Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：公平锁：按照线程在队列中的排队顺序，先到者先拿到锁非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在上层已经帮我们实现好了。AQS底层使用了模板方法模式同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用，下面简单的给大家介绍一下模板方法模式，模板方法模式是一个很容易理解的设计模式之一。模板方法模式是基于”继承“的，主要是为了在不改变模板结构的前提下在子类中重新定义模板中的内容以实现复用代码。举个很简单的例子假如我们要去一个地方的步骤是：购票buyTicket()-&gt;安检securityCheck()-&gt;乘坐某某工具回家ride()-&gt;到达目的地arrive()。我们可能乘坐不同的交通工具回家比如飞机或者火车，所以除了ride()方法，其他方法的实现几乎相同。我们可以定义一个包含了这些方法的抽象类，然后用户根据自己的需要继承该抽象类然后修改 ride()方法。AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：123456isHeldExclusively() //该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int) //独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int) //独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int) //共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数 //表示成功，且有剩余资源。tryReleaseShared(int) //共享方式。尝试释放资源，成功则返回true，失败则返回false。默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。acquire-releaseacquire(int)此方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。这也正是lock()的语义，当然不仅仅只限于lock()。获取到资源后，线程就可以去执行其临界区代码了。下面是acquire()的源码：12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;函数流程如下：tryAcquire()尝试直接去获取资源，如果成功则直接返回；addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；acquireQueued()使线程在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。tryAcquire(int)此方法尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。这也正是tryLock()的语义，还是那句话，当然不仅仅只限于tryLock()。如下是tryAcquire()的源码：123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;什么？直接throw异常？说好的功能呢？好吧，还记得概述里讲的AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现吗？就是这里了！！！AQS这里只定义了一个接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS）！！！至于能不能重入，能不能加塞，那就看具体的自定义同步器怎么去设计了！！！当然，自定义同步器在进行资源访问时要考虑线程安全的影响。这里之所以没有定义成abstract，是因为独占模式下只用实现tryAcquire-tryRelease，而共享模式下只用实现tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模式下的接口。说到底，Doug Lea还是站在咱们开发者的角度，尽量减少不必要的工作量。addWaiter(Node)此方法用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。还是上源码吧：123456789101112131415161718private Node addWaiter(Node mode) &#123; //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享） Node node = new Node(Thread.currentThread(), mode); //尝试快速方式直接放到队尾。 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //上一步失败则通过enq入队。 enq(node); return node;&#125;Node结点是对每一个访问同步代码的线程的封装，其包含了需要同步的线程本身以及线程的状态，如是否被阻塞，是否等待唤醒，是否已经被取消等。变量waitStatus则表示当前被封装成Node结点的等待状态，共有4种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE。CANCELLED：值为1，在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。SIGNAL：值为-1，被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消，将会通知该后继结点的线程执行。说白了，就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。CONDITION：值为-2，与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。PROPAGATE：值为-3，与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。0状态：值为0，代表初始化状态。AQS在判断状态时，通过用waitStatus&gt;0表示取消状态，而waitStatus&lt;0表示有效状态。enq(Node)12345678910111213141516private Node enq(final Node node) &#123; // CAS"自旋"，直到成功加入队尾 for (;;) &#123; Node t = tail; if (t == null) &#123; // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //正常流程，放入队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125;acquireQueued(Node, int)OK，通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了。聪明的你立刻应该能想到该线程下一部该干什么了吧：进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了。没错，就是这样！是不是跟医院排队拿号有点相似~~acquireQueued()就是干这件事：在等待队列中排队拿号（中间没其它事干可以休息），直到拿到号后再返回。这个函数非常关键，还是上源码吧：1234567891011121314151617181920212223242526final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true;//标记是否成功拿到资源 try &#123; boolean interrupted = false;//标记等待过程中是否被中断过 //又是一个“自旋”！ for (;;) &#123; final Node p = node.predecessor();//拿到前驱 //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。 p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！ failed = false; return interrupted;//返回等待过程中是否被中断过 &#125; //如果自己可以休息了，就进入waiting状态，直到被unpark() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;shouldParkAfterFailedAcquire(Node, Node)此方法主要用于检查状态，看看自己是否真的可以去休息了，万一队列前边的线程都放弃了只是瞎站着，那也说不定，对吧！1234567891011121314151617181920private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;//拿到前驱的状态 if (ws == Node.SIGNAL) //如果已经告诉前驱拿完号后通知自己一下，那就可以安心休息了 return true; if (ws &gt; 0) &#123; /* * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。 * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链，稍后就会被保安大叔赶走了(GC回收)！ */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;parkAndCheckInterrupt()如果线程找好安全休息点后，那就可以安心去休息了。此方法就是让线程去休息，真正进入等待状态。1234private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); //调用park()使线程进入waiting状态 return Thread.interrupted(); //如果被唤醒，查看自己是不是被中断的。&#125;park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程：被unpark()；被interrupt()。需要注意的是，Thread.interrupted()会清除当前线程的中断标记位。小结acquireQueued()分析完之后，我们接下来再回到acquire()！再贴上它的源码吧：12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125;再来总结下它的流程吧：调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。release(int)此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义，当然不仅仅只限于unlock()。下面是release()的源码：123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head;//找到头结点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒等待队列里的下一个线程 return true; &#125; return false;&#125;逻辑并不复杂。它调用tryRelease()来释放资源。有一点需要注意的是，它是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自定义同步器在设计tryRelease()的时候要明确这一点！！tryRelease(int)此方法尝试去释放指定量的资源。下面是tryRelease()的源码：123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。unparkSuccessor(Node)12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒&#125;这个函数并不复杂。一句话概括：用unpark()唤醒等待队列中最前边的那个未放弃线程，这里我们也用s来表示吧。此时，再和acquireQueued()联系起来，s被唤醒后，进入if (p == head &amp;&amp; tryAcquire(arg))的判断（即使p!=head也没关系，它会再进入shouldParkAfterFailedAcquire()寻找一个安全点。这里既然s已经是等待队列中最前边的那个未放弃线程了，那么通过shouldParkAfterFailedAcquire()的调整，s也必然会跑到head的next结点，下一次自旋p==head就成立啦），然后s把自己设置成head标杆结点，表示自己已经获取到资源了，acquire()也返回了！！And then, DO what you WANT!小结release()是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。acquireShared-releaseSharedacquireShared(int)此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。下面是acquireShared()的源码1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是：tryAcquireShared()尝试获取资源，成功则直接返回；失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回。doAcquireShared(int)1234567891011121314151617181920212223242526272829private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加入队列尾部 boolean failed = true;//是否成功标志 try &#123; boolean interrupted = false;//等待过程中是否被中断过的标志 for (;;) &#123; final Node p = node.predecessor();//前驱 if (p == head) &#123;//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的 int r = tryAcquireShared(arg);//尝试获取资源 if (r &gt;= 0) &#123;//成功 setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程 p.next = null; // help GC if (interrupted)//如果等待过程中被打断过，此时将中断补上。 selfInterrupt(); failed = false; return; &#125; &#125; //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;跟独占模式比，有一点需要注意的是，这里只有线程是head.next时（“老二”），才会去尝试获取资源，有剩余的话还会唤醒之后的队友。那么问题就来了，假如老大用完后释放了5个资源，而老二需要6个，老三需要1个，老四需要2个。老大先唤醒老二，老二一看资源不够，他是把资源让给老三呢，还是不让？答案是否定的！老二会继续park()等待其他线程释放资源，也更不会去唤醒老三和老四了。独占模式，同一时刻只有一个线程去执行，这样做未尝不可；但共享模式下，多个线程是可以同时执行的，现在因为老二的资源需求量大，而把后面量小的老三和老四也都卡住了。当然，这并不是问题，只是AQS保证严格按照入队顺序唤醒罢了（保证公平，但降低了并发）。setHeadAndPropagate12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node);//head指向自己 //如果还有剩余量，继续唤醒下一个邻居线程 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;此方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，毕竟是共享模式！doReleaseShared()我们留着下一小节的releaseShared()里来讲。小结至此，acquireShared()也要告一段落了。让我们再梳理一下它的流程：tryAcquireShared()尝试获取资源，成功则直接返回；失败则通过doAcquireShared()进入等待队列park()，直到被unpark()/interrupt()并成功获取到资源才返回。整个等待过程也是忽略中断的。其实跟acquire()的流程大同小异，只不过多了个自己拿到资源后，还会去唤醒后继队友的操作（这才是共享嘛）。releaseShared1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; //尝试释放资源 doReleaseShared(); //唤醒后继结点 return true; &#125; return false;&#125;此方法的流程也比较简单，一句话：释放掉资源后，唤醒后继。跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。doReleaseShared()123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head)// head发生变化 break; &#125;&#125;unparkSuccessor1234567891011121314private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125;MutexMutex是一个不可重入的互斥锁实现。锁资源（AQS里的state）只有两种状态：0表示未锁定，1表示锁定。下边是Mutex的核心源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Mutex implements Lock, java.io.Serializable &#123; // 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 判断是否锁定状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 尝试获取资源，立即返回。成功则返回true，否则false。 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // 这里限定只能为1个量 if (compareAndSetState(0, 1)) &#123;//state为0才设置为1，不可重入！ setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源 return true; &#125; return false; &#125; // 尝试释放资源，立即返回。成功则为true，否则false。 protected boolean tryRelease(int releases) &#123; assert releases == 1; // 限定为1个量 if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！ throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0);//释放资源，放弃占有状态 return true; &#125; &#125; // 真正同步类的实现都依赖继承于AQS的自定义同步器！ private final Sync sync = new Sync(); //lock&lt;--&gt;acquire。两者语义一样：获取资源，即便等待，直到成功才返回。 public void lock() &#123; sync.acquire(1); &#125; //tryLock&lt;--&gt;tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; //unlock&lt;--&gt;release。两者语文一样：释放资源。 public void unlock() &#123; sync.release(1); &#125; //锁是否占有状态 public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125;&#125;同步类在实现时一般都将自定义同步器（sync）定义为内部类，供自己使用；而同步类自己（Mutex）则实现某个接口，对外服务。当然，接口的实现要直接依赖sync，它们在语义上也存在某种对应关系！！而sync只用实现资源state的获取-释放方式tryAcquire-tryRelelase，至于线程的排队、等待、唤醒等，上层的AQS都已经实现好了，我们不用关心。Semaphoresynchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。示例代码如下：12345678910111213141516171819202122232425262728293031323334public class SemaphoreExample1 &#123; // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException &#123; // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); // 一次只能允许执行的线程数量。 final Semaphore semaphore = new Semaphore(20); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadnum = i; threadPool.execute(() -&gt; &#123;// Lambda 表达式的运用 try &#123; semaphore.acquire();// 获取一个许可，所以可运行线程数量为20/1=20 test(threadnum); semaphore.release();// 释放一个许可 &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); System.out.println("finish"); &#125; public static void test(int threadnum) throws InterruptedException &#123; Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println("threadnum:" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 &#125;&#125;Semaphore 有两种模式，公平模式和非公平模式。公平模式： 调用acquire的顺序就是获取许可证的顺序，遵循FIFO；非公平模式： 抢占式的。Semaphore 对应的两个构造方法如下：1234567public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125;源码解析Semaphore有两种模式，公平模式和非公平模式。公平模式就是调用acquire的顺序就是获取许可证的顺序，遵循FIFO；而非公平模式是抢占式的，也就是有可能一个新的获取线程恰好在一个许可证释放时得到了这个许可证，而前面还有等待的线程。构造方法123456public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125;从上面可以看到两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。Semaphore内部基于AQS的共享模式，所以实现都委托给了Sync类。这里就看一下NonfairSync的构造方法：123NonfairSync(int permits) &#123; super(permits);&#125;可以看到直接调用了父类的构造方法，Sync的构造方法如下：123Sync(int permits) &#123; setState(permits);&#125;可以看到调用了setState方法，也就是说AQS中的资源就是许可证的数量。获取许可先从获取一个许可看起，并且先看非公平模式下的实现。首先看acquire方法，acquire方法有几个重载，但主要是下面这个方法：1234public void acquire(int permits) throws InterruptedException &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.acquireSharedInterruptibly(permits);&#125;从上面可以看到，调用了Sync的acquireSharedInterruptibly方法，该方法在父类AQS中，如下：123456789public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //如果线程被中断了，抛出异常 if (Thread.interrupted()) throw new InterruptedException(); //获取许可失败，将线程加入到等待队列中 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;AQS子类如果要使用共享模式的话，需要实现tryAcquireShared方法，下面看NonfairSync的该方法实现：123456789101112131415protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);&#125;final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; //获取剩余许可数量 int available = getState(); //计算给完这次许可数量后的个数 int remaining = available - acquires; //如果许可不够或者可以将许可数量重置的话，返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;从上面可以看到，只有在许可不够时返回值才会小于0，其余返回的都是剩余许可数量，这也就解释了，一旦许可不够，后面的线程将会阻塞。看完了非公平的获取，再看下公平的获取，代码如下：12345678910111213protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; //如果前面有线程再等待，直接返回-1 if (hasQueuedPredecessors()) return -1; //后面与非公平一样 int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125;从上面可以看到，FairSync与NonFairSync的区别就在于会首先判断当前队列中有没有线程在等待，如果有，就老老实实进入到等待队列；而不像NonfairSync一样首先试一把，说不定就恰好获得了一个许可，这样就可以插队了。看完了获取许可后，再看一下释放许可。释放许可1234public void release(int permits) &#123; if (permits &lt; 0) throw new IllegalArgumentException(); sync.releaseShared(permits);&#125;releaseShared方法在AQS中，如下：12345678public final boolean releaseShared(int arg) &#123; //如果改变许可数量成功 if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;AQS子类实现共享模式的类需要实现tryReleaseShared类来判断是否释放成功，实现如下：12345678910111213protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; //获取当前许可数量 int current = getState(); //计算回收后的数量 int next = current + releases; if (next &lt; current) // overflow throw new Error("Maximum permit count exceeded"); //CAS改变许可数量成功，返回true if (compareAndSetState(current, next)) return true; &#125;&#125;从上面可以看到，一旦CAS改变许可数量成功，那么就会调用doReleaseShared()方法释放阻塞的线程。CountDownLatchCountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程的操作执行完后再执行。CountDownLatch 的三种典型用法某一线程在开始运行前等待n个线程执行完毕。将 CountDownLatch 的计数器初始化为n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown()，当计数器的值变为0时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。死锁检测：一个非常方便的使用场景是，你可以使用n个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。CountDownLatch 的使用示例1234567891011121314151617181920212223242526272829303132public class CountDownLatchExample1 &#123; // 请求的数量 private static final int threadCount = 550; public static void main(String[] args) throws InterruptedException &#123; // 创建一个具有固定线程数量的线程池对象（如果这里线程池的线程数量给太少的话你会发现执行的很慢） ExecutorService threadPool = Executors.newFixedThreadPool(300); final CountDownLatch countDownLatch = new CountDownLatch(threadCount); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadnum = i; threadPool.execute(() -&gt; &#123;// Lambda 表达式的运用 try &#123; test(threadnum); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; countDownLatch.countDown();// 表示一个请求已经被完成 &#125; &#125;); &#125; countDownLatch.await(); threadPool.shutdown(); System.out.println("finish"); &#125; public static void test(int threadnum) throws InterruptedException &#123; Thread.sleep(1000);// 模拟请求的耗时操作 System.out.println("threadnum:" + threadnum); Thread.sleep(1000);// 模拟请求的耗时操作 &#125;&#125;上面的代码中，我们定义了请求的数量为550，当这550个请求被处理完成之后，才会执行System.out.println(&quot;finish&quot;);。与CountDownLatch的第一次交互是主线程等待其他线程。主线程必须在启动其他线程后立即调用CountDownLatch.await()方法。这样主线程的操作就会在这个方法上阻塞，直到其他线程完成各自的任务。其他N个线程必须引用闭锁对象，因为他们需要通知CountDownLatch对象，他们已经完成了各自的任务。这种通知机制是通过 CountDownLatch.countDown()方法来完成的；每调用一次这个方法，在构造函数中初始化的count值就减1。所以当N个线程都调 用了这个方法，count的值等于0，然后主线程就能通过await()方法，恢复执行自己的任务。CountDownLatch 的不足CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。CyclicBarrier(循环栅栏)CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。CyclicBarrier 的应用场景CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个Excel保存了用户所有银行流水，每个Sheet保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的日均银行流水，最后，再用barrierAction用这些线程的计算结果，计算出整个Excel的日均银行流水。CyclicBarrier 的使用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class CyclicBarrierExample2 &#123; // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws InterruptedException &#123; // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public static void test(int threadnum) throws InterruptedException, BrokenBarrierException &#123; System.out.println("threadnum:" + threadnum + "is ready"); try &#123; /**等待60秒，保证子线程完全执行结束*/ cyclicBarrier.await(); &#125; catch (Exception e) &#123; System.out.println("-----CyclicBarrierException------"); &#125; System.out.println("threadnum:" + threadnum + "is finish"); &#125;&#125;/* threadnum:0is ready threadnum:1is ready threadnum:2is ready threadnum:3is ready threadnum:4is ready threadnum:4is finish threadnum:0is finish threadnum:1is finish threadnum:2is finish threadnum:3is finish threadnum:5is ready threadnum:6is ready threadnum:7is ready threadnum:8is ready threadnum:9is ready threadnum:9is finish threadnum:5is finish threadnum:8is finish threadnum:7is finish threadnum:6is finish ......*/可以看到当线程数量也就是请求数量达到我们定义的 5 个的时候， await方法之后的方法才被执行。另外，CyclicBarrier还提供一个更高级的构造函数CyclicBarrier(int parties, Runnable barrierAction)，用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。示例代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class CyclicBarrierExample3 &#123; // 请求的数量 private static final int threadCount = 550; // 需要同步的线程数量 private static final CyclicBarrier cyclicBarrier = new CyclicBarrier(5, () -&gt; &#123; System.out.println("------当线程数达到之后，优先执行------"); &#125;); public static void main(String[] args) throws InterruptedException &#123; // 创建线程池 ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 0; i &lt; threadCount; i++) &#123; final int threadNum = i; Thread.sleep(1000); threadPool.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public static void test(int threadnum) throws InterruptedException, BrokenBarrierException &#123; System.out.println("threadnum:" + threadnum + "is ready"); cyclicBarrier.await(); System.out.println("threadnum:" + threadnum + "is finish"); &#125;&#125;/* threadnum:0is ready threadnum:1is ready threadnum:2is ready threadnum:3is ready threadnum:4is ready ------当线程数达到之后，优先执行------ threadnum:4is finish threadnum:0is finish threadnum:2is finish threadnum:1is finish threadnum:3is finish threadnum:5is ready threadnum:6is ready threadnum:7is ready threadnum:8is ready threadnum:9is ready ------当线程数达到之后，优先执行------ threadnum:9is finish threadnum:5is finish threadnum:6is finish threadnum:8is finish threadnum:7is finish ......*/CyclicBarrier和CountDownLatch的区别CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用。但是我不那么认为它们之间的区别仅仅就是这么简单的一点。我们来从jdk作者设计的目的来看，javadoc是这么描述它们的：CountDownLatch: A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes.(CountDownLatch: 一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；)CyclicBarrier : A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point.(CyclicBarrier : 多个线程互相等待，直到到达同一个同步点，再继续一起执行。)对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。CopyOnWriteArrayList在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问List的内部数据，毕竟读取操作是安全的。CopyOnWriteArrayList 类的所有可变操作（add，set等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。1234567891011private transient volatile Object[] array;public E get(int index) &#123; return get(getArray(), index);&#125;@SuppressWarnings("unchecked")private E get(Object[] a, int index) &#123; return (E) a[index];&#125;final Object[] getArray() &#123; return array;&#125;CopyOnWriteArrayList 写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock();//加锁 try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组 newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock();//释放锁 &#125;&#125;ConcurrentLinkedQueueConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。ConcurrentLinkedQueue由head节点和tail节点组成，每个节点（Node）由节点元素（item）和指向下一个节点的引用(next)组成，节点与节点之间就是通过这个next关联起来，从而组成一张链表结构的队列。我们前面介绍了，ConcurrentLinkedQueue的节点都是Node类型的：12345678910111213141516171819202122232425262728293031private static class Node&lt;E&gt; &#123; volatile E item; volatile Node&lt;E&gt; next; Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("item")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("next")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125;Node类也比较简单，不再解释，ConcurrentLinkedQueue类有下面两个构造方法：12345678910111213141516171819202122232425// 默认构造方法，head节点存储的元素为空，tail节点等于head节点public ConcurrentLinkedQueue() &#123; head = tail = new Node&lt;E&gt;(null);&#125;// 根据其他集合来创建队列public ConcurrentLinkedQueue(Collection&lt;? extends E&gt; c) &#123; Node&lt;E&gt; h = null, t = null; // 遍历节点 for (E e : c) &#123; // 若节点为null，则直接抛出NullPointerException异常 checkNotNull(e); Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); if (h == null) h = t = newNode; else &#123; t.lazySetNext(newNode); t = newNode; &#125; &#125; if (h == null) h = t = new Node&lt;E&gt;(null); head = h; tail = t;&#125;默认情况下head节点存储的元素为空，tail节点等于head节点。入队操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546public boolean add(E e) &#123; return offer(e);&#125; public boolean offer(E e) &#123; // 如果e为null，则直接抛出NullPointerException异常 checkNotNull(e); // 创建入队节点 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); // 循环CAS直到入队成功 // 1、根据tail节点定位出尾节点（last node）；2、将新节点置为尾节点的下一个节点；3、casTail更新尾节点 for (Node&lt;E&gt; t = tail, p = t;;) &#123; // p用来表示队列的尾节点，初始情况下等于tail节点 // q是p的next节点 Node&lt;E&gt; q = p.next; // 判断p是不是尾节点，tail节点不一定是尾节点，判断是不是尾节点的依据是该节点的next是不是null // 如果p是尾节点 if (q == null) &#123; // p is last node // 设置p节点的下一个节点为新节点，设置成功则casNext返回true；否则返回false，说明有其他线程更新过尾节点 if (p.casNext(null, newNode)) &#123; // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become "live". // 如果p != t，则将入队节点设置成tail节点，更新失败了也没关系，因为失败了表示有其他线程成功更新了tail节点 if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; &#125; // Lost CAS race to another thread; re-read next &#125; // 多线程操作时候，由于poll时候会把旧的head变为自引用，然后将head的next设置为新的head // 所以这里需要重新找新的head，因为新的head后面的节点才是激活的节点 else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; // 寻找尾节点 else // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125;源代码角度来看整个入队过程主要做两件事情：第一是定位出尾节点。tail节点并不总是尾节点，所以每次入队都必须先通过tail节点来找到尾节点，尾节点可能就是tail节点，也可能是tail节点的next节点。代码中循环体中的第一个if就是判断tail是否有next节点，有则表示next节点可能是尾节点。获取tail节点的next节点需要注意的是p节点等于q节点的情况，出现这种情况的原因我们后续再来介绍。第二是使用CAS算法能将入队节点设置成尾节点的next节点，如不成功则重试。p.casNext(null, newNode)方法用于将入队节点设置为当前队列尾节点的next节点，q如果是null表示p是当前队列的尾节点，如果不为null表示有其他线程更新了尾节点，则需要重新获取当前队列的尾节点。tail节点不一定为尾节点的设计意图ConcurrentHashMap]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-分布式]]></title>
    <url>%2F2019%2F06-%E5%88%86%E5%B8%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[分布式系统我们先来介绍一下，为什么要分布式？随着大型网站的各种高并发访问、海量数据处理等场景越来越多，如何实现网站的高可用、易伸缩、可扩展、安全等目标就显得越来越重要。为了解决这样一系列问题，大型网站的架构也在不断发展。提高大型网站的高可用架构，不得不提的就是分布式。集中式系统用一句话概括就是：一个主机带多个终端。终端没有数据处理能力，仅负责数据的录入和输出。而运算、存储等全部在主机上进行。现在的银行系统，大部分都是这种集中式的系统，此外，在大型企业、科研单位、军队、政府等也有分布。集中式系统，主要流行于上个世纪。集中式系统的最大的特点就是部署结构非常简单，底层一般采用从IBM、HP等厂商购买到的昂贵的大型主机。因此无需考虑如何对服务进行多节点的部署，也就不用考虑各节点之间的分布式协作问题。但是，由于采用单机部署。很可能带来系统大而复杂、难于维护、发生单点故障（单个点发生故障的时候会波及到整个系统或者网络，从而导致整个系统或者网络的瘫痪）、扩展性差等问题。对于淘宝，腾讯等亿级用户量以及复杂的业务逻辑，且不说耦合严重，难于维护，单是这么庞大的并发量，集中式机构根本扛不住，所以就得需要进行分布式了，从2009年开始，阿里就启动了去“IOE”计划，其电商系统正式迈入分布式系统时代。分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。可以将不同的业务模块，数据进行水平切分部署。分布式意味着可以采用更多的普通计算机（相对于昂贵的大型机）组成分布式集群对外提供服务。计算机越多，CPU、内存、存储资源等也就越多，能够处理的并发访问量也就越大。分布式因为网络的不确定性，节点故障等情况，会带来各种复杂的问题。我们在学习分布式的相关理论时，一定要明确这样一个道理，就是：网络不可靠，网络分区以及节点宕机是常态，另外网络带宽资源是及其珍贵的，我们必须在网络不可靠、分区以及节点宕机的前提下，构建高性能、高可用的分布式系统。分布式环境的问题通信异常：从集中式向分布式演变过程中，必然会引入网络因素，而由于网络本身的不可靠性，因此也引入了额外的问题。分布式系统需要在各个节点之间进行网络通信，因此当网络通信设备故障就会导致无法顺利完成一次网络通信，就算各节点的网络通信正常，但是消息丢失和消息延时也是非常普遍的事情。网络分区（脑裂）：网络发生异常情况导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点，只有部分节点能够正常通行，而另一些节点则不能。我们称这种情况叫做网络分区（脑裂），当网络分区出现时，分布式系统会出现多个局部小集群（多个小集群可能又会产生多个master节点），所以分布式系统要求这些小集群要能独立完成原本需要整个分布式系统才能完成的功能，这就对分布式一致性提出了非常大的挑战。节点故障：节点宕机是分布式环境中的常态，每个节点都有可能会出现宕机或僵死的情况，并且每天都在发生。三态：由于网络不可靠的原因，因此分布式系统的每一次请求，都存在特有的“三态”概念，即：成功，失败与超时。在集中式单机部署中，由于没有网络因素，所以程序的每一次调用都能得到“成功”或者“失败”的响应，但是在分布式系统中，网络不可靠，可能就会出现超时的情况。可能在消息发送时丢失或者在响应过程中丢失，当出现超时情况时，网络通信的发起方是无法确定当前请求是否被成功处理的，所以这也是分布式事务的难点。分布式数据一致性在上面，我们介绍了一下分布式和分布式下的一些问题，接下来，我们要讨论，为什么会出现分布式数据一致性问题。因为在分布式系统中，节点宕机是常态，为了高可用性，我们一般会部署多台服务器，势必就会存在数据的复制问题。分布式系统对于数据的复制需求一般来自于以下两个原因：高可用：将数据复制到分布式部署的多台机器中，可以消除单点故障，防止系统由于某台（些）机器宕机导致的不可用。性能：通过负载均衡技术，能够让分布在不同地方的数据副本全都对外提供服务。有效提高系统性能。在分布式系统引入复制机制后，不同的数据节点之间由于网络延时等原因很容易产生数据不一致的情况。复制机制的目的是为了保证数据的一致性。但是数据复制面临的主要难题也是如何保证多个副本之间的数据一致性。对分布式数据一致性简单的解释就是：当对集群中一个副本数据进行更新的同时，必须确保能够同步更新到其他副本，否则不同副本之间的数据将不再一致。举个例子来说就是：当客户端C1将系统中的一个值K由V1更新为V2，但是客户端C2读的是另一个还没有同步更新的副本，K的值依然是V1，就导致了数据的不一致性。其中，常见的就是主从数据库之间的复制延时问题。CAP理论在介绍CAP理论时，我们首先介绍一下分布式事务的概念：分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点上。通常一个分布式事务会涉及对多个数据源或者业务系统的操作。对于本地事务处理或者集中式的事务处理系统，我们可以采用ACID模型来保证数据的严格一致性（事务概念上的）。在分布式系统中，当我们要求分布式系统具有严格一致性时，很可能就需要牺牲掉系统的可用性。如何构建一个兼顾可用性和一致性的分布式系统成为无数工程师探讨的问题，所以出现了诸如CAP和BASE这样的分布式系统经典理论。CAP是Consistency、Availablity和Partition-tolerance的缩写。分别是指：一致性（Consistency）：每次读操作都能保证返回的是最新数据，在分布式系统中，如果能针对一个数据项的更新执行成功后，所有的用户都可以读到其最新的值，这样的系统就被认为具有严格的一致性。可用性（Availablity）：任何一个没有发生故障的节点，会在合理的时间内返回一个正常的结果，也就是对于用户的每一个请求总是能够在有限的时间内返回结果；分区容忍性（Partition-torlerance）：当节点间出现网络分区（不同节点处于不同的子网络，子网络之内是联通的，但是子网络之间是无法联通的，也就是被切分成了孤立的集群网络），照样可以提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。CAP理论指出：CAP三者只能取其二，不可兼得。我们可以分析一下为什么会这样：CA满足的情况下，P不能满足的原因：数据同步(C)需要时间，也要正常的时间内响应(A)，那么机器数量就要少，所以P就不满足。CP满足的情况下，A不能满足的原因：数据同步(C)需要时间, 机器数量也多(P)，但是同步数据需要时间，所以不能再正常时间内响应，所以A就不满足AP满足的情况下，C不能满足的原因：机器数量也多(P)，正常的时间内响应(A)，那么数据就不能及时同步到其他节点，所以C不满足。所以我们必须明确一点：对于分布式系统而言，分区容错性是必须要满足的，因为分区的出现时必然，也是必须要解决的问题。所以，P必须要保证，那么我们就要在C和A之间做权衡。BASE理论在上边，我们谈到，因为P总是存在的，放弃不了。另外，可用性、一致性也是我们一般系统必须要满足的，如何在可用性和一致性进行权衡，所以就出现了各种一致性的理论与算法。BASE理论是：BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性(Strong consistency)，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性(Eventual consistency)。在《从Paxos到Zookeeper分布式一致性原理与实践》这本书中，介绍了相关BASE理论：基本可用：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用。以下两个就是“基本可用”的典型例子。响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1～2秒。功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。弱状态：弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。最终一致性：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。（注意：最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟、系统负载和数据复制方案设计等因素。）在实际工程实践中，最终一致性存在以下五类主要变种。因果一致性（Causal consistency）：因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。读己之所写（Read your writes）：读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。会话一致性（Session consistency）：会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更能操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。单调读一致性（Monotonic read consistency）：单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。单调写一致性（Monotonic write consistency）：单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。事实上，最终一致性并不是只有那些大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制过程通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致（强一致性）。而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的数据将是旧的，因此就出现了数据不一致的情况。当然，无论是采用多次重试还是人为数据订正，关系型数据库还是能够保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。2PC &amp; 3PC正是由于在系统的可用性和数据一致性之间反复的权衡，于是出现了一系列的一致性协议，如2PC，3PC，paxos算法等。本节先介绍两个最常见的分布式一致性算法：两阶段提交（2PC），三阶段提交（3PC）以及它们的相关应用。在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-JavaWeb和SSM]]></title>
    <url>%2F2019%2F05-JavaWeb%E5%92%8CSSM%2F</url>
    <content type="text"><![CDATA[Tomcat的结构## HTTP请求HTTP请求共有DELETE、HEAD、GET、OPTIONS、POST、PUT、TRACE和CONNECT八种请求方式。## HTTP响应## ServletServlet是指任何实现了Servlet接口的类。一般情况下Servlet用来扩展基于HTTP协议的Web服务器，它可以接受和响应通过HTTP协议从客户端发过来的信息。Servlet是一个类，但Servlet类的对象是由Web服务器创建的，不是由开发者创建的。并且多个客户端访问同一个Servlet时只会创建一个Servlet对象。### Servlet的方法Servlet有5个方法：1. void init(ServletConfig config)：在服务器创建 Servlet对象时执行。2. void destroy() ：在服务器关闭时调用。3. ServletConfig getServletConfig() ：返回一个ServletConfig对象。4. String getServletInfo() ：得到Servlet的信息。如作者、版本等。5. void service(ServletRequest req, ServletResponse res) ：被服务器调用去获得和响应从服务器发来的请求。### Servlet对象的生命周期1. Servlet何时创建：默认第一次访问Servlet时创建该对象。2. Servlet何时销毁：服务器关闭Servlet就销毁了。3. 每次访问必然执行的方法：service(ServletRequest req, ServletResponse res)方法### Servlet访问过程浏览器中输入的URL会被浏览器封装成HTTP请求发送给服务器。Tomcat收到从客户端发来的时候解析HTTP请求中的资源地址，然后创建代表请求的requset和代表响应的response对象，再把这两个对象作为参数去调用service()方法。## ServletConfig代表当前Servlet在web.xml中的配置信息。当Servlet配置了初始化参数后，web容器在创建Servlet实例对象时，会自动将这些初始化参数封装到ServletConfig对象中，并在调用Servlet的init方法时，将ServletConfig对象传递给Servlet。进而，程序员通过ServletConfig对象就可以得到当前Servlet的初始化参数信息。这样做的好处是：如果将数据库信息、编码方式等配置信息放在web.xml中，如果以后数据库的用户名、密码改变了，则直接很方便地修改web.xml就行了，避免了直接修改源代码的麻烦。最大的用处是获得ServletContext对象。## HttpServlet开发在开发的时候一般不直接实现Servlet来获取和响应从客户端发来的信息，而是继承Servlet接口的实现类HttpServlet。因为从客户端发来的请求和响应都是基于HTTP协议的，HttpServlet就是用于HTTP协议请求和响应的实现类，继承httpServlet后再覆盖某些方法进行开发即可。### 继承HttpServlet进行开发服务器会调用Servlet接口的service()方法，由于多态原则，真正被调用的方法是HttpServlet类的service()方法。HttpServlet类为每种请求方式都设置单独的处理方法，但我们使用的一般使用的是GET和POST请求方式，所以我们只需要覆盖doGet()和doPost()方法即可。这是因为HttpServlet()的service()方法中可以调用每种请求方式的方法，我们覆盖doGet()和doPost()就可以达到功能性需求。123456789101112131415161718@WebServlet("/TestServlet")public class TestServlet extends HttpServlet &#123; private static final long serialVersionUID = 1L; public TestServlet() &#123; super(); &#125; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // ... &#125; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125;### web.xml配置必须配置的参数有Servlet还不行，Web服务器不能直接通过类名访问Servlet，必须通过一个虚拟路径来访问这个Servlet，所以要对Servlet进行配置。配置在web.xml文件中进行。举例说明：12345678&lt;servlet&gt; &lt;servlet-name&gt;Begin&lt;/servlet-name&gt; &lt;servlet-class&gt;com.servlet.begin.Begin&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;Begin&lt;/servlet-name&gt; &lt;url-pattern&gt;/begin&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;当浏览器中地址输入为：…/begin，然后Tomcat去找此项目下虚拟路径为/begin对应的servlet-name，找到servlet-name后映射到servlet配置中找到它所对应的类com.servlet.begin.Begin。mapping在集合里指的是映射，在此指的也是映射。servlet-mapping里的Begin相当于Key。servlet里的servlet-class相当于Value。总结来说，servlet和servlet-mapping里的servlet-name必须一致，url-pattern是浏览器输入的地址，servlet-class是对访问做出处理的类。可选配置的参数1. load-on-startup：&lt;load-on-startup&gt;x&lt;/load-on-startup&gt;，x大于等于1的时候表示在服务器启动的时候就创建Servlet对象。2. 缺省Servlet：可以将url-pattern配置为’/’，代表该servlet是缺省的servlet，也就是当访问资源地址与所有的Servlet都不匹配时，有缺省的servlet负责处理，就是传说中的404界面。### url-pattern的三种匹配1. 完全匹配：访问的资源与配置的资源完全相同才能访问到。2. 目录匹配：格式：/虚拟的目录../*。如：…/abc/*表示当输入路径…/abc/xxx的xxx为任意的时候都可以访问的到。3. 拓展名匹配：格式：*.扩展名。如：*.abcd表示输入路径为…/xxx.abcd的xxx为任意的时候都能访问。在某路径下进行拓展名匹配是错误的，如：/aaa/bbb/*.abcd（错误的）## HttpServletResponseHttpServletResponse是一个接口，封装了向客户端输出信息的方法，部分方法如下：1. void setStatus(int sc)：设置响应状态码；2. void setHeader(String name, String data)：设置响应头；3. ServletOutputStream getOutputStream()：返回一个输出流对象；4. PrintWriter getWriter()：返回一个打印流对象。### HttpServletResponse的执行过程HttpServletResponse是向客户端输出信息的接口，但它的对象（设为response）不是直接把信息输出给浏览器，也不是直接输出给服务器。response会把要输出的信息输出到response的缓冲区，然后服务器拿到缓冲区的数据后再添加一些数据组成HTTP响应发送给客户端。### 重定向重定向的过程需要两次访问Servlet。当浏览器访问到重定向的Servlet时此Servlet会返回一个302的状态码和重定向的地址。代码会有两句：1. response.setStatus(int sc);2. response.setHeader(“location”, “要跳转的地址”);但Java把这两步进行了封装，response.sendRedirect(“要跳转的地址”);。### 定时刷新使用setHeader()。response.setHeader(“refresh”, “3”);表示这个页面3秒后会被刷新。还可以指定URL跳转到其他页面（URL可以带数据，所以是GET方式跳转）：1response.setHeader(“refresh”, “3;url=https:www.baidu.com”)### 输出乱码的解决1. 设置response缓冲区：response缓冲区的默认编码是iso8859-1，设置为UTF-8编码需要使用：response.setCharacterEncoding(String charset);2. 设置浏览器编码：浏览器默认使用GBK编码，但缓冲区设置的是UTF-8编码，仍然有乱码问题存在：response.setContentType(&quot;text/html;charset=UTF-8&quot;);3. 一键解决缓冲区和浏览器问题：仍然是response.setContentType(&quot;text/html;charset=UTF-8&quot;);此方法默认包含了response.setCharacterEncoding(String charset);。## ServletContext域对象ServletContext类的对象（后续servletContext特指ServletContext类对象）是域对象，就是说这个对象可以进行数据的存取操作，它的作用范围是所有的Servlet。方法如下：1. void setAttribute(String name, Object o)2. String getAttribute(String name)3. void removeAttribute(String name)## HttpServletRequestHttpServletRequest是一个接口，封装了获取浏览器发来的信息的方法。部分方法如下：1. String getMethod()：获得请求方式；2. String getHeader(String name)：获取某请求头的Value；3. String getParameter(String name)：获得提交时的某参数的Value；4. String getRemoteAddr()：获得客户端的IP地址；5. String getContextPath()：获得web应用的名称；### 提交乱码解决1. POST方式：request.setCharacterEncoding(&quot;UTF-8&quot;);2. GET方式：- 假设接收到的参数为param，在使用之前加上：1param = new String(param.getBytes(&quot;iso8859-1&quot;),&quot;utf-8&quot;);- 修改server.xml文件：补上此句HttpServletRequest域对象HttpServletRequest接口的对象引用（request特指HttpServletRequest接口的对象引用）同时也是域对象，就是说这个对象可以进行数据的存取操作，它的作用范围是一次http请求，当此次请求结束（返回一个response时）。方法如下：void setAttribute(String name, Object o)String getAttribute(String name)void removeAttribute(String name)请求转发当客户端请求某个Servlet的时候，此Servlet交给别的Servlet解决叫做请求转发。请求转发分为两步：获得转发器：RequestDispatcher rd = request.getRequestDispatcher(String path)转发的时候携带请求和响应：rd.forward(ServletRequest request, ServletResponse response)辨析重定向和请求转发重定向是两次请求服务器，请求转发只有一次请求服务器。重定向可以访问外部资源，转发只能访问内部资源。图解：转发的路径：项目中的url-pattern重定向的路径：项目名+项目中的url-pattern会话技术客户端访问服务器的时候，服务器并不知道客户端是谁，因为HTTP协议是无状态的。也就是说A把商品a加入购物车后关闭浏览器之后再来访问服务器时服务器分不出来是不是A访问了服务器。而会话技术就是帮助服务器区分客户端的。用户打开浏览器，访问Web服务器上多个资源，然后关闭浏览器，整个过程称之为一次会话。会话技术分为：Cookie和Session。CookieCookie技术是将用户状态的数据存储到客户端的技术。主要方法如下：创建Cookie（不能保存中文信息）：Cookie c = new Cookie(String name, String value);设置Cookie在客户端的持久化时间，无持久化时间Cookie在关闭浏览器时信息会销毁： c.setMaxAge(int seconds);，时间秒。设置Cookie的携带路径，如果不设置携带路径，那么该Cookie信息会在访问产生该Cookie的 web资源所在的路径都携带Cookie信息，如：cookie.setPath(&quot;/WEB&quot;); 代表访问WEB应用中的任何资源都携带该Cookiecookie.setPath(&quot;/WEB/cookieServlet&quot;); 代表访问WEB中的cookieServlet时才携带Cookie信息向客户端发送Cookie：response.addCookie(Cookie cookie);删除客户端的Cookie：使用同名同路径且持久化时间为0的Cookie覆盖。服务器获得客户端携带的Cookie：满足条件的Cookie会被自动以请求头的方式发送到服务器端。获得某一Cookie的内容需要两步：通过request获得所有的Cookie：Cookie[] cookies = request.getCookies();遍历Cookie数组，通过Cookie的名称获得我们想要的Cookie：12345for(Cookie cookie : cookies)&#123; if(cookie.getName().equal(cookieName))&#123; String cookieValue = cookie.getValue(); &#125;&#125;SessionSession技术是将用户状态的数据存储到服务器端的技术。服务器会为每个客户端都创建一块内存空间 存储客户的数据，但客户端需要每次都携带一个标识ID（通过Cookie储存在客户端，在Tomcat中叫做JSESSIONID）去服务器中寻找属于自己的内 存空间。同时由于Session具有存储数据的功能，也是一个域对象。主要方法如下：获得Session对象：HttpSession session = request.getSession();。此方法会获得专属于当前会话的Session对象，如果服务器端没有该会话的Session对象会创建一个新的Session返回，如果已经有了属于该会话的Session直接将已有的Session返回（实质就是根据JSESSIONID判断该客户端是否在服务器上已经存在session了）向Session中存储数据：session.setAttribute(String name, Object obj);从Session中获得数据：session.getAttribute(String name);移除Session中某名称的值：session.removeAttribute(String name);Session域的声明周期创建：第一次执行request.getSession()时创建。销毁：默认情况下在客户端不再操作服务器端资源时30分钟后session过期。手动销毁session： session.invalidate();也可以在工程的web.xml中进行配置来修改默认过期时间：123&lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt;&lt;/session-config&gt;作用范围：一次会话中任何资源公用一个session对象。获得各种路径## 过滤器12345678910111213141516171819202122232425262728293031323334353637383940@WebFilter(urlPatterns = "/api/*", filterName = "loginFilter")public class LoginFilter implements Filter &#123; /** * 容器加载的时候调用 */ @Override public void init(FilterConfig filterConfig) throws ServletException &#123; System.out.println("init loginFilter"); &#125; /** * 请求被拦截的时候进行调用 */ @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; System.out.println("doFilter loginFilter"); HttpServletRequest req = (HttpServletRequest) servletRequest; HttpServletResponse resp = (HttpServletResponse) servletResponse; String username = req.getParameter("username"); if ("xdclass".equals(username)) &#123; filterChain.doFilter(servletRequest, servletResponse); &#125; else &#123; resp.sendRedirect("/index.html"); return; &#125; &#125; /** * 容器被销毁的时候被调用 */ @Override public void destroy() &#123; System.out.println("destroy loginFilter"); &#125;&#125;多个过滤器的执行顺序是按照filterName按字典排序执行。| 属性名 | 类型 | 描述 || ————— | ————– | ———————————————————— || filterName | String | 指定过滤器的 name 属性，等价于&lt;filter-name&gt; || value | String[] | 该属性等价于 urlPatterns 属性。但是两者不应该同时使用。 || urlPatterns | String[] | 指定一组过滤器的 URL 匹配模式。等价于&lt;url-pattern&gt;标签。 || servletNames | String[] | 指定过滤器将应用于哪些 Servlet。取值是 @WebServlet 中的 name 属性的取值，或者是 web.xml 中&lt;servlet-name&gt;的取值。 || dispatcherTypes | DispatcherType | 指定过滤器的转发模式。具体取值包括： ASYNC、ERROR、FORWARD、INCLUDE、REQUEST。 || initParams | WebInitParam[] | 指定一组过滤器初始化参数，等价于&lt;init-param&gt;标签。 || asyncSupported | boolean | 声明过滤器是否支持异步操作模式，等价于&lt;async-supported&gt; 标签。 || description | String | 该过滤器的描述信息，等价于&lt;description&gt;标签。 || displayName | String | 该过滤器的显示名，通常配合工具使用，等价于&lt;display-name&gt;标签。 |## 监听器常用的监听器 servletContextListener、httpSessionListener、servletRequestListener。都是接口。123456789101112@WebListenerpublic class RequestListener implements ServletRequestListener &#123; @Override public void requestDestroyed(ServletRequestEvent sre) &#123; System.out.println("======requestDestroyed========"); &#125; @Override public void requestInitialized(ServletRequestEvent sre) &#123; System.out.println("======requestInitialized========"); &#125;&#125;## JDBCJava Database Connectivity，Java数据库连接。是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。JDBC提供了一种基准，据此可以构建更高级的工具和接口，使数据库开发人员能够编写数据库应用程序，所以说，JDBC对Java程序员而言是API，对实现与数据库连接的服务提供商而言是接口模型。作为API，JDBC为程序开发提供标准的接口，并为数据库厂商及第三方中间件厂商实现与数据库的连接提供了标准方法。数据库并不是Java提供的，所以在Java中如果想连接数据库，肯定需要使用第三方jar包，这些jar包是数据库厂商根据JDBC接口模型开发的自己数据库的连接包。文章里使用的数据库是mysql，所以使用mysql-connector。### 基本使用使用JDBC需要六步：注册驱动、建立连接、创建Statement、执行查询、获得结果集、处理结果集、释放资源。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Test &#123; public static void main(String[] args) throws Exception &#123; Connection con = null; Statement statement = null; ResultSet query = null; try &#123; /** * 1、注册驱动：在使用JDBC连接连接数据库的时候，Java程序并不知道自己是否连接上了相应的 * 数据库，所以在第一步需要注册驱动，如果连接正常则可以进行接下来的操作。也 * 就是说注册驱动这一步是通过我们导入的jar包测试能否正常连接数据库。 */ DriverManager.registerDriver(new com.mysql.jdbc.Driver()); /** * 2、获得连接：数据库服务器中可能存在多个数据库，我们需要连接上我们即将使用的数据库。 */ con = DriverManager.getConnection ("jdbc:mysql://localhost/jdbc-study", "root", "root"); /** * 3、创建Statement：如果想和数据库进行交互，一定需要使用这个类。JDK对他的解释是： * The object used for executing a static SQL statement and * returning the results it produces. */ statement = con.createStatement(); /** * 4、执行查询，获得结果集：想数据库中注入SQL语句，是我们能够进行操作 */ String sql = "select * from students"; /** * 5、处理结果集：query是数据库中的元组集合，可以通过循环获得每个元组 */ query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; /** * 6、释放资源：操作结束后进行操作 */ if(query != null) query.close(); if(statement != null) statement.close(); if(con != null) con.close(); &#125; &#125;&#125;### 封装工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class JDBCUtil &#123; static String driverClass = null; static String url = null; static String name = null; static String password= null; static&#123; try &#123; //1. 创建一个属性配置对象 Properties properties = new Properties(); InputStream is = new FileInputStream("jdbc.properties"); // 使用类加载器，去读取src底下的资源文件。 后面在servlet // InputStream is = JDBCUtil.class.getClassLoader(). // getResourceAsStream("jdbc.properties"); //导入输入流。 properties.load(is); //读取属性 driverClass = properties.getProperty("driverClass"); url = properties.getProperty("url"); name = properties.getProperty("name"); password = properties.getProperty("password"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; Connection conn = null; public Connection initialValue() &#123; try &#123; conn = DriverManager.getConnection(url, name, password); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125; &#125;; /** * 获取连接对象 * @return */ public static Connection getConn()&#123; Connection conn = null; try &#123; Class.forName(driverClass); conn = connectionHolder.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return conn; &#125; // 释放资源 public static void release(Connection conn , Statement st , ResultSet rs)&#123; closeRs(rs); closeSt(st); closeConn(conn); &#125; //开启事务 public static void startTransaction()&#123; try&#123; Connection conn = connectionHolder.get(); conn.setAutoCommit(false); &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //回滚事务 public static void rollback()&#123; try&#123; Connection conn = connectionHolder.get(); if(conn != null)&#123; conn.rollback(); &#125; &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //提交事务 public static void commit()&#123; try&#123; Connection conn = connectionHolder.get(); if(conn!=null)&#123; conn.commit(); &#125; &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; private static void closeRs(ResultSet rs)&#123; try &#123; if(rs != null)&#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; rs = null; &#125; &#125; private static void closeSt(Statement st)&#123; try &#123; if(st != null)&#123; st.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; st = null; &#125; &#125; private static void closeConn(Connection conn)&#123; try &#123; if(conn != null)&#123; conn.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; conn = null; &#125; &#125;&#125;1234driverClass=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost/jdbc-studyname=rootpassword=root### CURD123456789101112131415161718192021222324252627282930313233343536373839404142public class CRUD &#123; static Connection con; static &#123; con = JDBCUtil.getConn(); &#125; @Test public void query() throws Exception &#123; Statement statement = con.createStatement(); String sql = "select * from students"; ResultSet query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125; @Test public void insert() throws Exception &#123; Statement statement = con.createStatement(); String sql = "insert into students(id, name, clazz) values ('160341238', '赵承阳', '160341B')"; int row = statement.executeUpdate(sql); &#125; @Test public void update() throws Exception &#123; Statement statement = con.createStatement(); String sql = "update students set id = 'helloworld' where id = '160341237'"; int row = statement.executeUpdate(sql); &#125; @Test public void delete() throws Exception &#123; Statement statement = con.createStatement(); String sql = "delete from students where id = '160341238'"; //返回处理的行数 int row = statement.executeUpdate(sql); &#125;&#125;## PrepareStatement123456789101112131415public static void main(String[] args) throws Exception &#123; Statement statement = con.createStatement(); String qid = "160341238 or 1 = 1"; String sql = "select * from students where id = " + qid; ResultSet query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz);&#125; /**Console: * 160341238 赵承阳 160341B aaa 詹金浩 160341B */&#125;在上面这段代码中，查询的qid后面添加上了or 1 = 1就可以把表中所有信息都查询出来，因为or 1 = 1这句话是一定为真，而我们刚才使用的Statement又使用的是拼接字符串的方式，在字符串中or会被认为是关键字，所以sql语句的条件永远为真。可以采用PrepareStatement类来解决这个问题。### PrepareStatement123456789101112131415public static void main(String[] args) throws Exception &#123; String sql = "select * from students where id=?"; PreparedStatement ps = con.prepareStatement(sql); /** * 从1开始，把字符串填到匹配的?里。关键字也被认为是是字符串 */ ps.setString(1, "160341238 or 1 = 1"); ResultSet query = ps.executeQuery(); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz);&#125; //无结果### 改进的CURD123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class AdvancedCURD &#123; static Connection con; static &#123; con = JDBCUtil.getConn(); &#125; @Test public void query() throws Exception &#123; String sql = "select * from students where id=?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341238"); ResultSet query = ps.executeQuery(); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125; @Test public void insert() throws Exception &#123; String sql = "insert into students(id, name, clazz) values (?, ?, ?)"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341244"); ps.setString(2, "qwe"); ps.setString(3, "160341B"); int row = ps.executeUpdate(); System.out.println(row); &#125; @Test public void update() throws Exception &#123; String sql = "update students set id = ? where id = ?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "helloworld"); ps.setString(2, "160341243"); int row = ps.executeUpdate(); &#125; @Test public void delete() throws Exception &#123; String sql = "delete from students where id = ?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341238"); int row = ps.executeUpdate(); //返回处理的行数 System.out.println(row); &#125;&#125;## 数据库连接池### 自定义数据库连接池数据库连接池的概念本来就是sun公司提出来的额，所以sun公司针对数据库连接池也提供了一套规范，一个简单的数据库连接池如下，只有获取连接和归还连接的方法：123456789101112131415161718192021222324252627282930313233343536public class MyDataSource implements DataSource &#123; List &lt;Connection&gt; list = new ArrayList&lt;Connection&gt;(); public MyDataSource() &#123; for (int i = 0; i &lt; 10; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125;// 该连接池对外公布的获取连接的方法 @Override public Connection getConnection() throws SQLException &#123; //来拿连接的时候，先看看，池子里面还有没有。 if(list.size() == 0 )&#123; for (int i = 0; i &lt; 5; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; //remove(0) ---&gt; 移除第一个。 移除的是集合中的第一个。 移除的是开始的那个元素 Connection conn = list.remove(0); return conn; &#125; /** * 用完之后，记得归还。 * @param conn */ public void addBack(Connection conn)&#123; list.add(conn); &#125; //---------------------------- // other method&#125;#### 问题1. AddBack()：这个方法不是接口中的方法，不能使用面向接口的编程。2. 连接池不是单例：在一个程序中，连接池应该只存在一个，每new一个都会产生一个连接池和n个连接。3. 扩容：当连接数大于我们设置的数量时需要对连接池中的连接扩容，否则就会产生问题。#### 解决1. 使用装饰者模式装饰Connection；2. 把连接池设为单例；3. 连接池空时自动增加机制。### 改进的数据库连接池1234567891011121314151617181920212223242526272829303132333435363738394041public class MyDataSource implements DataSource &#123; private MyDataSource() &#123;&#125; private static MyDataSource mds = new MyDataSource(); static List &lt;Connection&gt; list = new ArrayList&lt;Connection&gt;(); static&#123; for (int i = 0; i &lt; 10; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; public static MyDataSource getMyDataSource() &#123; return mds; &#125;// 该连接池对外公布的获取连接的方法，扩容 @Override public Connection getConnection() throws SQLException &#123; //来拿连接的时候，先看看，池子里面还有没有。 if(list.size() == 0 )&#123; for (int i = 0; i &lt; 5; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; Connection conn = list.remove(0); Connection connection = new ConnectionWrap(conn, list); return connection; &#125; /** * 用完之后，记得归还。 * @param conn */ public void addBack(Connection conn)&#123; list.add(conn); &#125; //---------------------------- // other method&#125;1234567891011121314151617181920212223public class ConnectionWrap implements Connection&#123; private Connection connection = null; private List &lt;Connection&gt; list ; public ConnectionWrap(Connection connection, List &lt;Connection&gt; list) &#123; this.connection = connection; this.list = list; &#125; @Override public void close() throws SQLException &#123; list.add(connection); &#125; @Override public PreparedStatement prepareStatement(String sql) throws SQLException &#123; return connection.prepareStatement(sql); &#125; //==================================================================== //之后的方法没有被装饰，需要使用时再装饰&#125;123456789public static void main(String[] args) throws SQLException &#123; MyDataSource myDataSource = MyDataSource.getMyDataSource(); Connection connection = new ConnectionWrap(myDataSource.getConnection(), myDataSource.list); // ... &#125;### C3P0123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;c3p0-config&gt; &lt;!-- default-config 默认的配置， --&gt; &lt;default-config&gt; &lt;property name="driverClass"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="jdbcUrl"&gt;jdbc:mysql://localhost/jdbc-study&lt;/property&gt; &lt;property name="user"&gt;root&lt;/property&gt; &lt;property name="password"&gt;root&lt;/property&gt; &lt;property name="initialPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxIdleTime"&gt;30&lt;/property&gt; &lt;property name="maxPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxStatements"&gt;200&lt;/property&gt; &lt;/default-config&gt; &lt;!-- This app is massive! --&gt; &lt;named-config name="oracle"&gt; &lt;property name="acquireIncrement"&gt;50&lt;/property&gt; &lt;property name="initialPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;50&lt;/property&gt; &lt;property name="maxPoolSize"&gt;1000&lt;/property&gt; &lt;!-- intergalactoApp adopts a different approach to configuring statement caching --&gt; &lt;property name="maxStatements"&gt;0&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;5&lt;/property&gt; &lt;!-- he's important, but there's only one of him --&gt; &lt;user-overrides user="master-of-the-universe"&gt; &lt;property name="acquireIncrement"&gt;1&lt;/property&gt; &lt;property name="initialPoolSize"&gt;1&lt;/property&gt; &lt;property name="minPoolSize"&gt;1&lt;/property&gt; &lt;property name="maxPoolSize"&gt;5&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;50&lt;/property&gt; &lt;/user-overrides&gt; &lt;/named-config&gt;&lt;/c3p0-config&gt;12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; public static void main(String[] args) &#123; Connection connection = null; PreparedStatement ps = null; try &#123; //1、构建数据源 ComboPooledDataSource cpds = new ComboPooledDataSource(); //2、得到连接对象 connection = cpds.getConnection(); //3、执行sql语句 String sql = "select * from students"; ps = connection.prepareStatement(sql); //4、获得结果、处理结果 ResultSet query = ps.executeQuery(); while(query.next()) &#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; ps.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;## Dbutils### 增删改1234567891011121314151617181920212223import org.apache.commons.dbutils.QueryRunner;import com.mchange.v2.c3p0.ComboPooledDataSource;public class Test &#123; public static void main(String[] args) throws Exception &#123; //1、指定数据库连接池 ComboPooledDataSource dataSource = new ComboPooledDataSource(); //2、增删改都使用update方法 QueryRunner qr = new QueryRunner(dataSource); String insert = "insert into students(id, name, clazz) values(?, ?, ?)"; qr.update(insert, "123", "123", "123"); String update = "update students set name = ? where id = ?"; qr.update(update, "789", "123"); String delete = "delete from students where id = ?"; qr.update(delete, "123"); &#125;&#125;### 查询#### 自定义封装-返回值类型是单个对象123456789101112131415161718String query = "select * from students where id = ?";Student student = qr.query(query, new ResultSetHandler&lt;Student&gt;() &#123; public Student handle(ResultSet rs) throws SQLException &#123; Student s = new Student(); while(rs.next()) &#123; String id = rs.getString("id"); String name = rs.getString("name"); String clazz = rs.getString("clazz"); s.setId(id); s.setName(name); s.setClazz(clazz); &#125; return s; &#125;&#125;, "helloworld");System.out.println(student);#### 自定义封装-返回值类型是集合123456789101112131415String query = "select * from students";List&lt;Student&gt; list = qr.query(query, new ResultSetHandler&lt;List&lt;Student&gt;&gt;() &#123; public List&lt;Student&gt; handle(ResultSet rs) throws SQLException &#123; List&lt;Student&gt; l = new ArrayList&lt;&gt;(); Student s = new Student(); while(rs.next()) &#123; s.setId(rs.getString("id")); s.setName(rs.getString("name")); s.setClazz(rs.getString("clazz")); l.add(s); &#125; return l; &#125;&#125;);System.out.println(list);#### 快速封装-返回值类型是单个对象123456String query = "select * from students where id = ?";Student q = qr.query(query, new BeanHandler&lt;&gt;(Student.class), "helloworld");System.out.println(q);/**Console:* Student [id=helloworld, name=qwe, clazz=160341B]*/#### 快速封装-返回值类型是多个对象123456789String query = "select * from students";List&lt;Student&gt; l = qr.query(query, new BeanListHandler&lt;&gt;(Student.class));System.out.println(l);/** * [Student [id=160341240, name=qwe, clazz=160341B], * Student [id=160341244, name=qwe, clazz=160341B], * Student [id=aaa, name=詹金浩, clazz=160341B], * Student [id=helloworld, name=qwe, clazz=160341B]] */## 跨域问题和CORS### 同源策略如果两个页面的协议，端口（如果有指定）和主机都相同，则两个页面具有相同的源。下表给出了同源检测的示例，相对：http://store.company.com/dir/page.html:| URL | 结果 | 原因 || :———————————————— | :— | :—————————-: || http://store.company.com/dir2/other.html | 成功 | 只有路径不同 || http://store.company.com/dir/inner/another.html | 成功 | 只有路径不同 || https://store.company.com/secure.html | 失败 | 不同协议 ( https和http ) || http://store.company.com:81/dir/etc.html | 失败 | 不同端口 ( http:// 80是默认的) || http://news.company.com/dir/other.html | 失败 | 不同域名 ( news和store ) |### 没有同源策略限制的两个危险场景#### 没有同源策略限制的接口请求有一个小小的东西叫cookie大家应该知道，一般用来处理登录等场景，目的是让服务端知道谁发出的这次请求。如果你请求了接口进行登录，服务端验证通过后会在响应头加入Set-Cookie字段，然后下次再发请求的时候，浏览器会自动将cookie附加在HTTP请求的头字段Cookie中，服务端就能知道这个用户已经登录过了。知道这个之后，我们来看场景：- 你准备去清空你的购物车，于是打开了买买买网站www.maimaimai.com，然后登录成功，一看，购物车东西这么少，不行，还得买多点。- 你在看有什么东西买的过程中，你的好基友发给你一个链接www.nidongde.com，一脸yin笑地跟你说：“你懂的”，你毫不犹豫打开了。- 你饶有兴致地浏览着www.nidongde.com，谁知这个网站暗地里做了些不可描述的事情！由于没有同源策略的限制，它向www.maimaimai.com发起了请求！聪明的你一定想到一句话“服务端验证通过后会在响应头加入Set-Cookie字段，然后下次再发请求的时候，浏览器会自动将cookie附加在HTTP请求的头字段Cookie中”，这样一来，这个不法网站就相当于登录了你的账号，可以为所欲为了！当然，这只是对cookie的一方面限制，想完整的保证cookie的安全性还必须信息安全同学的头发。#### 没有同源策略限制的Dom查询- 有一天你刚睡醒，收到一封邮件，说是你的银行账号有风险，赶紧点进www.yinghang.com改密码。你吓尿了，赶紧点进去，还是熟悉的银行登录界面，你果断输入你的账号密码，登录进去看看钱有没有少了。- 睡眼朦胧的你没看清楚，平时访问的银行网站是www.yinhang.com，而现在访问的是www.yinghang.com，这个钓鱼网站做了什么呢？1234567// HTML&lt;iframe name="yinhang" src="www.yinhang.com"&gt;&lt;/iframe&gt;// JS// 由于没有同源策略的限制，钓鱼网站可以直接拿到别的网站的Domconst iframe = window.frames['yinhang']const node = iframe.document.getElementById('你输入账号密码的Input')console.log(`拿到了这个$&#123;node&#125;，我还拿不到你刚刚输入的账号密码吗`)但是对于如下的请求，会被同源策略放行：1&lt;script src="//static.store.com/jquery.js &gt;&lt;/script&gt;这样的话可以保证一些插件能从指定的地址下载放到我们自己的页面中。其实这种“嵌入式”的跨域加载资源的方式还有&lt;img&gt;、&lt;link&gt;等，相当于我们浏览器发起了一次GET请求，取到相关资源，然后放到本地而已。### CORS解决跨域问题CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing）。看名字就知道这是处理跨域问题的标准做法。CORS有两种请求，简单请求和非简单请求。#### 简单请求只要同时满足以下两大条件，就属于简单请求。1. 请求方法是以下三种方法之一：1. HEAD2. GET3. POST2. HTTP的头信息不超出以下几种字段：1. Accept2. Accept-Language3. Content-Language4. Last-Event-ID5. Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain当浏览器发现发起的ajax请求是简单请求时，会在请求头中携带一个字段：Origin。Origin中会指出当前请求属于哪个域（协议+域名+端口）。服务会根据这个值决定是否允许其跨域。如果服务器允许跨域，需要在返回的响应头中携带下面信息：123Access-Control-Allow-Origin: http://manage.leyou.comAccess-Control-Allow-Credentials: trueContent-Type: text/html; charset=utf-8- Access-Control-Allow-Origin：可接受的域，是一个具体域名或者（代表任意域名）- Access-Control-Allow-Credentials：是否允许携带cookie，默认情况下，cors不会携带cookie，除非这个值是true。服务器想要操作当前页面的cookie，需要满足3个条件：- 服务的响应头中需要携带Access-Control-Allow-Credentials并且为true。- 浏览器发起ajax请求需要指定字段withCredentials 为true- 响应头中的Access-Control-Allow-Origin一定不能为，必须是指定的域名#### 特殊请求特殊请求会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。12345678OPTIONS /cors HTTP/1.1Origin: http://manage.leyou.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.leyou.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0...与简单请求相比，除了Origin以外，多了两个头：- Access-Control-Request-Method：接下来会用到的请求方式，比如PUT- Access-Control-Request-Headers：会额外用到的头信息服务的收到预检请求，如果许可跨域，会发出响应：1234567891011121314HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2.0.61 (Unix)Access-Control-Allow-Origin: http://manage.leyou.comAccess-Control-Allow-Credentials: trueAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderAccess-Control-Max-Age: 1728000Content-Type: text/html; charset=utf-8Content-Encoding: gzipContent-Length: 0Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain除了Access-Control-Allow-Origin和Access-Control-Allow-Credentials以外，这里又额外多出3个头：- Access-Control-Allow-Methods：允许访问的方式- Access-Control-Allow-Headers：允许携带的头- Access-Control-Max-Age：本次许可的有效时长，单位是秒，**过期之前的ajax请求就无需再次进行预检了### SpringMVC实现实现比较简单：- 浏览器端都有浏览器自动完成，我们无需操心- 服务端可以通过拦截器统一实现，不必每次都去进行跨域判定的编写。事实上，SpringMVC已经帮我们写好了CORS的跨域过滤器：CorsFilter，内部已经实现了刚才所讲的判定逻辑，我们直接用就好了。1234567891011121314151617181920212223242526272829303132333435import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.cors.CorsConfiguration;import org.springframework.web.cors.UrlBasedCorsConfigurationSource;import org.springframework.web.filter.CorsFilter;@Configurationpublic class CorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; //1.添加CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //1) 允许的域,不要写*，否则cookie就无法使用了 config.addAllowedOrigin("http://manage.leyou.com"); //2) 是否发送Cookie信息 config.setAllowCredentials(true); //3) 允许的请求方式 config.addAllowedMethod("OPTIONS"); config.addAllowedMethod("HEAD"); config.addAllowedMethod("GET"); config.addAllowedMethod("PUT"); config.addAllowedMethod("POST"); config.addAllowedMethod("DELETE"); config.addAllowedMethod("PATCH"); // 4）允许的头信息 config.addAllowedHeader("*"); //2.添加映射路径，我们拦截一切请求 UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration("/**", config); //3.返回新的CorsFilter return new CorsFilter(configSource); &#125;&#125;## Mybatis### #{}和${}的区别是什么${}是变量占位符，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。#{}是sql的参数占位符，Mybatis会将sql中的#{}替换为?号，在sql执行前会使用PreparedStatement的参数设置方法，按序给sql的?号占位符设置参数值，比如ps.setInt(0, parameterValue)，#{item.name}的取值方式为使用反射从参数对象中获取item对象的name属性值，相当于param.getItem().getName()。### 当实体类中的属性名和表中的字段名不一样 ，怎么办第1种： 通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致123&lt;select id=”selectorder” parametertype=”int” resultetype=”me.gacl.domain.order”&gt; select order_id id, order_no orderno ,order_price price form orders where order_id=#&#123;id&#125;; &lt;/select&gt;第2种： 通过&lt;resultMap&gt;&lt;/resultMap&gt;来映射字段名和实体类属性名的一一对应的关系1234567891011&lt;select id="getOrder" parameterType="int" resultMap="orderresultmap"&gt; select * from orders where order_id=#&#123;id&#125;&lt;/select&gt;&lt;resultMap type=”me.gacl.domain.order” id=”orderresultmap”&gt; &lt;!–用id属性来映射主键字段–&gt; &lt;id property=”id” column=”order_id” /&gt; &lt;!–用result属性来映射非主键字段，property为实体类属性名，column为数据表中的属性–&gt; &lt;result property = “orderno” column =”order_no”/&gt; &lt;result property=”price” column=”order_price” /&gt; &lt;/reslutMap&gt;### 模糊查询like语句该怎么写第1种：在Java代码中添加sql通配符123456string wildcardname = &quot;%smi%&quot;; list&lt;name&gt; names = mapper.selectlike(wildcardname);&lt;select id=”selectlike”&gt; select * from foo where bar like #&#123;value&#125; &lt;/select&gt;第2种：在sql语句中拼接通配符，会引起sql注入123456string wildcardname = &quot;smi&quot;; list&lt;name&gt; names = mapper.selectlike(wildcardname);&lt;select id=”selectlike”&gt; select * from foo where bar like &quot;%&quot;#&#123;value&#125;&quot;%&quot;&lt;/select&gt;### 通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中MappedStatement的id值，接口方法内的参数，就是传递给sql的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在Mybatis中，每一个 &lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。Dao接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。### Mybatis是如何进行分页的？分页插件的原理是什么？Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。### Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？第一种是使用&lt;resultMap&gt;&lt;resultMap/&gt;标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用sql列的别名功能，将列别名书写为对象属性名，比如T_NAME AS NAME，对象属性名一般是name，小写，但是列名不区分大小写，Mybatis会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成T_NAME AS NaMe，Mybatis一样可以正常工作。有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。### 如何执行批量插入首先，创建一个简单的insert语句：123&lt;insert id=”insertname”&gt; insert into names (name) values (#&#123;value&#125;) &lt;/insert&gt;然后在java代码中像下面这样执行批处理插入：1234567891011121314151617List&lt;String&gt; names = new ArrayList&lt;&gt;();names.add("fred");names.add("barney");names.add("betty");names.add("wilma");// 注意这里 executortype.batchSqlSession sqlsession = sqlSessionFactory.openSession(ExecutorType.BATCH);try &#123; NameMapper mapper = sqlsession.getMapper(NameMapper.class); for (String name : names) &#123; mapper.insertname(name); &#125; sqlsession.commit();&#125; finally &#123; sqlsession.close();&#125;### 如何获取自动生成的(主)键值?insert 方法总是返回一个int值 ，这个值代表的是插入的行数。如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中。123&lt;insert id=”insertname” usegeneratedkeys=”true” keyproperty=”id”&gt; insert into names (name) values (#&#123;name&#125;)&lt;/insert&gt;1234567name name = new name();name.setname(“fred”);int rows = mapper.insertname(name);// 完成后,id已经被设置到对象中system.out.println(“rows inserted = ” + rows);system.out.println(“generated key value = ” + name.getid());### 在mapper中如何传递多个参数1234567891011121314151617181920212223（1）第一种：//DAO层的函数Public UserselectUser(String name,String area); //对应的xml,#&#123;0&#125;代表接收的是dao层中的第一个参数，#&#123;1&#125;代表dao层中第二参数，更多参数一致往后加即可。&lt;select id=&quot;selectUser&quot;resultMap=&quot;BaseResultMap&quot;&gt; select * from user_user_t where user_name = #&#123;0&#125; and user_area=#&#123;1&#125; &lt;/select&gt; （2）第二种： 使用 @param 注解:public interface usermapper &#123; user selectuser(@param(“username”) string username,@param(“hashedpassword”) string hashedpassword);&#125;然后,就可以在xml像下面这样使用(推荐封装为一个map,作为单个参数传递给mapper):&lt;select id=”selectuser” resulttype=”user”&gt; select id, username, hashedpassword from some_table where username = #&#123;username&#125; and hashedpassword = #&#123;hashedpassword&#125;&lt;/select&gt; （3）第三种：多个参数封装成maphttps://blog.csdn.net/earthhour/article/details/79635633### 一对一查询123456789101112131415public class Account implements Serializable &#123; private Integer id; private Integer uid; private Double money; private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125; // getter and setter&#125;123456789101112131415161718&lt;!-- 建立对应关系 --&gt;&lt;resultMap type="account" id="accountMap"&gt; &lt;id column="aid" property="id"/&gt; &lt;result column="uid" property="uid"/&gt; &lt;result column="money" property="money"/&gt; &lt;!-- 它是用于指定从表方的引用实体属性的 --&gt; &lt;association property="user" javaType="user"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="username" property="username"/&gt; &lt;result column="sex" property="sex"/&gt; &lt;result column="birthday" property="birthday"/&gt; &lt;result column="address" property="address"/&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;select id="findAll" resultMap="accountMap"&gt; select u.*, a.id as aid, a.uid, a.money from account a, user u where a.uid=u.id;&lt;/select&gt;### 一对多1234567891011121314151617public class User implements Serializable &#123; private Integer id; private String username; private Date birthday; private String sex; private String address; private List&lt;Account&gt; accounts; public List&lt;Account&gt; getAccounts() &#123; return accounts; &#125; public void setAccounts(List&lt;Account&gt; accounts) &#123; this.accounts = accounts; &#125; // getter and setter&#125;123456789101112131415161718&lt;resultMap type="user" id="userMap"&gt; &lt;id column="id" property="id"&gt;&lt;/id&gt; &lt;result column="username" property="username"/&gt; &lt;result column="address" property="address"/&gt; &lt;result column="sex" property="sex"/&gt; &lt;result column="birthday" property="birthday"/&gt; &lt;!-- collection 是用于建立一对多中集合属性的对应关系，ofType 用于指定集合元素的数据类型--&gt; &lt;collection property="accounts" ofType="account"&gt; &lt;id column="aid" property="id"/&gt; &lt;result column="uid" property="uid"/&gt; &lt;result column="money" property="money"/&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;!-- 配置查询所有操作 --&gt;&lt;select id="findAll" resultMap="userMap"&gt; select u.*, a.id as aid, a.uid, a.money from user u left outer join account a on u.id=a.uid&lt;/select&gt;## SpringMVC### 流程SpringMVC的流程用户发送请求至前端控制器DispatcherServlet；DispatcherServlet收到请求后，调用HandlerMapping处理器映射器，请求获取Handle；处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器（如果有则生成）一并返回给DispatcherServlet；DispatcherServlet 调用 HandlerAdapter 处理器适配器；HandlerAdapter 经过适配调用具体处理器（Handler，也叫后端控制器）；Handler执行完成返回ModelAndView；HandlerAdapter将Handler执行结果ModelAndView返回给DispatcherServlet；DispatcherServlet将ModelAndView传给ViewResolver视图解析器进行解析；ViewResolver解析后返回具体View；DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）DispatcherServlet响应用户。组件说明前端控制器 DispatcherServlet（不需要程序员开发）。作用：接收请求、响应结果，相当于转发器，有了DispatcherServlet 就减少了其它组件之间的耦合度。处理器映射器HandlerMapping（不需要程序员开发）。作用：根据请求的URL来查找Handler。处理器适配器HandlerAdapter（不需要程序员开发）。注意：在编写Handler的时候要按照HandlerAdapter要求的规则去编写，这样适配器HandlerAdapter才可以正确的去执行Handler。处理器Handler（需要程序员开发）视图解析器 ViewResolver（不需要程序员开发）。作用：进行视图的解析，根据视图逻辑名解析成真正的视图（view）视图View（需要程序员开发jsp）。View是一个接口， 它的实现类支持不同的视图类型（jsp，freemarker，pdf等等）。SpringMvc的控制器是不是单例模式，如果是，有什么问题，怎么解决？是单例模式,所以在多线程访问的时候有线程安全问题，不要用同步，会影响性能的，解决方案是在控制器里面不能写字段。SpringBean的生命周期在IoC容器启动之后，并不会马上就实例化相应的bean，此时容器仅仅拥有所有对象的BeanDefinition（BeanDefinition：是容器依赖某些工具加载的XML配置信息进行解析和分析，并将分析后的信息编组为相应的BeanDefinition）。只有当getBean()调用时才是有可能触发Bean实例化阶段的活动。因为当对应某个bean定义的getBean()方法第一次被调用时，不管是显示的还是隐式的，Bean实例化阶段才会被触发，第二次被调用则会直接返回容器缓存的第一次实例化完的对象实例（因为默认是singleton单例，当然，这里的情况prototype类型的bean除外）Bean的一生过程带星号的不用考虑。实例化bean对象(通过构造方法或者工厂方法)设置对象属性(setter等)（依赖注入）如果Bean实现了BeanNameAware接口，工厂调用Bean的setBeanName()方法传递Bean的ID。（和下面的一条均属于检查Aware接口）如果Bean实现了BeanFactoryAware接口，工厂调用setBeanFactory()方法传入工厂自身如果这个 Bean 已经实现了 ApplicationContextAware 接口，会调用 setApplicationContext(ApplicationContext)方法，传入 Spring 上下文将Bean实例传递给Bean的前置处理器的postProcessBeforeInitialization(Object bean, String beanname)方法调用Bean的初始化方法将Bean实例传递给Bean的后置处理器的postProcessAfterInitialization(Object bean, String beanname)方法使用Bean当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 这个接口，会调用那个其实现的 destroy()方法；最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法。基础示例1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Student implements BeanNameAware &#123; private String name; //无参构造方法 public Student() &#123; super(); &#125; /** 设置对象属性 * @param name the name to set */ public void setName(String name) &#123; System.out.println("设置对象属性setName().."); this.name = name; &#125; //Bean的初始化方法 public void initStudent() &#123; System.out.println("Student这个Bean：初始化"); &#125; //Bean的销毁方法 public void destroyStudent() &#123; System.out.println("Student这个Bean：销毁"); &#125; //Bean的使用 public void play() &#123; System.out.println("Student这个Bean：使用"); &#125; /* 重写toString * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "Student [name = " + name + "]"; &#125; //调用BeanNameAware的setBeanName() //传递Bean的ID。 @Override public void setBeanName(String name) &#123; System.out.println("调用BeanNameAware的setBeanName()..." ); &#125;&#125;123456789101112public class CycleTest &#123; @Test public void test() &#123; ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); Student student = (Student) context.getBean("student"); //Bean的使用 student.play(); System.out.println(student); //关闭容器 ((AbstractApplicationContext) context).close(); &#125;&#125;123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- init-method：指定初始化的方法 destroy-method：指定销毁的方法 --&gt; &lt;bean id="student" class="com.linjie.cycle.Student" init-method="initStudent" destroy-method="destroyStudent"&gt; &lt;property name="name" value="LINJIE"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;Bean的前/后置处理器上面bean的一生其实已经算是对bean生命周期很完整的解释了，然而bean的前/后置处理器，是为了对bean的一个增强。1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Student implements BeanNameAware &#123; private String name; // 无参构造方法 public Student() &#123; super(); &#125; /** 设置对象属性 * @param name the name to set */ public void setName(String name) &#123; System.out.println("设置对象属性setName().."); this.name = name; &#125; // Bean的初始化方法 public void initStudent() &#123; System.out.println("Student这个Bean：初始化"); &#125; // Bean的销毁方法 public void destroyStudent() &#123; System.out.println("Student这个Bean：销毁"); &#125; // Bean的使用 public void play() &#123; System.out.println("Student这个Bean：使用"); &#125; /* 重写toString * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "Student [name = " + name + "]"; &#125; // 调用BeanNameAware的setBeanName() // 传递Bean的ID。 @Override public void setBeanName(String name) &#123; System.out.println("调用BeanNameAware的setBeanName()..." ); &#125;&#125;123456789101112131415161718192021222324252627282930313233/** * bean的后置处理器 * 分别在bean的初始化前后对bean对象提供自己的实例化逻辑 * postProcessAfterInitialization：初始化之后对bean进行增强处理 * postProcessBeforeInitialization：初始化之前对bean进行增强处理 */public class MyBeanPostProcessor implements BeanPostProcessor &#123; //对初始化之后的Bean进行处理 //参数：bean：即将初始化的bean //参数：beanname：bean的名称 //返回值：返回给用户的那个bean,可以修改bean也可以返回一个新的bean @Override public Object postProcessAfterInitialization(Object bean, String beanname) throws BeansException &#123; Student stu = null; System.out.println("对初始化之后的Bean进行处理，将Bean的成员变量的值修改了"); if("student".equals(beanname) &amp;&amp; bean instanceof Student) &#123; stu = (Student) bean; stu.setName("Jack"); &#125; return stu; &#125; //对初始化之前的Bean进行处理 //参数：bean：即将初始化的bean //参数：beanname：bean的名称 //返回值：返回给用户的那个bean,可以修改bean也可以返回一个新的bean @Override public Object postProcessBeforeInitialization(Object bean, String beanname) throws BeansException &#123; System.out.println("对初始化之前的Bean进行处理,此时我的名字"+bean); return bean; &#125;&#125;123456789101112public class CycleTest &#123; @Test public void test() &#123; ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); Student student = (Student) context.getBean("student"); //Bean的使用 student.play(); System.out.println(student); //关闭容器 ((AbstractApplicationContext) context).close(); &#125;&#125;1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- init-method：指定初始化的方法，destroy-method：指定销毁的方法 --&gt; &lt;bean id="student" class="com.linjie.cycle.Student" init-method="initStudent" destroy-method="destroyStudent"&gt; &lt;property name="name" value="LINJIE"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置bean的后置处理器,不需要id，IoC容器自动识别是一个BeanPostProcessor --&gt; &lt;bean class="com.linjie.cycle.MyBeanPostProcessor"&gt;&lt;/bean&gt; &lt;/beans&gt;BeanFactoryAware和ApplicationContextAware这两个接口是为了获得Spring的上下文，Spring的IOC有两个常用接口，BeanFactory和ApplicationContext，这两个接口是为了分别获得这两个上下文。12345678910111213141516@Componentpublic class BeanUtil implements BeanFactoryAware&#123; private static BeanFactory beanFactory; @Override public void setBeanFactory(BeanFactory factory) throws BeansException &#123; this.beanFactory = factory; &#125; public static &lt;T&gt; T getBean(String beanName) &#123; if (null != beanFactory) &#123; return (T) beanFactory.getBean(beanName); &#125; return null; &#125;&#125;123456789101112131415@Componentpublic class AppUtil implements ApplicationContextAware &#123; private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext arg0) throws BeansException&#123; applicationContext = arg0; &#125; public static Object getObject(String id) &#123; Object object = null; object = applicationContext.getBean(id); return object; &#125;&#125;Spring支持的bean的作用域Spring容器中的bean可以分为5个范围：singleton：默认，每个容器中只有一个bean的实例，单例的模式由BeanFactory自身来维护。prototype：为每一个bean请求提供一个实例。request：为每一个网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收。session：与request范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效。global-session：全局作用域，global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。全局作用域与Servlet中的session作用域效果相同。AOPSpring的XML方式配置AOP12345678public class Logger &#123; /** * 用于打印日志：计划让其在切入点方法执行之前执行（切入点方法就是业务层方法） */ public void printLog()&#123; System.out.println("Logger类中的pringLog方法开始记录日志了。。。"); &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt;&lt;/bean&gt;&lt;!--spring中基于XML的AOP配置步骤 1、把通知Bean也交给spring来管理 2、使用aop:config标签表明开始AOP的配置 3、使用aop:aspect标签表明配置切面 id属性：是给切面提供一个唯一标识 ref属性：是指定通知类bean的Id。 4、在aop:aspect标签的内部使用对应标签来配置通知的类型 我们现在示例是让printLog方法在切入点方法执行之前之前：所以是前置通知 aop:before：表示配置前置通知 method属性：用于指定Logger类中哪个方法是前置通知 pointcut属性：用于指定切入点表达式，该表达式的含义指的是对业务层中哪些方法增强 切入点表达式的写法： 关键字：execution(表达式) 表达式： 访问修饰符 返回值 包名.包名.包名...类名.方法名(参数列表) 标准的表达式写法： public void com.itheima.service.impl.AccountServiceImpl.saveAccount() 访问修饰符可以省略 void com.itheima.service.impl.AccountServiceImpl.saveAccount() 返回值可以使用通配符，表示任意返回值 * com.itheima.service.impl.AccountServiceImpl.saveAccount() 包名可以使用通配符，表示任意包。但是有几级包，就需要写几个*. * *.*.*.*.AccountServiceImpl.saveAccount()) 包名可以使用..表示当前包及其子包 * *..AccountServiceImpl.saveAccount() 类名和方法名都可以使用*来实现通配 * *..*.*() 参数列表： 可以直接写数据类型： 基本类型直接写名称 int 引用类型写包名.类名的方式 java.lang.String 可以使用通配符表示任意类型，但是必须有参数 可以使用..表示有无参数均可，有参数可以是任意类型 全通配写法： * *..*.*(..) 实际开发中切入点表达式的通常写法： 切到业务层实现类下的所有方法 * com.itheima.service.impl.*.*(..) --&gt;&lt;!-- 配置Logger类 --&gt;&lt;bean id="logger" class="com.itheima.utils.Logger"&gt;&lt;/bean&gt;&lt;!--配置AOP--&gt;&lt;aop:config&gt; &lt;!--配置切面 --&gt; &lt;aop:aspect id="logAdvice" ref="logger"&gt; &lt;!-- 配置通知的类型，并且建立通知方法和切入点方法的关联--&gt; &lt;aop:before method="printLog" pointcut="execution(* com.itheima.service.impl.*.*(..))"&gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;Spring通知有哪些类型前置通知（Before advice）：在某连接点（join point）之前执行的通知，但这个通知不能阻止连接点前的执行（除非它抛出一个异常）。返回后通知（After returning advice）：在某连接点（join point）正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回。抛出异常后通知（After throwing advice）：在方法抛出异常退出时执行的通知。后通知（After (finally) advice）：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）。环绕通知（Around Advice）：包围一个连接点（join point）的通知，如方法调用。这是最强大的一种通知类型。 环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它们自己的返回值或抛出异常来结束执行。 环绕通知是最常用的一种通知类型。大部分基于拦截的AOP框架，例如Nanning和JBoss4，都只提供环绕通知。同一个aspect，不同advice的执行顺序：没有异常情况下的执行顺序：around before advicebefore advicetarget method 执行around after adviceafter adviceafterReturning有异常情况下的执行顺序：around before advicebefore advicetarget method 执行around after adviceafter adviceafterThrowing：异常发生1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 用于记录日志的工具类，它里面提供了公共的代码 */public class Logger &#123; /** * 前置通知 */ public void beforePrintLog()&#123; System.out.println("前置通知Logger类中的beforePrintLog方法开始记录日志了。。。"); &#125; /** * 后置通知 */ public void afterReturningPrintLog()&#123; System.out.println("后置通知Logger类中的afterReturningPrintLog方法开始记录日志了。。。"); &#125; /** * 异常通知 */ public void afterThrowingPrintLog()&#123; System.out.println("异常通知Logger类中的afterThrowingPrintLog方法开始记录日志了。。。"); &#125; /** * 最终通知 */ public void afterPrintLog()&#123; System.out.println("最终通知Logger类中的afterPrintLog方法开始记录日志了。。。"); &#125; /** * 环绕通知 * 问题： * 当我们配置了环绕通知之后，切入点方法没有执行，而通知方法执行了。 * 分析： * 通过对比动态代理中的环绕通知代码，发现动态代理的环绕通知有明确的切入点方法调用，而我们的代码中没有。 * 解决： * Spring框架为我们提供了一个接口：ProceedingJoinPoint。该接口有一个方法proceed()，此方法就相当于明确调用切入点方法。 * 该接口可以作为环绕通知的方法参数，在程序执行时，spring框架会为我们提供该接口的实现类供我们使用。 * * spring中的环绕通知： * 它是spring框架为我们提供的一种可以在代码中手动控制增强方法何时执行的方式。 */ public Object aroundPringLog(ProceedingJoinPoint pjp)&#123; Object rtValue = null; try&#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。前置"); rtValue = pjp.proceed(args);//明确调用业务层方法（切入点方法） System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。后置"); return rtValue; &#125;catch (Throwable t)&#123; System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。异常"); throw new RuntimeException(t); &#125;finally &#123; System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。最终"); &#125; &#125;&#125;1234567891011121314151617181920212223242526272829303132&lt;!-- 配置srping的Ioc,把service对象配置进来--&gt;&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt;&lt;/bean&gt;&lt;!-- 配置Logger类 --&gt;&lt;bean id="logger" class="com.itheima.utils.Logger"&gt;&lt;/bean&gt;&lt;!--配置AOP--&gt;&lt;aop:config&gt; &lt;!-- 配置切入点表达式 id属性用于指定表达式的唯一标识。expression属性用于指定表达式内容 此标签写在aop:aspect标签内部只能当前切面使用。 它还可以写在aop:aspect外面，此时就变成了所有切面可用 --&gt; &lt;aop:pointcut id="pt1" expression="execution(* com.itheima.service.impl.*.*(..))"&gt;&lt;/aop:pointcut&gt; &lt;!--配置切面 --&gt; &lt;aop:aspect id="logAdvice" ref="logger"&gt; &lt;!-- 配置前置通知：在切入点方法执行之前执行 &lt;aop:before method="beforePrintLog" pointcut-ref="pt1" &gt;&lt;/aop:before&gt;--&gt; &lt;!-- 配置后置通知：在切入点方法正常执行之后值。它和异常通知永远只能执行一个 &lt;aop:after-returning method="afterReturningPrintLog" pointcut-ref="pt1"&gt;&lt;/aop:after-returning&gt;--&gt; &lt;!-- 配置异常通知：在切入点方法执行产生异常之后执行。它和后置通知永远只能执行一个 &lt;aop:after-throwing method="afterThrowingPrintLog" pointcut-ref="pt1"&gt;&lt;/aop:after-throwing&gt;--&gt; &lt;!-- 配置最终通知：无论切入点方法是否正常执行它都会在其后面执行 &lt;aop:after method="afterPrintLog" pointcut-ref="pt1"&gt;&lt;/aop:after&gt;--&gt; &lt;!-- 配置环绕通知 详细的注释请看Logger类中--&gt; &lt;aop:around method="aroundPringLog" pointcut-ref="pt1"&gt;&lt;/aop:around&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;Spring的注解方式配置AOP12345&lt;!-- 配置spring创建容器时要扫描的包--&gt;&lt;context:component-scan base-package="com.itheima"&gt;&lt;/context:component-scan&gt;&lt;!-- 配置spring开启注解AOP的支持 --&gt;&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * 用于记录日志的工具类，它里面提供了公共的代码 */@Component("logger")@Aspect//表示当前类是一个切面类public class Logger &#123; @Pointcut("execution(* com.itheima.service.impl.*.*(..))") private void pt1()&#123;&#125; /** * 前置通知 */// @Before("pt1()") public void beforePrintLog()&#123; System.out.println("前置通知Logger类中的beforePrintLog方法开始记录日志了。。。"); &#125; /** * 后置通知 */// @AfterReturning("pt1()") public void afterReturningPrintLog()&#123; System.out.println("后置通知Logger类中的afterReturningPrintLog方法开始记录日志了。。。"); &#125; /** * 异常通知 */// @AfterThrowing("pt1()") public void afterThrowingPrintLog()&#123; System.out.println("异常通知Logger类中的afterThrowingPrintLog方法开始记录日志了。。。"); &#125; /** * 最终通知 */// @After("pt1()") public void afterPrintLog()&#123; System.out.println("最终通知Logger类中的afterPrintLog方法开始记录日志了。。。"); &#125; /** * 环绕通知 * 问题： * 当我们配置了环绕通知之后，切入点方法没有执行，而通知方法执行了。 * 分析： * 通过对比动态代理中的环绕通知代码，发现动态代理的环绕通知有明确的切入点方法调用，而我们的代码中没有。 * 解决： * Spring框架为我们提供了一个接口：ProceedingJoinPoint。该接口有一个方法proceed()，此方法就相当于明确调用切入点方法。 * 该接口可以作为环绕通知的方法参数，在程序执行时，spring框架会为我们提供该接口的实现类供我们使用。 * * spring中的环绕通知： * 它是spring框架为我们提供的一种可以在代码中手动控制增强方法何时执行的方式。 */ @Around("pt1()") public Object aroundPringLog(ProceedingJoinPoint pjp)&#123; Object rtValue = null; try&#123; Object[] args = pjp.getArgs();//得到方法执行所需的参数 System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。前置"); rtValue = pjp.proceed(args);//明确调用业务层方法（切入点方法） System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。后置"); return rtValue; &#125;catch (Throwable t)&#123; System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。异常"); throw new RuntimeException(t); &#125;finally &#123; System.out.println("Logger类中的aroundPringLog方法开始记录日志了。。。最终"); &#125; &#125;&#125;事务xml方式配置事务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!-- 配置业务层--&gt;&lt;bean id="accountService" class="com.itheima.service.impl.AccountServiceImpl"&gt; &lt;property name="accountDao" ref="accountDao"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置账户的持久层--&gt;&lt;bean id="accountDao" class="com.itheima.dao.impl.AccountDaoImpl"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置数据源--&gt;&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/eesy"&gt;&lt;/property&gt; &lt;property name="username" value="root"&gt;&lt;/property&gt; &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- spring中基于XML的声明式事务控制配置步骤 1、配置事务管理器 2、配置事务的通知 此时我们需要导入事务的约束 tx名称空间和约束，同时也需要aop的 使用tx:advice标签配置事务通知 属性： id：给事务通知起一个唯一标识 transaction-manager：给事务通知提供一个事务管理器引用 3、配置AOP中的通用切入点表达式 4、建立事务通知和切入点表达式的对应关系 5、配置事务的属性 是在事务的通知tx:advice标签的内部 --&gt;&lt;!-- 配置事务管理器 --&gt;&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置事务的通知--&gt;&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;!-- 配置事务的属性 isolation：用于指定事务的隔离级别。默认值是DEFAULT，表示使用数据库的默认隔离级别。 propagation：用于指定事务的传播行为。默认值是REQUIRED，表示一定会有事务，增删改的选择。查询方法可以选择SUPPORTS。 read-only：用于指定事务是否只读。只有查询方法才能设置为true。默认值是false，表示读写。 timeout：用于指定事务的超时时间，默认值是-1，表示永不超时。如果指定了数值，以秒为单位。 rollback-for：用于指定一个异常，当产生该异常时，事务回滚，产生其他异常时，事务不回滚。没有默认值。表示任何异常都回滚。 no-rollback-for：用于指定一个异常，当产生该异常时，事务不回滚，产生其他异常时事务回滚。没有默认值。表示任何异常都回滚。 --&gt; &lt;tx:attributes&gt; &lt;tx:method name="*" propagation="REQUIRED" read-only="false"/&gt; &lt;tx:method name="find*" propagation="SUPPORTS" read-only="true"&gt;&lt;/tx:method&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 配置aop--&gt;&lt;aop:config&gt; &lt;!-- 配置切入点表达式--&gt; &lt;aop:pointcut id="pt1" expression="execution(* com.itheima.service.impl.*.*(..))"&gt;&lt;/aop:pointcut&gt; &lt;!--建立切入点表达式和事务通知的对应关系 --&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="pt1"&gt;&lt;/aop:advisor&gt;&lt;/aop:config&gt;注解方式配置事务12345678910111213141516171819202122232425262728&lt;!-- 配置spring创建容器时要扫描的包--&gt;&lt;context:component-scan base-package="com.itheima"&gt;&lt;/context:component-scan&gt;&lt;!-- 配置JdbcTemplate--&gt;&lt;bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 配置数据源--&gt;&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/eesy"&gt;&lt;/property&gt; &lt;property name="username" value="root"&gt;&lt;/property&gt; &lt;property name="password" value="1234"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- spring中基于注解 的声明式事务控制配置步骤 1、配置事务管理器 2、开启spring对注解事务的支持 3、在需要事务支持的地方使用@Transactional注解 --&gt;&lt;!-- 配置事务管理器 --&gt;&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 开启spring对注解事务的支持--&gt;&lt;tx:annotation-driven transaction-manager="transactionManager"&gt;&lt;/tx:annotation-driven&gt;123456789101112131415161718192021222324252627282930313233343536/** * 账户的业务层实现类 * 事务控制应该都是在业务层 */@Service("accountService")@Transactional(propagation=Propagation.SUPPORTS, readOnly=true)//只读型事务的配置public class AccountServiceImpl implements IAccountService&#123; @Autowired private IAccountDao accountDao; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; //需要的是读写型事务配置 @Transactional(propagation= Propagation.REQUIRED,readOnly=false) @Override public void transfer(String sourceName, String targetName, Float money) &#123; System.out.println("transfer...."); //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source); int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125;事务的传播行为PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。Spring的设计模式简单工厂又叫做静态工厂方法（StaticFactory Method）模式，但不属于 23 种 GOF 设计模式之一。简单工厂模式的实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类。spring 中的 BeanFactory 就是简单工厂模式的体现，根据传入一个唯一的标识来获得 bean 对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。如下配置，就是在 HelloItxxz 类中创建一个 itxxzBean。单例模式（Singleton）保证一个类仅有一个实例，并提供一个访问它的全局访问点。spring 中的单例模式完成了后半句话，即提供了全局的访问点 BeanFactory。但没有从构造器级别去控制单例，这是因为 spring 管理的是是任意的 java 对象。核心提示点：Spring 下默认的 bean 均为 singleton，可以通过 singleton=“true|false” 或者 scope=“？”来指定适配器（Adapter）在 Spring 的 Aop 中，使用的 Advice（通知）来增强被代理类的功能。Spring 实现这一 AOP 功能的原理就使用代理模式（1、JDK 动态代理。2、CGLib 字节码生成技术代理。）对类进行方法级别的切面增强，即，生成被代理类的代理类， 并在代理类的方法前，设置拦截器，通过执行拦截器重的内容增强了代理方法的功能，实现的面向切面编程。代理（Proxy）为其他对象提供一种代理以控制对这个对象的访问。 从结构上来看和 Decorator 模式类似，但 Proxy 是控制，更像是一种对功能的限制，而 Decorator 是增加职责。spring 的 Proxy 模式在 aop 中有体现，比如 JdkDynamicAopProxy 和 Cglib2AopProxy。观察者（Observer）定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。spring 中 Observer 模式常用的地方是 listener 的实现。如 ApplicationListener。策略（Strategy）定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。spring 中在实例化对象的时候用到 Strategy 模式在 SimpleInstantiationStrategy 中有如下代码说明了策略模式的使用情况：模板方法（Template Method）定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method 使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。Template Method 模式一般是需要继承的。这里想要探讨另一种对 Template Method 的理解。spring 中的 JdbcTemplate，在用这个类时并不想去继承这个类，因为这个类的方法太多，但是我们还是想用到 JdbcTemplate 已有的稳定的、公用的数据库连接，那么我们怎么办呢？我们可以把变化的东西抽出来作为一个参数传入 JdbcTemplate 的方法中。但是变化的东西是一段代码，而且这段代码会用到 JdbcTemplate 中的变量。怎么办？那我们就用回调对象吧。在这个回调对象中定义一个操纵 JdbcTemplate 中变量的方法，我们去实现这个方法，就把变化的东西集中到这里了。然后我们再传入这个回调对象到JdbcTemplate，从而完成了调用。这可能是 Template Method 不需要继承的另一种实现方式吧。]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-操作系统和Linux]]></title>
    <url>%2F2019%2F04-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%92%8CLinux%2F</url>
    <content type="text"><![CDATA[操作系统的定义操作系统（Operating System，简称OS）是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。主要作用是管理硬件设备来提高利用率和吞吐量，同时为用户和应用系统提供易于使用的接口。提高利用率：使系统中各设备的空闲时间尽可能短。提高吞吐量：使单位时间内完成的业务更多。提供易于使用的接口：即是方便使用计算机资源。例如没有操作系统，操纵计算机可能需要用户输入二进制代码，有了操作系统，用户可以点击图标，操作系统就会将其转换成二进制代码。操作系统的目标方便性：即对用户和应用程序提供易于使用的接口。有效性：提高利用率和吞吐量。可扩充性：计算机硬件和体系结构等都在不断发展中，OS需要有好的可扩充性来满足不断发展的需求。开放性：为了使计算机的应用环境从单机转换成网络，OS需要满足相应的软硬件标准来实现设备的互联。操作系统的作用提供易于使用的接口，如Shell、图形界面等。管理计算机所有的资源，负责计算机系统全部资源的分配、控制、调度和回收。隐蔽硬件特性，如计算2*3，某些机器的实现是使用加法器做2+2+2，而有的机器是乘法器实现2*3。操作系统屏蔽这些细节，用户只需要输入2*3就能完成。未配置操作系统的计算机系统人工操作：程序员把程序和数据通过穿孔的方式记录在纸带上，再启动机器读入纸带，运行完成并取走计算结果后，才允许下一个用户上机。缺点：用户独占整机：计算机上的资源为上机用户独占。设备空闲率高：用户装卡，卸卡等人工操作时，设备资源是空闲的。脱机输入/输出（Off-Line I/O）：为了解决人机矛盾及CPU、I/O等设备之间速度的不匹配。它是先把纸带通过输入设备在外围机（与主机相比处于次要地位的计算机）的控制下输入到磁带上，当CPU需要这些信息时再从磁带上高速地调取。类似的，在输出时把信息输出到磁盘中，在外围机的控制下通过输出设备输出。也就是说主机直接对磁盘进行操作，输入输出和程序运行脱离。減少了CPU的空闲时间：主机不必依赖输入输出，可以从磁盘中读取数据。提升了I/O速度：主机读取信息不再是从卡片中读取，从磁盘读取速度较快。批处理系统为了提升计算机资源的利用率和提升计算机的吞吐量研发出了批操作系统。基础概念作业：程序+数据+作业说明书（系统根据说明书来对程序的运行进行控制）。周转时间：从作业进入系统到作业完成退出系统所用的时间。平均周转时间：同时参与系统运行的几个作业的周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NT_i]$带权周转时间：作业的周转时间（$T$）和系统为它提供服务的时间（$T_S$）。$W=\frac{T}{T_s}$平均带权周转时间：同时参与系统运行的几个作业的带权周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NW_i]$单道批处理系统设计一个常驻内存的程序（监督程序），操作员有选择地把若干作业合成一批，安装输入设备上，并启动监督程序，然后由监督程序自动控制这批作业运行，从而减少部分人工干预，有效地缩短了作业运行前的准备时间，相对的提高CPU的利用率。同一时刻只有一个硬件在运行。特点：自动性、顺序性、单道性。缺点：I/O的慢速与CPU 的高速不匹配，且输入时需要CPU等待。用户交互性差。作业安装输入后，就不能再交互。多道批处理系统把一个以上的作业存放在主存中，并且同时处于运行状态，使这些作业共享处理机和外部设备等其它系统资源。对于一个单处理机系统来说，作业同时处于运行状态只是宏观的概念，其含义是指每个作业都已开始运行，但尚未完成。就微观而言，在任意特定时刻，处理机上运行的作业只有一个。特点：多道性、无序性、调度性。优缺点：优点：资源利用率高、系统吞吐量大。缺点：作业仍然要排队处理，所以平均周转时间长、无交互能力。此时如何调度程序已经不是再用一张简单的流程图能说明了，第二章会有介绍。下图只是说明处理器利用率高。举例证明资源利用率高和系统吞吐量大设内存中有三道程序 A、B、C，它们的计算和I/O操作的时间如下表所示：程序操作ABC计算306020I/O403040计算101020单道- 多道分时系统批处理系统中，作业一旦提交就不能进行更改，所以人机交互性很差。为了满足人机交互的需求诞生分时系统。每一个用户通过一台终端与计算机相连，以交互式的命令使用系统，采用分享CPU的方法，由于CPU的速度比人在终端输入指令的时间快得多，所以用户感到自己独占了整个计算机系统。系统规定一个称之为“时间片”的时间单位，所有终端用户轮流享用一个时间片的CPU。需要解决的问题：及时接受：所有终端用户输入的信息都要能够被及时的送到处理器上。所以主机会以很快的速度循环扫描各个终端。每个终端也要拥有缓存区来保存输入的信息。及时处理：用户需要能对自己的作业及其允许及时地实施控制。所以所有的作业必须驻留在内存中，因此批作业系统不能被使用。它采用的方式是：作业直接进入内存。但每个用户只连续使用一个“时间片”的时间，对所有用户进行循环。这样每个用户都能及时地与自己的作业进行交互。分时系统与多道批处理系统的不同特性多路性：允许多个用户共享一台计算机，提高资源利用率。独立性：每个用户之间互不干扰，感觉就是一个人在独占一台计算机。及时性：用户的请求能在很短的时间内得到回应。交互性：用户可以通过终端和计算机进行及时交互。实时系统指系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。实时系统强调程序运行的时间，它需对接收到的某些信号做出及时地反应。大多数的实时系统是专用系统，如：工业（武器）控制系统、信息查询系统、多媒体系统、嵌入式系统等。最大的特点就是可靠性：系统必须高度可靠，因为任何可能的差错都可能带来灾难性后果，所以系统一般都有多级容错措施。按是否周期执行分类：周期性实时任务：如外部设备周期性地发出状态信号给计算机使其状态能被实时感知。非周期性实时任务：提交给系统时需要指定开始截止时间和完成截止时间。硬实时任务&amp;软实时任务：硬实时任务（Hard Real-time Task）：截止时间到达时任务必须完成，比如武器控制系统。软实时任务（Soft Real-time Task）：截止时间到达时任务没有完成没有太大影响，比如多媒体系统。进程和线程进程：在系统中能独立运行并作为资源分配的基本单位。线程：独立运行的基本单位，比进程更小，基本上不拥有系统资源。通常在一个进程中包含了若干个线程。操作系统的基本特性并发：宏观上是多个进程同时运行，微观上是每一时刻只有一道进程在执行。共享：系统中的资源可供内存中多个并发执行的进程（线程）共同使用。有两种共享方式：互斥共享方式，如打印机；同时访问方式，如共享文件夹、网络资源。虚拟：通过某种技术把一个物理实体变为若干个逻辑上的对应物。这样可以避免一个进程单独占用某个物理设备，一个物理设备被分配给多个进程便可以提升物理设备的使用率。不确定性（异步性）：进程以人们不可预知的速度向前推进，即为进程的不确定性。这样的话很可能是先进入内存的作业后完成；而后进入内存的作业先完成。尽管如此，但只要有合理的进程同步方式且运行环境相同，作业经多次运行，都会获得完全相同的结果。因此，异步运行方式是允许的。操作系统的结构传统操作系统结构无结构OS：关注功能的实现和获得高的效率操作系统是为数众多的一组过程的集合，各过程之间可以相互调用，在操作系统内部不存在任何结构。程序设计的技巧，只是如何编制紧凑的程序，以便于有效地利用内存。操作系统既庞大又杂乱，缺乏清晰的程序结构。程序错误很多，给调试工作带来很多困难；另一方面也使程序难以阅读和理解，增加了维护人员的负担。模块化结构OS模块化程序设计技术，是最早（20世纪60年代）出现的一种程序设计技术。该技术是基于“分解”和“模块”原则来控制大型软件的复杂度的。将OS按其功能划分为若干个具有一定独立性和大小的模块。每个模块具有某方面的管理功能，并规定好各模块间的接口， 使各模块之间能通过该接口实现交互，然后再进一步将各模块细分为若干个具有一定管理功能的子模块。（会导致模块之间的依赖关系很重，OS结构不清晰）若子模块较大时，再进一步将它细分。- 分层式结构OS：- 改进设计方式，使每一步设计都是建立在可靠的基础上一层一层地自底向上增添软件层，每一层都实现若干功能，最后总能构成一个能满足需要的OS。- 每一层都仅使用其底层所提供的功能和服务，这样可使系统的调试和验证都变得容易。- 一旦发现错误后，通常该错误只会局限于某一层，因为它与所有其高层的软件无关，而此层以下的各层软件，又都经过仔细的调试，bug修复较为容易。### 客户/服务器结构- 为了提高OS的灵活性和可扩充性而将OS划分为两部分。- 一部分是用于提供各种服务的一组服务器（进程），所有这些服务器（进程）都运行在用户态。当有一用户进程（现在称为客户进程）要求读文件的一个盘块时，该进程便向文件服务器（进程）发出一个请求；当服务器完成了该客户的请求后，便给该客户回送一个响应。- 另一部分是内核，用来处理客户和服务器之间的通信， 即由内核来接收客户的请求，再将该请求送至相应的服务器；同时它也接收服务器的应答， 并将此应答回送给请求客户。- 此外，在内核中还应具有其它一些机构，用于实现与硬件紧密相关的和一些较基本的功能。### 面向对象结构（20世纪80年代）- 该技术是基于“抽象”和“隐蔽”原则来控制大型软件的复杂度的。所谓对象，是指在现实世界中具有相同属性、服从相同规则的一系列事物的抽象，而把其中的具体事物称为对象的实例。- OS中的各类实体如进程、线程、消息、存储器等，都使用了对象这一概念，相应地，便有进程对象、线程对象、 存储器对象等。- 由于隐蔽了表示实体的数据和操作，因而可以改变对象的表示而不会影响其它部分， 从而可以方便地改变老的对象和增加新的对象。- 继承性。继承性是面向对象技术所具有的重要特性。继承性是指子对象可以继承父对象的属性，这样，在创建一个新的对象时， 便可减少大量的时空开销。- 正确性和可靠性。由于对象是构成操作系统的基本单元，可以独立地对它进行测试，这样，比较易于保证其正确性和可靠性，从而比较容易保证整个系统的正确性和可靠性。### 微服务结构（20世纪90年代）- 能有效支持多处理机，适用于分布式系统环境。- 以微内核为操作系统核心，以客户/服务器为基础，采用了面向对象的程序设计方法。- 所谓微内核技术，是指精心设计的、能实现现代OS核心功能的小型内核，它与一般的OS(程序)不同， 它更小更精炼，它不仅运行在核心态，而且开机后常驻内存， 它不会因内存紧张而被换出内存。- 微内核并非是一个完整的OS， 而只是为构建通用OS提供一个重要基础。- 在微内核OS结构中，通常都采用了客户/服务器模式，因此OS的大部分功能和服务，都是由若干服务器来提供的， 如文件服务器、作业服务器和网络服务器等。## 进程概念### 前趋图数据结构中的有向无环图。箭头表示进程之间执行的先后关系。结点表示一个程序或一个进程，甚至一条语句。程序的并发执行不存在前趋关系的程序之间才有可能并发执行。特征：间断性：程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间形成了相互制约的关系，进而导致并发程序具有“执行-暂停-执行”这种间断性的活动规律。失去封闭性：由于资源共享，所以当某程序的运行影响资源的状态时，其他程序的运行环境就会被破坏。不可再现性：计算结果与并发程序各自执行速度有关。即同一程序，使用相同输入、在相同环境下运行，却可能获得完全不同的结果。进程的定义在多道程序环境下，程序的执行属于并发执行，此时他们将失去其封闭性，并具有间断性，以及运行结果的不可再现性。由此，决定了通常的程序是不能参与并发执行的。为了能使程序并发执行，引入了进程。进程实体：程序+数据+进程控制块（Process Control Block，PCB）。进程：运行态的进程实体是就是进程，是系统进行资源分配和调度的一个独立单位。PCB是为了使程序能并发执行而诞生的一种数据结构，它用来控制和管理进程。由于数据和程序本来就存在，所以创建/撤销进程也就是创建/撤销PCB。至于如何并发执行，见下面的进程同步。区别于作业：进程是程序在数据集上的一次作执行，作业是用户提交给系统的一个任务，包含一个或多个进程。进程的特点动态性：由创建而产生，由调度而执行，由撤销而消亡。并发性：进程的重要特征，操作系统的重要特征。独立性：独立运行、独立分配资源、独立接受调度。异步性：按各自独立、不可预知的速度向前推进。PCBPCB中保存的信息进程标识符。用于唯一的标识某个进程。外部标识符：不仅可以标识进程，还指明其父进程、子进程以及拥有该进程的用户。内部标识符：方便系统使用进程，仅能标识进程。处理机状态。用于在进程切换时保存处理机中各个寄存器的内容。以便在该进程重新调度时能再从断点执行。进程调度信息。进程状态：指明进程的状态，方便进程调度和对换时的依据。进程优先级：进程优先级高的更容易获得处理机。进程调度所需信息：保存的内容和进程调度算法有关，如进程等待了多久CPU，使用了多长CPU。事件：进程因何由执行状态转变为阻塞状态，即阻塞原因。进程控制信息。程序和数据的地址。进程同步的通信机制。资源清单。进程已分配到的除处理机之外的资源。链接指针。用于指向下一个PCB的首地址。用于进程调度。PCB的组织方式线性方式：所有的PCB都保存在一张表中，每次寻找PCB都在表中查找。效率低。链接方式：把具有相同状态的PCB链接起来。索引方式：把具有相同状态的PCB保存在相应的表中。OS内核系统态 &amp; 用户态对于处理机来说，根据其执行的指令不同，可以将其分成系统态（管态、内核态）和用户态。处理机处于系统态时可以执行任意的指令，访问所有的寄存器和存储区，而处于用户态的时候会受到相应的限制。所以计算机中的程序可以分成系统程序和用户程序，用户程序运行在用户态，这样就可以防止用户程序对操作系统进行破坏。指令分类操作系统把CPU指令分成两类：特权指令：在系统态执行的指令。执行几乎不受限制，如启动外部设备、设置系统时钟等。非特权指令：在用户态执行的指令。限制较多，比如不能操作硬件等。内核概念现代操作系统采用分层设计模式，不同权重的程序分别设置在不同的层次中。通常与硬件紧密相关的程序、设备驱动程序和运行频率高的程序等放置在高级别层次中，操作系统会将它们常驻内存，这些程序便被称为OS内核。OS内核运行在系统态中。内核的功能不同操作系统的内核在功能上有一定的差异，但是一般都包含两类功能：支撑功能中断处理：是指计算机运行过程中，出现某些意外情况需主机干预时，机器能自动停止正在运行的程序并转入处理新情况的程序，且处理完毕后又返回原被暂停的程序继续运行。人机交互、设备驱动和进程调度等都需要依赖中断处理。时钟管理：系统中很多活动都需要用到时钟，如定时任务、时间片轮转调度算法等。原语操作：原语是若干条机器指令构成的，用以完成特定功能的一段程序。而原语操作便是原语的执行，其在执行期间是不可分割的。资源管理功能进程管理：进程的创建、撤销、调度等操作。存储器管理：空间的分配、撤销、逻辑地址转换为物理地址等。设备管理：进行设备分配、缓和CPU和I/O速度不匹配矛盾的缓冲管理等。进程的生命周期进程的创建为新进程申请内部标识符，同时从PCB集合中索取一个空白的PCB。为新进程分配其运行所需的资源。这些资源直接来自操作系统或者父进程。初始化PCB。如处理机状态信息、标识符和进程优先级等。若就绪队列还能接受进程，则插入就绪队列。不能接受则执行相应处理机制。进程的终止从PCB集合中获得某进程的PCB，并读出该进程的状态。若进程正处于执行状态，应立即终止该进程的执行。若此进程有子进程则一并终止，防止其成为不可控进程。将进程拥有的所有资源归还给其父进程或操作系统。将被终止的进程从所在队列或链表（指PCB的组织方式）中移出，等待其他程序收集信息，释放空间等。三种基本状态就绪状态：分配到出处理机之外的其他所有必要资源。此时可运行，但其他进程正在占用CPU。执行状态：就绪状态的进程获得CPU，正在执行的状态。阻塞状态：进程发出的请求没有及时得到满足而无法继续执行的状态，此时会引起进程调度，OS把处理机分配给其他就绪进程，原进程暂停。挂起进程暂停执行或不接受调度的状态。原因有如下几点：用户的需要：用户想暂停正在的进程，观察其状态或修改程序等。父进程请求：父进程为了完成某项任务，协调其各子进程间的活动。负荷调节的需要：系统压力过大或实时操作系统不能很好的满足可靠性时会挂起一些进程。操作系统的需要：操作系统挂起某些进程来更方便的检查系统资源。挂起和阻塞不同在于阻塞是客观条件不能得到满足，即资源不足引起暂停。挂起是主观需要引起暂停。进程同步进程同步的主要任务是使并发执行的诸进程之间能有效的共享资源和相互合作，从而使程序的执行具有可再现性。同步 &amp; 互斥并发执行的诸进程之间既有独立性又有制约性。独立性：各进程都可独立地向前推进；制约性：由于资源共享和进程合作引起的进程之间的相互依赖和相互制约的关系。可归结为互斥和同步。同步：两个或多个事件的发生有着某种时序上的关系。按照这种时序关系进行能保证各任务安全的完成。互斥：资源的使用要排它使用，防止冲突（不同时使用，但无先后次序。一种特殊同步）。临界资源 &amp; 临界区临界资源：需要被各进程互斥访问的资源。临界区：各进程中访问临界资源的代码。若能保证各进程互斥地进入自己的临界区，便可以保证互斥地访问临界资源，进而保证进程同步。常用的方式有硬件同步机制和信号量机制。同步准则空闲让进：当无进程处于临界区时，应当允许一个进程进入自己的临界区。忙则等待：当有进程处于临界区时其他请求就如临界区的进程必须等待。有限等待：对要求访问临界资源的进程，应保证在有限的时间内能进入自己的临界区。让权等待：当进程不能进入临界区时，应立即释放处理机避免进程陷入“忙等”的状态。硬件同步机制关中断当进程在临界区执行期间，计算机系统不响应中断，因此不会引发调度，临界资源只会被一个进程占据，这样就不会发生进程同步问题。利用Test-and-Set指令实现互斥指令的描述如下：123456boolean TS(boolean *lock)&#123; boolean old; old = *lock; *lock = true; return old;&#125;为临界资源设置一个布尔变量lock = false。在进程进入临界区之前利用TS指令测试，如果得到的值为false表示资源未被使用，如果得到的值为true，则一直测试到结果为false。使用TS指令实现互斥描述如下：1234567do&#123; ... while (TS(&amp;lock)); ... lock = false; ...&#125;while(true);利用Swap指令实现互斥指令描述如下：123456void swap(boolean *a, boolean *b)&#123; boolean temp; temp = *a; *a = *b; *b = temp;&#125;为每个临界资源设置一个全局变量lock=false。每个进程设置一个局部变量key。实现互斥的描述如下：12345678910do&#123; ... key = true; do&#123; swap(&amp;lock, &amp;key); &#125;while(key != false) critical section; lock = false; ...&#125;缺点关中断：效率低下且不适用于多处理机系统。且其他进行会”忙等“，不符合让权等待。TS指令 &amp; Swap指令：其他进行会”忙等“，不符合让权等待。信号量机制整型信号量整型信号量是一个用于描述资源数目的整型量（S）。但除了初始化以外，仅能通过两个原子操作来访问。wait(S)：P操作1234wait(S)&#123; while(S &lt;= 0); S--;&#125;signal(S)：V操作123signal(S)&#123; S++;&#125;P操作用于分配资源，V操作用于释放资源。记录型信号量整型信号量未遵循让权等待原则。只要S &lt;= 0就会不断的循环。此时需要增加一个进程链表指针链接等待进程。数据结构的描述：1234typedef struct&#123; int value; //资源数 struct process_control_block *list; //阻塞队列&#125; semaphore;wait(S)：12345wait(semaphore *S)&#123; S-&gt;value--; if(S-&gt;value &lt; 0) block(S-&gt;list);&#125;signal(S)：12345signal(semaphore *S)&#123; S-&gt;value++; if(S-&gt;value &lt;= 0) wakeup(S-&gt;list);&#125;当进程被阻塞时会被加入阻塞对列，资源被满足时唤醒阻塞对列中的某个资源。AND型信号量记录型信号量只能解决共享一个临界资源的情况，若有多个临界资源则需要使用多个记录型信号量。但是信号量越多，系统死锁的概率越大，且大量的同步操作会给系统的管理带来麻烦。AND型信号量的思想是一次性分配进程所需的全部资源，如果有一个没有分配成功，则其他所有可能为之分配的资源亦不分配。Swait(S)：123456789101112Swait(S1, S2, ..., Sn)&#123; while(true)&#123; if(Si &gt;= 1 &amp;&amp; ... &amp;&amp; Sn &gt;= 1)&#123; for(i = 1; i &lt;= n; i++) Si--; break; &#125;else&#123; 把进程阻塞在请求未能得到满足的资源Si所对应的阻塞队列里，同时把进程的程序计数器（放 置CPU下一条要执行的指令地址）放置在本操作的开始处（下一次再调度到此进程，需要再次 检查所有的资源）。 &#125; &#125;&#125;Ssignal(S)：12345678Ssignal(S1, S2, ..., Sn)&#123; while(true)&#123; for(i = 1; i &lt;= n; i++)&#123; Si++; 唤醒等待Si资源的阻塞队列。 &#125; &#125;&#125;信号量集之前的信号量都是一次申请或释放某资源一份，若申请或释放N份资源需要进行N次操作，效率比较低下。此外，当资源数量低于某一下限值时，为了系统安全，就不能再予以分配。所以产生信号量集解决以上问题。描述如下：Swait(S1, t1, d1, ..., Sn, tn, dn)：当Si &gt;= ti时Si = Si - di。（di &gt;= ti）Ssignal(S1, d1, ..., Sn, dn)：Si = Si + di。特殊的信号量集：Swait(S1, d, d)：每次申请d份资源，资源少于d时不分配。Swait(S, 1, 1)：退化成一般的记录型信号量。Swait(S, 1, 0)：S &gt;= 1时运行多个进行进入特定区。S &lt;= 0时禁止进程进入特定区。管程直接使用信号量机制会把大量的同步操作分散在各个进程中，这会增加系统死锁的概率并且不方便系统的管理。而管程就是把代表共享资源的数据结构和对共享数据结构的操作（包括同步机制）封装起来以更好的为进程使用。这时所有请求访问共享资源的进程都只能通过管程间接访问，同时管程每次只允许一个进程进入管程。此时的管程可以使用面相对象的操作来完成整型信号量的功能。但是此时无法解决“让权等待”的问题，所以再按照面相对象的思想将block和wakeup操作封装起来来解决这个问题，即构成条件变量。条件变量的操作如下：condition.wait()：使进程在因某条件不能满足时阻塞在其所对应的条件变量上。condition.signal()：唤醒因某条件不能满足而阻塞的进程。可以很容易看出来，设置不同的条件变量能使由不同原因等待的进程阻塞在不同的队列中。使用时把signal()操作放在函数/过程的最后，这样保证在唤醒其他进程后本进程能直接退出而不再产生冲突。管程的描述如下：123456789101112131415161718/* 1、局部数据和条件变量组成管程内的数据结构。 2、过程/函数1~过程/函数k组成管程内的一组过程对管程内的数据结构进行操作。 3、初始化代码：对管程内的数据结构进行初始化。*/Monitor monitor_name&#123; share variable declartions; //共享变量说明 condition declarations; //条件变量说明 &#123; //管程主体 initialization code; //初始化代码 ... &#125; public: //能被进程调用的过程 void P1(...)&#123;...&#125; void P2(...)&#123;...&#125; ... void Pn(...)&#123;...&#125;&#125;信号量的应用互斥访问资源设某共享资源的信号量是mutex，PA和PB进程并发时需互斥访问。12345678910111213141516171819semaphore mutex = 1;PA()&#123; while(1)&#123; ... wait(mutex); ... signal(mutex); ... &#125;&#125;PB()&#123; while(1)&#123; ... wait(mutex); ... signal(mutex); ... &#125;&#125;利用信号量实现前趋关系123456789101112P1（）&#123;...V(f1);V(f1);V(f1);&#125;P2（）&#123;P(f1)；... V(f2);&#125;P3（）&#123;P(f1)；... V(f3);&#125;P4（）&#123;P(f1)；... V(f4);&#125;P5（）&#123;P(f2)；... V(f5);&#125;P6（）&#123;P(f3);P(f4);P(f5);...;&#125;main()&#123; semaphore f1=f2=f3=f4=f5=0； Cobegin P1(); P2();P3(); P4();P5(); P6(); Coend&#125;在并发时，如果P1的功能代码未执行完，f1为0，每次对f1进行V操作能使P2、P3、P4运行一个。其他亦然。### 生产者—消费者问题- 问题描述：多个生产者进程生产产品以供多个消费者消费。通过由n个环形缓冲区构成的缓冲池（循环队列），把多个生产者和多个消费者联系起来。不允许消费者进程到一个空缓冲区去取产品，也不允许生产者进程向一个已装满产品且尚未取走的缓冲区中投放产品。- 分析：- 任何时刻，只能有一个进程在缓冲区中操作。- 对于“生产者”而言，缓冲区满则应等待。- 对于“消费者”而言，缓冲区空则应等待。- 利用记录型信号量解决问题12345678910111213141516171819202122232425262728293031int in = 0, out = 0;//in指向此次生产的产品应该放置的位置。out指向此次消费的产品所在的位置。item buffer[n];//缓存区大小为n，地址为[0, n-1]。semaphore mutex = 1, empty = n, full = 0; //mutex用于互斥访问缓存区void producer()&#123; do&#123; produce an item nextproducer; ... wait(empty); //消耗一个empty，当empty&lt;=0时等待 wait(mutex); buffer[in] = nextproducer; in = (in+1) % n; signal(mutex); signal(full); //增加一个full &#125;while(true);&#125;void consumer()&#123; do&#123; wait(full); //消耗一个full，当full&lt;=0时等待 wait(mutex); nextconsumer = buffer[out]; out = (out+1) % n; signal(mutex); signal(empty); //增加一个empty ... &#125;while(true);&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;- 互斥信号量 &amp; 资源信号量互斥使用的资源设置一个互斥信号量，资源数为1。资源信号量的资源数和资源的意义有关。资源信号量的资源为1时退化成互斥信号量。在使用时互斥信号量的P操作需要紧邻其对应共享资源的临界区使用，否则可能造成同步问题。比如互换上面代码的第8行和第9行之后，若生产者进程和消费者进程都只有一个，且生产者通过了P(mutex)，阻塞在P(empty)，消费者通过了P(full)，阻塞在P(mutex)，此时生产者等待消费者的V(empty)，消费者等待生产者的V(mutex)，发生死锁。而V操作不需要注意顺序。- 利用AND型信号量解决问题123456789101112131415161718192021222324252627int in = 0, out = 0;//in指向此次生产的产品应该放置的位置。out指向此次消费的产品所在的位置。item buffer[n];//缓存区大小为n，地址为[0, n-1]。semaphore mutex = 1, empty = n, full = 0; //mutex用于互斥访问缓存区void producer()&#123; do&#123; produce an item nextproducer; ... Swait(empty, mutex); //消耗一个empty，当empty&lt;=0时等待 buffer[in] = nextproducer; in = (in+1) % n; signal(empty, mutex); //增加一个full &#125;while(true);&#125;void consumer()&#123; do&#123; wait(full, mutex); //消耗一个full，当full&lt;=0时等待 nextconsumer = buffer[out]; out = (out+1) % n; signal(full, mutex); //增加一个empty ... &#125;while(true);&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;- 利用管程解决问题12345678910111213141516171819202122232425262728293031323334353637383940414243Monitor monitor&#123; item buffer[n]; int in = 0, out = 0, count = 0; condition notfull, notempty; public: void static put(item x)&#123; if(count &gt;= n) cwait(notfull); //阻塞在队列满的条件下 buffer[in] = x; in = (in+1) % n; count++; csignal(notempty); &#125; void static get(item &amp;x)&#123; if(count &lt;= 0) cwait(notempty); //阻塞在队列空的条件下 x = buffer[out]; out = (out+1) % n; count--; csignal(notfull); &#125;&#125;void producer()&#123; item x; while(true)&#123; ... produce an item in nextproducer; monitor.put(x); &#125;&#125;void consumer()&#123; item x; while(true)&#123; monitor.get(x); consume the item in nextconsumer; ... &#125;&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;### 哲学家进餐问题- 问题描述：五个哲学家坐在圆桌前，每人一份饭，每个哲学家两侧各有一支筷子,只有拿到左右两只筷子才能进餐，哲学家处于吃饭和思考两种状态。分析同一时刻一只筷子只能有一个哲学家拿起。只有获得两个筷子后才能进餐。如果每个哲学家都拿起一只筷子，都饿死。并行程度：五只筷子允许两人同时进餐。利用AND型信号量解决问题每次必须拿到两只筷子才能拿起，否则不拿起筷子。12345678semaphore chopstick[5] = &#123;1, 1, 1, 1, 1&#125;;do&#123; ... Swait(chopstick[i], chopstick[(i+1) % 5]); ... Ssignal(chopstick[i], chopstick[(i+1) % 5]); ...&#125;读者-写者问题问题描述：写者向共享数据区放数据，读者从共享数据区读数据。多个读者可同时读取数据，多个写者不能同时写数据。分析：读者进入共享数据区，写者必须等待。读者进入共享数据区，读者可以进入。写者进入共享数据区，读者必须等待。利用记录型信号量解决问题1234567891011121314151617181920212223242526272829semaphore readmutex = 1, writemutex = 1;int readcount = 0;void reader()&#123; do&#123; wait(readmutex); if(readcount == 0) wait(writemutex); readcount++; signal(readmutex); ... //read opreation wait(readmutex); readcount--; if(readcount == 0) signal(writemutex); signal(readmutex); &#125;while(true);&#125;void writer()&#123; do&#123; wait(writemutex); //当写者进入共享数据区，reader会阻塞在 ... //write operation signal(writemutex); &#125;while(true);&#125;void main()&#123; ConcurrentBegin reader();writer(); ConcurrentEnd;&#125;代码分析：最开始并发的时候：假如读者先抢到资源，readcount == 0，P(writemutex)，writer()会阻塞在第20行，但其他reader()仍可以运行，只是不会再P(writemutex)。同时每个reader()都readcount++，直到readcount == 0时V(writemutex)，然后writer()才有可能能进入。此时读者进程和写者进程进入共享数据区的个数都为0，即又是重新开始。假如写者先抢到资源，P(writemutex)，此时readcount == 0，所有reader()阻塞在第7行。此时读者进程和写者进程进入共享数据区的个数都为0，即又是重新开始。综上，完成了要求。读者-写者问题拓展问题描述：拓展就是又增加一个条件，最多只允许RN个读者同时读。利用信号量集解决问题123456789101112131415161718192021semaphore L = RN, mx = 1; //L用来控制访问数，mx控制写者访问时所有读者阻塞void reader()&#123; do&#123; Swait(L, 1, 1); //第RN+1个读者进入时会阻塞 Swait(mx, 1, 0);//mx &gt;= 1时才可以进入 ... //read operation Ssignal(L, 1); &#125;while(true);&#125;void writer()&#123; do&#123; Swait(mx, 1, 1; L, RN, 0); //mx &gt;= 1 &amp;&amp; L &gt;= RN时进入 ... //write operation Ssignal(mx, 1); &#125;while(true);&#125;void main()&#123; ConcurrentBegin reader();writer(); ConcurrentEnd;&#125;代码分析：最开始并发的时候：假如读者先抢到资源，L = L - 1，写者阻塞在第12行，但其他reader()仍可以运行，直至没有读者进程在访问共享数据区。当所有的读者进程都退出时，共享数据区中停留的个进程数都为0，即重新开始。假如写者先抢到资源，mx = mx - 1，所有读者进程和其他写者进程都要被阻塞，写者进程退出时，共享数据区中停留的个进程数都为0，即重新开始。理发师问题问题描述：一把理发椅，N把等待座位。理发师为理发椅上的顾客理发，没有顾客就在理发椅上睡觉，有一个顾客时需要叫醒理发师，多个顾客时需要在等待座位上等候。分析：理发椅上只能有一位顾客。等待座位是有限缓冲区。只要存在顾客，理发师就不能睡觉。利用记录型信号量解决问题：123456789101112131415161718192021222324semaphore customer = 0, barber = 0, mutex = 1; //barber使理发师只能为一个顾客服务int waiting = 0;void barber()&#123; while(true)&#123; wait(customer); //没有顾客的时候理发师睡觉 wait(mutex); waiting –= 1; //等待的人少一个 signal(mutex); signal(barber); ...//获得被激活进程的信息并给相应的顾客剪发 &#125;&#125;void customer()&#123; wait(mutex); if(waiting &lt; CHAIRS)&#123; //顾客到来的时候，还有座位就进去等待 waiting += 1; signal(mutex); signal(customer); wait(barber); ... //将被激活进程的信息发送给barber() &#125;else&#123; signal(mutex); &#125;&#125;代码分析在最开始并发的时候barber()会等待到有顾客时才醒来。顾客一来就需要访问waiting，所以获得mutex。如果位置不够就立即释放mutex。如果位置够，就让等待的人加1，再释放mutex。然后顾客人数customer += 1来激活理发师进程。理发师进程激活后会V(barber)，然后等待着的customer()进程争夺资源，争夺到P(barber)的进程将被激活进程的信息发送给barber()，barber()获得被激活进程的信息并给相应的顾客剪发。进程通信概念进程之间合作完成工作不仅仅需要有时序关系，还需要进程信息交互，比如刚才的理发师问题中就设计到了信息交互。从概念上说进程通信是指进程之间的信息交换，所以信号量机制本身就涉及到了信息交换，不过我们把这种信息交换叫做低级进程通信，因为其效率低且需要用户大量的干预。真正的进程通信需要满足使用方便且能高效传输大量数据的需求。共享存储器系统基于共享数据结构的通信方式：诸进程公用某些数据结构来实现进行通信 ，如生产者—消费者问题中的有界缓冲区，属于低级通信方式。基于共享存储区的通信方式：在存储器中划出一块共享存储区，诸进程通过对共享存储区中数据的读或写实现通信，此时数据的形式、位置和访问控制仍是进程实现。适用于传输大量数据，属于高级通信。管道通信系统所谓“管道”，是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe文件。向管道提供输入的发送进程（即写进程）以字符流形式将大量的数据送入管道，而接收进程（即读进程），可从管道中接收数据。管道通信系统必须满足以下三个要求：互斥：管道的使用必须互斥。因为存数据和取数据可归于写文件的添加和删除。同步：写进程把一定数量的数据写入管道后去睡眠，读进程读完后将其唤醒。读进程读空的管道时需要睡眠。确定对方存在：如果写进程不存在，读进程就会一直等待。如果读进程不存在，写进程写完数据后也会一直等待，所以通信双方必须同时存在。消息传递系统指进程可以利用一组通信命令（原语）把数据封装在消息中传送，不需要显示的指定共享存储区或数据结构等。它隐藏了通信的细节，也是目前使用最广泛的进程间通信机制。通常有两种实现方式：直接通信方式：OS提供原语给进程使用。间接通信方式：借助共享中间实体（称为邮箱）完成进程间的通信。和共享存储器系统的区别是进程不再需要指定数据的形式、位置和访问控制等，信箱内部自有实现。客户机-服务器系统前三种都是单机下的通信机制，这种是网络环境中的通信机制。主要有套接字和RPC两种方式。套接字：一个套接字是一个通信标识类型的数据结构，包含了通信目的地址、通信端口号、通信的网络协议、进程自身的地址以及对外提供的系统调用等。使用套接字可以在不同主机上的进程建立连接进而进行通信。RPC：Remote Procedure Call，它是一个通信协议，可以使本地进程调用其他主机的进程对程序员表现为常规方法调用。线程线程的由来进程解决了程序不能并发执行的问题，但是由于进程是拥有资源的基本单位，所以在创建、撤销和切换时所需的时空开销很大，因为处理机势必要付出更大的代价来保存现场。所以把拥有资源和独立运行两项功能分开，让线程作为独立运行的基本单位，进程作为拥有资源的基本单位。不过线程也拥有一些能保证其独立运行的资源，如TCB。TCB（Thread Control Block）所有用于控制和管理线程的信息都会被记录在线程控制块中，通常包含：线程标识符：每个线程都有唯一的线程标识符。处理机信息：包括程序计数器、状态寄存器、通用寄存器的内容。线程运行状态：线程和进程一样也有多种运行状态，就绪、阻塞、运行等。详见103-网络编程。优先级：和调度算法有关，优先级越高，得到处理机的机会越大。线程专有存储区：用于在线程切换时保存现场状态和保存线程的统计信息。信号屏蔽：屏蔽某些发送给线程的信号。堆栈指针：线程调用别的过程时需要保存局部变量和返回地址等来供返回时能继续执行。线程的实现线程是为了解决进程调度时过于笨重的问题，所以在不同的环境中实现线程的方式不同。根据内核能否感知到线程的存在可分为内核支持线程（Kernel Supported Threads，KST）和用户级线程（User Level Threads，ULT）。它俩的区别是能否直接调用系统服务，前者可以而后者需要借助中间系统。内核支持线程若线程是由内核直接调度，线程资源也是保存在内核空间，就可以说此类线程为内核支持线程。此类线程的创建、撤销和切换等操作都是在内核空间完成的，此时线程可以直接调用系统服务。一种可能的实现方式是在创建进程时分配一个任务数据区（Per Task Data Area，PTDA），各个线程的TCB保存在其中即可。不过仅实现内核支持线程的系统对用户进程创建的线程很不友好，每次线程调度处理机都要从用户态转换到核心态。用户级线程用户级线程是指线程虽客观存在但对内核来说是透明的，此时不能再直接调用系统服务，间接调用系统服务需要有中间系统的支持，通常的中间系统有运行时系统和内核控制线程。运行时系统：把创建线程、撤销线程和线程同步等只能由OS内核完成的操作封装起来作为运行时系统，而运行时系统停留在用户空间供其他进程调用来实现线程调度。内核控制线程：这种线程又被称作轻量进程（Light Weight Process，LWP），它既可以共享进程的资源，又可以使用内核提供的服务。虽然下图中LWP和用户线程是1对1关系，但实际上多个用户级线程可以复用一个LWP，但每个轻型线程都要连接到一个内核线程中。所以此种方式系统需要同时实现内核支持线程。概述处理机调度是指通过对处理机资源进程的合理分配来提升系统资源的利用率、降低作业周转时间等。但是由于不同操作系统的目标不同，所以处理机调度的策略和目标也不相同。处理机调度的层次高级调度：又称作业调度或长程调度。它的主要功能是根据某种算法决定把外存上处于后备队列中的哪些作业调入内存，并为他们创建进程、分配资源等，然后放入就绪进程队列。主要用于批处理系统，分时系统的实时系统中不设置高级调度。低级调度：又称进程调度或断层调度。它的主要功能是根据某种算法决定让哪些就绪队列获得处理机，并由分配程序将处理机分配给被选中的进程。在批处理系统、实时系统和分时系统中都设置低级调度。中级调度：又称内存调度。它的主要功能是根据某种算法决定将哪些暂时不能运行的进程调至外存等待，当它们具备运行条件且内存又有空闲时再调入内存。这实际上是存储器管理中的对换功能，在下一章再展开介绍，处理机调度的目标共同目标：提升资源利用率：$CPU的利用率=\frac{CPU有效工作时间}{CPU有效工作时间+CPU空闲等待时间}$。公平：每个进程都应获得合理的CPU时间，不发生进程饥饿现象。平衡：进程可以分成多个类型，如计算型、I/O型等等。平衡是指系统中不同的设备都能处于忙碌状态。策略强制执行：指某些强制型任务，比如安全策略等，即使会造成其他工作的延迟。批处理系统的目标：平均周转时间短：周转时间：从作业进入系统到作业完成退出系统所用的时间。平均周转时间：同时参与系统运行的几个作业的周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NT_i]$带权周转时间：作业的周转时间（$T$）和系统为它提供服务的时间（$T_S$）。$W=\frac{T}{T_s}$平均带权周转时间：同时参与系统运行的几个作业的带权周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NW_i]$系统吞吐量高：单位时间内系统完成的作业数尽量多。处理机利用率高。分时系统的目标：响应时间快：指终端提交一个请求到主机返回结果至终端的时间短。均衡：不同请求的复杂度不同，所以响应时间必定不同，均衡是指响应时间应和请求复杂度相适应。实时系统的目标：截止时间的保证：对于HRT任务截止时间必须满足要求，SRT也要尽可能满足。可预测性：如在观看电影时一般都会连续播放帧，所以请求是可预测的，假如采用双缓冲实现第i帧和第i+1帧并行处理就能提高实时性。高级调度作业作业：比程序更为广泛的概念，不仅包含了通常的程序和数据，还有一份作业说明书。在批处理系统中，是以作业为基本单位从外存调入内存的。作业步：在作业运行期间，每个作业都必须经过若干个相对独立。又相互关联的顺序加工步骤才能得到结果。期中每一个加工步骤成为一个作业步。作业控制块Job Control Block，JCB。是作业在系统中存在的标志。保存了系统对作业进行管理和调度所需的全部信息。如：作业标识、用户名称、用户账号、作业类型（CPU繁忙型、I/O繁忙型、批量型、终端型等）、作业状态、调度信息（优先级、作业运行时间）、资源需求（预计运行时间、要求内存大小等）、已申请到资源的使用情况。作业运行的三个阶段收容阶段：每一个作业进入系统时（即输入到硬盘），便由“作业注册”程序为该作业建立一个作业控制块JCB并把它放入作业后备队列中。运行阶段：后备队列中的作业被选中后，系统会为其分配必要的资源和建立进程，然后将其放入就绪队列。一个作业从第一次进入就绪状态开始到它运行结束前都是处于运行阶段。完成阶段：当作业完成或发生异常而终止时，作业便处于完成阶段，此时系统会撤销进程和资源，并将运行结果通过某种方式输入，如输出到文件中。先来先服务算法First-Come First-served，FCFS。每次调度都是选择一个或多个最先进入队列的作业或进程，为它们分配资源，创建进程和分配CPU，使之投入运行。它是最简单的调度算法，同时也可用于进程调度。效率不高，所以一般不作为主调度算法。适用于CPU繁忙型而不适用于I/O繁忙型。因为CPU繁忙型长时间占用CPU很少有I/O操作，一旦获得CPU，就会运行很长时间，就是会长时间占用CPU，而I/O繁忙型由于要频繁访问IO端口，每次访问都要放弃CPU，等I/O访问完后要重新等待下一次调度（此时排到了就绪队列的队尾），所以要等待很久才能重新被调度。因此先来先服务有利于CPU繁忙型而不利于I/O繁忙型。短作业优先算法Short Job First，SJF。指对短作业优先调度的算法，它从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。此种算法对长作业非常不利而且实际使用上很难预估每个作业的运行时间。静态优先级调度算法为照顾紧迫性作业，使之进入系统后获得优先处理，引入优先级调度算法。按照进程的优先级大小来调度，使高优先级进程得到优先处理的策略称为优先权调度算法。静态优先级调度算法是指在输入前作业为其赋予优先级且一直保持不变。虽然可以照顾紧迫性作业，但是没有考虑到作业本身的运行时间和作业的等待时间等，所以产生了更好的动态优先级算法。高响应比算法高响应比算法是动态优先级算法的一种，其中$优先级 = \frac{响应时间}{要求服务时间} = \frac{等待时间+要求服务时间}{要求服务时间}$。这样可以得到：对于短作业：其要求服务时间短，优先级相对较高。对于长作业：在等待一段时间之后，其优先级会增长，直至够高而能获得服务。对于先来作业：假如在某一时刻其仍未获得服务，和后来的作业相比其优先级相对较高。相应时间与周转时间的对比，假如作业运行完了，两者相等，假如没有则 $响应时间&lt;周转时间$周转时间：从作业进入系统到作业完成退出系统所用的时间。响应时间：等待时间+要求服务时间。低级调度进程调度的任务和机制保存处理机的现场信息：比如程序计数器、通用寄存器里的内容。按某种算法选取进程。把处理机分配给进程：把选中进程的PCB中的有关处理机调度的信息装入处理器的寄存器中，把处理器的控制权交给进程使其能从上次的断点处恢复运行。进程调度机制- 排队器：每当有进程转入就绪状态时，排队器会将它插入到相应的就绪队列。- 分派器：分派器依据进程调度程序（更直接的说，进程调度算法）所选定的进程，将其从就绪队列中取出。- 上下文切换器：会产生两次上下文切换：- 旧进程和分配程序之间的切换；- 分配程序和新进程之间的切换。排队器、分派器、上下文切换器本身也是程序，但是它们是处于系统态的程序，而被调度的进程一般是用户态的程序，从系统态到用户态进行上下文切换需要很大的耗费，所以一般采用两组（或多组）寄存器，一组用于处理机在系统态时使用，一组用于系统在用户态时使用，这样在系统态和用户态之间切换时就可以只改变指针（用于从寄存器中存取数据和指令）使其指向指定寄存器就行。### 进程调度方式### 非抢占方式一旦某进程获得处理机，就会一直运行下去，直至该进程完成或者因发生某种事件而被阻塞其他进程才能获得处理机。此时引起进程调度的因素：- 正在执行的进程运行完毕。- 外部环境的改变使其不能再继续运行，如程序运行发生异常。- 进程通信或进程同步时执行了某种原语，如Block。- 正在执行的进程发出I/O请求。### 抢占方式允许调度程序根据某种原则去暂停某个正在执行的进程，将处理机分配给其他进程。这些原则一般有三种：- 高优先级原则；- 短进程优先原则；- 时间片原则。我们后面所提到的进程调度算法其实都是抢占方式下的策略。## 轮转调度算法将CPU的处理时间分成固定大小的时间片q， q的大小从几ms到几百ms。系统将所有就绪进程按先来先服务的原则排成队列。每次调度时，把CPU分配给队首进程，令其执行一个时间片，时间片用完后若进程未结束，则送回就需队列尾部重新调度，在一给定的时间内，就绪进程均能获得一时间片的执行时间。此时时间片大小是关键问题，一般来说时间片q正比于响应时间，反比于就绪进程数目。计算机的处理能力。速度快，q可小些。通常q值是这样决定的：- 批处理系统:80%的CPU周期在一个时间片内完成- 分时系统：$q=T/N_{max}$，（$T-响应时间上限，N_{max}-最大进程数$）## 优先级调度算法### 非抢占式优先级调度算法即一旦某个高优先级的进程占有了处理机，就一直运行下去，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件）才让另一高优先级进程运行。主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。### 抢占式优先级调度算法任何时刻都严格按照高优先级进程在处理机上运行的原则进行进程的调度。常用于要求比较严格的实时系统中， 以及对性能要求较高的批处理和分时系统中。#### 静态优先权静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。一般地，优先权是利用某一范围内的一个整数来表示的，这些整数被称为优先数。确定优先权大小的依据：- 进程类型；- 进程对资源的需求；- 用户要求。#### 动态优先权动态优先权是指，在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间的增加而改变的，以便获得更好的调度性能。例如，我们可以规定，在就绪队列中的进程，随其等待时间的增长，其优先权以速率a提高。若所有的进程都具有相同的优先权初值，则显然是最先进入就绪队列的进程，将因其动态优先权变得最高而优先获得处理机，此即FCFS算法。若所有的就绪进程具有各不相同的优先权初值，那么，对于优先权初值低的进程，在等待了足够的时间后，其优先权便可能升为最高，从而可以获得处理机。当采用抢占式优先权调度算法时，如果再规定当前进程的优先权以速率b下降，则可防止一个长作业长期地垄断处理机。## 多队列调度算法之前介绍的调度算法都是用一个算法来解决所有的进程调度，这样无法满足系统中不同用户对进程调度策略的不同要求。而多队列调度算法就是将就绪队列从一个分成多个，将不同性质或类型的进程放在不同的就绪队列，这样不同的队列之间设置优先级，和队列内部也可以设置优先级，能更好的满足用户的需求。同时在多处理机系统中，可以方便的给每个处理机设置单独的就绪队列。## 多级反馈队列调度算法1. 设置多个就绪队列，每个队列赋予不同的优先级，一个队列的优先级最高，第二个队列次之，其余各队列的优先级逐个降低，各队列内部使用FCFS原则排列。2. 优先级越高的进程时间片越短。3. 当一个进程进入内存后，首先放在第一队列的尾部，按FCFS的原则调度，如果该时间片内未结束，进程调度时将此进程转入第二队列队尾，直至第N个对列，若进程仍未结束，在第N个对列上采用时间片轮转算法。4. 仅当第i队列空闲时才调度第i+1队列，如果有新进程进入优先级较高的队列，剥夺CPU执行新进程，旧进程放入原队列尾部。此算法不必事先知道各进程执行的所需时间，可满足各种进程需要，是目前公认较好的进程调度算法。举例第i个对列的时间片为$2^{i-1}$。基于公平原则的调度算法保证调度算法保证每个进程都获得相同的处理机时间：跟踪计算每个进程自创建以来已经执行的时间。计算每个进程应该获得的处理机时间，即自创建以来的时间除以n。比较各进程获得处理机时间的比率，即实际执行时间除以应获得的处理机时间。比较各进程获得处理机时间的比率，如A：0.5；B：0.9；C：1.2。调度程序应选择比率最小的进程将处理机分配给它，并让该进程一直运行，直到超过最接近它的进程比率，然后把处理机让给此时比率最小的进程。公平调度算法在上个算法中，如果用户A有4个进程，用户B有1各进程，那用户A获得处理机的时间是用户B的四倍。而公平调度算法的目标是保证每个用户都获得相同的处理机时间。实时调度实时调度必须能满足实时任务对截止时间的要求。所以实时任务的算法和优先级算法有些区别。实时算法的分类非抢占式调度算法非抢占式轮转调度算法；非抢占式优先调度算法。抢占式调度算法基于时钟中断的抢占式优先级调度算法：在某实时任务到达后，如果它的优先级高于当前任务的优先级，这时并不立即抢占当前任务的处理机，而是等到时钟中断发生时，调度程序才剥夺当前任务的执行，将处理机分配给新到的高优先级任务。立即抢占式优先级调度算法：一旦出现外部中断，只要当前任务未处于临界区，便立即剥夺当前任务的执行，把处理机分配给请求中断的紧迫任务。### 最早截止时间优先算法Earliest Deadline First，EDF。可用于非抢占式算法，也可用于抢占式算法。#### 非抢占式#### 抢占式有两个周期任务，A、B的周期分别是20ms，50ms。A、B的执行时间分别是10ms和25ms。### 最低松弛度优先即算法Least Laxity First，LLF。$松弛度=截止时间-当前时间-任务执行时间$。主要用于抢占式调度。#### 例有两个周期任务，A、B的周期分别是20ms，50ms。A、B的执行时间分别是10ms和25ms。优先级倒置即高优先级进程（或线程）被低优先级（或线程）延迟或阻塞。例，假如有三个完全独立的进程P1、P2和P3，优先级P1&gt;P2&gt;P3。P1和P3通过共享一个临界资源进行交互。123P1：...P(mutex); CS-1; V(mutex);... P2: ...Program2...;P3：...P(mutex); CS-3; V(mutex);...假如P3最先执行，在执行了P(mutex)操作后，进入临界区CS-3。在时刻a，P2就绪，因为它比P3的优先级高，P2抢占了P3的处理机而运行，在时刻b，P1就绪，因为它比P2的优先级高，抢占处理机执行，但P1执行P(mutex)之后被阻塞，处理机被P2获得，P2执行结束后，P1仍不能进入临界区，处理机被P3获得，等P3退出临界区，P1才能获得处理机。所以本应该高优先级的P1优先执行，但是由于存在临界资源而导致优先级倒置。优先级倒置的解决遵循动态优先级继承原则：当高优先级进程P1要进入临界区去使用临界资源，如果已经有一个低优先级进程P3正在使用该资源，此时一方面P1被阻塞，一方面P3继承P1的优先级并一直保持到P3退出临界区。这样做就能保证不会有比P3优先级高但比P1优先级低的进程插进来。资源分类可重用资源和消耗性资源可重用性资源：可供用户重复使用多次的资源。特点：互斥访问系统中此资源数目相对固定系统中大多数资源属于此类可消耗性资源：临时性资源由进程动态创建和消耗，数目是可以不断变化的，比如信号量、进程通信的信息等。可抢占性资源和不可抢占性资源可抢占性资源：CPU和主存，不会引起死锁。不可抢占性资源：只能进程自行释放。如打印机，因为如果打印到一半，打印机被抢占，造成的结果只能是此次打印作废，所以它是不可抢占资源。死锁定义如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。死锁的起因竞争不可抢占性资源引起死锁一个资源只能同时被一个进程使用，但是下图P1在获得R1后还去申请R2，同时P2获得R2后还去申请R1，陷入僵局，引发死锁。竞争可消耗性资源引起死锁123P1：receive(p3,m3)； send(p2,m1)；P2：receive(p1,m1)； send(p3,m2)；P3：receive(p2,m2)； send(p1,m3)；如上代码，P1在等待P3给P1发消息，P2在等待P1给它P2发消息，P3在等待P2给P3发消息。造成一个死循环。进程推进顺序非法在下图中，X轴表示进程P1推进图，Y轴表示进程P2推进图。如果按照4号路线推进，可以看出P1在经过b、d段的执行之后，获得R1，P2在进过a、c、e段的执行之后获得R2。此时如果不加以处理，系统一定会进入死锁状态，因为接下来P1在拥有R1后又去申请R2，P2在拥有R2后又去申请R1。死锁产生的必要条件互斥条件：某段时间内，某资源只能由一个进程使用；请求和保持条件：进程因请求资源而阻塞时，对已分配给它的资源保持不放；不可抢占条件 ：资源在未使用完前，不能被剥夺，由使用进程释放；循环等待条件 ：发生死锁时，有向图必构成一环路。死锁处理共有三类做法：第一类是预防死锁，也就是破坏死锁产生的条件（破坏其中一个就可以），这样系统就永远不会产生死锁。第二类是死锁避免，死锁产生的根本原因是系统资源分配出现问题，如果能进行合理的资源分配就能避免死锁的发生。第三类是死锁发生后的检测和解除。预防死锁预防死锁是给系统施加一个条件使其永远不可能满足死锁产生的必要条件，但是互斥条件是不能被破坏的条件，所以预防死锁有三类做法：破坏“请求和保持”条件即进程在请求资源时，它不能持有不可抢占资源。有两种做法：所有进程在开始运行之前，一次性的申请其在整个运行过程中的全部资源，如果申请成功，进程便陷入等待。这样进程在运行的时候就不会再发出请求。进程在只获得运行初期所需的资源后便开始运行，但是进程在运行过程中需要逐步释放以分配给自己的资源，等初期获得所有资源都被释放后才能请求其他资源。破坏“不可抢占”条件当进程保持了某些不可被抢占资源，且提出的新需求又不能被满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这种预防策略的代价非常昂贵，比如进程请求的打印机被强制剥夺后，之前的工作等于作废。破坏“循环等待”条件常见的方法是“资源有序分配”。其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号升序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程，在拥有大编号资源再申请小编号资源时需要释放和小资源编号相等及以上的编号。避免死锁避免死锁讲道理是属于死锁的预防，但是它和预防死锁不同，预防死锁是破坏死锁产生的条件，避免死锁是防止系统进入不安全状态。所以我们就要明白什么是安全状态，它和死锁产生的必要条件有什么区别。安全状态安全状态指的是系统能按某种进程推进顺序(P1, P2, …, Pn)为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。此时，序列(P1, P2, …, Pn)为安全序列。如果系统无法找到这样一个序列，则称系统处于不安全状态。为什么能找到这样的序列系统就是安全的呢？其实它是一个递推的关系，假如系统在时刻i发起申请资源请求，其此时状态为a，系统会判断它申请成功后是否还能寻找到一个安全序列，如果能找到便可以分配，否则便是系统不安全状态。假如系统申请到了资源，还想发出申请请求，便会再次判断请求成功之后能否找到安全序列，由此递推下去可保证整个系统能避免死锁。安全状态和死锁必要条件的区别仍以此图为例。假如我们采用的是预防死锁策略中的破坏“请求和保持”条件里的第一个做法，那么推进顺序就不可能为4，因为进程P1在执行的时候需要获取全部资源才能执行。但对于避免死锁来说，系统可以按照4号推进顺序推进到e段和阴影区的交界处，然后进程P2在申请资源R2的时候会去判断分配R2给P2之后系统能否找到安全序列，事实上是找不到的，所以R2便不会分配给P2，这样系统就进入不了阴影区，从而可以避免死锁。所以预防死锁和避免死锁的区别是：预防死锁是每个进程在执行之前确保其自身不陷入死锁状态，如果每个进程都能不陷入死锁状态，系统便能永远安全。即从单个进程角度静态解决问题。但避免死锁是在每一次进行资源分配时判断分配之后是否系统处于安全状态，如果处于安全状态便可分配，否则便不能分配。即从系统整体角度动态解决问题。### 银行家算法#### 数据结构1. 可利用资源向量$Available$：是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果$Available[j]=K$，则表示系统中现有$R_j$类资源K个。2. 最大需求矩阵$Max$：这是一个$n×m$的矩阵，它定义了系统中$n$个进程中的每一个进程对$m$类资源的最大需求。如果$Max[i, j]=K$，则表示进程$i$需要$R_j$类资源的最大数目为K。3. 分配矩阵$Allocation$：这也是一个$n×m$的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果$Allocation[i,j]=K$，则表示进程i当前已分得$R_j$类资源的 数目为K。4. 需求矩阵$Need$：这也是一个$n×m$的矩阵，用以表示每一个进程尚需的各类资源数。如果$Need[i,j]=K$，则表示进程$i$还需要$R_j$类资源K个，方能完成其任务。可得：$Need[i,j]=Max[i,j]-Allocation[i,j]$#### 算法设进程$cusneed$提出请求$REQUEST[i]$，则银行家算法按如下规则进行判断。1. 如果$REQUEST[cusneed] [i]&lt;= Need[cusneed][i]$，则转2；否则，出错。2. 如果$REQUEST [cusneed] [i]&lt;= Available[i]$，则转3；否则，等待。3. 系统试探分配资源，修改相关数据：1. $Available[i]-=REQUEST[cusneed][i]$;2. $Allocation[cusneed][i]+=REQUEST[cusneed][i]$;3. $Need[cusneed][i]-=REQUEST[cusneed][i]$;4. 系统执行安全性检查算法，如安全，则分配成立；否则试探险性分配作废，系统恢复原状，进程等待。#### 安全性算法1. 设置两个工作向量$Work=Available$、$Finish=false$。2. 从进程集合中找到一个满足下述条件的进程$i$，$Finish[i]==false;$$Need[i, j]&lt;=Work[j];$，如找到，执行3；否则，执行4。3. 设进程获得资源，可顺利执行，直至完成，从而释放资源。$Work[i]=Work[i]+Allocation[i,j];$，$Finish[i]=true;$，循环2。4. 如所有的进程$Finish= true$，则表示安全；否则系统不安全。#### 举例- 假定系统中有五个进程$\lbrace P0, P1, P2, P3, P4\rbrace$和三类资源$\lbrace A,B, C\rbrace$，各种资源的数量分别为10、5、7，在$T0$时刻的资源分配情况如图所示。- $T0$时刻的安全性- $P1$请求资源：$P1$发出请求向量$Request1(1,0,2)$，系统按银行家算法进行检查。- $Request_1(1, 0, 2)≤Need_1(1, 2, 2)$- $Request_1(1, 0, 2)≤Available_1(3, 3, 2)$- 系统先假定可为$P1$分配资源，并修改$Available,Allocation_1和Need_1$向量。由此得到的资源变换情况如上上图括号所示。- 再利用安全性算法检查此时系统是否安全。- $P4$请求资源：$P4$发出请求向量$Request_4(3,3,0)$，系统按银行家算法进行检查。- $Request_4(3, 3, 0)≤Need_4(4, 3, 1);$。- $Request_4(3, 3, 0)&gt;Available(2, 3, 0)$，让$P4$等待。- $P0$请求资源：$P0$发出请求向量$Requst_0(0,2,0)$，系统按银行家算法进行检查。- $Request_0(0, 2, 0)≤Need_0(7, 4, 3);$- $Request_0(0, 2, 0)≤Available(2, 3, 0);$- 系统暂时先假定可为$P0$分配资源，并修改有关数据，如下图所示。进行安全性检查：此时可用资源$Available(2,1,0)$已经不能满足任何进程的需要，进入不安全状态，因此系统不分配资源。死锁的检测和解除死锁的检测在图中找一既非阻塞又非独立的进程节点$P_i$，如顺利，$P_i$可获得所有资源直至运行完毕。消去$P_i$所有的请求边和分配边，即释放占有的所有资源，同理再选下一进程节点$P_{i+1}, …, $若能消去所有的边，那么该图是可完全简化的，否则该图是不可完全简化的。具体做法如下：1. 可利用资源向量$Available[]$，它表示了m类资源中每一类资源的可用数目。2. 把不占用资源的进程（向量$Allocation[i]∶= 0$）记入L表中，即$L_i \bigcup L$。3. 从进程集合中找到一个$Request_i≤Work$的进程，做如下处理：1. 将其资源分配图简化，释放出资源，增加工作向量$Work∶ =Work+Allocation_i$。2. 将它记入L表中。4. 若不能把所有进程都记入L表中， 便表明系统状态S的资源分配图是不可完全简化的。 因此，该系统状态将发生死锁。#### 死锁的解除死锁解除有多种做法，如下是按代价递减排序的几种。1. 撤销所有死锁的进程。2. 将每个进程回退到先前定义的某个检查点，再重新启动所有进程。3. 逐个撤销死锁进程，直至死锁不存在。撤销进程的顺序应是基于某种最小代价原则，每次撤销后，死锁检测算法应该重新检测死锁是否依然存在。4. 剥夺进程P的资源交给进程Q，P同时会退到获得此资源的节点上。对于3和4，选择的标准可以如下：- 以占用处理器的时间最小；- 以产生的输出少；- 所估计的剩余运行时间最长；- 所占用的资源最少；- 优先权最低。## 存储器的层次我们都知道存储器的容量和速度是限制计算机发展的一大原因，人们对存储器的要求需要既快又大，但是这样带来的结果就是存储器的造价非常昂贵，所以不可能在计算机中全部配置既快又大的存储器。所以现代的计算机系统中都配置了多层结构的存储器系统来平衡速度差异问题。存储器一般被分成六层，不过在只有前四层属于内存，所以此篇只介绍前四层：### 主存储器- 用于保存进程运行时的程序和数据。- 对于微机系统和大中型机，容量为数十MB到数GB；对于嵌入式系统，容量为数十KB到数MB。- CPU从主存读取指令和数据。- CPU与外设交换信息要依托主存。- 为缓解CPU执行指令速度和主存访问速度的矛盾，引入寄存器和高速缓冲。### 寄存器- 访问速度做快，完全与CPU协调工作，价格十分昂贵，容量不可能很大。- 长度一般以字为单位。- 对于微机系统和大中型机，可能有几十个甚至上百个；对于嵌入式系统，仅有几个到几十个。### 高速缓冲- 容量大于或远大于寄存器，比内存小两到三个数量级左右，从几十KB到几MB。- 访问速度快于主存。- 将主存中经常访问的信息存放在高速缓冲，减少访问主存次数。### 磁盘缓冲- 将一部分频繁使用的磁盘数据和信息，暂时存放在磁盘缓冲中，减少访问磁盘次数。- 不是实际存在的存储介质，利用主存的存储空间，暂存从磁盘读出或写入的信息。总结一下：磁盘缓冲是为了解决内存和外存的速度差异而在内存中开辟的一块用于暂存磁盘数据的存储介质。主存储器是保存进程运行时的程序和数据的。寄存器是和CPU速度匹配的存储器，直接给CPU提供数据。虽然CPU是直接从寄存器去取指令和数据，但是寄存器的数据来源最终还是主存储器，所以为了减少访问CPU的次数，产生了高速缓冲来缓和寄存器和主存储器的矛盾。至于为什么能缓和呢？这是由于程序局部性原理。## 程序的装入和链接用户程序要在系统中运行，必须将它装入内存，其中有三个过程。- 编译：由编译程序（Complier）将用户源代码编译成若干个目标模块（Object Module）；- 链接：由链接程序（Linker）将编译后形成的目标模块以及它们所需要的库函数，链接在一起，形成一个装入模块（Load Module）；- 装入：由装入程序(Loader)将装入模块装入内存。### 链接链接程序的功能是将经过编译或汇编后得到的一组目标模块以及它们所需要的库函数，装配成一个完整的装入模块。#### 静态链接方式生成可执行文件时进行链接。主要有两步。1. 修改相对地址。2. 变换外部调用符号。#### 装入时动态链接目标模块是在装入内存时，边装入边链接的。装入时动态链接方式有以下优点：- 便于修改和更新。- 便于实现对目标模块的共享。#### 运行时动态链接将对某些模块的链接推迟到执行时才执行，即在执行过程中，当发现一个被调用模块尚未装入内存时，立即由OS去找到该模块并将之装入内存， 把它链接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上，这样不仅可加快程序的装入过程，而且可节省大量的内存空间。### 装入装入是将一个具有执行资格的模块加载进内存。#### 绝对装入方式在可执行文件中指定内存地址，装入时直接定位在上述（即文件中记录的地址）内存地址。逻辑地址和物理地址完全相同。#### 可重定位装入方式编译程序所生成的目标模块中采用逻辑地址，根据当前内存情况，将装入模块装入到适当位置。地址映射是在装入模块装入内存时一次性进行的，即是静态重定位。#### 动态运行时装入方式静态重定位时程序装入内存后不能移动，而且通常需要占用连续的内存空间。所以与其对应的动态重定位是将地址映射工作推迟到程序真正执行时才进行。现代计算机运行过程预处理把存储在不同文件中的源程序聚合在一起。把被称为宏的缩写语句转换为原始语句。编译：将高级语言翻译成汇编语言或机器语言。链接将多个可重定位的机器代码文件（包括库文件）连接到一起。解决外部内存地址（一个文件中的代码会引用其他文件中的数据对象或过程，这些数据对象或过程的地址对于此文件来说就是外部地址）问题。装入确定程序在内中的绝对地址（即修改程序起始地址），将修改后的指令和数据放到内存中适当的位置。连续分配存储管理方式连续分配是指为一个用户程序分配空间的时候，将所有程序装入到一段连续的物理内存中。在早期（20世纪60-80年代）的操作系统中，这种分配内存的方式曾经被广泛的使用。单一连续分配这是最简单的一种存储管理方式，但只能用于单用户、单任务的操作系统中。内存分为以下两个分区：系统区和用户区。操作系统使用系统区；应用程序装入到用户区，可使用用户区全部空间。固定分区分配固定分区式分配，是最早使用的一种可运行多道程序的存储管理方式。它将内存空间划分为若干个固定大小的区域，每个分区大小可相同，也可不同。OS占一区，其余每个分区中可以装入一道作业。为了便于内存分配，系统需建立一张分区使用表。当有一用户程序要装入时，从表中找出一个能满足要求的、尚未分配的分区分配给该程序，然后修改分区使用表。动态分区分配数据结构空闲分区表每个空闲分区占用一个表项。分区表的表项中包含分区号、分区始址及分区大小等表目。表长不易确定。占用额外内存。空闲分区链表利用各空闲分区自身的单元组成双向链表。操作速度较慢。#### 分区分配#### 分区回收- 如果回收区的前后有空闲区，可分为图示三种情况。回收时将空闲区和回收区合并。- 如果回收区的前后无空闲区，新建一个表项，填写信息插入。#### 分区检索算法##### 顺序检索算法- 首次适应算法：按各空闲分区首址的升序的方法组织，分配时，按空闲分区表（或空闲分区链）的先后次序，从头查找，找到符合要求的第一个分区。- 循环首次适应算法：分配空闲空间时，不是从链首（或表头）开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找。- 最佳适应算法：按空闲区大小的升序方法组织，分配时，按空闲分区表（或空闲分区链）的先后次序，从头查找，找到符合要求的第一个分区。就说明它是最适合的（即最佳的）。- 最坏适应算法：按空闲区大小的降序方法组织，分配时总是取空闲分区表（或空闲分区链）中的第一项，若大小不能满足申请者的要求，则表示系统中无满足要求的空闲区，分配失败；否则分配。##### 索引检索算法- 快速适应算法：将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，同时在内存中设立一张管理索引表，该表的每一个表项对应一种空闲分区类型，并记录其表头指针。空闲分区的分类是根据进程常用的空间大小进行划分，对于其他大小的分区，可以放在一个特殊的空闲区链表中。- 伙伴系统：分区大小均为2的K次幂。假设系统可利用空间容量为$2^m$个字，系统运行过程中，不断划分，将空闲分区根据大小分类。为长度为n的进程分配分区时，首先计算$i$值使得$2^{i-1}≦n≦2^i$。先找大小为$2^i$的分区分配，否则找大小为$2^{i+1}$的分区分配，把$2^{i+1}$分区分成两个$2^i$分区（互称伙伴），一个分配，另一个加入$2^i$的空闲分区链表。分配可能经过多次分割，回收可能进行多次合并。- 哈希算法：根据空闲分区在可利用空闲区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算，即得到在哈希表中的位置，从中得到相应的空闲分区链表，实现最近分配策略。#### 紧凑可变式分区也有零头问题。在系统不断地分配和回收中，必定会出现一些不连续的小的空闲区，称为外零头。虽然可能所有零头的总和超过某一个作业的要求，但是由于不连续而无法分配。解决零头的方法是拼接（或称紧凑），即向一个方向（例如向低地址端）移动已分配的作业，使那些零散的小空闲区在另一方向连成一片。分区的拼接技术，一方面是要求能够对作业进行重定位，另一方面系统在拼接时要耗费较多的时间。分页存储管理方式基本概念页面：将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页。物理块：把内存空间分成与页面相同大小的若干个存储块，称为（物理）块或页框（frame）。页面碎片：由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“页内碎片”。页面大小：每一页可进行编址的地址数目。页面大小应该满足2的n此幂。逻辑地址：页表：系统为每个进程建一张页表，其在内存的起始地址和长度记录在该进程的PCB中。页表项：页表的每一行。页表项长度：每个页表项占用的编址个数。从逻辑地址那里我们可以看到页号占用了20位，对应的块号也要占用20位，当然块号本身可能不止$2^{20}$个。又由于为了控制对物理块的读写等操作，会在页表项中加上控制字段。如果内存按字节编址，即每个编址可以存储8个二进制位，那么页表项占用的二进制位总数大于内存的字长度。我们需要把一个页表项拆开存放在多个编址后的空间中。### 地址变换$物理地址=块号+块内地址=F(逻辑地址的页号*页表项长度+页表始址)+业内地址$。每次进行地址变换需要访问两次内存，内存速度较慢，所以影响计算机整体性能。### 具有快表的地址变换根据程序局部性原理，把最近使用的页表项存放在快表中，下次再进行地址变换时先去快表中查找对应项，如果没找到再去内存中查找，然后把新找到的页表项存放在快表中，如果快表已满，采用某种算法淘汰一份。有效访问时间设t是访问内存的时间，a是快表命中率，λ是查找快表所需的时间。普通地址变换时间：t+t具有快表的地址变换时间：$ a \ast \lambda + (1-a) \ast (t+\lambda)$。两级页表对于两级页表，是将页表再进行分页，页面的大小与内存物理块的大小相同。逻辑地址结构可描述如下：两级页表地址变换可推广至N级页表。### 反置页表页表是按每个进程的页号排序，指示出物理块号的位置，反置页表是按物理块号排序，指示出每个页隶属的进程和页号。此方法需要为每个进程创建一个外部页表，即将页表建立在外存中。进程进行地址变换时先从反置页表里查找，如果查找不到则去外村中查找，再将查找到的页表项调入内存。分段存储管理方式之前的分区管理都是为了更好的利用内存。为了满足程序员在编程上的要求引入了分段管理方式。方便编程：通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从0开始编址，并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名（段号）和段内偏移量（段内地址）决定的。例如，下述的两条指令便是使用段名和段内地址：其中，前一条指令的含义是将分段A中D单元内的值读入寄存器1；后一条指令的含义是将寄存器1的内容存入B分段的C单元中。12LOAD 1，[A] |〈D〉；STORE 1，[B] |〈C〉；信息共享：在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程和函数。分页系统中的“页”只是存放信息的物理单位（块），并无完整的意义，不便于实现共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用户程序分段的组织方式相适应。信息保护：信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地实现信息保护功能。动态增长：在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。动态链接：动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段（目标程序）调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。分段地址段表地址映射地址变换分页和分段的主要区别页是信息的物理单位，段则是信息的逻辑单位；页的的大小固定且由系统决定，而段的长度不固定，由用户所编写的程序决定；分页的地址空间是一维的，而分段的地址空间是二维的。分页是系统管理的需要；分段是为了更好满足用户的需要。段页式存储管理方式分段结构具有逻辑上清晰的优点，但它的一个致命弱点是每个段必须占据主存储器的连续区域，于是，要装入一个分段时可能要移动已在主存储器中的信息，为了克服这个缺点，可兼用分段和分页的方法，构成段页式存储管理。每个作业仍按逻辑分段，但对每一段不是按单一的连续整体存放到存储器中，而是把每个段再分成若干个页面，每一段不必占据连续的主存空间，可把它按页存放在不连续的主存块中。原理逻辑地址空间分段，段内分页，内存分块（页框），存储管理的分配单位是：物理块（页框）地址结构：段号，页号，页内偏移地址。每个作业一张段表，每段一张页表。地址变换：先查段表，再查该段的页表。映射地址变换机构传统存储器的问题传统的内存管理方式要求将一个作业全部装入内存才可以运行，由此造成了以下两种情况：大作业对内存的要求超出物理内存总容量，致使其无法运行。内存由于容量的限制，只能装入少量的作业使其运行，而其它大量作业留在外存。解决原理程序局部性原理程序执行时， 除了少部分的转移和过程调用指令外，在大多数情况下仍是顺序执行的。过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域， 但经研究看出，过程调用的深度在大多数情况下都不超过5。程序中存在许多循环结构， 这些虽然只由少数指令构成， 但是它们将多次执行。程序中还包括许多对数据结构的处理， 如对数组进行操作， 它们往往都局限于很小的范围内。表现两个方面时间局限性。如果程序中的某条指令一旦执行， 则不久以后该指令可能再次执行；如果某数据被访问过， 则不久以后该数据可能再次被访问。产生时间局限性的典型原因，是由于在程序中存在着大量的循环。空间局限性。一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，其典型情况便是程序的顺序执行。基于局部性原理在程序装入时，不必将其全部读入到内存，而只需将当前需要执行的部分页或段读入到内存，就可让程序开始执行。在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统，将相应的页或段调入到内存，然后继续执行程序。虚拟存储器定义所谓虚拟存储器， 是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。可见，虚拟存储技术是一种性能非常优越的存储器管理技术，故被广泛地应用于大、 中、 小型机器和微型机中。实现虚拟存储器的条件由于一个作业被分成多次地调入内存运行，所以在内存分配时必须采用离散分配方式。同时需要解决以下问题：页表（段表）的设计（软件支持）程序不在内存时去外存调度需要中断（硬件支持）逻辑地址转换为物理地址（软件硬件支持）如何给每个进程分配物理块一个页（段）进入内存时，淘汰哪个页（段）请求分页存储管理方式页表机制用于将用户逻辑地址空间变换为内存的物理地址空间。在页表中增加若干项，以便于标志程序或数据的状态。- 状态位（存在位）P：表示该页是否调入内存。- 访问字段A：用于记录该页在某段时间内被访问的次数。- 修改位M：表示该页在调入内存后是否被修改过。未修改过不必写回外存，修改要写回外存。- 外存地址：该页在外存上的地址，通常是物理块号。### 缺页中断机构- 在地址映射过程中，在页表中发现所要访问的页不在内存，则产生缺页中断。操作系统接到此中断信号后，就调出缺页中断处理程序，根据页表中给出的外存地址，将该页调入内存，使进程继续运行下去。- 如果内存中有空闲块，则分配一页，将新调入页装入内存，并修改页表中相应页表项目的状态位及相应的内存块号。- 若此时内存中没有空闲块，则要淘汰某页，若该页在内存期间被修改过，则要将其写回外存。- 缺页中断发生在指令执行期间，而通常情况下，CPU是在一条指令执行完后，才检查是否有中断请求到达；一条指令在执行期间，可能产生多次缺页中断。所以硬件机构应能保存多次中断时的状态，并保证最后能返回到中断前产生缺页中断的指令处，继续执行。### 地址转换机构内存分配最小物理块数的确定最小物理块数：保证进程正常运行所需的最小物理块数。与计算机的硬件机构有关，取决于指令的格式、功能和寻址方式。内存分配策略在请求分页中，可采取两种分配策略，即固定和可变分配策略。在进行置换时，也可采取两种策略，即全局置换和局部置换（置换范围不同）。于是组合出三种适用的策略：固定分配局部置换：分配固定数目的内存空间，在整个运行期间都不改变。如果缺页，则先从该进程在内存的页面中选中一页，进行换出操作，然后再调入一页。可变分配全局置换：每个进程预先分配一定数目的物理块，同时OS也保持一个空闲物理块队列。当缺页时，首先将对OS所占有的空闲块进行分配，从而增加了各进程的物理块数。当OS的空闲块全部用完，将引起换出操作。可变分配局部置换：系统根据缺页率动态调整各进程占有的物理块数目，使其保持在一个比较低的缺页率状态下。物理块分配算法平均分配算法：将系统中所有可供分配的物理块，平均分配给各个进程。按比例分配算法：按照进程的大小比例分配物理块。考虑优先权的分配算法：为了对于紧迫的作业，能够尽快完成。可以将内存的物理块分成两部分，一部分按照比例分配给各进程，另一部分根据进程优先级，适当增加其相应的份额，分配给各进程。页面调入何时调入页面提前取页：预先装入主存一页或几页（提前页）。请求取页：当用到某页而不在主存时即缺页时取页。从何处调入页面外存有两个部分：文件区和对换区。对换区I/O操作速度比文件区相对快一些，因此一般应当尽量使用对换区来调入页面。对于不同情况，采用不同的策略：系统有足够的对换空间：全部从对换区调入。系统对换空间不足：未修改的从文件区调入，修改的从对换区调入。UNIX的调入方式：未运行过的从文件区调入，运行过的放在对换区，允许页面共享。页面调入过程进程需要的页面不在内存，引起缺页中断中断处理程序保留现场环境，转入缺页中断处理程序中断处理程序查找页表，得到对应的外存物理块号。如果内存有空闲，则启动磁盘操作，将所缺的页面读入，并修改页表。否则，到4。执行置换算法，选出要换出的页面，如果该页修改过，应将其写入磁盘，然后将所缺页调入内存，修改相应表项，将其存在位置为1，并放入快表。利用修改后的页表，形成物理地址，访问内存数据。缺页率假设进程逻辑空间为n页，系统为其分配物理块数为m。如果进程运行过程中，访问页面成功次数为S，访问页面失败次数为F，总页面访问次数A=S+F，则进程运行过程中 缺页率f=F/A。影响缺页率的主要因素：页面大小：页面越大，缺页率越小进程所分配物理块数：物理块越多，缺页率越小页面置换算法：合理的置换算法能更少将页面调入调出程序固有特性：比如做循环操作时，缺页率较低，因为执行的命令都是一系列大致相同的指令。页面置换算法最佳置换算法所选择的被淘汰页面，将是以后永不使用的， 或许是在最长（未来）时间内不再被访问的页面。采用最佳置换算法，通常可保证获得最低的缺页率。这是一种理想情况，是实际执行中无法预知的，因而不能实现。可用作性能评价的依据。例：假定系统为某进程分配了三个物理块， 并考虑有以下的页面号引用串17，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1进程运行时， 先将7，0，1三个页面装入内存。 以后， 当进程要访问页面2时， 将会产生缺页中断。此时OS根据最佳置换算法， 将选择页面7予以淘汰。#### 先进先出页面置换算法选择装入最早的页面被置换。可以通过链表来表示各页的建立时间先后。#### 最近最久未使用置换算法选择内存中最久未使用的页面被置换。这是局部性原理的合理近似，性能接近最佳算法。但由于需要记录页面使用时间的先后关系，硬件开销太大。##### 硬件支持- 寄存器：每个页面设立移位寄存器：被访问时左边最高位置1，定期右移并且最高位补0，于是寄存器数值最小的是最久未使用页面。栈：一个特殊的栈，每当进程访问某页面时，便把被访问的页面移到栈顶，于是栈底的是最久未使用页面。最少使用置换算法选择到当前时间为止被访问次数最少的页面被置换。实现方法1：每个页面设立移位寄存器：被访问时左边最高位置1，定期右移并且最高位补0，这样，在最近一段时间内时用最少的页面将是$\sum_{R_i}$最小的页。实现方法2：每页设置访问计数器，每当页面被访问时，该页面的访问计数器加1；发生缺页中断时，淘汰计数值最小的页面，并将所有计数清零。Clock置换算法也称最近未使用算法（NRU, Not Recently Used），它是LRU（最近最久未使用算法）和FIFO的折衷。内存中所有页面通过链接指针形成一个循环队列，每页有一个使用访问位，若该页被访问则置1。置换时采用一个指针，从当前指针位置开始按地址先后检查各页，寻找访问位为0的页面作为被置换页。指针经过的访问位为1的页都修改0，最后指针停留在被置换页的下一个页。改进Clock置换算法由于Clock算法不考虑换出页面时，页面是否修改过的问题。这样在换出的页面如果被修改过的话，则必须做拷回磁盘处理，开销比较大。于是，改进型的Clock算法为每个页又增加了一个修改位。选择页面时，尽量选择既未使用又没有修改的页面。访问位A，修改位M有四种不同情形：1类(A=0，M=0）既未访问，又没有修改，最佳淘汰页2类(A=0，M=1）未访问，但是有修改，效率低的淘汰页3类(A=1，M=0）被访问，但没有修改4类(A=1，M=1）既被访问，又有修改算法：指针从当前位置开始，开始第一轮扫描循环队列，寻找A=0且M=0的页面，找到则可换出。如果找不到，则开始第二轮扫描，寻找A=0且M=1的页面，并且每经过一个页面时，将其访问位A设置为0。如果找到一个第2类页面，则可换出。如果仍旧未找到合适的换出页面，则此时指针回到初始位置，且所有页面其访问位A为0。再转回1继续工作。页面缓冲算法在请求分页系统中，进程在运行的时候经常会发生页面换进换出的情况。而影响换进换出效率的原因如下：页面置换算法：好的页面置换算法能使进程运行中具有较低的缺页率，从而可以减少换进换出的开销。写会磁盘的频率。读入内存的频率。而页面缓存算法就是降低读写磁盘的频率来降低开销。做法如下：空闲页面链表：当有一个未被修改的页要换出时，实际上并不将其换出到外存，而是把它们所在的物理块挂在空闲链表的末尾。如果以后某进程请求此页时，便将其从空闲页面链表上取下。修改页面链表：和空闲页面链表的功能一样，只是说此链表是存放已修改页面的。当链表上挂有足够多的页面时，将它们一齐写入磁盘，这样可以降低读写磁盘的频率。访问内存的有效时间被访问页在主存，且相应页表项在快表：$EAT= \lambda +t$查找快表+访问实际物理地址被访问页在主存，但相应页表项不在快表：$ EAT= \lambda +t + t + \lambda$查找快表+读取页表+读取数据+更新快表被访问页不在主存：$EAT= \lambda + t + \varepsilon + t + \lambda$查找快表+读取页表+缺页中断处理+读取数据+等新快表内存的有效访问时间为：$EAT= \lambda + t + (1 - a ) \ast [f \ast ( \varepsilon + \lambda + t)+(1-f) \ast(\lambda+t)]$a为命中率，f为缺页率。查找快表+访问内存一次+未命中不需要请求缺页访问快表+未命中时不需要请求缺页访问内存+未命中需要请求缺页访问快表+未命中时需要请求缺页访问内存+未命中时需要请求缺页开销。抖动与工作集抖动由于只装入一个进程的部分程序和数据便可开始运行，故希望运行更多进程，增加多道程序度。但在多道程序环境下，并不是多道程序的度越高，系统吞吐量越大。当CPU的利用率达到某一峰值后，若继续增加多道程度，将产生“抖动”。抖动是指同时运行进程太多，分配给每个进程物理块太少，进程在运行时频繁缺页，必须请求调页，等待页面调进调出的进程增多，磁盘访问时间急剧增加，进程大部分时间用于页面换进换出，处理机利用率急剧下降并趋于0。工作集基于程序运行的局部性原理，程序运行时，对页面的访问并不均匀，一段时间仅局限于较少的页面；另一段时间，有可能局限于另一些较少的页面，如果能预知这些页面，并提前调入，将大大减少缺页率工作集，是指在某段时间间隔内，进程实际要访问的页面的集合。为了降低缺页率，应将程序全部工作集装入主存。方法：用程序过去某段时间的行为作为程序将来某段时间行为的近似。定义：是指在某段时间间隔内，进程实际要访问的页面的集合。为了降低缺页率，应将程序全部工作集装入主存。方法：用程序过去某段时间的行为作为程序将来某段时间行为的近似。工作集$ \omega (t, \Delta) $是二元函数。某进程在时间t的工作集记为$ \omega (t, \Delta) $，其中，$\Delta$为工作集的窗口尺寸。例窗口大小$\Delta$选择得过小，频繁产生缺页中断。窗口大小$\Delta$选择得很大，失去了虚拟存储器的意义抖动的预防方法采取局部置换策略：仅允许进程在自身范围内进行置换，不影响其他进程在CPU调度程序中引入工作集算法：调入新作业时，应该检查每个进程在内存中的驻留集是否足够大L=S准则：产生缺页的平均时间L=系统处理进程缺页的平均时间S选择暂停的进程：使某些低优先级的进程进程挂起，从而腾出内存空间请求分段存储管理方式请求分页系统建立的虚拟存储器，是以页面为单位进行换入、换出操作的。在请求分段系统中实现的虚拟存储器，以分段为单位进行换入和换出。程序在运行之前，只需要装入必要的若干个分段即可运行。当访问的分段不在内存时，可由OS将所缺少的段调入内存。使用请求分段存储管理方式可以对动态链接有很好的支持。请求段表机制- 存取方式：标记本段存取属性。如读R，写W，执行X- 访问字段A：记录本段使用的频繁程度- 修改位：是否在调入内存后做过修改- 存在位：本段是否装入内存- 增补位：该段是否动态增长过### 缺段中断机构要有专门的缺段中断处理程序。特点：- 指令和操作数必定不会跨越在段边界上。- 由于段的长度是不固定的，处理比缺页系统复杂。- 调入一个段可能要淘汰几个内存中的段。### 请求中断处理地址中断机构分段的共享与保护共享段表- 共享进程计数：多少进程在使用此段。- 存取控制手段：每个共享段，应为不同进程赋予不同的存取权限。- 断号：同一个共享段在不同进程那有不同的断号。#### 分配第一个请求的进程，由系统分配一物理块，调入共享段，设置相关表项信息，并置count=1； 以后的进程，在自己的段表中增加一项，填入共享段的信息，在共享段表项中做count=count+1，填写进程相关信息。#### 回收1. 做count=count-1；2. 若count=0 ，则该共享段被回收。#### 分段保护- 越界检查：在进行存储访问时，要将逻辑地址的段号与段表长度进行比较，如果超出则发生越界中断信号；其次，将段内地址与段表中该段的长度进行比较，如果有效才进行转换，否则产生越界中断信号。- 存取控制检查：用于规定对该段的访问权限。通常的访问方式有：- 读：允许用户对该段/页内任何信息或其副本进行读操作。- 写：允许用户修改该段/页内任何信息直至撤消整个段/页。- 执行：用户可以执行该段/页程序，数据段/页除外。- 增加：用户可在段/页的末尾添加信息，但不允许修改已存在于段/页中的信息。- 环保护检查：是一种功能较完善的保护机制。- 思想：将所有的程序分成不同的级别，分别放置在不同的环上。内环（编号小，在内侧）的程序具有高优先权，外环的程序优先权低。- 操作系统核心安排在0环内；重要程序和操作系统服务安排在中间环；一般应用程序安排在外环。- 一个程序可以直接访问在相同环或低优先级环（比自身相对靠外的环）上的数据。- 一个程序访问高优先级（比自己靠内的环）时，通过系统调用方式实现。## IO系统的基本功能输入输出系统和OS中的其他部分有很大区别，因为其他部分都是在说计算机接受任务后该怎么运行能又快又可靠的完成任务并把结果输出。而输入输出系统是怎么快速稳定的将任务的需求输入和任务的结果输出。又由于输入输出设备种类繁多，比如输入设备中的键盘、鼠标、网卡、摄像头，输出设备中的打印机、音频等。所以输入输出系统被划分很多层次来尽可能屏蔽物理细节。- 隐藏物理设备的细节：只需要使用简单的命令就能操作各种具有不同实现的硬件完成相应需求。- 与设备的无关性：用户不需要指定哪些设备完成功能，只需要描述需求，OS会选择一个设备完成功能。- 提高处理机和IO设备的利用率：IO设备之间一般是相互独立的，因此设备之间能够并行操作，所以OS应让处理机和设备之间能并行操作。- 对IO设备进行控制：- 轮询的可编程IO方式。- 采用中断你的可编程IO方式。- 直接存储器访问方式。- IO通道方式。- 确保对设备的正确共享。- 错误处理。## IO软件的层次结构- 用户层软件：提供设备与用户交互的接口，用户可以使用该层提供的功能直接控制设备。- 设备独立性软件：设备分配，设备保护，设备分配，设备回收，数据缓存等。- 设备驱动软件：发出控制设备的命令。- 中断处理程序：保存被中断的进程的CPU环境，转入相应的中断处理程序仅需处理，处理完毕后再恢复被中断进程的现场，返回到被中断的进程。## IO系统各模块层次视图- 块设备：输入输出以数据块为单位的设备。如磁盘。- 流设备：字符设备的输入输出，如键盘。- 网络通信接口：网卡。## IO设备和设备控制器直接和IO设备对接的是设备控制器。### 作用1. 接收和识别命令（控制寄存器、命令译码器）：设备控制器将CPU送来的命令写入控制器寄存器中，并进行译码。2. 数据交换（数据寄存器）。3. 设备状态的了解和报告（状态寄存器）。4. 地址识别（地址译码器）：系统中的每个设备都有自己的地址段，设备接口电路中有多个寄存器，一个寄存器有唯一的一个地址，每个地址为I/O端口，该地址称为I/O端口地址。设备控制器必须能识别每个设备的地址。5. 数据缓冲：缓冲器。6. 差错控制：差错检测码。### 组成- 设备控制器和处理机的接口：用于实现CPU与设备控制器之间的通信。- 设备控制器和设备的接口。- IO逻辑：在一个设备控制器上，可以连一个或多个设备。相应的，在控制器中就有一个或多个设备接口，一个接口连一台设备，控制器中的I/O逻辑根据处理机发来的地址信号，去选择一个设备接口。控制器中的I/O逻辑用来实现对设备的控制。通过接收CPU 发来的命令和地址信息，对所选设备进行控制### CPU如何控制设备控制器CPU控制内存时需要指定指令地址、数据地址等。控制设备控制器亦如此，一般有两种控制方式：- 利用特定IO指令：利用特殊的IO指令控制设备控制器。- 内存映像IO：不再区分内存和控制器中的寄存器地址。假如有一个地址K，当0&lt;=K&lt;N时被认为是内存地址，K&gt;=N时被认为是寄存器地址。### IO通道有了设备控制器之后，CPU便可以操作控制器完成对IO设备的控制，但是此时数据交换仍然需要CPU的全程参与，所以引入IO通道来使数据传送、IO设备的组织管理等都独立于CPU。通道是独立于CPU的专门负责数据输入/输出传输工作的处理机，对外部设备实现统一管理，代替CPU对输入/输出操作进行控制，从而使输入，输出操作可与CPU并行操作。通道执行通道程序来控制IO操作。与CPU的区别：- 通道程序指令类型单一- 通道没有自己的内存，通道程序在主机的内存中，即通道与CPU共享内存。#### 字节多路通道主要连接以字节为单位的低速IO设备。如打印机，终端。- 按字节交叉方式工作的通道。通常含有许多非分配型子通道，其数量从几十个到数百个，每一个子通道连接一台I/O设备。这些子通道按时间片轮转方式共享主通道。- 字节多路通道以字节为单位传输信息，它可以分时地执行多个通道程序。当一个通道程序控制某台设备传送一个字节后，通道硬件就控制转去执行另一个通道程序，控制另一台设备传送信息。#### 数组选择通道主要连接磁盘，磁带等高速I/O设备选择通道是按数组方式进行数据传送，每次传送一批数据，故传送速度很高。选择通道在一段时间内只能执行一个通道程序，只允许一台设备进行数据传输。当这台设备数据传输完成后，再选择与通道连接的另一台设备，执行它的相应的通道程序。这种独占性又使得通道利用率很低。#### 数组多路通道主要连接高速设备。- 结合了数组选择通道传送速度高和字节多路通道能进行分时并行操作的优点。它先为一台设备执行一条通道指令，然后自动转接，为另一台设备执行一条通道指令。它含有多个非分配型的子通道，既有很高的数据传输率，又能获得令人满意的通道利用率- 对通道程序采用多道程序设计的硬件实现- 可以连接多台高速设备，数据传输按数组方式，一段时间内可以执行多道通道程序#### 解决瓶颈通道执行通道程序，向控制器发出命令，并具有向CPU发中断信号的功能。一旦CPU发出指令，启动通道，则通道独立于CPU工作。但是，由于通道价格贵，通道数量少，往往使之成为IO的“瓶颈”。解决办法是在不增加通道的前提下，增加设备到主机间的通路，一个通道可连接多个控制器，一个控制器可连接多个设备，形成树形交叉连接。## 中断机构和中断处理程序### 中断的理解说到中断还不得不从现代操作系统的特性说起，无论是桌面PC操作系统还是嵌入式都是多任务的操作系统，而很遗憾，处理器往往是单个的，即使在硬件成本逐渐下降，但处理器的数量依然不可能做到每个任务一个CPU，所以CPU必须作为一种全局的资源让所有任务共享。即什么时候给任务A用，什么时候给任务B用……这就是进程调度，具体的安排就由调度算法决定了。进程如何去调度？现代操作系统一般都是采用基于时间片的优先级调度算法，把CPU的时间划分为很细粒度的时间片，一个任务每次只能时间这么多的时间，时间到了就必须交出使用权，即换其他的任务使用。这种要看操作系统的定时器机制了。那么时间片到之后，系统做了什么呢？这就要用到我们的中断了，时间片到了由定时器触发一个软中断，然后进入相应的处理历程。当然这一点不足以表明中断的重要，计算机操作系统自然离不开外部设备：鼠标、键盘、网卡、磁盘等等。就拿网卡来讲，我计算机并不知道时候数据包会来到，我能保证的就是数据来了我能正常接收就行了。但是我又不可能一直等着接收数据包，要是这样其他任务就死完了。所以合理的办法是，你数据包来到之后，通知我，然后我再对你处理，怎么通知呢？？答：中断！键盘、鼠标亦是如此！### 中断的定义指处理机处理程序运行中出现的紧急事件的整个过程.程序运行过程中，系统外部、系统内部或者现行程序本身若出现紧急事件，处理机立即中止现行程序的运行，自动转入相应的处理程序（中断服务程序），待处理完后，再返回原来的程序运行，这整个过程称为程序中断。可分为两类：#### 硬中断（Hardware Interrupt）- 外部中断：一般是指由计算机外设发出的中断请求，如：键盘中断、打印机中断、定时器中断等。外部中断是可屏蔽的。- 内部中断是指因硬件出错（如突然掉电、奇偶校验错等）,或运算出错（除数为零、运算溢出、单步中断等）所引起的中断，内部中断是不可屏蔽的。#### 软中断（Software Interrupt）软中断是利用硬中断的概念，用软件方式进行模拟，实现宏观上的异步执行效果。很多情况下，软中断和”信号”有些类似，同时，软中断又是和硬中断相对应的，硬中断是外部设备对CPU的中断，软中断通常是硬中断服务程序（模拟硬件发出中断的程序）对内核的中断，信号则是由内核（或其他进程）对某个进程的中断。### 时钟中断在Linux的0号中断是一个定时器中断。在固定的时间间隔都发生一次中断，也是说每秒发生该中断的频率都是固定的。该频率是常量HZ，该值一般是在100 ~ 1000之间。该中断的作用是为了定时更新系统日期和时间，使系统时间不断地得到跳转。另外该中断的中断处理函数除了更新系统时间外，还需要更新本地CPU统计数。若进程的时间片递减到0，进程则被调度出去而放弃CPU使用权。Linux的OS时钟的物理产生原因是可编程定时/计数器产生的输出脉冲，这个脉冲送入CPU，就可以引发一个中断请求信号，我们就把它叫做时钟中断。时钟中断是特别重要的一个中断，因为整个操作系统的活动都受到它的激励。系统利用时钟中断维持系统时间、促使环境的切换，以保证所有进程共享CPU；利用时钟中断进行记帐、监督系统工作以及确定未来的调度优先级等工作。可以说，时钟中断是整个操作系统的脉搏。## 设备驱动程序### 功能1. 接受设备独立性软件发来的命令和参数，将接收到的抽象要求转换为具体要求2. 检查用户IO请求的合法性，了解IO设备的状态，传递有关参数，设置设备的工作方式3. 发出IO命令，如果设备空闲，启动IO设备完成指定的IO操作；如果设备忙碌，则将请求挂在设备队列上等待4. 及时响应由控制器或通道发来的中断请求，并根据其中断类型调用相应的中断处理程序进行处理。5. 对于设置有通道的计算机系统，驱动程序还应能够根据用户的IO请求，自动地构成通道程序。### 特点1. 驱动程序主要是在设备无关性软件和设备控制器之间的一个通信程序2. 驱动程序与IO设备特性密切相关：通常由硬件厂商提供3. 驱动程序与I/O控制方式密切相关:中断驱动和DMA方式4. 驱动程序与硬件相关,部分代码需用汇编语言编写5. 驱动程序应允许可重入### 处理过程1. 将抽象要求转换为具体要求1. 通常设备控制器中都有若干个寄存器，分别用于暂存命令、数据和参数等；2. 用户及上层软件对设备控制器的具体情况毫无了解，因而只能向它们发出抽象的要求(命令)，但不能直接传送给设备控制器。需要将抽象要求转换为具体要求(命令码，数据，参数)。例如，将抽象要求中的盘块号转换为磁盘的盘面、磁道号及扇区。这一转换工作只能由驱动程序来完成；3. 在OS中只有驱动程序才同时了解抽象要求和设备控制器中的寄存器情况；也只有它才知道命令、数据和参数应分别送往哪个寄存器。2. 检查IO请求的合法性3. 读出和检查设备的状态4. 传送必要的参数，设置工作方式5. 启动I/O设备1. 在完成上述准备工作后，驱动程序可以向控制器中的命令寄存器传送相应的控制命令2. 对于字符设备，若发出的是写命令，驱动程序将把一个数据传送给控制器；若发出的是读命令，则驱动程序等待接收数据，并通过从控制器中的状态寄存器读入状态字的方法，来确定数据是否到达。3. 驱动程序发出IO命令后，基本的IO是在设备控制器的控制下进行的，通常IO操作所要完成的工作较多，需要一定的时间，如读/写一个盘块中的数据，此时，驱动程序进程把自己阻塞起来，直至中断到来时才将它唤醒。### 对IO设备的控制方式#### 使用轮询的可编程I/O方式CPU发出启动外设的I/O指令，同时将忙/闲标志置为1。如果外设的工作没有完成，则标志一直为1，CPU不断循环检测该标志，直到标志为不忙为止。#### 使用中断的可编程I/O方式CPU设定I/O设备的初始值，然后不再忙等待，运行其他进程，当前进程阻塞；I/O设备完成对当前数据的处理后，向CPU发出中断，I/O中断处理程序将负责传送剩余数据。#### 直接存储器访问(DMA)方式采用中断驱动IO方式时的CPU，是以字为单位进行干预的。如果将这种方式用于块设备的I／O，是极其低效的。如：为了从磁盘中读出1KB的数据块；需要中断1K次CPU。而DMA方式使用独立的DMA控制器代替CPU的工作，I/O设备与DMA通信，DMA在传输完成一个数据缓冲区之后再向CPU发中断。- 数据传输的基本单位是数据块，即CPU与IO设备之间，每次传送至少是一个数据块，主要用在块设备的IO操作中。- 在DMA方式中，利用总线直接连接外设和内存，由DMA控制机构窃取总线占有权，完成外设与内存间的成批数据交换。所传送的数据是从设备直接送入内存的，或者相反。- 仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在控制器的控制下完成的，不再需要CPU进行干预。#### I/O通道控制方式使用DMA方式，CPU每发出一条I/O指令，只能读写一个连续的数据块。如果需要一次去读多个离散的数据块且将它们分别送到不同的内存区域，则需要CPU分别发出多条I/O指令及进行多次中断处理，才能完成。而IO通道可实现CPU、通道和I/O设备三者的并行操作，进一步提高CPU与外设之间的并行工作能力，使I/O操作形成独立于CPU的体系，减少CPU的负担，使外设与内存的数据交换更加灵活，从而更有效地提高整个系统的资源利用率。## 与设备无关的I/O软件为了便于对外设进行管理，系统对每台进入计算机系统中的设备都给定一个对应的编号，作为调用时识别和区分设备用。这种编号无任何重复，一般被称为设备的绝对号（或物理设备名）。早期操作系统，应用程序直接使用物理设备名称，非常不灵活。所以引入逻辑设备名，规定用户申请外设时，只需要向系统说明所需用的某类设备真正在实际中使用哪台设备，由系统根据这类设备的应用情况作出分配。### 设备分配在多道程序环境下，设备不允许用户自行使用，而必须由系统分配。对于进程的IO请求，只要是安全（无死锁），设备分配程序便按照一定的策略进行设备分配。数据结构：- 系统设备表SDT：System Device Table。- 整个系统中只有一张，全面反映了系统中的外设资源的类型、数量、占用情况等。- 在SDT表中，每个接入系统中的外围设备都占有一个表目项。登录了该设备的名称、标识、设备控制表DCT的入口地址、设备驱动程序的入口地址及占用设备的进程名称等相关信息。设备控制表DCT ：Device Control Table。每台设备都有一张设备控制表DCT，用于记录本设备的情况。Type：设备类型Deviceid:设备标识符设备队列队首指针设备状态：标识设备忙或者空闲；与设备连接的控制器表指针。重复执行次数控制器控制表COCT：Controller Control Table。每个控制器都有一张，用于记录某控制器的使用分配情况及与该控制器相连的通道的情况。控制器号：控制器的内部标识符。控制器状态：控制器忙/闲，好/坏的状态标志。通道指针：指向与该控制器相联的通道控制表CHCT，当控制器与若干通道连接时该项内含多个指针。等待队列指针：指向等待该控制器的I/O进程队列通道控制表CHCT：Channel Control Table。反映了通道的情况，系统中的每个通道一张CHCT。通道号：通道内部标识符通道状态：通道的各种状态（好/坏，已分/未分等）的反映等待队列指针：等待该通道的I/O进程队列的首位置设备分配算法用户层的I/O软件系统调用与库函数用户层软件必须使用一组系统调用来取得操作系统服务，在高级语言中都提供了相应的库函数来完成此功能。SPOOLing程序多道程序技术将一台CPU虚拟为多台CPU，从而可以提高CPU的利用率。而SPOOLing系统是模拟脱机输入输出系统来实现多个用户共享一台物理IO设备。脱机输入输出系统的IO处理机 对应 SPOOLing程序。脱机输入输出系统的高速缓冲 对应 内存。缓冲区单缓冲区双缓冲区为输入或输出分配两个缓冲区，让两个缓冲区交替工作，形成并行操作的方式。环形缓冲区空缓冲区R：用于存放数据（指针：Nexti）已装满数据的缓冲区G：其中的数据提供给进程使用。（指针：Nextg）现行工作缓冲区C：当前进程使用的缓冲区。（指针：Current）磁盘存储器的性能和调度当磁盘驱动器执行读/写功能时。盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头（又叫磁头）下通过，就可以进行数据的读/写了。一般磁盘分为固定头盘（磁头固定）和活动头盘。固定头盘的每一个磁道上都有独立的磁头，它是固定不动的，专门负责这一磁道上数据的读/写。活动头盘 （如上图）的磁头是可移动的。每一个盘面上只有一个磁头（磁头是双向的，因此正反盘面都能读写）。它可以从该面的一个磁道移动到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的（行动整齐划一）。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。### 磁盘访问时间1. 寻道时间$T_s$：$T_s = s$2. 旋转延迟时间$T_τ$：$T_t = \frac{1}{2r}$3. 磁盘访问时间 ：$T_t=\frac{b}{rN}$$s$是指磁头从当前位置定位到开始点的时间，$b$是传输的字节数，$r$是每秒的转数，$N$是一条磁道上的字节数。$总时间 = T_s + \frac{1}{2r} + \frac{b}{rN}$### 磁盘调度算法假设磁盘访问序列：98，183，37，122，14，124，65，67，读写头起始位置：53。#### 先来先服务按访问请求到达的先后次序服务。#### 最短寻道时间优先#### 扫描算法当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复。#### 循环扫描算法CSCAN算法规定磁头单向移动，例如由里向外移动，当磁头移到最外的磁道并访问后磁头立即返回到最里的欲访问磁道，即最小磁道号紧接最大磁道号构成循环，进行循环扫描。## 文件管理概述计算机中有很多的程序和数据都是保存在外存中，在需要使用的时候才调入内存中。而如何保存这些信息是很重要的问题，因为不同类型的文件存储的数据格式不同，但这些格式却必须“迎合”硬件只能存储二进制数据的硬性条件。所以操作系统提供了文件管理的功能，让使用者能在不了解文件特性和外存特性的情况下完成文件的存储和查找等功能。同时还提供了文件共享和安全管理等功能。### 文件系统 &amp; 文件操作系统中负责管理和存储文件信息的软件称为文件管理系统，简称文件系统。包含：文件系统的接口，对对象操纵和管理的软件集合，对象及属性三部分。它负责对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。包含创建文件、删除文件等功能。文件是指具有文件名的若干相关元素的集合，可以分成有结构文件和无结构文件，无结构文件可以看成一个字符流。有结构文件是由一组记录的集合，记录又是一组数据项的集合。- 数据项：用来描述一个对象的某种属性的字符集。例如学生的学号、姓名等。- 记录：一组数据项的集合，用来描述一个对象在某方面的属性，例如学生的成绩。能唯一标识一个记录的一个或多个数据项叫做关键字。### 文件类型不同的文件类型由于本身存储的信息具有不同的结构，在管理的时候也是不同。所以文件会被分成很多类型，下面是常用的文件分类方法：- 按用途分类：系统文件、库文件、用户文件。- 按文件中数据的形式分类：源文件、目标文件、可执行文件。- 按存储控制属性分类：可读、可写、可执行文件。- 按组织形式和处理方法分类：普通文件、目录文件、特殊文件。### 剖析文件和目录我们刚才在定义中说道，文件是指具有文件名的若干相关元素的集合，在有结构文件中这些元素是数据项集合的集合，在无结构文件指的是字符流。所以文件的概念中本身是：文件系统的层次结构文件系统从底层到高层可分成三部分：对象及其属性、对对象操纵和管理的软件集合、文件系统接口：对象及其属性：文件管理系统管理的文件如下：文件：在文件管理系统中有着各种不同类型的文件，它们都作为文件管理的直接对象。目录：用于对文件的存储和检索，目录的每个目录项包含了一个文件或目录的信息。磁盘存储空间：文件和目录必定占用存储空间，对这部分空间的有效管理不仅能提高外存的利用率，而且能提高对文件的存取速度。对对象操纵和管理的软件集合：该层是文件管理系统的核心部分。文件系统的功能大多是在这一层实现的。如：文件存储的管理、文件目录的管理、将文件的逻辑地址转换为物理地址的机制、文件读写控制的管理、文件的共享和保护等功能。这些功能被可分为四层：I/O控制层：文件系统的最底层、主要由磁盘驱动程序等组成。基本文件系统层：主要用于处理内存和磁盘之间数据块的交换。基本I/O管理程序：完成与磁盘I/O有关的事务，如将文件的逻辑块号转换为物理块号、管理磁盘中的空闲盘块、I/O缓冲的指定等。逻辑文件系统：管控对文件的操作，如控制用户或应用程序对文件的读写等。文件系统的接口：操作系统提供给用户或应用程序用来使用文件系统的接口：命令接口：用户与文件系统直接交互的接口，如Shell命令。程序接口：应用程序可以通过一系列命令调用文件系统的服务。文件的打开和关闭当用户要求对一个文件实施多次读/写操作时，如果每次都检索目录效率较低，所以为了避免多次重复的检索目录，OS提供了“打开（Open）”操作，当此操作被执行时，OS会把被打开文件的信息存为“打开文件表”的一个条目，然后把这个条目编号返回用户，这样用户就可以通过这个编号和文件之间建立一个连接，也就可以进行文件的读写等操作。当用户再次向系统发出请求时，把这个编号提交给OS，OS通过这个编号在打开文件表中查找文件信息就可以减少检索时间。而关闭就是OS从“打开文件表”上删除此条目，这样断开了用户和文件之间的连接。文件的逻辑结构和物理结构逻辑结构：从用户的角度来看，文件是能被存取的基本单位。物理结构：文件在磁盘上存储时的组织形式。逻辑文件按结构分类有结构文件：每个文件用于描述实体集中的一个实体。每个记录的长度对OS来说都是可知的。但记录之间可以分为定长和变长两种。定长记录：所有记录的长度都是相同的、所有记录中的各数据项都处在记录中相同的位置具有相同的顺序和长度。变长记录：各记录的长度不相同。比如论文的摘要可能长度差距很大，不能在存储之前估计出所需要的空间。无结构文件：系统中运行的大量的源程序、可执行文件、文本文件等都是无结构文件，即流式文件。其文件长度是以字节为单位的。逻辑文件按组织方式分类组织方式指的是文件中记录的组织方式。只对有结构文件有效。可以分成：顺序文件、索引文件、索引顺序文件。顺序文件指由一系列记录按某种顺序排列所形成的的文件。串结构：按存入时间的先后顺序排列。所以检索时必须从头挨个查找，效率低。顺序结构：用户指定一个字段作为关键字，他可以是任意类型的变量。如sql文件。索引文件为变长记录文件创建一张索引表，索引表是定长记录文件，检索时，先查找索引表，再根据指针所指的地址读取记录。可以解决变长文件记录较难直接存取的问题。### 索引顺序文件将顺序文件的所有记录分成若干组，为顺序文件建立一张索引表，索引表中为每组的第一个记录建立一个索引项。检索时，先检索索引表，找到记录所在记录组的第一个记录的表项，再顺序查找主文件，得到要求的记录。## 文件目录### 文件控制块包含三类信息：- 基本信息类：文件名、文件物理位置、文件逻辑结构、文件物理结构- 控制信息类：各类用户的读、写、可执行文件等。- 使用信息类：文件的建立时间，当前的使用信息，上一次修改的时间，是否被进程锁住等。### 索引节点为了唯一确定外存中的一个文件，必须要把文件的FCB加载进内存，而每次加载的数据大小是一定的，所以为了一次能多加载进内存一个文件标识。将FCB分成两部分：#### 磁盘索引节点- 文件主标识符- 文件类型- 文件存取权限- 文件物理地址- 文件长度- 文件连接计数：本人理解为硬链接计数- 文件存取时间#### 内存索引节点。- 索引节点编号- 状态- 访问计数- 文件所属文件系统的逻辑设备号：不明白- 链接指针：不明白### 树形结构目录在树形结构目录中，目录应该保存文件的信息。同时目录的目录项要能既作为目录文件的FCB，又作为数据文件的FCB。## 文件共享### 基于有向无循环图实现文件共享此种方法存在问题：比如对于文件F8，D5:p、D6:e、D3:p都保存了F8的物理地址，即从某个盘块开始，总长度多少等。此时如果D6:e对F8进行了删除操作，D5:p和D3:P都无法察觉，仍然会认为在它们存储的位置上有文件，即一个目录项对文件的操作对其他目录项来说是不可见的。### 利用索引节点引入索引结点，将文件的物理地址和其他的属性放在索引结点中，只在目录项中存放文件名和指向索引结点的指针。由任何用户对文件进行Append操作或修改，引起相应索引结点内容的改变。此种方法即Linux中的硬链接。### 利用符号链接实现文件共享建立符号链接文件，它是一种特殊类型的文件，其内容是被链接文件的路径名。建立符号链接文件，并不影响原文件，实际上它们各是一个文件。可以建立任意的别名关系，甚至原文件是在其他计算机上。只有文件主才有指向索引结点的指针，而其他共享用户只有该文件的路径名。## 文件保护### 访问权&amp;保护域- 访问权：一个进程能对某对象执行操作的权利，用&lt;对象名，权集&gt;表示，如&lt;F1, {R/W}&gt;表示进程对F1有读和写的权利。- 保护域：进程对一组对象访问权的集合，进程只能在域内进行操作。### 进程和域的联系方式进程和域之间是一对多的关系，即一个进程可以联系多个域。此时进程的运行分为多个阶段，每个阶段联系一个域，这样就可以根据运行的实际需要规定进程每个阶段所能访问的对象。### 访问矩阵- R：在域内运行的进程对文件具有读权限- W：在域内运行的进程对文件具有写权限- $R^\ast$：在域内运行的进程能把其对文件的读权限扩展到其他域中，但在其他域中是R权限，不再是$R^\ast$。- $W^\ast$：在域内运行的进程能把其对文件的写权限扩展到其他域中，但在其他域中是W权限，不再是$W^\ast$。- S：在域Di中运行的进程能转移到域Dj中运行，如图中在域D3运行的进程能转移到域D2中运行。- O：在域中运行的进程能增加或删除对某文件的访问权。- Control：在域Di中运行的进程能删除在域Dj中运行进程对各对象的访问权。如图中在D2中运行的进程能删除在D3中运行进程的访问权。### 访问矩阵的实现#### 访问控制表将访问对象按列划分，为每一列建立一张访问控制表，在该表中把属于对象的所有空项都删除。此时表中的每一项都是一个有序对&lt;域，权集&gt;构成。#### 访问权限表将访问矩阵按行划分，每一行是一个访问权限表，表中的每一项表示该域对某对象的访问权限。文件管理的目标是管理文件的组织方式，管理文件的访问权等。而磁盘存储器的管理是管理存储器的使用，如何高效利用存储器。他俩是棋与棋盘的关系。## 连续组织方式文件的信息存放在若干连续的物理块中。- 优点- 简单- 支持顺序存取和随机存取- 顺序存取速度快，所需的磁盘寻道次数和寻道时间最少- 缺点- 文件不能动态增长（预留空间：浪费、重新分配和移动）- 不利于文件插入和删除- 外部碎片问题## 链接组织方式### 隐式链接在文件的目录中记录该文件的第一和最后一个盘块的指针，每一个盘块的指针指向文件的下一物理块号。- 优点- 文件可动态增长- 有利于文件的插入和删除- 提高了磁盘空间利用率,不存在外部碎片问题- 缺点- 存取速度慢，不适于随机存取- 可靠性问题，如指针出错- 更多的寻道次数和寻道时间- 链接指针占用一定的空间### 显示链接将链接文件各物理块的指针显示地放在内存的一张链接表（文件分配表，File Allocation Table）中。在FCB的物理地址中填写其首指针所对应的盘块号。由于文件分配表示存储在内存中的，可以大大减少访问磁盘的次数。FAT微软公司早、中期推出的操作系统一直都是采用的FAT技术，即利用文件分配表FAT来记录每个文件中所有盘块之间的链接。FAT中引入了“卷”的概念，支持将一个物理磁盘分成四个逻辑磁盘，每个逻辑磁盘就是一个卷（也称为分区），每个卷都可以被单独格式化和使用。把盘块作为基本分配单位，同时每个分区中都配有两张相同的文件分配表FAT1和FAT2。FAT技术的发展有三个阶段：FAT12、FAT16和FAT32FAT12FAT表的每个表项占用12个bit。所以最多有$2^{12}$个表项，每个盘块的大小是512B，则每个磁盘分区的容量是2MB，能处理的磁盘最大容量是8MB。为了增大FAT能管理的最大容量，引入了“簇”的概念，每个簇是一组相邻的扇区，这样如果分配时以簇为单位进行分配就能管理更大的磁盘容量，但是相应的簇内零头也会更大，降低磁盘的利用率。FAT16FAT表的每个表项占用16个bit。最多有$2^{16}$个表项。FAT32FAT表的每个表项占用16个bit。最多有$2^{32}$个表项。同时每个簇固定为4KB。所以最大可管理$4 \ast 2^{10} \ast 2^{32} = 2TB$大小的空间。NTFS索引组织方式单级索引组织方式一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构索引表，并将这些块的块号存放在一个索引表中。一个索引表就是磁盘块地址数组，其中第i个条目指向文件的第i块。·### 多级索引组织方式### 增量式索引组织方式可以更好的满足大、中、小文件的组织。## 文件存储空间的管理文件存储空间的管理包括空闲块的组织分配和回收。### 空闲表法把一个连续未分配区域称为“空闲文件”，系统为所有空闲文件单独建立一个目录。表目内容：序号，第一个空白块号，空白块个数。- 分配算法：内存管理中的首次适应算法、循环首次适应算法。- 合并：空闲区邻接合并### 空闲链表法空闲盘块链：所有空闲盘块拉成一条链，分配时从头分配，回收时链接在尾部。空闲盘区链：每个连续的盘块组成一个盘区，每个盘区包含本盘区的大小和下一个盘区的地址。### 位示图法用一串二进制位反映磁盘空间中分配使用情况，每个物理块对应一位，分配物理块为1，否则为0。申请物理块时，可以在位示图中查找为0的位，返回对应物理块号；归还时；将对应位转置0。### 成组链接法（重点）- 把所有的空闲盘块按每n个一组分成m个组。- 最后一个组放在内存的空闲盘块号栈中，其他组存在外存上。空闲盘块号栈是一个临界资源，只允许一个进程同时访问。- 数据结构，一个size为n+1的栈。图上是一个倒着的的栈（栈底在上方，栈顶在下方）- 一个n+1的栈实际可用盘块只有n（图上只有99个可用盘块），因为栈底是一个计数器，指示当前有多少个可用盘块，但是可用盘块中有一个是指向下一个组，即stack[1]指向下一个组。如果stack[1]==0表示此时是最后一组。- 分配时从栈顶开始向下分配，直至分配出n-1个盘块，此时如果再想分配一个块就需要把下一个组调入空闲盘块号栈。调入后新组覆盖旧组。然后把新组在外存中占用的盘块分配出去。- 回收时从栈底向上回收，如果计数器==100时还有空闲盘块（设这个盘块编号为p）要回收，就把空闲盘块号栈内的组取出来存在p中，在空闲盘块号栈内新开辟一个组，新组的stack[1]指向p。### 例此题题目及来源：https://blog.csdn.net/ajay666/article/details/73569654分配3个盘块后，回收它所占的5个盘块，回收的盘块号依次为700、711、703、788、701，画出分配回收过程。#### 第一次分配#### 第二次分配注意：300号盘块中存储的组信息调入空闲盘块号栈之后其自己也可以被分配。#### 第三次分配#### 第一次回收#### 第二次回收#### 第三次&amp;第四次&amp;第五次回收Linux介绍Linux是一套免费使用和自由传播的操作系统。严格来讲，Linux这个词本身只表示Linux内核，但一般来说使用Linux内核的操作系统都被称为Linux。而不同的厂家使用相同的Linux内核所构建的操作系统叫做Linux发行版。常见的Linux发行版有Ubuntu、Centos、Debian等。这些发行版的使用方法大同小异。但Linux不仅限于使用在PC机上，移动端（安卓系统是由Linux改写而来）、路由器（只保留少许功能的Linux系统）等终端都在使用Linux。Linux安装虚拟机安装：blog.csdn.net/qq_38206090/article/details/82559358双系统：笔者没有安装过，因为怕系统出问题导致文件损失。云服务器：云服务器系统配置Linux版本我认为是最简单的方式，所以以下实例均采用阿里云服务器。连接服务器工具SecureCRT：去 http://59.110.143.226/Sharing-Your-Story/ 搜索。Termius：https://www.microsoft.com/store/productId/9NK1GDVPX09V推荐使用Termius，好看也好用。SecureCRT是破解版，Termius是免费使用。Linux目录结构Linux的目录结构是一个树形结构，树根是一个/。直接子目录包括root、home等。如我的阿里云服务器根目录：ShellShell是指“为使用者提供操作界面”的软件（命令解析器）。Shell翻译过来叫做“壳”，用来区别于“核”，也就是说它把底层的东西封装成命令，使用者键入命令就能得到相应的结果。比如上面的这张图中，我在根目录下输入ll命令，就在终端上给我显示根目录下的文件信息。也就是说Shell解析了我输入的ll命令，返回我想要的信息（根目录文件信息）。Bash命令Shell是命令解释器，自然会有不同的分类，就类比于同是循环结构，Java和Python却有不同的语法。但是Bash（Bourne-Again SHell）是Linux默认的Shell交互类型，也就是说在Linux中打开一个终端，就启动一个Bash进程。Bash命令格式格式：命令名 [选项] [参数1] [参数2] … 有如下特点：命令名必须是小写英文字母。一般格式中，方括号括起来的部分是可选选项。选项是对命令的特别定义，以“-”开始。一个命令可以使用多个选项且多个选项连接起来同样有效（部分发行版不支持）。如：ls -al和ls -a -l效果相同。命令正常执行后返回一个0表示执行成功，返回非0值表示执行过程出错。在终端上很难体现出来，但在shell脚本（后续会介绍）中可作为控制逻辑流程的一部分（用$?查看）。Bash举例查看内核版本号：uname -a:uname是命令名，-a是选项，这个命令没有参数。uname解释输入终端窗口中的命令以Enter键结束，且Shell命令区分大小写。如果命令太长，一行放不下时，在行尾输入\并按Enter键。这时Shell会返回一个大于号（&gt;）作为提示符，表示该命令行尚未结束，允许继续输入有关信息。echoecho命令把命令行中的参数全部显示到标准输出（终端）中。如果参数用引号引起来，会按原样输出。否则会把各个单词按字符串输出，字符串之间用空格隔开。单引号/双引号的区别请看Shell那一部分。输出重定向Linux的标准输出是屏幕，把结果输出到指定的文件叫做输出重定向。&gt;：目标文件不存在，系统将建立该文件；文件存在，重定向将会删除该文件，并重新建立一个新文件存放结果。&gt;&gt;：目标文件不存在，系统将建立该文件；如果目标文件存在，新的输出结果将会追加到文件末尾。pwd显示出当前所在目录的路径。历史命令history命令可以看到用户所有曾经输入过的命令。!!：执行上一个命令；`!n：执行第n个命令；!-n：执行倒数第n个命令；!xxx：执行以xxx开头的命令，如之前使用过clear，!cle会执行clear。~/.bash_history文件中会存储你近期使用过的命令。查看此文件：cat ~/.bash_historydatedate命令在屏幕上显示或设置系统的日期和时间：date [+格式控制字符串]格式控制字符串常用单引号引起来。年:Y 月:m 日:d 小时:H 分:M 秒:S有且只有超级用户能设置或修改系统时钟，语法如下：date -s “year-month-day hour:minute:second”系统在启动的时候是从CMOS（用来存储计算机某些参数的芯片）中加载时钟，为了保持系统时间与CMOS时间的一致性，Linux每隔一段时间会将系统时间写入CMOS。由于该同步是每隔一段时间进行的，在我们执行date -s后，如果马上重起机器，修改时间就有可能没有被写入CMOS，而hwclock –w强制把系统时间写入CMOS。cal列出日历信息。单独一个cal：列出当前月的日历信息。cal xxxx：列出xxxx年的日历信息。cal yy xxxx：列出xxxx年yy月的日历信息。cal dd yy xxxx：列出xxxx年yy月xx日所在月的日历信息。clearclear命令清除屏幕上的信息，清屏后，提示符移到屏幕左上角。关机 &amp; 重启shutdown -h now：立刻关机shutdown -h 15:30：15:30 关机shutdown -h +30：30 分钟后关机reboot：重启shutdown -k +2 &quot;一会要关机，抓紧保存&quot;：向所有用户输出关机通知，但不做真正操作。+2表示通知的关机时间是现在之后的两分钟。帮助命令如果我们忘记某些命令或其参数如何使用，需要使用帮助命令。whatis &lt;命令&gt;：显示命令的简短描述。&lt;命令&gt; -help：显示使用方法概述和参数列表。man &lt;命令&gt;：为命令提供相关帮助文档，页面分成章节。info &lt;命令&gt;：类似man命令，但是通常比它更详细。切换路径命令cd &lt;位置&gt;：切换到指定位置；cd ~：切换到用户家目录；cd -：切换到上一个所在目录；passwd修改密码。单独的passwd：修改使用该命令的用户的密码。passwd 用户名：root用户可以使用该命令修改其他用户的密码。Linux用户登录Linux系统时，必须通过指定的用户名和密码进行登录。不过所有的用户在Linux眼中都是一个数字，用userid（一个32位的二进制整数）来表示。可以通过id命令，查看自己的userid。userid为0的表示根用户。同时，在系统运行的每个进程、所创建的每个文件都有一个userid，这个userid代表运行这个程序的用户，或者文件的所有者。Linux系统中，用户被保存在/etc/passwd文件中。用户又分成三类：一般用户（userid&gt;=500）、超级用户（userid=0）和系统用户（userid&lt;500）。查看用户Linux是一个多用户系统，即很多个用户同时操作一个设备中的资源，但不同的用户有不同的权限。这些用户中有一个是超级用户（root），它是权限最高的用户。root用户在终端中的输入命令以#开头，其他的用户以$开头。who：列出正在使用系统的所有用户、所用的终端名和注册到系统的时间。who am i：列出使用该命令的用户、所用的终端名和注册到系统的时间。用户组由于不同的用户有不同的权限。为了给不同的用户赋予相同的权限更加方便，诞生了用户组的概念。即同一个用户组里的人员可以有相同的某些权限。Linux中的用户或文件至少属于一个用户组。添加用户useradd或者adduser。执行后的具体操作（不同发行版有区别）：分配一个新的userid，数值等于之前所有userid中数值最大的加一。在/etc/passwd中添加一行。为用户在/home下建立一个新的目录（用户的家目录），目录名和用户名相同。在/etc/group中为用户建立一个新的个人组。在/var/spool/mail中创建用户的邮件文件。删除用户userdel &lt;用户&gt;。删除用户及部分相关信息，家目录和邮件文件还会存在。-r：包括家目录和邮件池等在内的所有用户信息都会被删除。添加/删除组groupadd &lt;组名&gt;。所有的组都保存在/etc/group文件中。groupdel &lt;组名&gt;。删除组。/etc/passwd &amp; /etc/shadow/etc/passwd有7列：用户名、密码、用户id、主要组id、备注信息、主目录、登录shell。各列之间使用:分割。同时密码一般都是x（被加密了），加密后的密码在/etc/shadow中。/etc/shadow有9列：用户名、加密密码、最近更改密码的日期、密码不可更改的天数、密码需要重新更改的天使、密码更改期限前的警告期限、密码过期的宽限时间、帐号失效日期、保留字段。但这里显示的密码是加密的。查看用户所属的组groups：查看使用此命令的用户所属组；groups &lt;用户&gt;：查看指定用户所属组。用户可多选，使用空格隔开。/etc/group &amp; /etc/gshadow/etc/group：组名、组密码、组id、组中附加用户。/etc/gshadow：组名、密码、组管理者、组中附加用户。为用户添加备注在创建的时候添加：useradd -c &lt;备注&gt; 用户名。创建后修改：usermod -c &lt;备注&gt; 用户名。（会清除之前的备注信息）。usermod改变用户某些属性的命令。-l：改变用户的名称；-G：改变用户支持的用户组，会退出原来的附属组，配合-a不会删除之前组；-L：不让该用户登录；-e：设定用户失效日期。日期格式：“YYYY-MM-DD”。-s：改变Shell。新创建的用户默认使用bash，此选项修改登录Shell。如：usermod -aG 组名 用户gpasswdgpasswd -d userName groupName：从组中删除用户切换用户超级用户输入su 用户名可以不用输入密码切换到其他用户。普通用户切换到其他所有用户（su 用户名）需要输入密码。文件系统操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件：文件系统中存储数据的一个命名的对象。即使是空文件（不包含用户数据）也会为操作系统提供其他信息。目录：包含文件项目的一类特殊文件。Linux中在应用层上来看目录和文件是被区分开来的。查找文件find &lt;路径&gt; -name &#39;正则表达式&#39;：如find . -name &#39;*.so&#39;，查找当前目录下以.so结尾的文件。catcat &lt;文件&gt;：显示文件的内容。文件可以多选，之间用空格隔开。cat f1 &gt; f2：把f1文件的内容合并到f2文件中。touch文件不存在：则创建一个空的新文件；文件存在：把文件的时间标签更新为系统当前时间。grep命令的意思：global search regular expression and print out the line。部分选项如下：-a：将 binary 文件以 text 文件的方式搜寻数据-c：计算找到 ‘搜寻字符串’ 的次数-i：忽略大小写的不同，所以大小写视为相同-n：顺便输出行号-v：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行！--color=auto：可以将找到的关键词部分加上颜色的显示喔！举例如下：管道命令管道命令是用来过滤信息的，比如我们之前grep -n root /etc/passwd之后显示带有root的行，如果想在结果中再按其他条件过滤就要使用管道命令：“|”。统计文件信息wc：统计指定文件的字节数（-c）、字数（-w）、行数（-l）例子：统计文件a中以b开头的行数：cat a | grep ^b | wc -l创建目录mkdir &lt;文件名&gt;。-p：父目录不存在时也可以创建。删除文件/目录rm -rf &lt;文件名&gt;。-r表示递归删除；-f表示强制删除，不询问。列出文件ls命令列出指定目录的内容。-l：文件的详细信息。输出的信息分成多列，它们依次是：文件类型与权限、链接数、文件主、文件组、文件大小、建立或最近修改的时间、文件名。total的计算：https://yq.aliyun.com/ziliao/264744。-a：显示所有文件。之前显示的没有隐藏文件（以.开头）。-h：文件大小以人类可读的方式显示。需要配合-l使用。拷贝文件cp &lt;文件&gt; &lt;目录&gt;。剪切文件mv &lt;文件&gt; &lt;目录&gt;。修改文件名mv &lt;文件&gt; &lt;新文件名&gt;。文件结构Linux中所有的文件都由两部分构成。索引结点：包含此文件的信息，如文件权限、文件主、文件大小等。数据：文件的实际内容，有没有数据都可以。链接链接就是把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。硬链接：硬链接是多一个文件名和inode结点关联。由于它依赖于inode，所以不能在不同的文件系统之间做硬链接。硬链接不能用于目录。用法：ln &lt;被链接的文件&gt; &lt;新的文件名&gt;软连接：软连接是再拓展出一份inode，这个inode指向的区域保存如何找到真正数据的信息。用法：ln -s &lt;被链接的文件&gt; &lt;新的文件名&gt;用户和权限文件主：文件所有者，并赋予唯一的注册名。只有文件主或root才有权利用chown命令改变文件的所有关系（UID）。用户组：通常，组中包含了有相同需求的用户。文件主或超级用户（root）可以利用chgrp命令改变文件的GID。用户存取权限：Linux系统中规定了4种不同类型的用户：文件主、同组用户、其他用户、超级用户。3种访问文件或目录的方式：r（读）、w（写）、 x（可执行或查找）。chmod只有文件主或超级用户root才有权用chmod命令改变文件或目录的存取权限。使用格式：chmod [选项] MODE 文件。MODE可多选，之间用,隔开。MODE：&lt;who&gt;&lt;操作符号&gt;&lt;权限&gt;。who：u——user、g——group、o——others、a——all（可叠加）。操作符号：+ 添加、- 取消、= 赋予；权限：r 读、w 写、x 执行。（可叠加）举例以绝对方式改变权限置为1表示有相应权限，置为0表示没有相应权限。例如：r w x r - x r - -1 1 1 1 0 1 1 0 0转换成十进制是754。chmod 754 aa和chmod u=rwx,g=rx,o=r aa一致。umask官方的解释是掩码，其实就是用户创建文件或目录后它们的默认权限。不过和chomd有区别的是它把有权限设置为0，没权限设置为1，而且umask命令显示的是八进制数字。我的umask显示的是0022，转换成二进制就是000 010 010，转换成权限就是rwx r-x r-x。所以创建的目录的默认权限就是这个。但是Linux不允许新创建的文件有可执行权限，所以创建的文件的默认权限是rw- r-- r--。chown改变某个文件或目录的所有者。chown &lt;用户&gt; &lt;文件&gt;/&lt;目录&gt;chgrp改变文件或目录所属的用户组。chgrp &lt;用户组&gt; &lt;文件&gt;/&lt;目录&gt;文件权限的理解可读（r）：浏览文件中的内容；可写（w）：修改文件中的内容；可执行（x）：将文件作为命令使用。目录权限的理解可读：只能查看到目录下的子目录名和文件名；可执行：可以访问目录中的文件，包括子目录；可写：要在目录下添加删除目录和文件，必须有可执行的权利。压缩 &amp; 打包 &amp; 解压缩tar -zcvf：打包压缩后的文件名 要打包压缩的文件（多个之间用space分开）z：调用gzip压缩命令进行压缩c：create，打包文件v：显示运行过程f：指定文件名tar -xvf xxx.tar.gz -C 位置x：extract，解包v：显示允许过程f：指定文件名别名我们可以使用ll代替ls -l。但是对于ls -a，系统并没有提供la命令，不过我们可以使用alias定义la。取消别名使用unalias 别名定时任务cron工具允许用户配置要定期运行的任务，通过配置crontab的文件可以指定要运行哪些作业以及何时运行。配置crontab文件使用命令crontab。命令由6个用空白分隔的字段组成：字段minutehourday of monthmonthday of weekcommand to run举例4516***date&gt;/tmp/date.txt范围0-590-231-311-120-7*corntab命令的参数：-e：编辑crontab的内容（会打开一个文件）；设置定期任务（16:45时把当前时间写入/tmp/date.txt文件中）：过一段时间之后查看/tmp文件夹：-u：只有root才能执行这个选项，帮助其他用户建立/删除crontab；-l：查看crontab的工作内容:-r：删除crontab的工作内容；成组命令被成组命令约束的命令被认为是一条命令。{ 命令; }：需要有空格和命令隔开，且命令后面需要“;”。不创建子进程。(命令)：不强制需要有空格和命令隔开，不强制需要“;”。创建子进程完成功能。例如下例把两条ls命令的值全部由管道输入给grep。sortsort lines of text files，将文本文件内容加以排序，以行为单位来排序，但不改变文件原始内容。默认排序规则：从第每行一个字符开始，依次按照ASCII码值进行比较。-n：按数字的大小排序，默认情况下把数字看成字符。-r：反转排序效果。uniq文件输出时，删除重复行或列。但如果重复的行不连续则不起作用。文件类型-：普通文件l：符号链接文件d：目录s：套接字文件（socket）b：块设备文件p：命名管道文件（pipe）c：字符设备文件ex1：用户管理在系统中添加三个用户：Blondie、Prince和Madonna他们都希望属于次要组musicBlondie要求在他的条目中添加特殊备注“heart of glass”Prince要求使用/bin/csh作为登录shellMadonna的使用期限为2020-12-1。Blondie决定加入摔跤俱乐部wrestle组。Prince要将他的用户名改为tafkap。Madonna开始对风水感兴趣，加入组fengshui，并要求将她的userid改为888。groupadd fengshuiusermod -a –G fengshui Madonnausermod –u 888 MadonnaPrince又要改名字了，我们觉得太麻烦，干脆锁住他的帐号。usermod –L PrinceBlondie最近表现不好，我们决定将他踢出去。userdel –r Blondie（想把该用户所有信息都一起删除可以使用-r）ex2：文件目录管理Ventura同时属于次要组governor和wrestle。Ventura撰写了自己的摔跤计划plans.txt，并将它放到目录/tmp下。Ventura希望将他的摔跤计划和用户Hogan以及其他摔跤组的成员共享，但他不希望组外的成员访问。用户Hogan想往用户Ventura的计划上添加内容，可以吗？怎么做？用户Hogan对他自己的贡献很满意，他希望将这个计划公开，让所有人都能读到这个文件，可以实现吗？不可以，只有root和文件主能修改文件访问权。vi &amp; vim这俩都是文本编辑器。vi是Linux默认的编辑器，类似于windows的记事本。vim是vi的拓展，比vi更强大。可以用于在Linux中编辑文件内容。笔记中使用vim。它有两种模式，命令模式和编辑模式，在命令模式中可以做一些检索、筛选等操作。在编辑模式中可以对文档进行修改。进入 &amp; 退出进入命令模式方法：vim &lt;文件名&gt;。此时进入命令模式，不能对文件内容进行操作。对文档的检索是在这种模式下进行的。进入编辑模式：i：编辑位置在当前光标位置之前按下i再按_I：在光标所在行的行首插入新增文本按下I再按_a：在该命令之后输入的字符都插到光标之后按下a再按_A：在光标所在行的行尾添加文本按下A再按_o：在光标所在行的下面新开辟一行，随后输入的文本就插入在这一行按下o再按_O：在光标所在行的上面新开辟一行，随后输入的文本就插入在这一行上按下O再按_r：替换光标所在的哪一个字符按下r再按_R：一直替换光标所在的文字，直到按下ESC为止按下R再按三次_再按Esc退出编辑模式在编辑模式下按 Esc 键。退出命令模式需要使用转义字符::q：若未修改文件，此命令可以退出编辑器。:wq：把编辑缓冲区的内容写入文件中，退出编辑器，回到Shell下。:ZZ或:x：仅当作过修改时才将缓冲区内容写到文件上。:q!： 强行退出vi。告诉vi，无条件退出，丢弃缓冲区内容。vim流程图命令模式下的光标跳转方向键和Backspace键的使用和正常情况下相同。移动到上一行，列不变：k移动到上一行行头：-移动到下一行，列不变：j移动到下一行行头：+如果在相应命令的前面加上一个数字n，相应命令执行n次。如2k表示向上移动两行，列不变。移至行首：^或0移至行尾：$移至指定行：行号G。如2G，移动到第二行行首。移至指定列：列号|。如2|，移动到本行第2列。文本删除命令x（小写字母）删除光标所在的字符。命令X（大写字母）删除光标前面的那个字符命令dd删除光标所在的整行命令D从光标位置开始删除到行尾d&lt;光标移动命令&gt;删除从光标位置开始至光标移动命令之间的所有字符。如：d0：从光标位置（不包括光标位）删至行首。d3l：从光标位置（包括光标位）向右删3个字符。d$：从光标位置（包括光标位）删至行尾。与D相同。d5G：将光标所在行至第5行都删除。复原命令u：取消前面刚执行的插入或删除命令的效果，恢复到此前的情况。U：总是把当前行恢复成它被编辑之前的状态。重复命令.：在命令模式下，重复执行前一次插入命令或删除命令补充文本编辑命令方式下d0：删至行首d$：删至行尾ndd：删除当前行及其后的n-1行yy：复制当前行的文本10yy：复制包括当前行及其后面9行文本p：在当前行后面插入一个空行，把缓冲区的内容粘贴过来P：在当前行前面插入一个空行，把缓冲区的内容粘贴过来ex转移方式下:n1,n2 d：将n1行到n2行的内容删除:n1,n2 co n3：将n1行到n2行的内容复制到n3行下:n1,n2 m n3：将n1行到n2行的内容移到n3行下字符串检索向下检索：/模式〈Enter〉。例如：/int向上检索：?模式〈Enter〉。例如：?flout字符串替换:n1,n2s/word1/word2/g：n1和n2为数字。在n1与n2行之间寻找word1这个字符串，并将该字符串替换为word2。例如:100,200s/a/A在100行到200行之间搜索a并替换成A。:1,$s/word1/word2/gc：全局搜索word1，替换成word2。g改成gc表示要用户确认。:%s/$/s2/g：在整个行的末尾添加s2。全局替换命令g：:g/模式/命令表。:g/s1/p：打印文本中有s1的行。p命令表示打印。块选择ctrl+v，然后使用方向键选择块。y：复制反白的地方d：将反白的地方删除掉p：插入复制的内容参考：https://jingyan.baidu.com/article/84b4f565c6b9e560f6da3291.html。Linux的进程状态psProcess Status。查看进程状态的最常用的命令，它可以提供关于进程的许多信息。直接用ps命令可以列出每个与你的当前Shell有关的进程的基本信息。ps -ef：显示系统中所有进程的全面信息。-e：显示所有进程-f：全格式用户ID、进程ID、父进程ID、CPU占用率、开始时间、开始此进程的终端设备、此进程运行的总时间、命令名。ps aux显示所有终端上所有用户的有关进程的所有信息。终结进程通常来说，终结一个前台进程可以使用Ctrl+C。终结一个后台进程得使用kill命令。kill &lt;进程号&gt;。如果想强制杀掉一个进程需要使用-9：kill -9 &lt;进程号&gt;sleep使进程暂停由时间值所指定的秒数。此命令大多用于shell程序设计中，使两条命令执行之间停顿指定的时间。如：sleep 100; who | grep &#39;root&#39;。waitwait是用来阻塞当前进程的执行，直至指定的子进程执行结束后，才继续执行。wait [进程号 或 作业号]：eg：wait 23 or wait %1如果wait后面不带任何的进程号或作业号，那么wait会阻塞当前进程的执行，直至当前进程的所有子进程都执行结束后，才继续执行。fork()fork()函数会创建一个和原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事。但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。一个进程调用fork()函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。fork()调用一次，分别向父子进程返回，它可能有三种不同的返回值：在父进程中，fork()返回新创建子进程的进程ID；在子进程中，fork()返回0；如果出现错误，fork()返回一个负值；所以我们可以通过fork返回的值来判断当前进程是子进程还是父进程。同时每个进程都有一个互不相同的进程标识符（process ID），可以通过getpid()函数获得，还有一个记录父进程pid的变量，可以通过getppid()函数获得变量的值。题1源代码运行结果分析程序运行到第7行，创建一个新的进程，克隆一份当前进程。向父进程返回子进程的pid，向子进程返回0。所以执行后父进程进入第3个分支，子进程进入第2个分支。题2源代码结果分析题3源代码结果分析题4题目分析执行第5行之后，向父进程返回真，向子进程返回假，但是没有任何影响，此时创建了一个进程，之后父子进程创建的进程个数相同，所以只分析一个再乘以2即可。第一个子进程分析结果如下图。注意，对于A &amp;&amp; B || C：表达式A为假，B不执行，C执行；表达式A为真，B执行：B为真：C不执行；B为假：C执行。所以答案是1+9*2=19个。简介Shell是一个命令解释器，用户输入命令来获得自己想要的结果，但是终端中输入的命令很难进行高级语言的选择、循环等操作。不过Shell程序可以存放在文件上，称为Shell脚本（虽然Linux文件不以后缀名区分文件类型，但是一般编写Shell脚本时文件名会命名为以.sh结尾）。在脚本中可以较方便的进行类似高级语言的操作。最简单的Shell脚本我们都知道，直接在终端输入echo命令是回显参数，把echo命令放在shell脚本中有相同的效果。设置成可执行文件变量Shell脚本中的变量直接使用=便可创建，使用$解析变量名。{}是分组命令，表示H是一个变量，这里不加也可以。特殊变量$#：除脚本名外，命令行上参数的个数。$*：表示在命令行上实际给出的所有实参。如：exam3.sh A B C D E F G H I J K。$#是11。$*是： A B C D E F G H I J K$n：表示命令行上第n个参数$0表示文件名 $1表示第一个参数 …$@：表示在命令行上实际给出的所有实参。如：exam3.sh A B C D E F G H I J K。$@就是： “A” “B” “C” “D” “E” “F” “G” “H” “I” “J” “K”$$：当前进程的进程号$!：上一个后台命令对应的进程号。$?：上一条前台命令执行后的返回值。算术运算执行算术运算需要使用let，如let c=$a+$b。可以使用c=$(($a+$b))代替。其中算术运算符及优先级等同于C语言。同时多了个**表示幂运算。（运算符前后不要有空格）从命令行读入参数直接使用read，命令行中的参数会读到read后面跟的参数（相当于变量）里。读入时输出提示信息：引号双引号：由双引号引起来的字符（除$、`和`\`）都被当做普通字符对待。$表示变量替换； `表示命令替换；\之后的字符只有是$、 、双引号、`或换行符之一时会成为转义字符。其他情况都是\本身。单引号：单引号引起来的字符都是普通字符。特殊字符也失效。倒引号：被到引号引起来的字符被解释为命令。如上上图中所示。数组变量之间使用空格隔开各个元素。如果元素中有空格，使用双引号引起来。测试条件任何命令都可以作为条件，shell会执行这个命令并检查返回值，如果命令成功（返回值为0），表示真。test &lt;条件&gt;：如test n1 -eq n2[ 条件 ]：如[ n1 -eq n2 ]有关文件方面的测试-r 文件名：真 &lt;==&gt; 文件存在并且是用户可读-w 文件名：真 &lt;==&gt; 文件存在并且是用户可写-x 文件名：真 &lt;==&gt; 文件存在并且用户可执行-f 文件名：真 &lt;==&gt; 文件存在且是普通文件-d 文件名：真 &lt;==&gt; 文件存在且是目录文件-s 文件名：真 &lt;==&gt; 文件存在且长度大于0有关字符串方面的测试-z s1：真 &lt;==&gt; 字符串长度为0-n s1：真 &lt;==&gt; 字符串长度大于0s1：真 &lt;==&gt; 字符串不是空字符串s1 = s2（在“=”前后应有空格）：真 &lt;==&gt; 字符串相等s1 != s2：真 &lt;==&gt; 字符串不等s1 &lt; s2：真 &lt;==&gt; 按字典顺序s1在s2之后s1 &gt; s2：真 &lt;==&gt; 按字典顺序s1在s2之前数值方面的测试n1 -eq n2：真 &lt;==&gt; 数值相等n1 -ne n2：真 &lt;==&gt; 数值不等n1 -lt n2：真 &lt;==&gt; n1小于n2n1 -le n2：真 &lt;==&gt; n1小于或等于n2n1 -gt n2：真 &lt;==&gt; n1大于n2n1 -ge n2：真 &lt;==&gt; n1大于或等于n2逻辑运算符!：逻辑非-a：逻辑与-o：逻辑或(表达式)：圆括号括起来表示为一条语句选择结构循环结构break &amp; continue和C语言一致。shift参数跳转命令：不跟数组默认跳转1位，跟了跳转n位。命令行ex.shABCDEF原位置参数$0$1$2$3$4$5$6移位后参数$0$1$2$3$4$5还可以用于循环结构的done上面，表示每次选择指定参数。参数置换变量格式var1为空var1不空var2=${var1:-str}var2=str。var1不变var2=$var1。var1不变var2=${var1:=str}var2=var1=strvar2=$var1。var1不变var2=${var1:+str}var2为空。var1不变var2=str。var1不变var2=${var1:?str}输出：“shell 脚本名:var1:str”并退出shell。var2不变var2=$var1。var1不变ex1编写ex1.sh，参数为一个大于 20 的正整数。先检查参数是否符合要求。如果不符合要求，请给出提示；如果符合要求，输出这个参数的平方。ex2编写ex2.sh，首先显示当天日期，然后查找给定的用户是否在系统中工作（who 命令）。如果在系统中，就输出一条欢迎语句（例如 hello，xxxx！）；如果不在系统中，就输出一条语句（waiting for xxx！）ex3编写 ex3.sh，该脚本接受一个参数。若改参数不是目录，则给出提示信息；否则使用ll命令列出该目录下的内容，并输出有多少个子目录（d开头），多少个普通文件（-开头）。ex4编写 ex4.sh，将第一个参数指定的内容 copy 到第二个参数指定地点。若第一个参数是目录，自动添加-r选项（即把目录下的所有内容都 copy 过去）；若第一个参数是普通文件，则将其 copy 到指定地点；若第一个参数指定的文件或目录不存在，则报错；若第二个参数指定的文件或目录已经存在，则提示是否替换，若选择 yes，则先删除原来的文件或目录，然后再执行 copy 操作，否则放弃。ex5编写 ex5.sh。检查命令行的第一个参数是否是-b或者-s。如果是-b，则计算由第二个参数指定的文件中以 b 开头的行数。如果是-s，则计算由第二个参数指定的文件中以 s 开头的行数。否则显示选择有错的信息。ex6编写 ex6.sh。该脚本需要输入两个文件的名称，然后由用户选择相应的操作（若两个参数中任何一个不是普通文件，则报错）。cat：输出两个文件的内容statistic：统计两个文件分别有多少行merge：将第 1 个文件的内容合并到第 2 个文件后面copy：将第 1 个文件的内容 copy 到第 2 个文件（覆盖原文件）bye：退出1ex编写 1ex.sh，利用 for 循环将当前目录下的.c 文件移动到指定的目录下，完成后显示指定目录下的文件内容，并按文件从小到大排序。(ll -r -S）2ex编写 2ex.sh，显示 Fibonacci 数列的前 10 项及其总和。3ex编写 ex3.sh，判断给定的参数是否是素数。4ex编写 ex4.sh，将给定的参数转换成二进制表示。5exex5.sh假设存在一个/homework的文件夹，其中包含一个 studentlist.csv的文件，当中存放了若干学生的学号，每个一行。例如：150341101、150341102、150341105、150341106，编写 ex11.sh。查看/homework 文件夹下学生是否提交了作业，假设作业名的格式为：学号_homework.txt。最后输出没提交作业的学号名单。]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-IO流和网络]]></title>
    <url>%2F2019%2F03-IO%E6%B5%81%E5%92%8C%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[IO流构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145ByteArrayInputStream(byte[] buf) // 创建一个 ByteArrayInputStream，使用 buf 作为其缓冲区数组。 ByteArrayInputStream(byte[] buf, int offset, int length) // 创建 ByteArrayInputStream，使用 buf 作为其缓冲区数组。 FileInputStream(File file) // 通过打开一个到实际文件的连接来创建一个 FileInputStream，// 该文件通过文件系统中的 File 对象 file 指定。 FileInputStream(String name) // 通过打开一个到实际文件的连接来创建一个 FileInputStream，// 该文件通过文件系统中的路径名 name 指定。 ObjectInputStream(InputStream in) // 创建从指定 InputStream 读取的 ObjectInputStream。 BufferedInputStream(InputStream in) // 创建一个 BufferedInputStream 并保存其参数，即输入流 in，以便将来使用。 BufferedInputStream(InputStream in, int size) // 创建具有指定缓冲区大小的 BufferedInputStream 并保存其参数，即输入流 in，以便将来使用。 BufferedReader(Reader in) // 创建一个使用默认大小输入缓冲区的缓冲字符输入流。 BufferedReader(Reader in, int sz)// 创建一个使用指定大小输入缓冲区的缓冲字符输入流。 CharArrayReader(char[] buf) // 根据指定的 char 数组创建一个 CharArrayReader。 CharArrayReader(char[] buf, int offset, int length) // 根据指定的 char 数组创建一个 CharArrayReader。 StringReader(String s) // 创建一个新字符串 reader。FileReader(File file) // 在给定从中读取数据的 File 的情况下创建一个新 FileReader。 FileReader(String fileName) // 在给定从中读取数据的文件名的情况下创建一个新 FileReader。 ByteArrayOutputStream() // 创建一个新的 byte 数组输出流。 ByteArrayOutputStream(int size) // 创建一个新的 byte 数组输出流，它具有指定大小的缓冲区容量（以字节为单位）。 FileOutputStream(File file)// 创建一个向指定 File 对象表示的文件中写入数据的文件输出流。 FileOutputStream(File file, boolean append) // 创建一个向指定 File 对象表示的文件中写入数据的文件输出流。 FileOutputStream(String name) // 创建一个向具有指定名称的文件中写入数据的输出文件流。 FileOutputStream(String name, boolean append) // 创建一个向具有指定 name 的文件中写入数据的输出文件流。 ObjectOutputStream(OutputStream out) // 创建写入指定 OutputStream 的 ObjectOutputStream。BufferedOutputStream(OutputStream out) // 创建一个新的缓冲输出流，以将数据写入指定的底层输出流。 BufferedOutputStream(OutputStream out, int size) // 创建一个新的缓冲输出流，以将具有指定缓冲区大小的数据写入指定的底层输出流。 PrintStream(File file) // 创建具有指定文件且不带自动行刷新的新打印流。 PrintStream(File file, String csn) // 创建具有指定文件名称和字符集且不带自动行刷新的新打印流。 PrintStream(OutputStream out) // 创建新的打印流。 PrintStream(OutputStream out, boolean autoFlush) // 创建新的打印流。 PrintStream(OutputStream out, boolean autoFlush, String encoding) // 创建新的打印流。 PrintStream(String fileName) // 创建具有指定文件名称且不带自动行刷新的新打印流。 PrintStream(String fileName, String csn) // 创建具有指定文件名称和字符集且不带自动行刷新的新打印流。 BufferedWriter(Writer out) // 创建一个使用默认大小输出缓冲区的缓冲字符输出流。 BufferedWriter(Writer out, int sz) // 创建一个使用给定大小输出缓冲区的新缓冲字符输出流。 CharArrayWriter() // 创建一个新的 CharArrayWriter。 CharArrayWriter(int initialSize) // 创建一个具有指定初始大小的新 CharArrayWriter。 StringWriter() // 使用默认初始字符串缓冲区大小创建一个新字符串 writer。 StringWriter(int initialSize) // 使用指定初始字符串缓冲区大小创建一个新字符串 writer。 FileWriter(File file) // 根据给定的 File 对象构造一个 FileWriter 对象。 FileWriter(File file, boolean append) // 根据给定的 File 对象构造一个 FileWriter 对象。 FileWriter(String fileName) // 根据给定的文件名构造一个 FileWriter 对象。 FileWriter(String fileName, boolean append) // 根据给定的文件名以及指示是否附加写入数据的 boolean 值来构造 FileWriter 对象。 PrintWriter(File file) // 使用指定文件创建不具有自动行刷新的新 PrintWriter。 PrintWriter(File file, String csn) // 创建具有指定文件和字符集且不带自动刷行新的新 PrintWriter。 PrintWriter(OutputStream out) // 根据现有的 OutputStream 创建不带自动行刷新的新 PrintWriter。 PrintWriter(OutputStream out, boolean autoFlush) // 通过现有的 OutputStream 创建新的 PrintWriter。 PrintWriter(String fileName) // 创建具有指定文件名称且不带自动行刷新的新 PrintWriter。 PrintWriter(String fileName, String csn) // 创建具有指定文件名称和字符集且不带自动行刷新的新 PrintWriter。 PrintWriter(Writer out) // 创建不带自动行刷新的新 PrintWriter。 PrintWriter(Writer out, boolean autoFlush) // 创建新 PrintWriter。计算机网络计算机网络就是互联的、自治的计算机集合。自治指的是所有的计算机直接没有主从关系；互联指的是互联互通，能进行数据交换。计算机网络的本质是一种通信网络，只不过信源和信宿都是主机。它是计算机技术和通信技术的结合。信道信道是数据交换的载体。狭义上说人和人之间交流所承载信息的空气就是信道。广义上说它还可以包括有关的变换装置，这样的话信道往往被分成信道编码器、信道本身和信道译码器。简易通信系统模型如下：主机（host）诸如手机、电脑、服务器等端系统（end systems）。交换机如果想实现多个计算机之间的互联，按照之前的想法是每两台计算机进行连接，但这样太麻烦，一个好的做法是把这个计算机连接在某一中心上，这个中心把所有连接上来的计算机进行互联，在链路层这个中心叫做交换机。分组分组是带有地址信息的信息小片，可以理解成是计算机把一个文件切片后打成的包裹，由两部分构成：地址信息和真正传输的东西。路由器是计算机网络的一种专用计算机，它只有一个功能，就是转发分组。可以简单的理解为路由器是电子化的邮局，全国所有的邮局之间互联，是包裹能够传递，路由器之间互联，是分组能够正确转发。路由器和交换机的区别是：交换机将计算机连在一起，构成局域网；路由器将局域网连在一起，形成互联网。计算机网络基本原理分组交换技术，也就是拆分分组、传输分组、合并分组的技术。这个技术的优点就是便宜，因为把数据打包成分组和分组拆分都在计算机中进行，网络上只进行分组的转发，就使得网络的结构很简单，路由器设计也很简单。这一中原则被叫做“端到端的原则”，即能在端系统做的事情不在网络上实现。分组交换技术一个主机至少连接一个路由器：数据最终是通过路由器进行转发的，所以一个主机至少得连接一个路由器。分组存储转发：分组完全进入路由器后，路由器按照地址信息检索转发表。注意不是第一个bit或Byte进入时就开始转发，是全部进入才转发。分组独立选择路径：一个文件被分成多个分组，但这些分组之间是独立的，路由器给他们看成相互独立的数据。分组的组装是通过接收方进行的，和网络无关。Internet组成细节角度ISP网络互联形成的网络之网络。由运行各种网路应用的计算设备，光纤、铜缆、无线电等通信链路、路由器和交换机等组成的分组交换设备组成。服务角度是为网络应用提供通信服务的通信基础设施和为网络应用提供的应用编程接口。ISPISP，全称为Internet Service Provider，因特网服务提供商，即指提供互联网服务的公司。能提供拨号上网服务、网上浏览、下载文件、收发电子邮件等服务。IXPInternet eXchange Point，互联网交换点IXP的主要作用就是允许两个网络直接相连并交换分组，而不需要再通过第三个网络来转发分组。网络的结构网络边缘：位于“网络边缘”运行网络应用程序的端系统。接入网络、物理介质：有线或无线的通信链路。网络核心：互联的路由器（或分组转发设备）。构成“网络之网络”的关键。网络应用模型客户/服务器应用模型：依赖于专用服务器，如Web应用。对等应用模型：不依赖专用服务器，通信在对等实体之间进行，如P2P应用。接入网络接入网络是一种用户网络，它连接用户到特定的服务提供商并通过承载网络到达其他网络。两个被用户关心的特征：带宽（数据传输速率，bps）、独占/共享（独占是带宽为某用户独用，共享是多个用户分用同一带宽）。数字用户线路：DSL是以电话线为传输介质的传输技术组合。DSL技术在传递公用电话网络的用户环路上支持对称和非对称传输ADSL：上行速度较慢，下行速度较快）模式。用DSL接入Internet时用户一方会有DSL调制解调器，被接入方会有DSL接入多路复用器与多个用户进行接入。电缆网络又被称为混合光纤同轴电缆网络。也是一种非对称式的接入网络。但它是共享网络，多个用户共同接入一个解调器。常见网络接入家庭接入机构（企业）接入无线局域网广域局域网网络核心网络核心的功能是：路由（routing）：确定分组从源到目的传输路径；转发（forwarding）：将分组从路由器的输入端口交换至正确的输出端口。Internet结构一级ISP包含：网通、电信等商业ISP，还包含谷歌、微软等内容提供商网络。IXP：全称：Internet eXchange Point，即互联网交换中心。互联网Internet是由众多的网络互相连接而形成的全球性网络，互联网交换中心负责这些不同的网络之间互相通信的交换点，是互联网的关键基础设施。数据交换方式电路交换包含三个阶段：建立连接、通信、释放连接。最显著的特点是独占电路资源。最典型的是电话网络。（下图的中继线上可以存在多组用户通信，详见复用技术）报文交换报文交换是指把信息整个打包，然后经过存储转发送到目的地。分组交换分组交换是把信息拆分成不同的分组，然后把所有的分组相继发送给路由器，路由器通过路由&amp;转发把数据传输到目的地。和报文交换的区别是：报文交换不拆分信息。和电路交换的区别是：如果把每个分组看成原子单位，区别就是各分组走不同的路径，不需要独占资源。图解三种交换分组交换的优势和报文交换相比：速度快，因为在报文交换时，同一时间只有一个路由器在工作，其他路由器在等待。路由器的存储空间小，最低存储空间和分组大小差不多。和电路交换相比：分组交换允许更多用户同时使用网络，让网络资源充分共享。分组交换的劣势可能产生拥塞（congestion）：分组延迟和丢失。需要协议处理可靠数据传输和拥塞控制。RFC文档Request For Comments（RFC），是一系列以编号排定的文件。文件收集了有关互联网相关信息，以及UNIX和互联网社区的软件文件。目前RFC文件是由Internet Society（ISOC）赞助发行。基本的互联网通信协议都有在RFC文件内详细说明。RFC文件还额外加入许多的论题在标准内，例如对于互联网新开发的协议及发展中所有的记录。因此几乎所有的互联网标准都有收录在RFC文件之中。IETF全称：The Internet Engineering Task Force，国际互联网工程任务组。全球互联网最具权威的技术标准化组织，主要任务是负责互联网相关技术规范的研发和制定，是一个由为互联网技术工程及发展做出贡献的专家自发参与和管理的国际民间机构。主要任务是负责互联网相关技术标准的研发和制定，是国际互联网业界具有一定权威的网络相关技术研究团体。绝大多数国际互联网技术标准出自IETF。网络协议network protocol。为进行网络中的数据交换而建立的规则、标准或约定。其中规定了通信实体之间所交换的消息的格式、意义、顺序以及针对收到的消息或发生的事件而产生的动作。也可以说网络协议规定了网络中所有信息的发送和接受过程。协议三要素语义：语义是解释控制信息每个部分的意义。它规定了需要发出何种控制信息，以及完成的动作与做出什么样的响应。语法：语法是用户数据与控制信息的结构与格式，以及数据出现的顺序。时序：时序是对事件发生顺序的详细说明。（也可称为“同步”）。总结：语义表示要做什么，语法表示要怎么做，时序表示做的顺序。速率 &amp; 带宽速率：又称数据率，数据传输速率或比特率。单位bps、kbps、Mbps、Gbps。带宽：数字信道所能传输的最大数据率。单位bps等。丢包如果路由器的缓存满了，再到达的分组会被路由器丢弃，即造成丢包现象。丢包率 = 丢包数 / 已发分组数。分组延迟结点处理延迟：差错检测、确定输出链路；排队延迟：等待输出链路可用、取决于路由器拥塞程度；传输延迟：分组长度/链路带宽；传播延迟：物理链路长度/信号传输速度。流量强度设链路带宽为R(bps)，分组长度为L(bits)，平均每组到达速率为v。则：$L \ast v / R \longrightarrow 0 $时：平均排队延迟很小；$L \ast v / R \longrightarrow 1$时：平均排队延迟很大；$L \ast v / R &gt; 1$时：超出服务能力，延迟 趋向于 无限大。时延带宽积$时延带宽积 = 传播时延 \ast 带宽$，单位：bit。实际意义是：从我们向某一信道上发送第一个bit，到这个bit被接收方接受这个时间里，发送方总共向信道上发送了多少bit。也可以称为以比特为单位的链路长度，比如某段链路长度为n比特。吞吐率/量（Throughput）发送端与接收端之间的传送数据率（b/s）。端到端的吞吐量取决于瓶颈链路。网络体系结构指通信系统的整体设计，它为网络硬件、软件、协议、存取控制和拓扑提供标准。计算机网络是一个非常复杂的系统，需要解决的问题很多并且性质各不相同。所以，在设计时，就使用了“分层”的思想，即将庞大而复杂的问题分为若干较小的易于处理的局部问题。各层之间是按照功能进行分层的，同时每层遵循相应的网络协议完成本层功能。OSI参考模型的通信过程七层结构：物理层、数据链路层、网络层、传输层、对话层、表示层和应用层。端系统需要完成七层的功能，中间系统完成三层功能。协议之间是对等的，比如应用层的协议对发送方来说是如何把信息传输到表示层，而对接收方来说，是如何把从表示层传来的信息还原到应用层。对于后四层，从逻辑上说不需要经过中间系统，所以被称为“端-端层”。OSI参考模型的数据封装后六层每层在把数据向下一层传输时都会加上控制信息。而物理层不再封装，因为到达它的数据已经时二进制数据，直接传输就行。数据链路层传送给物理层时一般加头加尾，其他层只加头。头是首部，尾是循环冗余校验。PDU协议数据单元。可能包括地址：标识发送端/接收端等；差错检测编码：用于差错检测或纠正；协议控制：一些如优先级、服务质量、安全控制等信息。TCP/IP参考模型四层结构：应用层、运输层、网际层和网络接口层。所有的应用都架构在IP上，在网络接口层只要能构建IP，能进行分组就可以算是网络的一部分，这是互联网发展迅速的一大原因。五层参考模型五层结构：物理层、链路层、网络层、传输层和应用层。此模型结合了OSI概念清晰，分工明确的优点和TCP/IP简单实用的优点。五层传输模型的数据封装三种模型对应物理层实现的功能概述核心功能：透明地传送比特流。解决的问题一般如下：接口特性：机械特性：接口的几何形状，位置等等；电气特性：使用电压的高低等等；功能特性：各个引脚的作用等等；规程特性：工作的过程是什么样的，如哪个引脚先发送数据，哪个后发送等。比特编码：用信号的什么特征表示信息，如什么时候用0，什么时候用1。数据率：在物理层上传输数据的速率。比特同步：解决时钟同步问题，发送端何时发送数据，接收端何时接受数据。传输模式：单工通信：一个为确定的发送端、一个为确定的接收端，不能互换。半双工：发送端和接收端可以互换，但是随时间交替的。双工：两端可以同时发送和接受数据。数据链路层功能概述核心功能：在两个相邻结点之间的链路上“透明”地传送数据。解决的问题如下：组帧：来自网络层的数据被加头加尾后形成的数据叫做帧。组帧问题包含：头和尾里包含什么信息等。物理寻址：物理层只进行比特流的传输，其他的都不做。物理寻址是在数据链路层做的，也就是数据链路层传输层给物理层的数据包含处理好的地址。流量控制：使数据的发送和数据的接收尽可能平衡，防止数据太多造成丢失等。差错处理：检测并重传损坏或丢失帧，并避免重复帧。访问（接入）控制：在任一时刻觉得哪个设备拥有链路使用权。网络层功能概述核心功能：负责为分组交换网上的不同主机提供通信服务。选择合适的路由，是源主机运输层所传下来的分组，能够通过网络中的路由器找到目的主机。解决的问题：逻辑寻址：全局唯一逻辑地址，确保数据分组被送达的主机，如IP地址。路由和分组转发：确保在网络中数据能从源主机到目的主机传输层功能核心功能：负责向两个主机中进程之间的通信提供服务。解决的问题：分段与重组：网络层传输的分组大小是有限制的。应用层的SAP寻址：确保将完整报文提交给正确进程，如端口号SAP：Service Access Point，在同一系统中相邻两层的实体进行交互的地方。连接控制：有两种协议，面向连接的TCP和无连接的UDP。流量控制：匹配发送方和接收方的速度。差错控制：如发送的报文接收方没有接受到或者接收方缓冲区由于满把报文丢弃该怎么处理。应用层核心功能：直接为用户的应用进程提供服务。码元官方解释数字通信中对数字信号的计量单位。在使用时间域（或简称为时域）的波形表示数字信号时，代表不同离散数值的基本波形。理解假如基带信号是101011000110111010...，如果直接发送，则每个码元携带一个比特的信息（每个码元只有2种状态），但是如果将信号中的三个比特编为一组，即101，011，000，110，111，010…，三个比特共有8种不同的排列，我们可以用不同的调制方法来表示这种信，如8种不同的振幅，频率，相位等，如果采用相位调制，相位$\phi_0$表示000，$\phi_1$表示001，以此类推，那么接收端如果收到相位是$\phi_0$的信号就知道表示的是000，以此类推，这样一个码元就不知不觉的传输了三个比特位的信号，此时每个码元有8种状态。一个码元可表示的比特数越多，则在接收端进行解调时要正确识别每一种状态就越困难。编码级别如果把n个比特编码成一个码元，则此时编码状态$M=2^n$，其表示当前传输时有多少不同的状态，如8级编码，会有：000、001、010 …奈斯准则码间串扰码元的传输速率是有限制的，超过某上限就会出现码间串扰问题。这是由于在真正传输中，信号在传输时都不是理想化的，如下图就是理想化的高低电平和真实传输时的高低电平。假如此时速度太快，就可能把低电平和高电平弄混。而最高的码元传输速率被奈斯准则限制。奈斯准则内容理想低通信道（能通过信号频率在某值之下）的最高码元传输速率为：$2W Baud$。理想带通信道（能通过信号频率在某范围之内）的最高码元传输速率为：$1W Baud$。W是理想低通信道的带宽，单位为赫(Hz)。Baud 是波特，是码元传输速率的单位，1 波特为每秒传送 1 个码元。波特率单位时间内数据通信系统所传输的码元个数（信号个数），单位是波特（Baud）。比特率表示单位时间内数据通信系统传输的比特数，单位是比特/秒（b/s或bps）。$比特率 = 波特率 * log_2M$香农公式编码级数限制虽然码元传输速率有限制，但是如果我们能尽可能提高编码级数不就能提升信息传输速率了吗？但事实上信号传输速率不受限于调制技术，而是受限于信噪比。举个例子，如果我们是在天气晴朗的一天出门，我们穿任意颜色衣服都能被分辨出来，但是如果我们在沙尘暴天气出门，穿橘黄和橙黄两种颜色的衣服别人自然就认不出来了。在这个比喻中衣服的颜色代表码元，确定衣服的颜色代表信息，沙尘暴就是噪声。香农公式内容带宽受限且有高斯白噪声干扰的信道的极限信息传输速率$C=W \ast log_2(1+PS/PN)（b/s）$。其中$W$是信道的带宽。$PS$是信号的能量。$PN$是噪声的能量。信噪比：$S/N=10lg{PS/PN}$。举例设带宽是1MHz，信噪比是24dB，则信道的最高信息传输速率为：$C=1M \ast log_2{(1+(10^{2.4}))}=7.98Mbps$。奈氏准则vs香农公式多路复用电路交换中独占电路资源，并不是指用户线和中继线都被此次交换所独占，而是说在两个用户建立连接之后，除非连接中断，否则他们当前所拥有的资源不会被释放，即使他们之间不传输信息。而如何在中继线上实现多组用户通信就是多路复用技术。产生多路复用的物理基础是：传输媒体的带宽或容量往往会大于传输单一信号的需求，使用多路复用，为了有效地利用通信线路，希望一个信道同时传输多路信号。这种技术会将链路/网络资源（如带宽）划分为“资源片”，将资源片分配给各路“呼叫”（calls），每路呼叫独占分配到的资源片进行通信，资源片可能“闲置”常见的复用技术有：频分多路复用、时分多路复用、波分多路复用、码分多路复用。频分多路复用FMD：Frequency-division multiplexing，是指载波带宽被划分为多种不同频带的子信道，每个子信道可以并行传送一路信号的一种多路复用技术。也就是说信道的可用频带被分成若干个互不交叠的频段，每路信号用其中一个频段传输，因而可以用滤波器将它们分别滤出来，然后分别解调接收。时分多路复用TDM：time division multiplexing，它使不同的信号在不同的时间内传送，将整个传输时间分为许多时间间隔（Time Slot，TS，又称为时隙），每个时间片被一路信号占用。TDM就是通过在时间上交叉发送每一路信号的一部分来实现一条电路传送多路信号的。电路上的每一短暂时刻只有一路信号存在。因数字信号是有限个离散值，所以TDM多应用于数字通信系统。波分多路复用将两种或多种不同波长的光载波信号（携带各种信息）在发送端经复用器（亦称合波器，Multiplexer）汇合在一起，并耦合到光线路的同一根光纤中进行传输的技术；在接收端，经解复用器（亦称分波器或称去复用器，Demultiplexer）将各种波长的光载波分离，然后由光接收机作进一步处理以恢复原信号。码分多路复用为每个用户分配一个唯一的mbit的码片序列（chipping sequence），二进制下的0用-1表示，二进制下的1用+1表示。在信道上传输的信号 = 原始数据 码片序列，比如码片序列是：(-1, 1, 1)，需要传一个0，应该是 -1 (-1, 1, 1)，所以传输的就是(1, -1, -1)。同时为了保证数据之间不相互影响，被共享的用户所占有的码片应该相互正交的。即：$\frac{1}{m}S_i \cdot S_j = 0 (i \neq j)$。而信道上真正传输的数据是各用户发送数据的叠加值。数字信号在模拟信道传输数字信号需要编码后才能传输。常见的三种编码：NRZ编码：进制数字0、1分别用两种电平来表示。常用-5V表示1，+5V表示0。曼切斯特编码：用电压的变化表示0和1：高→低 &lt;=&gt; 0，低→高 &lt;=&gt; 1。差分曼切斯特编码：在码元开始处有无跳变来表示0和1：有 &lt;=&gt; 0，无 &lt;=&gt; 1。相邻计算机网络中链路层的功能是“相邻节点间的数据传输”。这句话什么意思呢？我们先讨论“相邻”一词，再讨论“数据传输”。两台主机，用一根网线相连是相邻。多台主机，用一根网线相连，仍然是相邻。这根线缆退化成一个节点，这样的设备称为集线器。通过集线器相连的多台主机也是相邻。集线器没有任何智能，等同于线缆。在集线器上增加简单的智能控制功能，就是交换机。通过交换机相连的多台主机也是相邻。交换机将计算机互联在一起，构成局域网。所以“相邻节点间的数据传输”换一种说法就是“构建局域网”，再换一种说法就是“局域网内的主机都是邻居关系”。链路层的功能就是构建局域网。相邻这一概念很重要，主机间的数据传输可以分为两种情况，一种是两个主机在同一个局域网内，两主机是相邻关系，简称内网通信，另一种是两个主机在两个不同的网络里，可称外网通信，两种数据传输原理完全不同。本篇博文只关注内网通信。链路层解决的问题数据传输就是将一台主机内的数据传输到另一台主机，物理层解决了比特转换为电磁信号传输的问题，但这不是数据传输的全部问题，还有一些问题，例如：物理层传输中的数据有可能出错，如何处理？发送方与接收方的速度可能不匹配，如何调节？数据如何封装成数据帧，然后传输，如何传输封装？发生碰撞该怎么办？针对这些问题制定的解决方案称为数据链路层的通信协议。物理链路+通信协议构成了我们要研究的数据链路。循环冗余码循环冗余码（CRC）在很多地方都被用来校验传输的数据是否出错，至于其如何证明，博主也未曾探究，下文介绍冗余码的思想和计算方法。如果发送方只传输 87，接收方收到 82，接收方是无法判断 82 是不是发送方发送的数据，就是说无法判断 82 是对还是错。怎么办？发送方与接收方事先商量好一个数，例如 15，发送时先计算 87 除 15 的余数，为 12，将这个余数与 87 一起发送，即 8712，接收时先计算 82 除 15 的余数，为 7，不等于 12，就认为传输的数据出错，这样检错的概率并非百分之百，例如87 错成 72 就检测不出来，但总体来说，检错概率已经非常高了。CRC 计算方法第一，CRC 有一个生成多项式 P(x)，其作用等同于除数 15，将其写成比特串，转化规则如图：第二，如果 P(x) 的比特串是 n 位，在发送数据后补 n-1 个 0。例如 P(x)为 1101，就要补 000。第三，做模2除法。注意模二除法不是二进制除法。第四，用余数替换补的 0，形成发送数据，101001001。第五，接收方用接收数据 101001001 除以 P(x)1101，如果能整除，就表示没有错（等同与原理中的余数相同），如果不能整除，就表示出错了（等同与原理中的余数不相等）。停止等待协议（Stop-and-Wait protocol）如果两个主机间数据传输时，接收方的速度永远不会低于发送方的速度；传输的数据帧不会出错，也不会丢失，完全理想化的数据传输，那就没有什么问题，当然也不需要解决问题的办法，也就不需要协议。现在假设，没有差错，但是接收方的速度低于发送方的速度，怎么办？显然控制的思路只能是快的一方牵就慢的一方，就是由慢的一方指挥快的一方。具体来说，就是发送方每发送一帧就停下来，等待；收到 ACK 发送下一帧，接收方则是等待，收到数据帧，发送 ACK（确认 Acknowledgment ），等待下一帧。停下来，等待就是停止等待协议的由来。停止等待协议当然不仅仅需要这一个问题，其需要解决的问题如下：接收方的速度低于发送方的速度；传输的数据帧可能出错；数据帧可能丢失，确认帧 ACK 也可能丢失；确认号接收方收到一个数据帧，并校验正确，给发送方一个确认 ACKn，ACKn 表示“第 n-1 号帧已经收到，现在期望接收第 n 号帧”。确认号是接收方预期接收的下一帧的序号。差错数据帧出错时，接收方收到一个数据帧，校验时发现数据帧出错，接收方丢弃此数据帧，此外不做任何事，即不发送 ACK。发送方发送完数据帧后在停止等待 ACK，然而此时不会有 ACK，发送方就等死在这里了。重传定时器发送方设计一个重传定时器的机制，发送方每发送一个数据帧，就启动一个倒计时的重传定时器，如果在超时 timeout 之前收到确认，就关闭定时器并发送下一帧。如果超时，就重传之前的帧。丢失接收方收到一个数据帧，校验正确发送 ACK，等待接收下一帧，如果确认帧丢失，发送方收不到确认，超时后重传旧帧，而接收方在等待新帧，此刻发送方与接收方的状态不同步，如何区分新帧与重传的帧？帧编号停等协议使用序号和确认号，以区分重传的数据帧。发送方发送帧时使用序号，接收方使用确认号。信道利用率停止等待协议的优点是简单，但缺点是信道利用率太低。信道利用率公式：$U=\frac{T_D}{T_D+RTT+T_A}$，其中：$T_D$：数据帧传输时延$RTT$：数据帧+确认帧传播时延$T_A$：确认帧传输时延举例：假设主机甲与主机乙使用停等协议传输数据，若甲乙之间的单向传播延迟是 15ms，数据帧长为 1000 字节，信道宽带为 100Mbps，乙每收到一个数据帧立即利用一个短帧（忽略其发送时延）进行确认，则信道利用率为：发送一个数据帧到 100Mbps 链路所需时间为：$T_D = \frac{1000 \ast 8bits}{100 \ast 10^6bit/s }= 80\mu s$。发送方在 t=0 时刻发送，15ms 后第 1 个比特到达主机乙，15.08ms 时主机乙收到最后一比特，开始发送确认帧，由于确认帧很短，我们忽略其发送时延，在30.08ms 时，确认帧到达主机甲，总时间周期为T𝐷 + RTT + T𝐴(忽略) = 30.08ms，信道利用率为0.0027。信道利用率为 0.27%，就是说发送方只有百分之0.27的时间是忙的。停止等待协议信道利用率太低了。GBN 协议我们讨论一个可以获得较高信道利用率的协议：连续 ARQ 协议(Go-back-NProtocol)，或称 GBN 协议，也称为滑动窗口协议（Sliding Window Protocol）。发送方在接收到确认之前，发送一组数据帧，而不是发送一个数据帧就停止等待确认。确认号在 GBN 协议中，采用累积确认的方式，确认号是希望接收的下一个分组序号。举例，ACK7 表示序号 6 以内的所有帧都已正确收到了，等待接收 7 号帧。发送窗口在 GBN 协议中，发送一组帧，然后停止等待确认。发送窗口定义了最多可以发送多少个数据帧。举例如下图：一个大小为 7 的窗口，窗口左侧是已确认，已丢弃的帧，窗口内有色的是已发送的，尚未收到确认的帧，0，1，2，3 号帧，发送方需要等待，可称为未完成帧，窗口内无色的是可发送还未发送的帧，是 4，5，6 号帧，窗口右侧是不能发送的帧。描述发送窗口需 3 个变量：$S_f$：发送窗口，第一个未完成分组。完成指的是发送方接收到确认方的确认帧。$S_n$：发送窗口，下一个待发送分组。$S_{size}$：发送窗口，大小。当 ackNo 大于等于 $S_f$ 且小于 $S_n$ 的无错 ACK 到达时，发送窗口可以滑动一个或多个槽。举例，当发送方收到 $ACK_6$，表示 4，5 号帧已正确接收，窗口滑动，状态如下图。接收窗口在 GBN 协议中，接收窗口大小总是 1。只有序号在接收窗口内的数据帧才接收。任何失序的分组都会被丢弃，需要重发。描述接收窗口控制只需 1 个变量 $R_n$，表示其期待下一次接收的帧，重传定时器在 GBN 协议中，只使用一个计时器。接收窗口大小总是 1。当定时器超时，发送方重发所有未完成分组。例如，假设发送方已经发送了分组 6（$S_n=7$），但是唯一的计时器终止。如果 $S_f=3$，这意味着分组 3、4、5 和 6 没有被确认；发送方回退并重发分组 3、4、5 和 6。发送方发送分组。发送方会开启唯一的计时器。$S_n$ 的值增长，（$S_n=S_n+1$）如果达到窗口值进入阻塞状态。如果 ACK 到达，其 ackNo 与一个未完成分组有关，那么发送方滑动窗口（令 $S_f=ackNo$），并且如果所有未完成分组都被确认（$ackNo=S_n$），那么关闭计时器。如果并不是所有未完成分组都被确认，那么重新开启计时器。如果超时发生，发送方重发所有未完成分组并重新开启计时器。接收方如果 $seqNo=R_n$ 的无错分组到达，之后窗口滑动，$R_n=（R_n+1）$。$ackNo=R_n$的 ACK 被发送。如果 seqNo 在窗口之外的无错分组到来，分组被丢弃，但是 $ackNo=R_n$的 ACK 被发送。发送窗口的最大值当用 n 个比特进行帧编号时，接收窗口的大小为 1，则只有在发送窗口的大小$W_T ≤ 2^n − 1$时，连续 ARQ 协议才能正确运行。例如，当采用 2bit 编码时，发送窗口的最大值是 3 而不是 4。下图比较 4 与 3 两种情况。如果窗口的大小是 4 并且所有确认都丢失，发送方将会重传旧的所有 4 个帧。但是接收方等待接收的是新的 0 号帧，由于窗口匹配，接收 0 号帧，接收方认为接收的是新的 0 号帧，这是一个错误。如果窗口大小为 3 并且所有三个确认都丢失，那么超时并且重发所有 3 个分组，接收方现在期待 3 号帧，而不是 0 号帧，因此重传分组被正确丢弃。不会产生错误。为能正确区分重传的帧，应保证在$W_T+W_R$的窗口内不出现重复序号，即$W_T + W_R ≤ 2^n$，我们将 WT 和 WR 拼接在一起，在$W_T + W_R$窗口内如果出现重复序号，就会发生上述的错误，如果不出现重复的序号，就不会发生上述的错误。GBN 协议的接收窗口为 1，所以发送窗口最大为$2^n − 1$CSMA/CD共享信道有一个基本问题，碰撞 （Collision）。若某时刻两帧同时发出，会相互重叠，结果使信号无法辨认，称为碰撞。如下图便是碰撞：碰撞的结果是两个帧都变得无用。解决碰撞的思路大致有两类：一类思路是将工作做在前面，预防碰撞，即受控接入：各主机不能任意发送数据，必须服从一定的控制。如令牌环网，拥有令牌的主机可发送数据，没有令牌的主机只能接收数据，令牌如击鼓传花般依次传递。另一类思路是将工作做在后面，撞就撞吧，做好事故的处理，即随机接入：所有主机都可以根据自己的意愿随机地发送数据。CSMA/CD（Carrier Sense Multiple Access with Collision Detection）载波监听多点接入/碰撞检测。载波监听（Carrier Sense）指监测信道上有无数据信号传输，监测方法是判断基带上是否有脉冲二进制 0 或 1。多点接入（Multiple Access）同时有多个站点连接在信道上。显然，使用随机接入的方式是无法避免碰撞的。在随机接入的情况下，需要完成几项工作：尽量减少碰撞是否碰撞有明确结论碰撞之后的事故处理CSMA/CD 协议完成这些工作的原理，简缩为三句口诀。先听后发边发边听冲突重发先听后发我们当然希望尽量减少碰撞，想个什么办法呢？就是在发送数据帧之前，先监听信道。“载波监听”就是“发送前先监听”，如果信道上有数据帧，当然就先不发送数据帧，否则一发送数据帧就产生碰撞，碰撞了就毫无意义。当监听信道时，如果信道忙有数据帧，站点回去睡一段随机时间，然后再回来监听信道，这种策略称非坚持型 CSMA。当监听信道时，如果信道忙有数据帧。站点不是回去睡一会，而是蹲守在这儿，继续监听直到信道空闲，这种策略称坚持型 CSMA。当监听到信道空闲下来时，站点立即就发送数据，称 1-坚持型 CSMA。当监听到信道空闲下来时，站点并不立即发送数据，先抛一次硬币，如果是字就发，如果是花就不发，就是说以概率 p 发送数据，称 p-坚持型 CSMA。边发边听站点发出数据帧后，是否碰撞需要有明确的结论。就需要“碰撞检测”（Collision Detection）。如何检测呢？站点检测信道上的信号电压大小，当几个站同时在总线上发送数据时，总线上的信号电压摆动值将会增大（互相叠加）。当检测到的信号电压摆动值超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞，“碰撞检测”也称为“冲突检测”。假设 A 站点与 B 站点是网络最远的两端，从 A 站点发出一数据帧，到达 B站点的所花费的时间为$\tau$，A 站点发出一数据帧，就在即将到达 B 站的时刻，B站发出一数据帧，立即发生碰撞，碰撞信号继续到达 A 站，A 站在经过时间 $2\tau$（两倍的端到端传播时延）发现碰撞。所以，$发送站点监听时间&gt;2\tau$，就可以得到是否碰撞的明确结论。$2\tau$ 也即称为争用期，或碰撞窗口。所以为得到是否碰撞的明确结论，只需要$监听时间&gt;2\tau$就可以了。冲突重发发生碰撞，两个数据帧都损坏，当然需要重发。但是如果两个站点都立即重发数据帧，又会再次碰撞，两个站点发送时刻最好能够错开一些。CSMA/CD 协议使用截断二进制指数退避算法，发生碰撞的站在停止发送数据后，要推迟（退避）一个随机时间才能再发送数据。重传次数 k，$k=Min[重传次数,10]$从整数集合$[0,1,…,(2^k-1)]$中随机地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。基本退避时间一般是取为争用期。当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告。使用 CSMA/CD 协议后不能进行全双工通信而只能进行双向交替通信（半双工通信）。每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率。10BASE-T 以太网10Base-T以太网使用的是1-坚持型CSMA / CD。10BASE-T 以太网不用同轴电缆而用无屏蔽双绞线，降低了成本，还增加了一种可靠性非常高的设备，叫做集线器（hub）。正是这两个原因，使得 10BASE-T以太网拥有很低的成本和很高的可靠性，迅速在局域网中占据了统治地位。10BASE-T 以太网定义：争用期的长度为 51.2 us，而$监听时间 &gt; 2 \tau$ 便等价于$发送数据帧的时间 &gt; 2\tau$。可得：$\frac{帧长L}{10Mbps}&gt;51.2 \mu s$，即$L &gt; 512bit$。最短帧长 64 字节。帧间最小间隔为 9.6us，因为要给双方留下缓冲时间。站点到集线器的距离不超过 100m，为了保证双绞线上的信号不会出错。如果数据帧太长就会出现有的主机长时间不能发送数据，而且有的发送数据可能超出接收端的缓冲区大小，造成缓冲溢出。为避免单一主机占用信道时间过长，规定了以太网帧的数据部分最大长度为1500。网卡在主机内部，需要 10BASE-T 的网络接口板又称为通信适配器（adapter）或网络接口卡 NIC(Network Interface Card)，或“网卡”。网络适配器的重要功能：对数据进行串行/并行传输的转换编码与译码即曼彻斯特编码与译码。链路管理主要是 CSMA/CD 协议的实现。数据的封装与解封封装以太网帧。网卡的第一，第二项功能属于物理层的功能。第三项 CSMA/CD 协议的原理上文也介绍了，在此主要介绍一下以太网帧，也称 MAC 帧。网络适配器工作在数据链路层和物理层。生产网卡时，在网卡的 ROM 固化了 6 字节的 MAC 地址，因此 MAC 地址也叫做硬件地址(hardware address)或物理地址。MAC 地址唯一标识了一块网卡。MAC 地址字段是 6 字节（48 位），前三个字节（即高位 24 位），是生产厂家标识，称为组织唯一标识符，后三个字节（即低位 24 位）由厂家自行指派的产品串号，称为扩展唯一标识符，必须保证串号没有重复。网卡将上一层交下来的数据加上首部和尾部，成为以太网的帧。接收时将以太网的帧剥去首部和尾部，然后送交上一层。常用的以太网 MAC 帧格式有两种标准：DIXEthernetV2 标准和 IEEE 的 802.3 标准，最常用的 MAC 帧是以太网 V2 的格式。网卡工作要点适配器从网络层获得一个分组，加上以太网的首部和尾部，组成以太网帧，放入适配器的缓存中，准备发送。若适配器检测到信道空闲，就发送这个帧。若检测到信道忙，则继续检测并等待信道转为空闲（加上 96 比特时间），然后发送这个帧。在发送过程中继续检测信道，若一直未检测到碰撞，就顺利把这个帧成功发送完毕。若检测到碰撞，则中止数据的发送，并发送人为干扰信号。在中止发送后，适配器就执行指数退避算法，等待 r 倍 512 比特时间后，返回到步骤 2。对于检查出的无效 MAC 帧就简单地丢弃。以太网不负责重传丢弃的帧。早期以太网采用无源的总线结构。现在采用以太网交换机的星形结构成为以太网的首选拓扑。总线以太网使用 CSMA/CD 协议，以半双工方式工作。以太网交换机以全双工方式工作，不使用共享总线，没有碰撞问题，因此不使用CSMA/CD 协议。但仍然采用以太网的帧结构。网桥与交换机我们看下面一个拓扑，某学院有三个系，各自有一个以太网，三个以太网是三个独立的碰撞域，如果用集线器连成一个更大的以太网，同时也形成一个更大的碰撞域。连接的范围扩大了，但碰撞也多了，能不能只扩大范围，不扩大碰撞呢？网桥有一种网络设备，称为网桥（bridge），能只扩大范围，不扩大碰撞。网桥工作在数据链路层，其内部维护一张转发表，根据 MAC 地址转发数据帧。当网桥收到一个帧时，根据此帧的目的 MAC 地址，检索转发表，然后再转发帧到接口。我们看下面的一个拓扑图，先不考虑网桥的转发表是怎么来的，先看一下网桥 B1 和网桥 B2 的转发表的最终形态，可以看出，转发表的本质就是拓扑图的描述，推想一下，这是必然的，网桥若要正确转发数据帧，就需要知道各主机与其的位置关系。那么，这张转发表又是怎么来的呢？网桥 B1 和网桥 B2 刚上电时，其内部转发表都是空表，这时，主机 A 给主机 B 发送一数据帧，网桥 B1 的接口 1 收到这帧，网桥 B1 能判断出主机 A 在它的接口 1 侧，但判断不出主机 B 在哪侧，首先转发，把帧向网桥除接口 1 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“A 接口 1”填入转发表，网桥 B1 就学到 1 个条目。网桥 B2 收到网桥 B1 的转发帧，网桥 B2 也能判断出主机 A 在它的接口 1 侧，但判断不出主机 B 在哪侧，首先转发，把帧向网桥除接口 1 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“A 接口 1”填入转发表，网桥 B2 也学到 1 个条目。接下来，第二个数据帧是主机 F 给主机 C 发送的，网桥 B2 的接口 2 收到这帧，网桥 B2 能判断出主机 F 在它的接口 2 侧，但判断不出主机 C 在哪侧，首先转发，把帧向网桥除接口 2 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“F 接口 2”填入转发表，网桥 B2 就学到 2 个条目。网桥 B1 收到网桥 B2 的转发帧，网桥 B1 也能判断出主机 F 在它的接口 2 侧，但判断不出主机 C 在哪侧，首先转发，把帧向网桥除接口 2 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“F 接口 2”填入转发表，网桥 B1 也学到 2 个条目。第三个数据帧是主机 B 给主机 A 发送的，网桥 B1 的接口 1 收到这帧，网桥B1 能判断出主机 B 在它的接口 1 侧，由于已经学到 2 个条目，网桥 B1 由前 2个条目，知道主机 A 在接口 1 侧的，所以不转发。第二，将“B 接口 1”填入转发表，网桥 B2 就学到 3 个条目。因为网桥 1 没转发，网桥 B2 没收到任何数据帧，网桥 B2 仍维持着 2 个条目。经过一段时间，各主机发送了很多数据帧，网桥 B1 和网桥 B2 就学习到了完整的转发表。但是需要注意，在下图中三个碰撞域内是可以进行通信，但是跨碰撞域之后还是会产生碰撞。如A给D发消息时，B和C不能进行通信。交换机网桥只有 2 个接口，可是谁规定网桥只能有 2 个接口呢，网桥也可以有更多接口，这就是以太网交换机，以太网交换机（switch）实质上就是一个多接口的网桥。通常都有十几个或更多的接口。每个接口都直接与一个单台主机或另一个以太网交换机相连，工作在全双工方式。以太网交换机工作原理也是按转发表转发数据帧，工作在数据链路层，是第二层交换机，其内部的帧交换表（又称为地址表）是通过自学习算法自动地逐渐建立起来的。我们看下面的一个拓扑图，先不考虑交换机的转发表是怎么来的，先看一下交换机的转发表的最终形态，可以看出，转发表的本质就是拓扑图的描述，推想一下，这是必然的，交换机若要正确转发数据帧，就需要知道哪个接口与哪个主机相连。那么，这张转发表又是怎么来的呢？交换机启动时，其内部转发表是空表。A 先向 B 发送一帧，交换机收到帧后，先执行转发功能。查找交换表，如果没有查到，洪泛，交换机向除接口 1 以外的所有的接口广播这个帧。再执学习发功能，把这个帧的源地址 A 和接口 1 写入交换表中。当所有主机都发送过数据帧后，交换机就将交换表学完整了。考虑到可能有时要在交换机的接口更换主机，或者主机要更换其网络适配器，这就需要更改交换表中的项目。为此，在交换表中每个项目都设有一定的有效时间。过期的项目就自动被删除。以太网交换机的这种自学习方法使得以太网交换机能够即插即用，不必人工进行配置，因此非常方便。交换机工作原理是按转发表（MAC 表）转发数据帧，转发表的本质就是拓扑图的描述。要把交换机转发表的本质牢固的记住：交换机就是要知道哪个接口与哪个主机相连。MAC 表抖动与广播风暴网桥和交换机的使用可能会发生一下问题，我们以网桥举例：会发生 MAC 表抖动（flapping）的问题：就是说同一个MAC地址在一台交换机上的两个及以上接口都学习到，导致MAC地址表中关于此MAC地址与交换机的端口对应不断改变。数据帧会循环兜圈子，形成广播风暴。在拓扑图上，我们可以看到 帧F 到 网桥1 的时候将 F 转发出去，设为 F1，此时 网桥1 学习 到MACA（主机A的MAC地址）在下方接口。F1 到 F2 是 网桥2 学习到 MACA 在 上方接口，但是 帧F 到达 网桥2 的时候网桥2学习到MACA在下方接口，这便是MAC表抖动。同样的 F2 到 网桥1 的时候 网桥1 学习到 MACA 在上方接口，也会发生抖动。（注意：F、F1、F2的MAC地址一致）如果数据帧按照我们上面所述的方式运行，他们会在网桥1和网桥2之间不停的转圈。至于交换机自然也会出现上述的问题。解决的办法，就是在逻辑上将环打断，环打断就是棵树。一句话，就是将环打断生成树，简称为“生成树”。在网桥或交换机上运行生成树协议 STP（Spanning Tree Protocol）。生成树协议的要点是：不改变网络的实际拓扑，但在逻辑上则切断某些链路，使得从一台主机到所有其他主机的路径是无环路的树状结构，从而消除了兜圈子现象。无线局域网与 CSMA/CAIEEE802.11是一个有固定基础设施的无线局域网WLAN（Wireless Local Area Network）的国际标准。简单地说，802.11 就是无线以太网的标准：使用星形拓扑，其中心叫做接入点 AP(Access Point)，在 MAC 层使用 CSMA/CA 协议，802.11 无线局域网又称为 Wi-Fi（Wireless-Fidelity，意思是“无线保真度”）。以下讨论都是这种无线局域网。无线局域网最小构件是基本服务集 BSS（Basic Service Set），基本服务集里面的基站叫做接入点 AP（AccessPoint，AP 的逻辑功能等同与以太网的集线器），一个基本服务集通过接入点 AP 连接到一个主干分配系统 DS（Distribution System），然后再接入到另一个基本服务集，构成了一个扩展的服务集 ESS。无线局域网没有碰撞检测无线局域网逻辑上也是共享信道，采用的也是随机接入的思路。但是，无线局域网与有线局域网有一个重要的差异，无线局域网没有碰撞检测（Collision Detection）。“碰撞检测”要求一个站点在发送本站数据的同时，还必须不间断地检测信道，但接收到的信号强度往往会远远小于发送信号的强度，在无线局域网的设备中要实现这种功能就花费过大。隐蔽站问题，如下图，有 ABCD 四个站，但 A 只知道有 B，不知道有 CD。A 和 C 互相检测不到对方的无线信号时，都以为 B 是空闲的，都向 B 发送数据，结果发生碰撞。隐蔽站问题使“碰撞检测”失去意义。由于以上两个原因，无线局域网没有碰撞检测。为什么没有碰撞检测就成为问题了呢？因为没有碰撞检测引发了两个问题：怎么确定发出的数据帧是否发生碰撞，是否碰撞要有明确的结论，这个结论怎么下？在碰撞发生时，就没有感觉，撞了发送方也不会停止发送数据，仍发送数据，直到发送完才停止。不是“撞-停”的情况，而是“撞撞撞撞撞撞···”的情况，碰撞的损失过大。这两个问题都需要解决。先说第一个问题，是否碰撞的结论怎么下？无线网使用了停止等待协议，由接收方发送 ACK 帧来表示正确收到数据帧，否则引发超时重传。再说第二个问题，对于这个问题的解决办法，当然就是“尽量不碰撞”。无线网为了“尽量不碰撞”，设计了一个复杂的协议 CSMA/CA。注意，CSMA/CA协议只能做到“尽量少碰撞”，做不到“完全不碰撞”。第一个问题仍需解决，无线网的 CSMA/CA 替代不了无线网的停等协议。CSMA/CA 协议无线局域网没有碰撞检测，所以有线的 CSMA/CD 就被阉割为 CSMA，可不甘心，还想进一步的减少碰撞，就又加了一个 CA（Collision Avoidance 碰撞避免）功能。802.11 就使用 CSMA/CA 协议。而在使用 CSMA/CA 的同时，还增加使用停止等待协议。帧间间隔 IFS所有的站在完成发送后，必须再等待一段很短的时间（继续监听）才能发送下一帧。这段时间的通称是帧间间隔 IFS（Inter Frame Space）。SIFS，即短（Short）帧间间隔，长度为 28us，使用 SIFS 的帧类型有：ACK 帧、CTS 帧。DIFS，即分布协调功能帧间间隔，长度为 128us。DIFS 用来发送数据帧和管理帧。争用窗口（二进制指数退避）信道从忙态变为空闲时，任何一个站要发送数据帧时，不仅都必须等待一个DIFS 的间隔，而且还要进入争用窗口，各站就要执行退避算法。802.11 使用二进制指数退避算法。这样做就减少了发生碰撞的概率。但其避退算法和CSMA/CD的有区别。第i次退避就在$2^{2+i}$个时隙中随机地选择一个。这就是说，第1次退避是在8个时隙（而不是2个）中随机选择一个，而第2次退避是在16个时隙（而不是4个）中随机选择一个。 这样做的目的是减少碰撞。发送算法如下：如果某站点检测到信道空闲，会等待一个DIFS发送该帧。否则该站点选取一个随机值进行避退，并且在检测到信道忙的时候递减该值。当检测不忙的时候计数值保持不变。当计数值减为0的时候（此时信道一定为空闲），该站点发送整个数据帧并等待确认。如果发送方收到确认，发送站点知道他的帧被目的站正确接收了，如果该站点要发送另一帧它需要从第二步开始进行。如果未收到，执行回退算法，此次会在一个更大的范围里选取。需要注意，上图中的退避区间内退避算法得到的计数值不一定在减少。冻结指的就是再次检测到信道忙的时候不再减少计数值。信道预约为了更好地解决隐蔽站带来的碰撞问题，802.11 允许要发送数据的站对信道进行预约。有线与无线的对比无线局域网与有线局域网都是使用随机接入的方式，都是无法绝对避免碰撞的。在这种情况下，都需要考虑以下问题：尽量减少碰撞、是否碰撞要有明确结论、碰撞之后的事故处理。简单做一对比：无线网中碰撞造成的损失更大，就需要在减少碰撞的方面做更多的工作，精心设计了 CSMA/CA 协议，包含帧间间隔，争用窗口（二进制指数退避），信道预约三种机制，但仍无法完全避免碰撞。由于没有碰撞检测，是否碰撞的明确结论，由接收方发送 ACK 确认帧机制。碰撞事故处理是空，是因为将重发中的二进制指数退避已经融合到 CSMA/CA 协议中。802.11 局域网的 MAC 帧802.11 帧共有三种类型：控制帧、数据帧和管理帧。只简单讨论数据帧。数据帧的三大部分，MAC 首部，共 30 字节。帧的复杂性都在帧的首部。帧主体，数据部分不超过 2312 字节，通常都是小于 1500 字节。帧检验序列 FCS 是尾部，共 4 字节。802.11 数据帧最特殊的地方就是有四个地址字段。地址 4 用于自组网络（博主暂未接触）。我们在这里只讨论前三种地址。地址 1 总是帧将访问的下一个设备的地址，地址 2 总是帧离开的前一个设备的地址，如果地址 1 没有定义最后的目的地址，地址 3 就是最后的目的站点的地址，如果地址 2 没有定义原始源地址，地址 3 就是原始源站点地址。站点 A 向 B 发送数据帧，但这个数据帧必须经过 AP 转发。首先站点 A 发送数据帧到 AP1，然后 AP1 把数据帧发送给 B。举例：A-&gt;AP1 时：ARPARP（Address Resolution Protocol），根据 IP 地址查询MAC 地址。ARP 协议的工作原理如下图，有 ARP 请求（Request）和 ARP 回答（Reply）两个报文。ARP 报文封装成 Mac 帧，是 Mac 帧的负载，mac 帧类型值 0806 指示 mac 帧的数据部分是 ARP 报文。ARP 请求（Request）是广播，ARP 回答（Reply）是单播，见下图：ARP 请求报文所封装的 Mac 帧，目的 Mac 地址是 FF-FF-FF-FF-FF-FF，这 个地址是广播地址，交换机就会广播这个帧。ARP 请求报文和校园广播的大喇叭是不是很像呢？如果目的主机也在你的网络里，你用大喇叭喊它，要来它的mac 地址，就可以封装 mac 帧了。注意，ARP 直接封装为 MAC 帧，不是封装为 IP 报。从这点看，我个人更赞同将 ARP 理解为链路层协议。报文格式：RARPARP 是设备通过自己知道的IP地址来获得自己不知道的物理地址的协议。假如一个设备不知道它自己的IP地址，但是知道自己的物理地址，应该怎么办呢？RARP（逆地址解析协议）正是针对这种情况的一种协议。RARP以与ARP相反的方式工作。RARP发出要反向解析的物理地址并希望返回其对应的IP地址，应答包括由能够提供所需信息的RARP服务器发出的IP地址。虽然发送方发出的是广播信息，RARP规定只有RARP服务器能产生应答。许多网络指定多个RARP服务器，这样做既是为了平衡负载也是为了作为出现问题时的备份。网络通信分类不同主机间的数据通信可以分为三种：两个主机属于同一个网、两个主机属于相邻的两个网中、两个主机属于不相邻的两个网络中。其中第一类是链路层所解决的问题，而后两类都是网络需要解决的问题，图示如下。为了叙述方便，博主将第二类情况简称“两个网”，第三类情况简称“三个网”，但实际上“三个网”的理论可以推广到“n个网”中。传统的IP地址划分传统的IP地址划分规则中，地址由两个部分组成：网络号 + 主机号。具有相同网络号的IP地址属于同一个网络。同时网络被划分为5类：但是并不是所有的主机号都能被用来标识主机，主机号全为0的IP地址被称为网络地址，标识一个网络。主机号全为1的地址被称为广播地址，用于向某个网络的所有主机广播。例：主机 212.111.44.136 所在网络的广播地址为212.111.44.255。而对于任意一个主机若想向其所在的网络中广播都可以使用255.255.255.255。按照这个划分我们可以得到各类地址的特性：各类地址特性A类地址前1字节标识网络地址，后3字节标识主机地址每个网络最多可容纳（$2^{24} －2$）台主机从高位起，前1位为“0”，第1字节用十进制表示的取值范围为“0～127”具有A类地址特征的网络总数为126个B类地址前2字节标识网络地址，后2字节标识主机地址每个网络最多可容纳（$2^{16} －2$）台主机从高位起，前2位为“10”，第1字节用十进制表示的取值范围为“128～191”具有B类地址特征的网络总数为 $2^{14} －1$ 个C类地址前3字节标识网络地址，后1字节标识主机地址每个网络最多可容纳254台主机从高位起，前3位为“110”，第1字节用十进制表示的取值范围为“192～223”具有C类地址特征的网络总数为 $2^{21} －1$个D类地址多播通信地址（multicast address）从高位起，前4位为“1110”，第1字节用十进制表示的取值范围为“224－239”，用于标识multicast通信地址后28位用于区分不同的multicast组E类地址从高位起，前4位为“1111”，第1字节用十进制表示的取值范围为“240－255”，用于标识E类地址后28位留作它用划分子网早期的 IP 地址的设计确实不够合理。会存在如下问题：IP 地址空间的利用率有时很低。给每一个物理网络分配一个网络号会使路由表变得太大因而使网络性能变坏。两级的 IP 地址不够灵活。网络很快就被分配完了。所以从 1985 年起在 IP 地址中又增加了一个“子网号字段”，使两级的 IP 地址变成为三级的 IP 地址。但划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。其实现思路就是从主机号借用若干个比特作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个比特。CIDR划分子网后仍然没有解决IP V4的问题，1992年互联网的三大危机：B类地址耗尽路由表爆炸IP地址整体耗尽无分类域间路由选择，Classless Inter-Domain Routing，是为解决上述危机而开发的一种方案。在CIDR技术中，IP 地址由两部分组成，网络前缀 + 主机号。CIDR 还使用“斜线记法”(slash notation)，它又称为CIDR记法，即在IP地址后面加上一个斜线“/”，然后写上网络前缀所占的比特数（这个数值对应于三级编址中子网掩码中比特 1 的个数）。CIDR 将网络前缀都相同的连续的 IP 地址组成“CIDR地址块”。128.14.32.0/20 表示的地址块共有 212 个地址（因为斜线后面的 20 是网络前缀的比特数，所以主机号的比特数是 12）。这个地址块的起始地址是 128.14.32.0。在不需要指出地址块的起始地址时，也可将这样的地址块简称为“/20 地址块”。128.14.32.0/20 地址块的最小地址：128.14.32.0。128.14.32.0/20 地址块的最大地址：128.14.47.255全 0 和全 1 的主机号地址一般不使用。路由聚合一个 CIDR 地址块可以表示很多地址，这种地址的聚合常称为路由聚合，它使得路由表中的一个项目可以表示很多个（例如上千个）原来传统分类地址的路由，减少了路由器之间的路由信息交换。路由聚合也称为构成超网。（super netting）。这个 ISP 共有 6 个 C 类网络。如果不采用 CIDR 技术，则在与该 ISP 的路由器交换路由信息的每一个路由器的路由表中，就需要有 64 个项目。但采用地址聚合后，只需用路由聚合后的 1 个项目 206.0.64.0/18 就能找到该 ISP。 需要注意的是若是因特网中某路由器想标识该ISP，只需要记录206.0.64.0/18，但是对于ISP内的路由器还是会将各子地址块的网络地址记录。最长前缀匹配使用 CIDR 时，路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。应当从匹配结果中选择具有最长网络前缀的路由：最长前缀匹配（longest-prefix matching）。网络前缀越长，其地址块就越小，因而路由就越具体。最长前缀匹配又称为最长匹配或最佳匹配。网关如果把计算机网络与快递网络做类比，假设东北大学是一个网络，西南大学是一个网络，东北大学想向西南大学寄点东西那么它需要通过自己学校的驿站寄到西南大学的驿站。网络之间进行通信的时候也需要有一个这种“驿站”。这便是网关。默认网关就是为主机转发分组的路由器网络接口，就是主机的第一跳路由器，网关就是你邮信时需要找到的校园邮筒的地址，即默认网关是在网关中选一个。主机 H1 的默认网关是路由器的 E0 接口。“两个网”时，需要正确配置网关。网关是主机的第一跳路由器。举例：假设主机 H2 的 E0 接口 IP 地址 100.16.0.1，掩码 255.255.0.0，E1 接口 IP 地址 100.17.0.1，掩码 255.255.0.0：主机 H1 本地连接 IP 地址 100.16.0.2，掩码 255.255.0.0，默认网关 100.16.0.1。主机 H3 的默认网关是什么呢？100.16.0.1。主机 H5 的默认网关又是什么？是100.17.0.1。在“多个网”时，多个网络如何互联？我们看下面的网络拓扑图，这是 3 个路由器连接了 4 个网络。假设网 1 内部有一个主机 H1，网 1 内部只有一个路由器 R1，因此默认网关只能设为 R1 的 15.0.0.4，再配置好 IP 地址，就可以与外网通信了。假设网 2 内部有一个主机 H3，在网 2 内有两个路由器 R1 和 R2，可以任选一个做默认网关，假设选 R2，默认网关设为 20.0.0.9，再配置好 IP 地址，就可以与外网通信了。再讨论如何配置路由器。路由器不傻，只要配置好路由器接口的 IP 地址，路由器会从接口的 IP 地址计算出网络地址，也就是说路由器能看清自己身边的网络。至于路由器是怎么看到的，在网络层-网络构建中会解释。数据转发之前说了这么多都是在做铺垫，其实主要想介绍的一点是路由器是如何转发不同网络中的数据包。算法如下：从收到的分组的首部提取目的 IP 地址 D。先用各网络的子网掩码和 D 逐位相“与”，看是否和相应的网络地址匹配。若匹配，则将分组直接交付。否则就是间接交付，执行3。若路由表中有目的地址为 D 的特定主机路由，则将分组传送给指明的下一跳路由器；否则，执行4。对路由表中的每一行的子网掩码和 D 逐位相“与”，若其结果与该行的目的网络地址匹配，则将分组传送给该行指明的下一跳路由器；否则，执行5。若路由表中有一个默认路由，则将分组传送给路由表中所指明的默认路由器；否则，执行6。报告转发分组出错。R1的路由表：目的网络地址子网掩码下一跳128.30.33.0255.255.255.128接口0128.30.33.128255.255.255.128接口1128.30.36.0255.255.255.0R2R2的路由表：目的网络地址子网掩码下一跳128.30.33.0255.255.255.128R1128.30.33.128255.255.255.128接口0128.30.36.0255.255.255.0接口1在上图中，若H1（128.30.33.13）想给H3（128.30.36.12）发送数据，我们来分析一下具体的过程：主机 H1 首先将本子网的子网掩码 255.255.255.128与分组的 IP 地址 128.30.36.12 逐位相“与”（AND 操作）。即255.255.255.128 AND 128.30.36.12 得到 128.30.36.0，发现不等于128.30.33.0，所以他要将数据报发送到它的默认网关（128.30.33.1）上。R1收到这个地址后，会遍历所有的子网掩码，进行按位与后再和对应的网络地址做比对。可以得到转发给R2计算过程如下：255.255.255.128 AND 128.30.36.12 = 128.30.36.0 不等于 128.30.33.0255.255.255.128 AND 128.30.36.12 = 128.30.36.0 不等于 128.30.33.128、255.255.255.0 AND 128.30.36.12 等于 128.30.36.0R1收到这个地址后，会遍历所有的子网掩码，进行按位与后再和对应的网络地址做比对。可以得到转发给接口1。然后便是链路层需要解决的问题。ARP深入只要主机或路由器要和本网络上的另一个已知 IP 地址的主机或路由器进行通信，ARP 协议就会自动地将该 IP 地址解析为链路层所需要的硬件地址。可以分为四种情况：发送方是主机，要把IP数据报发送到本网络上的另一个主机。这时用 ARP 找到目的主机的硬件地址。发送方是主机，要把 IP 数据报发送到另一个网络上的一个主机。这时用 ARP 找到本网络上的一个路由器的硬件地址。剩下的工作由这个路由器来完成。发送方是路由器，要把 IP 数据报转发到本网络上的一个主机。这时用 ARP 找到目的主机的硬件地址。发送方是路由器，要把 IP 数据报转发到另一个网络上的一个主机。这时用 ARP 找到本网络上的一个路由器的硬件地址。剩下的工作由这个路由器来完成。IP数据报的格式版本：占 4 位，指 IP 协议的版本目前的 IP 协议版本号为 4 （即 IPv4）。首部长度：占 4 位，可表示的最大数值是 15 个单位（一个单位为 4 字节）因此 IP 的首部长度的最大值是 60 字节。区分服务：占 8 位，用来获得更好的服务在旧标准中叫做服务类型，但实际上一直未被使用过。1998 年这个字段改名为区分服务。只有在使用区分服务（DiffServ）时，这个字段才起作用。在一般的情况下都不使用这个字段。总长度——占 16 位，指首部和数据之和的长度，单位为字节，因此数据报的最大长度为 65535 字节。总长度必须不超过最大传送单元 MTU。标识（identification）：占 16 位，它是一个计数器，用来产生数据报的标识。标志（flag）：占 3 位，目前只有前两位有意义。标志字段的最低位是 MF（More Fragment）。MF = 1 表示后面“还有分片”。MF = 0 表示最后一个分片。标志字段中间的一位是 DF（Don’t Fragment）。只有当 DF=0 时才允许分片。片偏移(13 位)指出：较长的分组在分片后某片在原分组中的相对位置。片偏移以 8 个字节为偏移单位。生存时间（8 位）记为 TTL（Time To Live）：数据报在网络中可通过的路由器数的最大值。协议（8 位）：指出此数据报携带的数据使用何种协议，即运输层协议。首部检验和（16 位）字段只检验数据报的首部不检验数据部分。源地址和目的地址都各占 4 字节。NAT私有地址在现在的网络中，IP地址分为公网IP地址和私有IP地址。公网IP是在Internet使用的IP地址，而私有IP地址则是在局域网中使用的IP地址。私有IP地址是一段保留的IP地址。只使用在局域网中，无法在Internet上使用。A类私有地址：10.0.0.0～10.255.255.255B类私有地址：172.16.0.0～172.31.255.255C类私有地址：192.168.0.0～192.168.255.255这些地址可以在任何组织或企业内部使用，和其他Internet地址的区别就是，仅能在内部使用，不能作为全球路由地址。这就是说，出了组织的管理范围这些地址就不再有意义，无论是作为源地址，还是目的地址。对于一个封闭的组织，如果其网络不连接到Internet，就可以使用这些地址而不用向 IANA（The Internet Assigned Numbers Authority，互联网数字分配机构，是负责协调一些使Internet正常运作的机构） 提出申请，而在内部的路由管理和报文传递方式与其他网络没有差异。对于有Internet访问需求而内部又使用私有地址的网络，就要在组织的出口位置部署NAT网关，在报文离开私网进入Internet时，将源IP替换为公网地址，通常是出口设备的接口地址。一个对外的访问请求在到达目标以后，表现为由本组织出口设备发起，因此被请求的服务端可将响应由Internet发回出口网关。出口网关再将目的地址替换为私网的源主机地址，发回内部。这样一次由私网主机向公网服务端的请求和响应就在通信两端均无感知的情况下完成了。依据这种模型，数量庞大的内网主机就不再需要公有IP地址了。自治系统Autonomous System，AS。每个AS由一组通常处在相同管理控制下的路由器组成。一个ISP中的路由器以及连接他们的线路可以构成一个AS，一个ISP也可以将他们的网络划分成多个AS。每个AS由一个唯一的ASN来标识。所以在构建网络的时候，我们需要对 AS 内的网络和 AS 之外的网络进行区分。这两个统称为路由协议。内部网关协议Interior Gateway Protocol （IGP），用于自治系统（AS）内部的路由交换也叫做域内路由选择（intradomain routing），如 RIP 和 OSPF 协议外部网关协议Exterior Gateway Protocol （EGP），用于不同自治系统（AS）之间的路由交换，也叫做域间路由选择（interdomain routing），目前使用最多的是 BGP-4。路由选择算法分类常用的分类是：每个路由器知道的是全局的信息还是分散的信息？全局的所有的路由器具有完整的拓扑和链路费用信息“链路状态(L-S)”算法应用于RIP协议分散的路由器只知道物理连接的邻居和到邻居的链路费用迭代的计算过程，与邻居交换信息“距离向量(D-V)”算法应用于OSPF协议RIP协议基于距离向量的分布式路由选择协议，规定：“距离”为到目的网络所经过的路由器数。从一路由器到直接连接的网络的距离定义为 1。RIP允许一个通路最多包含15个路由器，多于15个路由器时不可达。RIP不能在两个网络之间同时使用多条路由，它选择一个具有最少路由器的路由，具有相同路径长度的路规定先入为主。特点仅和相邻路由器交换信息。交换的信息是当前本路由器所知道的全部信息，即自己的路由表。按固定的时间间隔交换路由信息，例如，每隔 30 秒。距离向量算法收到相邻路由器（其地址为 X）的一个 RIP 报文：先修改此 RIP 报文中的所有项目：将“下一跳”字段中的地址都改为 X，并将所有的“距离”字段的值加 1。对修改后的 RIP 报文中的每一个项目，重复以下步骤：若项目中的目的网络不在路由表中，则将该项目加到路由表中。否则若下一跳字段给出的路由器地址是同样的，则将收到的项目替换原路由表中的项目否则若收到项目中的距离小于路由表中的距离，则进行更新否则，什么也不做。若 3 分钟还没有收到相邻路由器的更新路由表，则将此相邻路由器记为不可达的路由器，即将距离置为16（距离为16表示不可达）。返回。举例一开始，各路由表只有到相邻路由器的信息：路由器 B 收到相邻路由器 A 和 C 的路由表：修改 A 的路由表，将 RIP 报文中的所有项目下一跳的字段都改成 A ，距离增加 1。目的网络距离下一跳12A23A33A修改 C 的路由表，将 RIP 报文中的所有项目下一跳的字段都改成 C ，距离增加 1。目的网络距离下一跳42C62C将 B 原来不可达的项目加入到B的路由表中，加入后B的路由表：目的网络距离下一跳31-41-12A22A62C修改 收到的目的网络原本在B路由器中且下一跳的字段和原B路由表项目中的字段一致 的项目，发现不用修改。修改 B 可达，A和C也可达的项目，发现收到项目中的距离小于路由表中的距离，则进行更新，否则不更新。则修改后B的路由表是：目的网络距离下一跳31-41-12A22A62CRIP 协议的优缺点RIP 存在的一个问题是当网络出现故障时，要经过比较长的时间才能将此信息传送到所有的路由器。即好消息传播得快，而坏消息传播得慢。RIP 协议最大的优点就是实现简单，开销较小。RIP 限制了网络的规模，它能使用的最大距离为 15（16 表示不可达）。路由器之间交换的路由信息是路由器中的完整路由表，因而随着网络规模的扩大，开销也就增加。好消息传播得快，坏消息传播得慢在正常情况下，R1中项目表示到网1距离为1，R2中项目表示到网1距离为2。R2收到 R1 的项目后修改R2的项目为：1 2 R1，R2发现到网1的下一跳为R1，和原路由表一致，修改原路由表该项目为：1 2 R1。R1 说：“我到网 1 的距离是 16 （表示无法到达），是直接交付”。但 R2 在收到 R1 的更新报文之前，还发送原来的报文，因为这时 R2 并不知道 R1 出了故障。我们列出一个网1出现故障后的交换表：R1R2正常1 1 -1 2 R1故障1 16 -1 2 R1第1次1 3 R21 16 R1第2次1 16 R21 4 R1第3次1 5 R21 16 R1………这样不断更新下去，直到 R1 和 R2 到网 1 的距离都增大到 16 时，R1 和 R2 才知道网1是不可达的。RIP协议的位置RIP 协议使用运输层的用户数据报 UDP进行传送（使用 UDP 的端口 520）。因此 RIP 协议的位置应当在应用层。但转发 IP 数据报的过程是在网络层完成的。这时有一个困惑，RIP是网络层协议，可是为什么用UDP封装？因为路由器虽然是网络层设备，但并不代表他只具备物理层、链路层、网络层功能，他还具备一些应用层的功能，当遇到RIP报文这类应用层的协议，他也能够解封。然后读取RIP报文中的下一跳路由。RIP2 协议的报文格式RIP2由RIP而来，属于RIP协议的补充协议，提升装载的信息量，增加安全性。OSPF协议开放最短路径优先协议OSPF （Open Shortest Path First）。RIP 协议的问题以跳数评估的路由并非最优路径最大跳数16导致网络尺度小收敛速度慢更新发送全部路由表浪费网络资源要点向本自治系统中所有路由器发送信息，这里使用的方法是洪泛法。发送的信息就是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息。“链路状态”就是说明本路由器都和哪些路由器相邻，以及该链路的“度量”（metric）。只有当链路状态发生变化时，路由器才用洪泛法向所有路由器发送此信息。链路状态数据库由于各路由器之间频繁地交换链路状态信息，因此所有的路由器最终都能建立一个链路状态数据库。这个数据库实际上就是全网的拓扑结构图，它在全网范围内是一致的（这称为链路状态数据库的同步）。OSPF 的链路状态数据库能较快地进行更新，使各个路由器能及时更新其路由表。OSPF 的更新过程收敛得快是其重要优点。Dijkstra 算法| | 1 | 2 | 3 | 4 | 5 | 6 || :—–: | :–: | :—: | :–: | :—: | :—: | :—: || 初始化1 | 0 | 2 | 6 | 1 | +无穷 | +无穷 || 第1步 | 0 | 2 | 4 | 1 | 2 | +无穷 || 第2步 | 0 | 2 | 3 | 1 | 2 | 4 || 第3步 | 0 | 2 | 3 | 1 | 2 | 6 |路径：1 -&gt; 4 -&gt; 5 -&gt; 2 -&gt; 3 -&gt; 6OSPF 的区域(area)为了使 OSPF 能够用于规模很大的网络，OSPF 将一个自治系统再划分为若干个更小的范围，叫作区域。每一个区域都有一个 32 bit 的区域标识符（用点分十进制表示）。区域也不能太大，在一个区域内的路由器最好不超过 200 个。 同时 OSPF 划分为两种不同的区域：划分区域的好处就是将利用洪泛法交换链路状态信息的范围局限于每一个区域而不是整个的自治系统，这就减少了整个网络上的通信量。在一个区域内部的路由器只知道本区域的完整网络拓扑，而不知道其他区域的网络拓扑的情况。OSPF 使用层次结构的区域划分。在上层的区域叫作主干区域(backbone area)。主干区域的标识符规定为0.0.0.0。主干区域的作用是用来连通其他在下层的区域。 图中的R3、R4、R6、R7是主干路由器。OSPF 载体OSPF 不用 UDP 而是直接用 IP 数据报传送。OSPF 构成的数据报很短。这样做可减少路由信息的通信量。数据报很短的另一好处是可以不必将长的数据报分片传送。分片传送的数据报只要丢失一个，就无法组装成原来的数据报，而整个数据报就必须重传。OSPF 的五种分组类型类型1，问候（Hello）分组。类型2，数据库描述（Database Description）分组。类型3，链路状态请求（Link State Request）分组。类型4，链路状态更新（Link State Update）分组，用洪泛法对全网更新链路状态。类型5，链路状态确认（Link State Acknowledgment）分组。BGP协议BGP 是不同自治系统的路由器之间交换路由信息的协议。 BGP 较新版本是 2006 年 1 月发表的 BGP-4，可以将 BGP-4 简写为 BGP。每一个自治系统的管理员要选择至少一个路由器作为该自治系统的“BGP 发言人” 。一般说来，两个 BGP 发言人都是通过一个共享网络连接在一起的，而 BGP 发言人往往就是 BGP 边界路由器，但也可以不是 BGP 边界路由器。一个 BGP 发言人与其他自治系统中的 BGP 发言人要交换路由信息，就要先建立 TCP 连接，然后在此连接上交换 BGP 报文以建立 BGP 会话（session），利用 BGP 会话交换路由信息。使用 TCP 连接能提供可靠的服务，也简化了路由选择协议。使用 TCP 连接交换路由信息的两个 BGP 发言人，彼此成为对方的邻站或对等站。BGP报文打开（Open）报文，用来与相邻的另一个BGP发言人建立关系。更新（Update）报文，用来发送某一路由的信息，以及列出要撤消的多条路由。保活（Keepalive）报文，用来确认打开报文和周期性地证实邻站关系。通知（Notificaton）报文，用来发送检测到的差错。ICMPIP协议只有一种报文格式：IP报文功能：传递上层数据缺乏：应付可能出现差错的能力网际控制报文协议 ICMP (Internet Control Message Protocol)IP的辅助协议为IP提供差错报告机制同时为其它层（TCP/UDP、应用）提供辅助功能ICMP 报文的种类有两种，即 ICMP 差错报告报文和 ICMP 询问报文。格式差错报告报文终点不可达源点抑制(Source quench)时间超过参数问题改变路由（重定向）(Redirect)询问报文回送请求和回答报文时间戳请求和回答报文PINGPing发送一个ICMP 报文；回声请求消息给目的地并报告是否收到所希望的ICMPecho （ICMP回声应答）。它是用来检查网络是否通畅或者网络连接速度的命令。网络层完成了“主机到主机”的通信，但主机间的通信并不是最后的结果，产生和消耗数据的并不是主机，而是某项网络应用，真正通信的是两个应用“进程”。“进程”就是“正在进行的程序”。而“进程到进程的通信”正是传输层的功能。但这不是全部，更重要的，传输层的任务是为从源主机到目的主机提供可靠的，低价格的数据传输。可靠性，低价格是两个关键词，或者为了更明显一些，可以有第三个关键词，拥塞控制。其实可靠性与拥塞控制本质上是一个词。可靠性、低价格、拥塞控制使传输层成为整个协议体系的核心与灵魂。如果没有传输层，就没有可靠的数据传输，网络层也将失去意义。传输服务传输层的服务与网络层服务很相似，为何要分为两个层呢？答案就是“可靠性”。网络层并不提供可靠性，路由器可以丢失分组，用户无法控制中间的网络设备，用户不能选择性能更好的路由器或质量更好的数据链路，那么如何保证数据可以正常传输呢？添加一个传输层，传输层应该检测到各种问题，并采取补救措施，从而提供可靠的数据传输。传输层就是要弥补网络层技术、设计的各种缺陷。用个不恰当的比方，传输层就是“填坑的”，将网络层与应用层之间的坑、沟填平。传输层服务前，是遍布坑、沟的公路，传输层服务后，是平坦的公路。再谈谈“低价格”这个关键词。如果在设计网络时，由网络层提供可靠性，会如何呢？如果由网络层提供可靠性，就要在中间网络的千万个路由器上添加可靠性的功能，系统的复杂性会提高数据传输的成本，那就与电话通信网的成本差别不大。可靠性由通信网提供还是由端计算机提供，二者的价格差别可太大了。可靠性由端计算机提供，才有了低成本的数据传输，低价格才是计算机网络将其他通信技术淘汰的本质。要低价格，可靠性就要放置在端计算机内部。显然放置在操作系统内部更加合理，直接由操作系统对应用程序提供可靠的数据传输服务，是非常自然的选择。传输层封装在端计算机的操作系统内，用个不恰当的比方，如同封装在房间内的电线，在装修时已经埋好了，只是提供了许多插座，这个插座接洗衣机，那个插座接冰箱，那个插座接电视，等等。对计算机网络来说，“可靠性”的关键是什么？或者反过来，造成数据传输不可靠的最主要的原因是什么？是网络拥塞，当网络拥塞时，路由器就会丢弃数据包。传输层需要具有“调控网络”的功能。我们说，传输层在端主机内，而端主机是无法控制中间的网络设备的，“调控网络”从何谈起呢？后面会说到网络拥塞如同现实生活的堵车，根本的解决办法是不让车上路，所有的车都不上路，路就不堵了。“调控网络”是说所有端计算机内的传输层要能感知到网络的状态，能感知到当前通信网的态势，网络拥塞，就少发数据，网络通畅，就多发数据。尤其是网络拥塞时，要少发数据，让中间网络尽快恢复传输能力。端口最常用的进程到进程的通信方式是客户机与服务器模式。我们这里说的客户机与服务器都是指一个应用进程，而不是机器。客户机，请求服务，主动发起呼叫的进程。服务器，提供服务，被动等待的进程。总是客户机呼叫服务器，绝不可能是服务器呼叫客户机。在生活中，总是你给消防队打电话，绝不可能是消防队给你打电话。某一项服务，就是一项网络应用。端主机完全可以同时有多项网络应用，如同时打开浏览器浏览网页，打开 QQ 聊天。标识不同的网络应用进程的标识符称为协议端口号 (protocol port number)，简称为端口 (port)。端口是一个 16 位的标识符。客户机用一个临时端口号定义自己。客户机可以随机选择一个端口号使用。服务器也需要用一个端口号来定义自己，但是服务器不能随机选用一个端口号。为什么呢？假设消防队随机使用一个电话号码，当发生火灾时，人们向哪打电话呢？服务器必须使用一个预先定义的，众所周知的端口号，就如同消防队使用119，急救中心使用 120 一样。端口范围划分熟知端口，端口号范围是 0~1023。由 ICANN 分配和控制。注册端口，端口号范围是 1024~49151，ICANN 不分配也不控制，但必须在 ICANN 登记以防止重复。通常为没有熟知端口号的应用程序使用的。动态端口，端口号范围是 49152~65535，这范围的端口号即不用指派，也不需注册，可以由任何进程使用。最初的建议是客户机使用的临时端口号应该在这个范围，但许多程序员可没有遵守这个建议。注意：端口号只具有本地意义，只是为了标志本计算机应用层中的各进程。复用与分用某台主机中可能有多个应用进程同时分别和网络上的许多其他主机中的某个或多个应用进程通信。这表明运输层有一个很重要的功能：复用（multiplexing）和分用（demultiplexing）。当一个实体接受来自多个源的输入时，就称为复用（multiplexing） （多到一）。而当一个实体将数据交到多个源时，就称为分用（demultiplexing）（一到多）。UDP用户数据报协议 UDP（User Datagram Protocol）是无连接不可靠的传输层协议。它只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和校验和的功能。校验和功能是可选的，如果不选择校验功能，就全填入 0。UDP 缺点是不可靠，优点是开销小。发送数据之前不需要建立连接。这对某些实时应用是很重要的。网络出现拥塞时，不调整，不降低发送速率。UDP 用户数据报首部如下图：源端口和目的端口号，各占 16 位，标志应用进程，总长度为 UDP 的总长度，UDP 首部加 UDP 数据的长度，校验和计算下面介绍。校验和UDP 的校验和功能是可选的，如果不选择校验和功能，就全填入 0，否则，计算校验和。计算时包含三个部分，伪首部，首部，数据部分，注意计算校验和是包含了数据部分的。如下图：计算 UDP 检验和的例子二进制反码计算规则：0 + 0 = 10；0 + 1 = 1； 1 + 1 = 0TCPTCP格式一个 TCP 报文段分为首部和数据两部分，首部的前 20 个字节是固定的，后面有 4n 字节是根据需要而增加的选项 (n 是整数)。因此 TCP 首部的最小长度是 20 字节。而 TCP 的全部功能都体现在它首部中各字段的作用：源端口和目的端口字段：各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。序号字段：占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。确认号字段：占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。窗口字段：占 2 字节，用来让对方设置发送窗口的依据，单位为字节。数据偏移（即首部长度）：占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。保留：占 6 位，保留为今后使用。控制：占 6 位，定义了 6 种不同的控制位或标志。在同一时间可设置位或多位标志位。分别是 URG、ACK、PSH、RST、SYN、FIN。检验和：占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。紧急指针字段：占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。选项字段：长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。”差错控制TCP 是可靠的传输层协议。就是说 TCP 向应用层交付的是按顺序的，没有差错的，没有丢失的数据。TCP 通过 3 种机制进行差错控制：检验和，确认与超时。检验和TCP 规定每个报文段都必须使用 16 位的检验和。TCP 检验计算时包含三个部分，伪首部，首部，数据部分，注意计算校验和是包含了数据部分的。计算方 法同 UDP 一样。确认和超时TCP 采用确认的方式来证实收到报文。接收方可以在合适的时候单独发送确 认报文，也可以在自己有数据要发送时把确认信息捎带上。TCP 使用肯定的累积确认。先解释“肯定”，ACK 就是“肯定”的意思。就是只在正确的情况下才发送确认。当发生丢弃，丢失，重复这些错误时，就什么也不做。“报喜不报忧”，注意，当发生错误时，不发送确认。这样，对方收不到确认，重传定时器就会超时，触发重传。 再解释“累积”，就是表示的累积效果，确认号字段值表示的是希望接收的下一个字节的序号。例如确认号为 301，是表示 301 号字节之前的数据都正确接收了，希望接收的下一个字节是 301 号字节。重传定时器差错控制的核心就是重传机制。TCP 使用确认-超时重传机制。具体说，TCP 每发送一个报文段，就设置一个重传定时器，当重传时间到，但还没有收到确认，就要重传这一报文段。重传定时器的值怎么设是 TCP 最复杂的事情之一。后面我们会解释原因，现在我们只要知道，重传定时器的值的估算要尽可能的准确，定时器的值不像加班费，越大越好，也不是越小越好，是越准确越好。首先，很自然的想法，重传定时器的值应该是“一个往返时延再多一点”。“一个往返时延”如何确定？举例，8 点测了一次往返时延，8:05 又测一次，间隔 5 分钟，测了 10 次，往返时延应该用哪次测量的值呢？显然，用哪一次的也不合适，应该是某种“平均值”。下面介绍的这个算法的目标是使估计值更加“平滑”，我们将往返时延估计值记作 RTTs。这个算法中，历史的累积效应权重更大一些，占比 7/8，新测量值的权重小，占比1/8。下图是 RTT 样本与 RTT 估计值示意图，蓝色的是各次的测量值，红色的是RTT 的估计值。说完“一个往返时延”，再说“多一点”。这一点Δ怎么算呢？取样本值到平滑线的距离为Δ，|RTTs-新样本|，显然，每个样本点到平滑线都有一个Δ，就是Δ1，Δ2，Δ3，Δ4，···，取哪个Δ合适呢？显然，用哪一个Δ也不合适，还应该是某种“平均值”。算法也是给出一种“平滑平均值”，记作 RTTD。这个算法中，历史的累积效应权重更大一些，占比 3/4，新测量值的权重小，占比 1/4。总的RTO计算公式：$RTO=RTTs + 4 \ast RTTD$流量控制TCP 是全双工通信，TCP 为每个方向的数据传输使用两个窗口，发送窗口和接收窗口。双向通信就有四个窗口，为简化讨论，只讨论单向数据传输。发送窗口下图是一发送窗口例子，TCP 中的窗口以字节为单位。TCP 的传输实际是一个一个的报文段，但控制窗口的变量是以字节为单位。TCP 中只使用一个重传计时器。为方便说明，字节编号取得很小。发送窗口的后沿（left wall）只能向前移动（关闭 closes），前沿可向前移动（opens），也可收缩（shrinks），但 TCP 标准不赞成收缩。接收窗口下图是一接收窗口例子。实际上，接收窗口永远不会收缩。通常，接收方 TCP 等待应用进程来取数据。就是说，分配给接收方的缓存可能包含已接收且确认的数据字节，它们在正等待应用进程将它们拉走。接收窗口总是小于缓冲区的大小。接收窗口通常称为 rwnd，rwnd = 缓冲区大小 – 正在等待被拉走的字节数，如下图：rwnd = 40 。窗口如何滑动TCP 通过滑动窗口机制实现流量控制。我们先忽略差错、拥塞等其他因素，且只简化讨论一个方向的数据传输。下图描述了一个例子，总是客户端发送数据，服务器确认。客户端是发送方，发送窗口，使用序号字段，服务器是接收方，接收窗口，使用确认号和窗口两个字段，窗口字段值是 rwnd 的值。假设发送方的缓冲区与接收方的缓冲区大小都是 800 字节。第 1 个报文段，客户端发给服务器，SYN 报文段，seq=100。三次握手建立连接的第一个报文，请求连接，并通告初始序号是 seq=100。第 2 个报文段，服务器发给客户端，SYN+ACK 报文段，ack=101，rwnd=800。三次握手建立连接的第二个报文，窗口值通告 rwnd=800。第3个报文段，客户端发给服务器，ACK报文段。客户端通告rwnd=2000，表示客户端的接收缓冲区的大小，我们忽略这个值，只讨论单向传输。第 4 个报文段，客户端发给服务器，数据报文段，seq=101。客户端发送一数据报文段，携带 200 字节数据，数据字节编号 101~300，序号字段填写第 1个数据字节的编号 seq=101。发送窗口前沿在 901，后沿在 101，显示已发送 200字节数据，正等待确认。第 5 个报文段，服务器发给客户端，ACK 报文段，ack=301，rwnd=600。服务器收到 101~300 号字节，共 200 字节数据，接收窗口调整，后沿向前滑动 200 字节，表示已收好 200 字节。向客户端发送 ACK 确认，确认字段值 ack=301，表示 301 号之前数据收好，下一个希望接收的字节是 301 号字节。注意，此刻 200 字节数据仍在接收缓冲区内，服务器的应用进程还没将它们拉走，接收窗口的大小 rwnd= 800 – 200 = 600。报文段中通告的窗口值为 600。第 6 个报文段，客户端发给服务器，数据报文段，seq=301。客户端收到确认 ack=301，rwnd=600。客户端知道服务器已经收好 101~300 号字节，就可以删除这些数据，发送窗口调整，后沿向前滑动 200 字节，至01 处。但前沿不能向前滑动，因为现在接收方通告的 rwnd=600，前沿=301+600=901。客户端发送数据报文段，携带 300 字节数据，数据字节编号 301~600，序号字段eq=301。第 7 个报文段，服务器发给客户端，ACK 报文段，ack=601，rwnd=400。服务器收到第二次的 301~600 号字节数据，共 300 字节数据。接收窗口调整，后沿向前滑动 300 字节，至 601 处。因 TCP 使用累积确认，向客户端发送的确认为 ack=601，表示 601 号之前所有数据收好，下一个希望接收的字节是 601 号字节。注意，此刻 200+300=500 字节数据仍在接收缓冲区内。这时，服务器的应用进程拉走 100 字节数据，接收缓冲区的 101~200 号字节空间被释放，但 201~601的 400 字节数据滞留在接收缓冲区内。接收窗口的大小 wnd= 800 – 400 = 400。通告窗口值为 rwnd=400。客户端收到确认 ack=601，rwnd=400。客户端知道服务器已经收好 601 号之前的数据，就可以删除这些数据，发送窗口调整，后沿向前滑动至 601 处。因为现在接收方通告的 rwnd=400，前沿=601+400=1001。前沿向前滑动至 1001 处。第 8 个报文段，服务器发给客户端，ACK 报文段，ack=601，rwnd=600。服务器的应用进程又拉走 200 字节数据，接收缓冲区的 201~400 号字节空间被释放，但 401~601 的 200 字节数据仍滞留在接收缓冲区内。接收窗口的大小 rwnd= 800 – 200 = 600。通告窗口值为 400。对于确认来说，服务器现在收好的是 601 号字节之前的数据，确认为 ack=601，表示希望接收的下一个字节是 601 号字节。客户端收到确认 ack=601，wnd=600。客户端知道服务器已经收好 601 号之前的数据，发送窗口的后沿就在 601 处，不需滑动。因为现在接收方通告的rwnd=600，前沿=601+600=1201。前沿向前滑动至 1201 处。糊涂窗口综合症假如 TCP 发送的报文段只含有 1 个字节的数据，那么意味着为发送 1 字节的数据，而发送了 41 个字节的报文段，20 个字节的 TCP 首部和 20 个字节的 IP首部。此时的效率是 1/41。这一现象称为糊涂窗口综合症（Silly Window Syndrome）。糊涂窗口综合症是怎样产生的呢?由发送方产生的糊涂窗口综合症（Syndrome Created by the Sender）如果发送方 TCP 正在为一个产生数据很缓慢的应用程序服务，例如一次产生 1 字节数据，就有可能产生糊涂窗口综合症。解决方法是使用 Nagle 算法。Nagle 算法发送方 TCP 把它从应用进程收到的第一块数据发送出去，即使只有 1 字节。在发送一个报文段后，发送方 TCP 就在输出缓存中累积数据并等待，直至收到接收方发来的确认，或者已积累了足够的数据已达到报文段的最大长度时，就立即发送一个报文段。重复步骤 2。Nagle 算法之巧妙，在于其巧妙地平衡了应用程序产生数据速度和网络传输速度。如果应用程序比网络速度快，报文段就大（最大报文段长度），如果应用程序比网络速度慢，报文段就小。由接收方产生的糊涂窗口综合症（Syndrome Created by the Receiver）如果接收方 TCP 正在为一个消耗数据很缓慢的应用程序服务，例如一次消耗 1 字节数据，接收方每次发送 rwnd=1 的通告，就有可能产生糊涂窗口综合症。解决方法的是推迟确认。报文到达时，不立即发送确认，接收方等待一段时间，直到输入缓存有足够的空间（或者接收缓存已有一个最长报文段的空间，或者接收缓存已有一半空闲的空间），就发送确认报文。但推迟确认不能超过 500ms。拥塞控制拥塞控制是 TCP 协议中最重要的一部分。理解 TCP 的拥塞控制，关键在于真正理解网络拥塞这一现象，理解了拥塞，以后的内容都会顺理成章的很好理解。拥塞概述两个主机，通过中间的一个传输网，连接在一起。正是因为中间有网络，就有了网络拥塞问题。谈网络拥塞之前，先回忆一下路由器的原理。网络层的路由器是一种“尽力而为”的机制。当超过路由器的能力时，路由器就将会丢弃数据报。假设路由器每秒能转发 1000 个数据报，此刻来了 1200 个数据报，路由器就将后 200 个数据报丢弃。注意：当没有超过路由器的负载能力时，路由器是不会丢弃数据报的。换一句话说，就是某个路由节点拥塞了，才会丢弃数据报。怎么解决拥堵呢？很明显有两种方案，用公路网来打比方就是增加路的数量和减少驶入公路网的车。从协议的角度考虑，自然是做不到增加路的数量，所以我们就要控制发送到网络中的数据量。传输网络当网络拥塞时，如同城市交通堵塞，南城的人去不了北城，北城的人一样也去不了南城，路都堵死了，谁也走不了。也就是说，拥塞时，网络外围的所有主机，发送的数据包都会被丢掉，所以一定不会有返回的 ACK 确认，超时定时器一定会闹响。也就是说，网络拥塞时，所有主机都会超时。这样问题就解决了，简单归纳为一句话，超时就表示网络拥塞。超时就表示网络全拥塞。因为 TCP 协议中以超时做为网络拥塞的判断依据，重传定时器的值需要估算合适，这很重要。值估算小了，实际网络不拥塞，确产生了超时重传，误判为拥塞，就不能充分使用网络的传输能力。值估算大了，实际网络已经拥塞，确没有产生超时重传，误判为通畅，就会使拥塞更加恶化，最终通信崩溃。在日常的生活中，城市的交通堵塞一定是渐渐堵死的，绝无可能在前一分钟，全城都是通畅的，后一分钟，全城所有的道路都堵死。总是开始时某些路段堵死，然后慢慢扩大，最后全部堵死。如果在某些路段堵死的时候，就开始疏导，有可能不会演变为全堵死。同理在计算机网络中，也很难相信，在前一分钟，所有的路由器都负载很轻，后一分钟，所有的路由器都超负载。应该是，某些路由器超负载了，其他路由器正常，这时后续的数据包就会自动绕路。假设某主机，连续发送了 2，3，4，5号数据包，2 号数据包碰到超负荷的路由器，被路由器丢弃，3，4，5 号数据包绕路到达目的主机，目的主机发送了 3 个 ACK 确认，请求 2 号数据包。当发送方收到 3 个重复 ACK 时，就会判断，网络是部分拥塞的，前面的数据包堵死在路上，后面的数据包绕路走了，已经到达目的地。简单归纳为一句话，3 个重复ACK 就表示网络部分拥塞，我称为半拥塞。3 个重复 ACK 就表示网络半拥塞。至此，外围的主机有了推测中间传输网络状态的办法，这两个事件就标志着网络的两种状态。用两个事件标志两种网络状态的方法，需要认真领会。TCP 的拥塞控制不能算闭环，没有一个具体的设备发出一个网络拥塞的信号，因为拥塞是全网的状态，不是某一个路由器的状态。一个路由器超载，可以绕其他路由器。TCP 的拥塞控制也不能算开环，“超时”与“3ACK”这两个事件确实反馈了中间传输网络的状态，为决策提供了依据。了解了网络现在的状态，就好办了。全拥塞有全拥塞的处理办法，半拥塞有半拥塞的处理办法。拥塞窗口在上文中，讨论过 TCP 的流量控制，发送方窗口大小是由接收方的可用缓存空间（rwnd）决定的，就是由接收方指示发送方应当使用多大的窗口，这当然可以保证接收方不会溢出。但是，这个方法没考虑网络的存在，上文说过，要调控网络拥塞，就要根据当前网络的状态，调整发送到网络中的数据量。也就是说，TCP 需要一个控制变量，即TCP 发送方使用拥塞窗口 cwnd （Congestion Window）作为控制变量，根据当前网络的拥塞程度，拥塞窗口的大小动态地变化，调整发送的数据量。这样一来发送窗口大小不仅取决于接收方通告的接收窗口 rwnd，还取决于网络的拥塞状况 cwnd，进而 实际的发送窗口 = min（ rwnd , cwnd ）拥塞检测TCP 的发送方使用两个事件作为判断网络全拥塞和半拥塞的依据。超时表示网络全拥塞。3 次重复 ACK 表示网络半拥塞。超时上文已经解释过拥塞的现象，我们现在简单理解为：发送方的超时事件就表示中间网络全部堵死了。发送方 TCP 在整个连接期间，只维护一个 RTO 计时器。发送方发送段 1 和 段 2，计时器启动，接收方发回 ACK，发送方收到 ACK 后，计时器清零。在启动计时器，发送段 3，段 4，段 3 丢失，段 4 到达，接收方将段 4 存储下来，因为段 3 丢失，接收方留出一个间隙，表明数据是不连续的，接收方只能再发送对段 2 的确认 ACK。发送方收到确认，但因为不是对段 3，段 4 的确认，计时器不能清零，计时器超时，就会重传段 3，并重启计时器，这次段 3 正常到达，接收方发送 ACK，发送方收到，将计时器清零。三次重复 ACK（3dupACKs）三次重复 ACK，也称做“快重传”（Fast retransmission）。如下图：发送方发送 2 个段后，正常收到 ACK，这个 ACK 是原始的 ACK，超时计时器清零。发送方再发送 4 个段，并再次启动超时计时器，段 3 丢失，段 4，5，6 到达。当接收方收到失序的数据段时，立即发送 ACK。接收方会发出 3 个重复的 ACK。发送方收到三个重复的 ACK，就立即重传丢失的报文段，而不等待计时器超时，并重启计时器。这一规则称为“快重传”，目前的 TCP 都遵守这规则。三次重复 ACK，显然是某个报文段丢失了，后面的报文段正常到达。这就表示网络有堵死的地方，造成丢失，其他部分通畅，后面的报文段绕行了通畅的路径。我们现在简单理解为：发送方收到三次重复 ACK，就表示中间网络半堵死。拥塞控制策略TCP 拥塞策略基于两个阶段，慢启动（slow-start，SS）阶段和拥塞避免（congestion avoidance，CA）阶段。在慢启动阶段，发送方从非常慢的速率开始，很快达到一个门限值。当到达门限值，进入拥塞避免阶段。慢启动（SS, Slow start）指数增大，拥塞窗口 cwnd 从 1 个最大报文段 MSS 开始。每收到一个 ACK 确认，拥塞窗口增加一个 MSS。慢启动算法开始很慢，但它是以指数增大的。按 ACK 计算， cwnd = cwnd + 1。如图，从 cwnd=1 开始，第 1 个 ACK 到达后，cwnd 加 1，就是 2。这时，就可发送 2 个段，相应的回来 2 个 ACK，对于每个 ACK，cwnd 加 1，就是 4 了。是按指数增大的。慢启动不能无限制的指数增大，有一个门限值来终止慢启动。发送方有一个慢开始门限 ssthresh（slow-start threshold）的变量，当拥塞窗口大小达到阈值时，慢启动停止，开始拥塞避免阶段。拥塞避免（CA，Congestion avoidance）加法增大，在慢启动阶段，当拥塞窗口达到慢开始门限 ssthresh 的值时，慢启动停止，进入拥塞避免阶段。此时，拥塞窗口按加法增大。每次整个“窗口”的所有段都被确认后，拥塞窗口增加 1。举例，发送方以 cwnd=4 开始，此刻发送方只能发 4 个段，在 4 个 ACK 到达后，拥塞窗口才加 1。如果按往返时延 RTT 观察，拥塞窗口是每一轮次加 1。按 ACK 计算， cwnd = cwnd + ( 1 / cwnd )按 RTT 计算， cwnd = cwnd + 1拥塞控制策略的转换在拥塞避免阶段，拥塞窗口加法增大。拥塞避免阶段会一直持续下去吗？继续下去，会是什么情况？显然，拥塞避免阶段继续下去，网络只会有处于通畅，半拥塞，全拥塞三种状态中的一种。就如同城市交通一样，只会是不堵车，部分堵死，全部堵死这三种情况之一。通畅：标志是无事件发生。拥塞避免阶段继续，拥塞窗口继续按加法增大。半拥塞：标志事件是：发送方收到三次重复 ACK（3dupACKs）。处理办法是：ssthresh 门限值设为此刻 cwnd 的一半 ssthresh = cwnd / 2将拥塞窗口设为门限值。 cwnd = ssthresh进入拥塞避免阶段。全拥塞标志事件是：发送方超时。处理办法是：ssthresh 门限值设为此刻 cwnd 的一半 ssthresh = cwnd / 2将拥塞窗口重新设置设为 1。 cwnd = 1进入慢启动阶段拥塞举例：连接管理TCP 是一种面向连接的协议。TCP 以全双工方式传送数据。在 TCP 中，面向连接的传输需要经过三个阶段：连接建立，数据传输，连接断开。TCP 连接采用客户服务器方式。主动发起连接建立的应用进程叫做客户(client)，被动等待连接建立的应用进程叫做服务器(server)。连接建立TCP 建立连接的过程叫做三次握手（three-way handshaking）。服务器首先打开一个端口，端口处于监听态，称为被动打开。客户端发起连接请求，连接到服务器的打开的端口上，连接就建立了。客户端发送第 1 个报文段，SYN 标志置 1，SYN 是请求同步的意思，SYN 报文段是控制报文，只在每个方向的第 1 个报文里出现。客户随机选择一个数字作为初始序号，假设为 x。TCP协议规定：SYN 报文段不能携带数据，但要消耗掉一个序号。服务器发送第 2 个报文段，SYN，ACK 置 1。SYN 标志表示服务器方的请求同步，并且服务器设置自己的初始序号，假设为 y。ACK 置 1 表示包含确认，这个确认是对客户端 SYN 报文的确认，所以确认号=x+1，表示序号 x+1 之前的报文都收好了，希望收到序号为 x+1 的报文段。客户端发送第 3 个报文段，ACK 标志置 1。这个报文段仅仅是一个 ACK 段，通常不携带数据。这个段是客户端发出的，序号就是 x+1。ACK 置 1 表示包含确认，这是对服务器 SYN 报文的确认，确认号=y+1，表示服务器发送的序号 y+1 之前的报文都收好了，希望收到服务器发送的序号为 y+1 的报文段。要特别注意教材中的这句话，并需要真正理解。TCP 的标准规定，ACK 报文段可以携带数据。但如果不携带数据则不消耗序号。举例：客户端发送的第 1 个 SYN 报文段，序号为 8000，服务器发送的第 2 个 SYN+ACK 报文段，序号为 15000，此后，客户端发送了第 3 个报文段，未携带数据，第 4 个报文段，携带 100 字节数据，问客户端发送的第 3，4 个报文段的序号是什么？解析：第 3 个报文段，序号为 8001，因为序号 8000 已经被 SYN 报用掉了。 第 4 个报文段，序号仍然是 8001，注意不是 8002，因为第 3 个报文段是一个 ACK 报文段，并且没携带数据，所以不消耗序号，就是说第 3 个报文的序号 8001 没有被用掉，在第 4 个报文中继续使用。为什么要三次握手三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常所以三次握手就能确认双发收发功能都正常，缺一不可。为什么TCP客户端最后还要发送一次确认呢一句话，主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。数据传输连接建立后，可进行双向的数据传输。客户端和服务器都可以发送数据和确认。TCP 连接使用了序号和确认号的机制。序号TCP 把要发送的数据都按字节编上号。两个方向的编号是相互独立的。编号并不是从 0 开始，而是使用一个随机数作为初始编号，初始编号在建立连接的第一个 SYN 报文段里通告给对方。每个 TCP 报文段都有序号字段，序号字段值是这个报文段中第一个数据字节的编号。TCP 报文的序号字段值是这个报文段中第一个数据字节的编号。确认号TCP 使用确认机制。当报文段中 ACK 标志置 1，报文的确认号字段有效，TCP 的确认是累计确认，确认号字段值是完全接收好的数据的最后一个字节的编号+1，表示此值前的数据已收好，期望接收的下一字节是此值。举例，确认号是5644，表示从开始到 5643 号字节的数据都已收好，希望接收 5644 号字节。TCP 是累积确认。确认号字段值是期望接收的下一个字节的编号。举例：客户端发送一报文段，序号 8001，确认号 15001，携带 1000 字节数据。服务器发送的下一个报文段，序号，确认号是多少？服务器的回复携带 2000 字节数据，则客户端发送的再下一个报文，序号，确认号是多少？解析：因第 1 个报文的确认号 15001，是期望接收的下一个报文段的序号，所以，服务器发送的下一个报文段的序号是 15001。因第 1 个报文的序号 8001，携带 1000 字节数据，服务器收到了 8001-9000 编号的 1000 字节数据，确认号是9001，表示 9001 号字节之前的数据已经收好，希望接收的下一个字节是 9001号字节。同理，第 3 个报文，序号为 9001，确认号是 17001。连接断开数据传输结束后，客户端和服务器任一方都可以发起断开连接。一般来说客户端发起断开连接。TCP 连接释放过程是四次握手。客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗ *∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。为什么客户端最后还要等待2MSLMSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。为什么建立连接是三次握手，关闭连接确是四次挥手呢建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。如果已经建立了连接，但是客户端突然出现故障了怎么办TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。TCP 连接管理的三规则规则 1：TCP 规定，SYN 报文段不能携带数据，但要消耗掉一个序号规则 2：TCP 的标准规定，ACK 报文段可以携带数据。但如果不携带数据则不消耗序号。规则 3：TCP 规定，FIN 报文段即使不携带数据，它也消耗掉一个序号。打开网页的过程总体来说分为以下几个过程:DNS解析TCP连接发送HTTP请求服务器处理请求并返回HTTP报文浏览器解析渲染页面连接结束SocketInetAddressThis class represents an Internet Protocol (IP) address.获得本机IP地址获得本地IP地址InetAddress iaddress = InetAddress.getLocalHost();但是这个函数有问题，因为这个函数的原理是通过获取本机的hostname，然后对此hostname做解析，从而获取IP地址的。那么问题来了，如果在本机的/etc/hosts文件里对这个主机名指向了一个错误的IP地址，那么InetAddress.getLocalHost就会返回这个错误的IP地址。当然如果你的hostname是到DNS去解析的，碰巧DNS上的信息也是错的，也同样是悲惨结局。InetAddress是由两部分组成的，一部分是getHostName()，一部分是getHostAddress()。获得本机所有的IP地址1234567891011121314151617181920212223242526272829/** * 获取机器所有网卡的IP（ipv4） */public static List&lt;String&gt; getLocalIP() &#123; List&lt;String&gt; ipList = new ArrayList&lt;String&gt;(); InetAddress ip = null; try &#123; Enumeration&lt;NetworkInterface&gt; netInterfaces = (Enumeration&lt;NetworkInterface&gt;) NetworkInterface.getNetworkInterfaces(); while (netInterfaces.hasMoreElements()) &#123; NetworkInterface ni = (NetworkInterface) netInterfaces.nextElement(); // 遍历所有ip Enumeration&lt;InetAddress&gt; ips = ni.getInetAddresses(); while (ips.hasMoreElements()) &#123; ip = (InetAddress) ips.nextElement(); if (null == ip || "".equals(ip)) &#123; continue; &#125; String sIP = ip.getHostAddress(); if(sIP == null || sIP.indexOf(":") &gt; -1) &#123; continue; &#125; ipList.add(sIP); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ipList;&#125;获取其他主机的IP地址对象InetAddress otherInetAddress = InetAddress.getByName(&quot;www.baidu.com&quot;);123456789101112131415public static void main(String[] args) throws UnknownHostException &#123; //1.获取本地主机 InetAddress iaddress = InetAddress.getLocalHost(); System.out.println(iaddress); //打印 InetAddress对象 默认格式: 用户名/IP地址 //2.获取主机名 String hostName = iaddress.getHostName(); //3.获取主机IP地址 String ip = iaddress.getHostAddress(); System.out.println(hostName); System.out.println(ip); //3.获取其他主机的IP地址对象 InetAddress otherInetAddress = InetAddress.getByName("www.baidu.com"); System.out.println(otherInetAddress);&#125;UDPUDP通信需要两个类的支持：数据的发送接收器：DatagramSocket数据包类：DatagramPacket123456789101112131415161718192021222324252627282930313233343536import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.net.SocketException;public class UDPReceiver &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub //1.创建DatagramSocket对象, //强调:接收端必须指定一个端口号 DatagramSocket ds = new DatagramSocket(12345); while(true)&#123; //2.直接创建一个DatagramPacket对象 byte[] bs = new byte[1024]; DatagramPacket dp = new DatagramPacket(bs, bs.length); //3.接收 System.out.println("等待发送端发送数据...."); ds.receive(dp);//这个方法具有等待功能,等待发送端发送过来的数据 System.out.println("接收数据成功!!"); //获取发送端的地址 InetAddress sendAddress = dp.getAddress(); System.out.println("发送端是:"+sendAddress.getHostAddress()); //获取真正的数据 byte[] data = dp.getData(); //获取发送端 发来了多少字节 int len = dp.getLength(); //打印数据 String receiveMsg = new String(data, 0, len); System.out.println("发送端说:"+receiveMsg); &#125; //4.关闭资源（程序运行结束之后是需要关闭资源的，但是我们的程序是一个死循环，此句永不会执行，所以不能加关闭） //ds.close(); &#125;&#125;1234567891011121314151617181920212223242526import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.util.Scanner;public class UDPSender &#123; public static void main(String[] args) throws Exception &#123; Scanner sc = new Scanner(System.in); //1.创建DatagramSocket对象 DatagramSocket ds = new DatagramSocket(); while(true)&#123; //2.创建DatagramPacket对象 //存储 发送的数据,对方的IP,端口号 System.out.println("请输入您要发送的数据:"); String sendMsg = sc.nextLine(); byte[] bs = sendMsg.getBytes(); //IP地址:127.0.0.1 代表本机,本地回环地址 DatagramPacket dp = new DatagramPacket(bs,bs.length,InetAddress.getByName("127.0.0.1"),12345); //3.发送 ds.send(dp); System.out.println("发送数据成功!!!");//192.168.146.72 &#125; //4.关闭资源（程序运行结束之后是需要关闭资源的，但是我们的程序是一个死循环，此句永不会执行，所以不能加关闭） //ds.close(); &#125;&#125;TCP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;/** * TCP服务器:(ServerSocket) 步骤: * * 1.创建一个ServerSocket对象,必须绑定一个端口,这个端口必须和客户端连接的端口一致 * * 2.调用server的accept()方法,获取到底哪一个客户端连接的服务器 * * 3.通过刚刚获取到的客户端对象 调用getInputStream()方法 * * 4.通过输入流调用read方法,读取客户端写过来的数据 * * 5.关闭资源 * */public class ServerDemo &#123; public static void main(String[] args) throws IOException &#123; // 1.创建一个ServerSocket对象,必须绑定一个端口,这个端口必须和客户端连接的端口一致 ServerSocket server = new ServerSocket(12345); // 2.获取到 哪一个 客户端连接的我 System.out.println("等待客户端连接..."); Socket client = server.accept();// 此方法也具有等待功能,等待某一个客户端连接 // 打印一些和客户端有关信息 String ip = client.getInetAddress().getHostAddress(); System.out.println("小样,抓到你了:" + ip); // 3.获取输入流,实际上是客户端写数据时的输出流 InputStream in = client.getInputStream(); // 4.读取数据 byte[] bs = new byte[1024]; int len = in.read(bs); // 打印 System.out.println("客户端说:" + new String(bs, 0, len)); // 5.要向客户端 回写数据,告诉客户端您的信息我已经收到了 OutputStream out = client.getOutputStream(); out.write("您的消息已经收到...".getBytes()); System.out.println("给客户端反馈的信息发送成功!!!"); // 关闭资源 server.close(); client.close(); in.close(); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738import java.io.IOException;import java.io.InputStream;import java.net.Socket;/** * * 使用TCP协议的客户端(Socket类) 步骤: 1.创建一个客户端对象(注意:指定这个Socket要连接的服务器的IP和端口) * * 2.从客户端对象中获取 输出流:getOutputStream() * * 3.调用输出流的Write方法写数据到服务器即可 * * 4.关闭资源 * */public class ClientDemo &#123; public static void main(String[] args) throws IOException &#123; // 1.创建一个客户端对象(注意:指定这个Socket要连接的服务器的IP和端口) /* * 这个构造方法干了很多事情: a.自动去连接服务器 b.自动进行三次握手,建立连接 c.自动为连接中创建两个流 */ Socket client = new Socket("127.0.0.1", 12345); // 2.从客户端对象中获取 输出流:getOutputStream() // OutputStream out = client.getOutputStream(); // 3.调用输出流的Write方法写数据到服务器即可 // out.write("How are you".getBytes()); client.getOutputStream().write("How are you".getBytes()); System.out.println("给服务器发送数据成功!!"); // 4.读取服务器 发送过来的反馈信息 InputStream in = client.getInputStream(); byte[] bs = new byte[1024]; int len = in.read(bs); System.out.println("服务器响应:" + new String(bs, 0, len)); // 关闭资源 client.close(); &#125;&#125;文件传输案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;public class FileUploadServer &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub //1.创建ServerSocket对象,绑定一个端口 ServerSocket server = new ServerSocket(12345); while(true)&#123; //2.获取哪一个客户端连接的服务器 System.out.println("等待客户端连接..."); final Socket client = server.accept(); //开启一个线程,和clinet进行交互 new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // TODO Auto-generated method stub System.out.println("小样:"+client.getInetAddress().getHostAddress()); //3.获取输入流,读取客户端发来数据 InputStream in = client.getInputStream(); //4.创建文件的输出流,把数据写到文件中 String picName = "D:\\"+System.currentTimeMillis()+".png"; FileOutputStream fos = new FileOutputStream(picName); //5.循环 从输入流读取客户端数据, 写入到文件中 byte[] bs = new byte[1024]; int len = 0; while((len=in.read(bs))!=-1)&#123; fos.write(bs, 0, len); &#125;//1小时 System.out.println("客户端的文件已经保存完毕,可以查看了"+picName); //6.告知客户端,文件真的真的真的上传成功 try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; OutputStream out = client.getOutputStream(); out.write("您的文件真的真的真的上传成功".getBytes()); client.close(); in.close(); out.close(); fos.close(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; //6.关闭 // server.close(); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;public class FileUploadClient &#123; public static void main(String[] args)throws IOException &#123; //1.创建Socket对象,连接服务器 Socket client = new Socket("127.0.0.1", 12345); System.out.println("连接服务器成功.."); //2.获取输出流,把数据写向服务器 OutputStream out = client.getOutputStream(); //3.创建文件的输入流,读取本地的文件数据 FileInputStream fis = new FileInputStream("C:\\Users\\ISJINHAO\\Desktop\\我.jpg"); //4.循环,读取本地文件,写到服务器 byte[] bs = new byte[1024]; int len = 0; while((len=fis.read(bs))!=-1)&#123; out.write(bs, 0, len); &#125; //关闭输出流 client.shutdownOutput(); //5.获取服务器反馈的信息 InputStream in = client.getInputStream(); byte[] bs1 = new byte[1024]; int len1 = in.read(bs1); System.out.println("服务器说:"+new String(bs1,0,len1)); //6关闭 client.close(); out.close(); fis.close(); &#125;&#125;Socket属性TCP_NODELAY：是否采用nagle算法。SO_REUSEADDR：表示是否允许重用Socket所绑定的本地地址。SO_TIMEOUT：表示接收数据时的等待超时时间。SO_SNFBUF：表示发送数据的缓冲区的大小。SO_RCVBUF：表示接收数据的缓冲区的大小。SO_KEEPALIVE：表示对于长时间处于空闲状态的Socket，是否要自动把它关闭。SO_LINGER：表示当执行Socket的close()方法时，是否立即关闭底层的Socket。默认第一种。onlingerclosesocket行为发送队列底层行为true忽略立即返回。保持直至发送完成。系统接管套接字并保证将数据发送至对端。false零立即返回。立即放弃。直接发送RST包，自身立即复位，不用经过2MSL状态。对端收到复位错误号。false非零阻塞直到linger时间超时或数据发送完成。(套接字必须设置为阻塞状态)在超时时间段内保持尝试发送，若超时则立即放弃。超时则同第二种情况，若发送完成则皆大欢喜。OOBINLINE：Enable/disable SO_OOBINLINE(receipt of TCP urgent data)By default, this option is disabled and TCP urgent data received on a socket is silently discarded. If the user wishes to receive urgent data, then this option must be enabled. When enabled, urgent data is received inline with normal data.Note, only limited support is provided for handling incoming urgent data. In particular, no notification of incoming urgent data is provided and there is no capability to distinguish between normal data and urgentdata unless provided by a higher level protocol.PerformancePreferences：设置连接时间、低延迟、高带宽之间的权重。ChannelJava NIO的通道类似流，但又有些不同：既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。通道可以异步地读写。通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。java.nio.channels.Channel接口只声明了两个方法：close()：关闭通道。isOpen()：判断通道是否打开。通道在创建时被打开，一旦关闭通道，就不能重新打开它。Channel的实现这些是Java NIO中最重要的通道的实现：FileChannel：从文件中读写数据。DatagramChannel：能通过UDP读写网络中的数据。SocketChannel：能通过TCP读写网络中的数据。ServerSocketChannel：可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。BufferJava NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。为了理解Buffer的工作原理，需要熟悉它的三个属性：capacity：作为一个内存块，Buffer有一个固定的大小值，叫“capacity”。你只能往对应的Buffer里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。position：当你写数据到Buffer中时，position表示当前的位置。初始的position值为0，当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0. 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。limit：写模式下，Buffer的limit表示你最多能往Buffer里写多少数据，此时limit等于Buffer的capacity。当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）Buffer的实现Java NIO 有以下Buffer类型ByteBufferMappedByteBufferCharBufferDoubleBufferFloatBufferIntBufferLongBufferShortBufferBuffer详解在我们刚才的说明中提到了写模式和读模式，但是实际上这只是被强行赋予的，即JDK中并没有说法，这么说只是为了更方便的理解，所以下面我们来解读一下Buffer的API及怎么在两种模式之间进行切换。需要指出：写模式指的是想Buffer写入，读模式是从Buffer里读出。Buffer的分配要想获得一个Buffer对象首先要进行分配。 每一个Buffer类都有一个allocate方法。下面是一个分配48字节capacity的ByteBuffer的例子。ByteBuffer buf = ByteBuffer.allocate(48);这是分配一个可存储1024个字符的CharBuffer：CharBuffer buf = CharBuffer.allocate(1024);刚获得的Buffer默认是写模式。向Buffer中写数据写数据到Buffer有两种方式：从Channel写到Buffer：int bytesRead = inChannel.read(buf); //read into bufferbytesRead指读出的数据大小。当bytesRead为-1时表示缓存区中不再有数据。通过Buffer的put()方法写到Buffer里：buf.put(127);put()：相对写。向缓冲区的当前位置写入一个单元的数据，写完后把位置加1。put(int index)：绝对写。向参数index指定的位置写入一个单元的数据。12345678910111213141516171819202122232425262728293031323334package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo1 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); FileChannel inChannel = fileIn.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf); while (bytesRead != -1) &#123; System.out.println("Read " + bytesRead); buf.flip(); //写模式切换为读模式 System.out.println(charset.decode(buf).toString()); buf.clear(); bytesRead = inChannel.read(buf); &#125; fileIn.close(); &#125;&#125;inChannel.read(buf);之后，buf.flip();之前Buffer的状态：向Channel中写数据12345678910111213141516171819202122232425262728293031323334353637package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo2 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 * test_out中没有数据，用于Java程序的写出 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel inChannel = fileIn.getChannel(); FileChannel outChannel = fileOut.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = -1; do &#123; bytesRead = inChannel.read(buf); System.out.println("Read " + bytesRead); buf.flip(); //写模式切换为读模式 outChannel.write(buf); buf.clear(); &#125;while(bytesRead != -1); fileIn.close(); fileOut.close(); &#125;&#125;buf.flip();之后，outChannel.write(buf);之前Buffer的状态。测试limit1234567891011121314151617181920212223242526272829303132333435363738package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo2 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 * test_out中没有数据，用于Java程序的写出 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel inChannel = fileIn.getChannel(); FileChannel outChannel = fileOut.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = -1; do &#123; bytesRead = inChannel.read(buf); System.out.println("写模式下： " + buf.limit()); buf.flip(); //写模式切换为读模式 System.out.println("读模式下： " + buf.limit()); outChannel.write(buf); buf.clear(); &#125;while(bytesRead != -1); fileIn.close(); fileOut.close(); &#125;&#125;rewind()方法Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。clear()与compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer被清空了。Buffer中的数据并未清除。如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。mark()与reset()方法通过调用Buffer.mark()方法，可以标记Buffer中的一个特定位置。之后可以通过调用Buffer.reset()方法将position置于这个位置。equals()与compareTo()方法equals()当满足下列条件时，表示两个Buffer相等：有相同的类型（byte、char、int等）。Buffer中剩余的byte、char等的个数相等。Buffer中所有剩余的byte、char等都相同。如你所见，equals只是比较Buffer的一部分，不是每一个在它里面的元素都比较。实际上，它只比较Buffer中的剩余元素。compareTo()方法compareTo()方法比较两个Buffer的剩余元素(byte、char等)， 如果满足下列条件，则认为一个Buffer“小于”另一个Buffer：第一个不相等的元素小于另一个Buffer中对应的元素 。所有元素都相等，但第一个Buffer比另一个先耗尽（第一个Buffer的元素个数比另一个少）。Scatter/Gatherscatter：分散，从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此，Channel将从Channel中读取的数据“分散（scatter）”到多个Buffer中。Scattering Reads是指数据从一个channel读取到多个buffer中。如下图描述：12345678910111213141516171819202122232425package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo3 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; RandomAccessFile file = new RandomAccessFile("test_in", "rw"); FileChannel channel = file.getChannel(); ByteBuffer header = ByteBuffer.allocate(6); ByteBuffer body = ByteBuffer.allocate(64); ByteBuffer[] bufferArray = &#123; header, body &#125;; long read = channel.read(bufferArray); System.out.println(read); header.flip(); body.flip(); System.out.println(charset.decode(header).toString()); System.out.println(charset.decode(body).toString()); &#125;&#125;read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息（消息大小不固定）。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。gather：聚集，写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。Gathering Writes是指数据从多个buffer写入到同一个channel。如下图描述：123456789101112131415161718192021222324252627package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class Demo4 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel channelOut = fileOut.getChannel(); ByteBuffer header = ByteBuffer.allocate(6); ByteBuffer body = ByteBuffer.allocate(64); header.put("陈".getBytes()); body.put("钰琪是个大可爱".getBytes()); ByteBuffer[] bufferArray = &#123; header, body &#125;; header.flip(); body.flip(); channelOut.write(bufferArray); fileOut.close(); &#125;&#125;通道之间的数据传输在Java NIO中，如果两个通道中有一个是FileChannel，那你可以直接将数据从一个channel传输到另外一个channel。transferFrom()FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中（这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中）。下面是一个简单的例子：123456789101112131415161718192021222324package com.test;import java.io.RandomAccessFile;import java.nio.channels.FileChannel;public class Demo5 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fromFile = new RandomAccessFile("test_in", "rw"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile("test_out", "rw"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count); fromFile.close(); toFile.close(); &#125;&#125;transferTo()将数据从FileChannel传输到其他的channe中。下面是一个简单的例子：123456789101112131415161718192021222324package com.test;import java.io.RandomAccessFile;import java.nio.channels.FileChannel;public class Demo6 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fromFile = new RandomAccessFile("test_in", "rw"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile("test_out", "rw"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel); fromFile.close(); toFile.close(); &#125;&#125;概述服务器程序只需要一个线程就能同时负责接收客户的连接、接收各个客户发送的数据，以及向各个客户发送响应数据。服务器程序的处理流程如下：12345678while(一直等待，直到有接收连接就绪事件、读就绪事件或写就绪事件发生)&#123; //阻塞 if(有客户连接) 接收客户的连接; //非阻塞 if(某个Socket的输入流中有可读数据) 从输入流中读数据; //非阻塞 if(某个Socket的输出流可以写数据) 向输出流写数据; //非阻塞&#125;以上处理流程采用了轮询的工作方式，当某一种操作就绪，就执行该操作，否则就察看是否还有其他就绪的操作可以执行。线程不会因为某一个操作还没有就绪，就进入阻塞状态，一直傻傻的在那里等待这个操作就绪。SelectorSelector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。Selector的创建通过调用Selector.open()方法创建一个Selector，如下：1Selector selector = Selector.open();向Selector注册通道为了将Channel和Selector配合使用，必须将channel注册到selector上。通过SelectableChannel.register()方法来实现，如下：12channel.configureBlocking(false);SelectionKey key = channel.register(selector, Selectionkey.OP_READ);与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。注意register()方法的第二个参数。这是一个“interest集合”，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件：SelectionKey.OP_ACCEPT：接收连接就绪事件，表示服务器监听到了客户连接，服务器可以接收这个连接了。常量值为16SelectionKey.OP_CONNECT：连接就绪事件，表示客户与服务器的连接已经建立成功。常量值为8。SelectionKey.OP_READ：读就绪事件，表示通道中已经有了可读数据，可以执行读操作了。常量值为1。SelectionKey.OP_WRITE：写就绪事件，表示已经可以向通道写数据了。常量值为4。以上常量分别占居不同的二进制位，因此可以通过二进制的或运算“|”，来将它们进行任意组合。总结来说：通道触发了一个事件意思是该事件已经就绪。所以，某个channel成功连接到另一个服务器称为“连接就绪”。一个serverSocketChannel准备好接收新进入的连接称为“接收就绪”。一个有数据可读的通道可以说是“读就绪”。等待写数据的通道可以说是“写就绪”。SelectionKey在上一小节中，当向Selector注册Channel时，register()方法会返回一个SelectionKey对象。这个对象包含了一些你感兴趣的属性：interest集合ready集合ChannelSelector附加的对象（可选）interest集合就像向Selector注册通道一节中所描述的，interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合，像这样：1234int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；// 其他的也类似...ready集合ready 集合是通道已经准备就绪的操作的集合。在一次选择（Selection）之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合：intreadySet = selectionKey.readyOps();可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型：1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable();Channel + Selector从SelectionKey访问Channel和Selector很简单。如下：12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector();附加的对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下：12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment();还可以在用register()方法向Selector注册Channel的时候附加对象。如：1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);通过Selector选择通道一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。下面是select()方法：int select()：阻塞到至少有一个通道在你注册的事件上就绪了。int select(long timeout)：和select()一样，除了最长会阻塞timeout毫秒(参数)。int selectNow()：不会阻塞，不管什么通道就绪都立刻返回（此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。）。select()方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，因为有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。selectedKeys()一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示：1Set selectedKeys = selector.selectedKeys();当像Selector注册Channel时，Channel.register()方法会返回一个SelectionKey 对象。这个对象代表了注册到该Selector的通道。可以通过SelectionKey的selectedKeySet()方法访问这些对象。可以遍历这个已选择的键集合来访问就绪的通道。如下：123456789101112131415Set selectedKeys = selector.selectedKeys();Iterator keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125;这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。SelectionKey.channel()方法返回的通道需要转型成你要处理的类型，如ServerSocketChannel或SocketChannel等。SocketChannel打开 SocketChannel下面是SocketChannel的打开方式：12SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress("127.0.0.1", 20000));关闭 SocketChannel1socketChannel.close();ServerSocketChannelJava NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。ServerSocketChannel类在 java.nio.channels包中。打开 ServerSocketChannel通过调用 ServerSocketChannel.open() 方法来打开ServerSocketChannel，如：1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();关闭 ServerSocketChannel通过调用ServerSocketChannel.close() 方法来关闭ServerSocketChannel，如：1serverSocketChannel.close();监听新进来的连接通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。通常不会仅仅只监听一个连接,在while循环中调用 accept()方法，如下面的例子：123456while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125;当然，也可以在while循环中使用除了true以外的其它退出准则。非阻塞模式ServerSocketChannel可以设置成非阻塞模式。在非阻塞模式下，accept() 方法会立刻返回，如果还没有新进来的连接,返回的将是null。 因此，需要检查返回的SocketChannel是否是null，如：12345678910111213ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); if(socketChannel != null)&#123; //do something with socketChannel... &#125;&#125;服务器使用NIO向客户端Echo数据的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package com.core;import java.io.BufferedInputStream;import java.io.FileInputStream;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.ClosedChannelException;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.nio.charset.Charset;import java.util.ArrayList;import java.util.Date;import java.util.Iterator;import java.util.List;import java.util.Scanner;import java.util.Set;public class EchoSeverZJH &#123; private Selector selector; private ServerSocketChannel serverSocketChannel; private int port = 8000; private Charset charset = Charset.forName("utf-8"); private List&lt;String&gt; list = new ArrayList&lt;&gt;(); private int num; public EchoSeverZJH()&#123; try &#123; selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.socket().setReuseAddress(true); serverSocketChannel.socket().bind(new InetSocketAddress(port)); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; System.out.println("服务器开启成功... : " + new Date()); list.add("一共有18018条航班数据"); try (Scanner cin = new Scanner(new BufferedInputStream(new FileInputStream("copy")))) &#123; String line = null; while(cin.hasNext()) &#123; line = cin.nextLine(); list.add(line); &#125; list.add("no data"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; num = list.size(); System.out.println("数据已准备好... : " + new Date()); &#125; public void service()&#123; try &#123; serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (ClosedChannelException e) &#123; e.printStackTrace(); &#125; while (true) &#123; //没有连接就会阻塞 int n = 0; try &#123; n = selector.select(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (n == 0) continue; Set&lt;SelectionKey&gt; readkeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = readkeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); if(!key.isValid()) &#123; iterator.remove(); continue; &#125; if (key.isAcceptable()) &#123; accept(key); &#125; if (key.isWritable()) &#123; send(key); &#125; iterator.remove(); &#125; &#125; &#125; // 处理接收连接就绪事件 private void accept(SelectionKey key)&#123; // 返回一个对象 SocketChannel socketChannel; try &#123; socketChannel = serverSocketChannel.accept(); System.out.println("收到了客户端连接，来自 ： " + socketChannel.getRemoteAddress()); socketChannel.configureBlocking(false); //注册到selector socketChannel.register(selector, SelectionKey.OP_WRITE, 0); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 处理写就绪事件 private void send(SelectionKey key)&#123; SocketChannel socketChannel = (SocketChannel) key.channel(); int index = (int)key.attachment(); key.attach((index + 1) % num); String line = list.get(index); ByteBuffer outputBuffer = charset.encode(line + "\r\n"); while (outputBuffer.hasRemaining()) &#123; try &#123; socketChannel.write(outputBuffer); &#125; catch (IOException e) &#123; key.cancel(); try &#123; System.out.println(socketChannel.getRemoteAddress() + " 断开连接----"); socketChannel.socket().close(); socketChannel.close(); outputBuffer.clear(); break; &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args)&#123; new EchoSeverZJH().service(); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435package com.core;import java.io.IOException;import java.net.InetAddress;import java.net.Socket;import java.util.Scanner;public class ReadFromSocket&#123; public static void main(String[] args) &#123; Socket socket = null; Scanner sc = null; try &#123; socket = new Socket(InetAddress.getByName("127.0.0.1"), 8000); String line = null; sc = new Scanner(socket.getInputStream()); line = sc.nextLine(); System.out.println(line); while (sc.hasNext()) &#123; Thread.sleep(1000); line = sc.nextLine(); System.out.println(line); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; sc.close(); &#125; &#125;&#125;Selector维护的集合对上面的代码有一个很大的疑问，即服务器端为什么要进行iterator.remove();。解答这个问题之前我们先来理一下思路：服务器端有一个ServerSocketChannel，它绑定了端口号，且设置为非阻塞模式，它先向Selector中注册：serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);。ServerSocketChannel在注册的时候指定的事件是：OP_ACCEPT，表示接收连接就绪事件，即服务器在监听客户连接。每一个注册到selector上的channel都会被加入一个集合（key set），这个集合可以通过selector.keys()方法返回。然后判断已经准备好的连接n = selector.select();有几个，如果等于0则表示没有准备好的连接，此时需要continue。其中，已经准备好的连接可以按如下获得：Set&lt;SelectionKey&gt; readkeys = selector.selectedKeys();。即所有已经准备好channel都在一个集合（selected-key）中。但是selected-key本身并不是线程安全的，所以在处理的时候需要判断其是不是已经合法的，比如如果客户端中断了访问，则不能在传输数据，即其实不合法的。同时，每个都撤销的channel都在cancelled-key set中，但是所关联channel还没有被撤销登记。其不能够被直接返回，但也一定是key set的子集。所以我们移出的其实只是已准备好的channel的key。]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-MySQL]]></title>
    <url>%2F2019%2F02-MySQL%2F</url>
    <content type="text"><![CDATA[B树磁盘访问时间磁盘构造当磁盘驱动器执行读/写功能时。盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头（又叫磁头）下通过，就可以进行数据的读/写了。一般磁盘分为固定头盘（磁头固定）和活动头盘。固定头盘的每一个磁道上都有独立的磁头，它是固定不动的，专门负责这一磁道上数据的读/写。活动头盘 （如上图）的磁头是可移动的。每一个盘面上只有一个磁头（磁头是双向的，因此正反盘面都能读写）。它可以从该面的一个磁道移动到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的（行动整齐划一）。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。#### 访问时间典型的磁盘访问时间包括以下三个部分：寻道时间、旋转延迟时间、磁盘访问时间。这其中，时间开销最大的是$s$，台式机的旋转速度一般是7200转/分钟（RPM），即旋转一周需要8.33ms，所以式子中的$s$平均为4.165ms，而且磁臂的移动也需要时间，而硅存储的常见存取时间是50ns，即$s$约为一次存取时间100000倍。通常一页的长度为$2^{11}-2^{14}$，即使磁盘一般是一次读取连续的几个页面，定位到信息的时间也比存取信息的时间多（通常磁盘的平均存储时间是$8-11ms$）。所以当大量数据存储在外存磁盘中时，需要一种合理高效的数据结构来降低访问外存的时间：B树。需要说一下，B树的英文名是B-tree，所以有时候有人会把B树叫做B-树，这两个名词是同一个意思。B树的典型执行过程中，B树算法的运行时间取决于DISK-READ和DISK-WRITE。1234x = a pointer to some objectDISK-READ(x)operations of xDISK-WRITE(x)通常一个B树的结点和磁盘的一页一样大，这样一次读写操作能获取更多的信息。而每页能存储多少个数据和关键字大小有关。下图中的B树每个结点有1000个数据（B树中结点的度数为结点数据个数+1，见后面的定义），高度为2。所以它可以存储超过十亿个关键字，查找某个关键字至多进行两次磁盘访问。### B树的定义#### B树的定义- 每个结点有如下属性：1. $x.n$：表示当前存储在结点$x$中的关键字个数。2. 每个结点中的关键字以非降序方式存放：$x.key_1 \leq x.key_2 \leq \cdots \leq x.key_n$。3. $x.leaf$：一个布尔值，如果$x$是叶结点，则为$true$，否则为$false$。- 每个内部结点还包含包含$x.n+1$个指向其孩子的指针：$x.c_1, x.c_2, \cdots , x.c_n $，叶结点的$c_i$属性没有定义。- 关键字$x.key_i$对存储在各子树中的关键字范围加以分割：如果$k_i$为任意一个存储在以$x.c_i$为根的子树中的关键字，满足：$k_i \leq x.key_1 \leq k_2 \leq x.key_2 \leq \cdots \leq x.key_{x.n} \leq k_{x.n+1}$。- 每个叶结点具有相同的深度，即树的高度h。- 每个结点关键字所包含的关键字个数有上界和下界。用一个被称为B树的最小度数的固定整数$t$来表示这些界，$t \geq 2$。1. 除了根结点外的每个结点都至少有$t-1$个关键字，因此，除了根结点以外的每个内部结点至少有$t$个孩子。如果树非空，根结点至少有一个关键字。2. 每个结点至多可包含$2t-1$个关键字，因此一个内部结点至多可有$2t$个孩子，当一个结点恰好有$2t-1$个关键字时，该结点是满的。3. $t=2$的树是最简单的，每个内部结点有2个、3个或4个孩子。那么为什么最小度数不能取1呢？因为最小度数取1之后，内部结点（设指向其的指针为p）可以包含0个关键字，此时包含0个关键字的结点只有一个孩子（设为c），这个结点就被浪费了，我们其实可以直接让p指向c。### B树的高度对任意一棵包含n（$n \geq 1$）个关键字、最小度数为t的B树来说，有：$h \leq log_t{\frac{n+1}{2}}$。证明：假设根所在的层高度为0，则高度为h的B树在高度为1的层至少包含2个结点，在高度为2的层至少包含$2t$个结点，在高度为3的层至少包含$2t^2$个结点…直到高度为h的层至少包含$2t^{h-1}$个结点。可得关键字个数n满足不等式：$n \geq 1+(t-1)\sum_{i=1}^h2t^{i-1} = 1+2(t-1)(\frac{t^h-1}{t-1})=2t^h-1$$\Longrightarrow t^h \leq (n+1)/2$$\Longrightarrow h \leq log_t{\frac{n+1}{2}}$（t-1）指的是每个结点至少包含t-1个关键字。### B树的阶我们经常会遇到一个B数的术语：阶，假如树中的结点最多含有m个孩子，此B树的阶为m。当阶为偶数的时候，我们可以把定义中的$t$替换成$m/2$，但是当阶为奇数的时候就要考虑一个问题了，除根结点外的每个内部结点至少含有ceil(m/2)个结点还是floor(m/2)个结点？应该是ceil(m/2)，因为除了根结点每个结点的孩子个数满足：$t \leq keyNum \leq 2t$，如果取floor(m/2)会发现无法满足上式，所以一棵含有n个总关键字数的m阶的B树的最大高度是：$log_{ceil(m/2)}(n+1)/2$。（ceil向上取整，floor向下取整）### 搜索设$x$是根结点，被搜索的关键字是$k$。需要说明一下，伪代码中$key$和$c$的起始下标都为1。NIL代表空。### 插入插入的时候会遇到两种情况：1. 将新的关键字插在一个已经存在但未满的结点上：直接插入；2. 将新的关键字插在一个已经存在但已满的结点上：分裂后插入；#### 分裂将一个满的结点$y$（有$2t-1$个关键字）按照中间关键字分裂成两个各含有$t-1$个关键字的结点，中间关键字被升到$y$的父结点。如果$y$的父结点也是满的，也需要分裂，最终满结点的分裂会向上传播。如果向上传播时全程都是满结点会把根结点分裂，使B树的高度增1。分裂是使B树增高的唯一办法。但是在实际操作中不是等到找出插入过程中实际要分裂的结点才做分裂，而是在沿着树向下查找时分裂所有遇到的满结点，这样就能保证在插入的时候节点一定非满。$x$是被分裂的结点的父节点，$y$是$x$的第$i$个孩子。#### 非满结点插入$x$是被插入的节点，$k$是插入的键。解释几行代码：- 12行：被操作的节点从磁盘中读入到内存中，然后在内存中进行操作。- 7行+17行：每次插入的都是叶节点。#### 完整插入过程此时对根的分裂需要创建两个节点，而且对根的分裂是B树长高的唯一办法。而且在分裂之后我们会发现根节点必然会有一个关键字，这也对应了定义中的B树的根至少有两个孩子。### 创建分配空节点：分配之后循环调用插入即可。### 删除在删除时需要注意两个部分：1. 除根节点外，被删除关键字的节点在删除后仍然要满足$keyNum \geq t-1$。2. 删除后需要重新安排这个结点的孩子。#### 操作1. 如果关键字$k$在结点$x$中，并且$x$是叶节点，从$x$中删除$k$2. 如果关键字$k$在结点$x$中，但$x$是内部非根节点：上移孩子结点中的某相近元素（“左孩子最右边的节点”或“右孩子最左边的节点”）到父节点中，并且递归被上移的孩子。删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于$ceil(m/2)-1$，则需要看其某相邻兄弟结点是否贫困（结点中元素个数等于$ceil(m/2)-1$）如果非贫困，则父节点下降一个元素来此节点，兄弟结点上升一个元素。如果其相邻兄弟都贫困，则该结点与其相邻的某一兄弟结点进行“合并“成一个结点。#### 举例- 刪除H：直接删除- 删除T：W上升到T的位置，4上升到W的位置- 删除R：删除导致只有1个元素，已经小于最小元素数目$ceil(5/2)-1=2$，由于右相邻兄弟结点不贫困，所以先向父节点借一个元素T下移到该叶子结点中，代替原来S的位置，S前移；然后W上移到父结点中，X、Y、Z依次前移。- 删除E：因为E所在的结点和相邻的兄弟结点的关键字都刚好达标，删除后不能再向父节点借元素，所以需要该节点与某相邻兄弟结点进行合并操作；首先移动父结点中的元素（该元素在两个需要合并的两个结点元素之间）下移到其子结点中，然后将这两个结点进行合并成一个结点。所以在该实例中，咱们首先将父节点中的元素D下移到已经删除E而只有F的结点中，然后将含有D和F的结点与含有A和C的相邻兄弟结点进行合并成一个结点。但是此时还没有结束，此时的情况如下图第一幅，此时父节点只包含一个元素G，没达标。如果这个问题结点的相邻兄弟比较丰满，则可以向父结点借一个元素。假设这时右兄弟结点（含有Q,X）含有的元素个数大于2，咱们可以将M下移到元素很少的子结点中，将Q上移到M的位置，但此时咱们没有办法去借一个元素，只能与兄弟结点进行合并成一个结点，而根结点中的唯一元素M下移到子结点，即树的高度减少一层。### B+树在B树中，我们做操作的时候都默认了关键字和其对应的数据都存在一个页面中，但是实际上可以只存储关键字，而且仅存关键字可以让每页能存储更多的数据。基于此点和为了更好的在文件系统中存取数据，诞生了B+树。#### 定义B+树可以被视为每个节点仅包含键（不是键值对），并且链接了各叶节点叶的B树。和B树的区别如下：- 所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 （而B树的叶子节点并没有包括全部需要查找的信息）。- 所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 （而B树的非终节点也包含需要查找的有效信息）#### 为什么数据库使用B+树作为索引- B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。- B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。而B+树只要遍历叶子节点就可以实现整棵树的遍历。- B+树对range-query的支持很强大。比如要查5-10之间的，B+树一把到5这个标记，再一把到10，然后串起来就行了，B树就非常麻烦。#### 分裂B+树的分裂和B树没有太大区别，只是分裂后注意叶子结点需要有链接到下个结点的指针。### B*树#### 定义B*树是B+树的变体，在B+树的基础上（所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针）:- B*树中非根和非叶子结点再增加指向兄弟的指针；- B*树定义了非叶子结点关键字个数至少为$ceil((2/3) \ast m)$，即块的最低使用率为2/3（代替B+树的1/2）。#### 分裂当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。### 总结B树及其变形可以非常好的处理一维空间存储的问题。它的思想就是把一维直线分为若干段线段，当我们查找满足某个要求的点的时候，只要去查找它所属的线段即可。也可以说要查找某一满足条件的点，先去找到满足条件的线段，然后遍历所在线段上的点，即可找到答案。### 对比- B树：有序数组+平衡多叉树；- B+树：有序数组链表+平衡多叉树；- B*树：一棵丰满的B+树。## 多列索引假如有如下表：1234567CREATE TABLE People( last_name varchar(50) not null, first_name varchar(50) not null, dob date not null, gender enum('m', 'f') not null, key(last_name, first_name, dob));对应的B树如下（Mysql中实际上应该是B+树，但是在高性能mysql这本书里使用的是B树）：### 匹配原则多列索引的特点就和英语一样，比如查找mysql这个单词，对于第一个单词是有序的，所以先按顺序找到m，再m范围下的单词也是有序的，再找到y，以此类推。所以建立的索引对如下类型的查询有效：#### 全值匹配和索引中定义的所有列进行匹配，如查找姓名为Cuba Allen，出生于1996-01-01的人。#### 匹配最左前缀前面提到的索引可用于查找所有姓为Allen的人，即只使用索引的第一列。#### 匹配列前缀也可以只匹配某一列的值的开头部分，例如前面提到的索引可用于查找所有以J开头的姓的人。这里使用了索引的第一列。#### 匹配范围值例如前面提到的索引可用于查找姓在Allen和Barrymore之间的人。这里也只用了索引的第一列。#### 精确匹配某一列并范围匹配另外一列前面提到的索引也可用于查找所有姓为Allen，并且名字是K开头的人。### 多列索引在代码中的使用假设建立的索引是(a,b,c)：12345678910111213141516171819202122232425262728select * from mytable where a=3 and b=5 and c=4;-- 三个索引都在where条件里面用到了，而且都发挥了作用select * from mytable where c=4 and b=6 and a=3; -- where里面的条件顺序在查询之前会被mysql自动优化，效果跟上一句一样select * from mytable where a=3 and c=7; -- a用到索引，b没有用，所以c是没有用到索引效果的select * from mytable where a=3 and b&gt;7 and c=3;-- a用到了，b也用到了，c没有用到，这个地方b是范围值，也算断点，只不过自身用到了索引select * from mytable where b=3 and c=4;-- 因为a索引没有使用，所以这里 bc都没有用上索引效果select * from mytable where a&gt;4 and b=7 and c=9;-- a用到了 b没有使用，c没有使用select * from mytable where a&gt;4 and b like '%xxx%' and c=9;-- a用到了 b没有使用，c没有使用select * from mytable where a=3 order by b;-- a用到了索引，b在结果排序中也用到了索引的效果，前面说了，a下面任意一段的b是排好序的select * from mytable where a=3 order by c;-- a用到了索引，但是这个地方c没有发挥排序效果，因为中间断点了select * from mytable where b=3 order by a;-- b没有用到索引，排序中a也没有发挥索引效果## 索引分类和创建### 分类#### 普通索引MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了查询数据更快一点。#### 唯一索引索引列中的值必须是唯一的，但是允许为空值，#### 主键索引是一种特殊的唯一索引，不允许有空值。后面会有介绍，在INNODB中，主键索引是聚簇索引。### 创建#### 建表时创建123456CREATE TABLE table_name ( [col_name data_type], ..., [UNIQUE] [INDEX | KEY] [index_name] (col_name[length], ...) [ASC | DESC]);#### 后期添加12ALTER TABLE table_name ADD [UNIQUE] [INDEX | KEY] [index_name](col_name[length], ...) [ASC | DESC]12CREATE [UNIQUE] [INDEX | KEY] index_name ON table_name(col_name[length], ...) [ASC | DESC]INDEX和KEY具有相同的效果。length是指该列在B+树中的关键字所占的长度。### 聚簇索引和非聚簇索引#### 聚簇索引聚簇的意思是键值和数据行紧凑地存储在一起，因为无法把数据行放在两个不同的地方，所以一个表只有一个聚簇索引。而主键会被默认添加上聚簇索引，如果没有主键，INNODB会选择一个非空索引来替代，如果没有这样的索引，INNODB会隐式定义一个主键来作为聚簇索引。#### 非聚簇索引非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。又被称为二级索引。INNODB的二级索引其叶子结点上保存的是KEY+PRIMARY COL。### INNODB索引注意：INNODB中主键索引就是聚簇索引。### MyISAM索引单表DQL数据准备12345678910111213141516171819create table product( pid int primary key, pname varchar(20), price double, category_id varchar(32));INSERT INTO product(pid,pname,price,category_id) VALUES(1,'联想',5000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(2,'海尔',3000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(3,'雷神',5000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(4,'JACK JONES',800,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(5,'真维斯',200,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(6,'花花公子',440,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(7,'劲霸',2000,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(8,'香奈儿',800,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(9,'相宜本草',200,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(10,'面霸',5,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(11,'好想你枣',56,'c004');INSERT INTO product(pid,pname,price,category_id) VALUES(12,'香飘飘奶茶',1,'c005');INSERT INTO product(pid,pname,price,category_id) VALUES(13,'果9',1,NULL);简单查询查询表的所有字段信息：select * from 表名;查询表中某字段信息：select 字段1, 字段2 from 表名;去掉重复值：select distinct 字段1, 字段2, ... from 表名;若有多个字段则所有字段相等才被算为重复值。查询结果是表达式（运算查询）：将商品的价格+10元进行显示，select pname,price+10 from product;别名查询，使用的关键字是as（as可以省略的）：表别名：select * from product as p;列别名：select pname as pn from product;条件查询符号含义&gt; &lt; &lt;= &gt;= = &lt;&gt;!=大于、小于、大于(小于)等于、不等于BETWEEN …AND…显示在某一区间的值(含头含尾)(也可以是日期)IN(set)显示在in列表中的值，例：in(100,200)LIKE ‘张%’%代表零个或多个任意字符，_代表一个字符。例如：first_name like ‘_a%’IS NULL / IS NOT NULL判断为空/不为空and多个条件同时成立or多个条件任一成立not不成立，例：where not(salary&gt;100);例查询商品名称为“花花公子”的商品所有信息：SELECT * FROM product WHERE pname = &#39;花花公子&#39;查询价格为800商品：SELECT * FROM product WHERE price = 800查询价格不是800的所有商品：SELECT * FROM product WHERE price != 800SELECT * FROM product WHERE price &lt;&gt; 800SELECT * FROM product WHERE NOT(price = 800)查询商品价格大于60元的所有商品信息：SELECT * FROM product WHERE price &gt; 60;查询商品价格在200到1000之间所有商品：SELECT * FROM product WHERE price &gt;= 200 AND price &lt;=1000;SELECT * FROM product WHERE price BETWEEN 200 AND 1000;查询商品价格是200或800的所有商品：SELECT * FROM product WHERE price = 200 OR price = 800;SELECT * FROM product WHERE price IN (200,800);查询含有’霸’字的所有商品：SELECT * FROM product WHERE pname LIKE &#39;%霸%&#39;;查询以’香’开头的所有商品：SELECT * FROM product WHERE pname LIKE &#39;香%&#39;;查询第二个字为’想’的所有商品：SELECT * FROM product WHERE pname LIKE &#39;_想%&#39;;查询没有分类的商品：SELECT * FROM product WHERE category_id IS NULL;查询有分类的商品：SELECT * FROM prod quct WHERE category_id IS NOT NULL查询所有价格大于2000的电脑商品或者价格大于1000的服装商品：SELECT * FROM product WHERE (price &gt; 2000 AND category_id=&#39;c001&#39;) OR (price &gt;1000 AND category_id=&#39;c002&#39;);排序查询SELECT * FROM 表名 ORDER BY 排序字段 ASC|DESC;ASC： 升序 (默认)DESC：降序例：查询所有商品信息，使用价格排序(降序)：SELECT * FROM product ORDER BY price DESC;在价格排序(降序)的基础上，以分类排序(降序)：SELECT * FROM product ORDER BY price DESC, category_id DESC;显示商品的价格(去重复)，并排序(降序)：SELECT DISTINCT price FROM product ORDER BY price DESC;聚合查询聚合函数SELECT不仅可以作用于字段，还可以作用于聚合函数。count(…)：统计指定列不为NULL的记录行数；sum(…)：计算指定列的数值和，如果指定列类型不是数值类型，那么计算结果为0；max(…)：计算指定列的最大值，如果指定列是字符串类型，那么使用字符串排序运算；min(…)：计算指定列的最小值，如果指定列是字符串类型，那么使用字符串排序运算；avg(…)：计算指定列的平均值，如果指定列类型不是数值类型，那么计算结果为0；例：查询商品的总条数：SELECT COUNT(*) FROM product;查询价格大于200的商品总条数：SELECT COUNT(*) FROM product WHERE price &gt; 200;查询分类为’c001’的商品价格总和：SELECT SUM(price) FROM product WHERE category_id = &#39;c001&#39;;查询分类为’c002’商品的平均价格：SELECT AVG(price) FROM product WHERE category_id = &#39;c002&#39;;查询商品的最大价格和最小价格：SELECT MAX(price),MIN(price) FROM product;分组分组查询是指使用group by字句对查询信息进行分组。​ SELECT 字段1, 字段2… FROM 表名 GROUP BY 分组字段 HAVING 分组条件;HAVING：分组操作中的having子语句，是用于在分组后对数据进行过滤的，作用类似于where条件。与where的区别:having是在分组后对数据进行过滤。where是在分组前对数据进行过滤。having后面可以使用聚合函数过滤数据。where后面不可以使用聚合函数。例：统计各个分类商品的个数：SELECT category_id ,COUNT(*) FROM product GROUP BY category_id;统计各个分类商品的个数,且只显示个数大于1的信息：SELECT category_id, COUNT(*) FROM product GROUP BY category_id HAVING COUNT(*) &gt; 1;分页查询由于数据量很大，显示屏长度有限，因此对数据需要采取分页显示方式。例如数据共有30条，每页显示5条。格式：SELECT 字段1，字段2... FROM 表明 LIMIT M, N;M: 整数，表示从第几条索引开始，计算方式 （当前页-1）*每页显示条数N: 整数，表示查询多少条数据例：SELECT 字段1，字段2... FROM 表明 LIMIT 0,5;SELECT 字段1，字段2... FROM 表明 LIMIT 5,5;多表数据准备123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*功能：创建 scott 数据库中的 dept 表 */CREATE TABLE dept( deptno INT UNSIGNED AUTO_INCREMENT PRIMARY KEY COMMENT '部门编号', dname VARCHAR(15) COMMENT '部门名称', loc VARCHAR(50) COMMENT '部门所在位置')ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='部门表'; /*功能：创建 scott 数据库中的 emp 表 */CREATE TABLE emp( empno INT UNSIGNED AUTO_INCREMENT PRIMARY KEY COMMENT '雇员编号', ename VARCHAR(15) COMMENT '雇员姓名', job VARCHAR(10) COMMENT '雇员职位', mgr INT UNSIGNED COMMENT '雇员对应的领导的编号', hiredate DATE COMMENT '雇员的雇佣日期', sal DECIMAL(7,2) COMMENT '雇员的基本工资', comm DECIMAL(7,2) COMMENT '奖金', deptno INT UNSIGNED COMMENT '所在部门', FOREIGN KEY(deptno) REFERENCES dept(deptno))ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='雇员表'; /*功能：创建数据库 scott 中的 salgrade 表，工资等级表 */CREATE TABLE salgrade( grade INT UNSIGNED COMMENT '工资等级', losal INT UNSIGNED COMMENT '此等级的最低工资', hisal INT UNSIGNED COMMENT '此等级的最高工资' )ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='工资等级表'; /*功能：创建数据库 scott 的 bonus 表，工资表 */CREATE TABLE bonus( ename VARCHAR(10) COMMENT '雇员姓名', job VARCHAR(9) COMMENT '雇员职位', sal DECIMAL(7,2) COMMENT '雇员工资', comm DECIMAL(7,2) COMMENT '雇员资金' )ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='工资表'; /*功能：插入数据库 scott 中表 dept 的初始化数据 */INSERT INTO dept VALUES (10,'ACCOUNTING','NEW YORK');INSERT INTO dept VALUES (20,'RESEARCH','DALLAS');INSERT INTO dept VALUES (30,'SALES','CHICAGO');INSERT INTO dept VALUES (40,'OPERATIONS','BOSTON'); /*功能：插入数据库 scott 中表 emp 的初始数据 */INSERT INTO emp VALUES (7369,'SMITH','CLERK',7902,'1980-12-17',800,NULL,20);INSERT INTO emp VALUES (7499,'ALLEN','SALESMAN',7698,'1981-2-20',1600,300,30);INSERT INTO emp VALUES (7521,'WARD','SALESMAN',7698,'1981-2-22',1250,500,30);INSERT INTO emp VALUES (7566,'JONES','MANAGER',7839,'1981-4-2',2975,NULL,20);INSERT INTO emp VALUES (7654,'MARTIN','SALESMAN',7698,'1981-9-28',1250,1400,30);INSERT INTO emp VALUES (7698,'BLAKE','MANAGER',7839,'1981-5-1',2850,NULL,30);INSERT INTO emp VALUES (7782,'CLARK','MANAGER',7839,'1981-6-9',2450,NULL,10);INSERT INTO emp VALUES (7788,'SCOTT','ANALYST',7566,'87-7-13',3000,NULL,20);INSERT INTO emp VALUES (7839,'KING','PRESIDENT',NULL,'1981-11-7',5000,NULL,10);INSERT INTO emp VALUES (7844,'TURNER','SALESMAN',7698,'1981-9-8',1500,0,30);INSERT INTO emp VALUES (7876,'ADAMS','CLERK',7788,'87-7-13',1100,NULL,20);INSERT INTO emp VALUES (7900,'JAMES','CLERK',7698,'1981-12-3',950,NULL,30);INSERT INTO emp VALUES (7902,'FORD','ANALYST',7566,'1981-12-3',3000,NULL,20);INSERT INTO emp VALUES (7934,'MILLER','CLERK',7782,'1982-1-23',1300,NULL,10); /*功能：插入数据库 scott 中表 salgrade 的初始数据 */INSERT INTO salgrade VALUES (1,700,1200);INSERT INTO salgrade VALUES (2,1201,1400);INSERT INTO salgrade VALUES (3,1401,2000);INSERT INTO salgrade VALUES (4,2001,3000);INSERT INTO salgrade VALUES (5,3001,9999);1234567891011121314151617181920212223242526272829dept( DEPTNO, //部门编号，由两位数字所组成 DNAME, //部门名称，最多由14个字符所组成, LOC //部门所在的位置);emp( EMPNO, //雇员的编号，由四位数字所组成 ENAME, //雇员的姓名，由10位字符所组成 JOB, //雇员的职位 MGR, //雇员对应的经理编号，经理也是雇员 HIREDATE, //雇员的雇佣日期 SAL, //基本工资，其中有两位小数，五倍整数，一共是七位 COMM, //奖金，佣金 DEPTNO //雇员所在的部门编号);salgrade( GRADE, //工资的等级 LOSAL, //此等级的最低工资 HISAL //此等级的最高工资);bonus( ENAME, //雇员姓名 JOB, //雇员职位 SAL, //雇员的工资 COMM //雇员的奖金);自连接自连接就是自己和自己连接，在使用时将一张表看做多张表使用。查询员工编号，员工姓名，经理的编号，经理的姓名KING没有经理，所以查询出来只有13条记录12345678910SELECT e1.empno, e1.ename, e1.mgr, m1.enameFROM emp e1, emp m1WHERE e1.mgr = m1.empno查询员工编号，员工姓名，员工的部门名称，经理的编号，经理的姓名12345678910111213SELECT e1.empno, e1.ename, d1.dname, e1.mgr, m1.enameFROM emp e1, emp m1, dept d1WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno查询员工编号，员工姓名，员工的部门名称，经理的编号，经理的姓名，经理的部门名称12345678910111213141516SELECT e1.empno, e1.ename, d1.dname, e1.mgr, m1.ename, d2.dnameFROM emp e1, emp m1, dept d1, dept d2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno这里有一个难点是为什么需要拓展出两张部门表？这里需要理解刚才说的一句话：在使用时将一张表看做多张表使用，想象一下，如果真实存在一张员工表和一张经理表，员工表.部门=部门.id，经理表.部门=部门.id，不就等于是经理和员工在一个部门才能要求吗？这个题意明显不符。查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称12345678910111213141516171819SELECT e1.empno, e1.ename, d1.dname, s1.grade, e1.mgr, m1.ename, d2.dnameFROM emp e1, emp m1, dept d1, dept d2, salgrade s1WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称，员工所属经理的工资等级12345678910111213141516171819202122SELECT e1.empno, e1.ename, d1.dname, s1.grade, e1.mgr, m1.ename, d2.dname, s2.gradeFROM emp e1, emp m1, dept d1, dept d2, salgrade s1, salgrade s2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal AND m1.sal BETWEEN s2.losal AND s2.hisal查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称，经理的工资等级（将工资等级 1,2,3,4 显示成 中文的 一级 二级 三级…）1234567891011121314151617181920212223242526272829303132333435363738394041424344SELECT e1.empno, e1.ename, d1.dname, CASE s1.grade WHEN 1 THEN '一级' WHEN 2 THEN '二级' WHEN 3 THEN '三级' WHEN 4 THEN '四级' ELSE '五级' END "等级", e1.mgr, m1.ename, d2.dname, CASE s2.grade WHEN 1 THEN '一级' WHEN 2 THEN '二级' WHEN 3 THEN '三级' WHEN 4 THEN '四级' ELSE '五级' END "等级"FROM emp e1, emp m1, dept d1, dept d2, salgrade s1, salgrade s2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal AND m1.sal BETWEEN s2.losal AND s2.hisal外连接数据准备：insert into emp(empno,ename) values(9527,&#39;HUAAN&#39;);左外连接以左表为基准，右表能匹配上左表则匹配，右表没有一条记录匹配上左表，左表显示为空。右连接是以右表为基准，左表能匹配上右表则匹配，左表没有一条记录匹配上右表，右表显示为空。查询员工所在的部门12345SELECT *FROM emp e1LEFT OUTER JOIN dept d1 ON e1.deptno = d1.deptno;查询部门的员工12345SELECT *FROM emp e1 RIGHT OUTER JOIN dept d1 ON e1.deptno = d1.deptno;子查询查询最高工资的员工信息123456SELECT *FROM empWHERE sal = (SELECT max(sal) FROM emp);查询出比雇员7654的工资高,同时和7788从事相同工作的员工信息123456789101112131415161718192021SELECT *FROM empWHERE sal &gt; ( SELECT sal FROM emp WHERE empno = 7654 )AND job = ( SELECT job FROM emp WHERE empno = 7788 );查询每个部门最低工资的员工信息和他所在的部门信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 查询每个部门的最低工资,分组统计SELECT deptno, min(sal) minsalFROM empGROUP BY deptno; # 员工工资等于他所处部门的最低工资SELECT *FROM emp e1, ( SELECT deptno, min(sal) minsal FROM emp GROUP BY deptno ) t1WHERE e1.deptno = t1.deptno AND e1.sal = t1.minsal;# 查询部门相关信息SELECT *FROM emp e1, ( SELECT deptno, min(sal) minsal FROM emp GROUP BY deptno ) t1, dept d1WHERE e1.deptno = t1.deptno AND e1.sal = t1.minsal AND e1.deptno = d1.deptno;查询领导信息123456SELECT *FROM empWHERE empno IN (SELECT mgr FROM emp);查询不是领导的信息1234567891011121314151617181920212223242526272829# 错误的写法SELECT *FROM empWHERE empno NOT IN (SELECT mgr FROM emp);# &lt;&gt; ALL 等价于 NOT INSELECT *FROM empWHERE empno &lt;&gt; ALL (SELECT mgr FROM emp); # 正确的写法SELECT *FROM empWHERE empno NOT IN ( SELECT mgr FROM emp WHERE mgr IS NOT NULL );查询出比20号部门所有员工薪资高的员工信息 10 20 301234567891011121314151617181920212223242526272829# 写法1SELECT *FROM empWHERE sal &gt; ( SELECT max(sal) FROM emp WHERE deptno = 20 ); # 写法2SELECT *FROM empWHERE sal &gt; ALL ( SELECT sal FROM emp WHERE deptno = 20 );查询有员工的部门的信息12345678910111213SELECT *FROM dept d1WHERE EXISTS ( SELECT * FROM emp e1 WHERE e1.deptno = d1.deptno );补充EXISTS假设有三张表，学生、课程、选课表。查询选修了全部课程的同学。1234567891011121314151617181920212223242526/* 思路： 从上面的例子可以看到EXITSTS其实是对外部表的某个字段做循环。循环变量带入内部表后判断 从内部表能否查出来信息，能查出来表示真（留下），查不出来表示假（去除）。 所以这个题就是对每个学生做循环，把学生带入内部查询，查询学生是否有未选修的课，如果有 学生去除，否则学生留下，所以选用not exists： select * from student where not exists (学生未选修的课) 假设某次循环的学号是 110，此时需要拿course中的每个课号到sc表中做循环，查询在sc表的 学号为110且course.no = sc.cno的情况下，记录是否存在，记录存在course去除，记录不存 在course留下，所以选用not exists： select * from course where not exists select * from sc where 110 = sc.sno and sc.cno = course.no; 这样，可以查出学号为110的同学未选修的课程。 结果： 把两次分析的合并之后： select * from student where not exists( select * from course where not exists( select * from sc where student.no = sc.sno and sc.cno = course.no; ) )*/现在还是这三张表，我们换个题，查询被所有学生选修的课程信息123456789101112131415161718192021/* 思路： 对课程做循环，把课程带入内部查询，如果有学生未选此课，课程去除，否则课程留下， 所以选用not exists：： select * from course where not exists (未被选的课) 假设某次循环，课号为120，此时拿student中的每个学号到sc表做循环，查询在sc表的课号为 120且student.no = sc.sno的情况下，记录是否存在，记录存在student去除，记录不存在 student留下，所以选用not exists：： select * from student where not exists select * from sc where student.no = sc.sno and 120 = sc.no 结果： 两次分析合并 select * from course where not exists( select * from student where not exists( select * from sc where course.no = sc.cno and sc.sno = student.no ) )*/查询没有一个学生选择的课：123456789101112/* 对course做循环，如果存在学生选此课去除，没有学生选此课保留，选用not exists： 对内部循环，记录存在保留，记录不存在去除，选用exists：*/select * from course where not exists( select * from student where exists( select * from sc where course.no = sc.cno and sc.sno = student.no ))事务ACIDA：原子性（Atomicity）：事务是数据库的逻辑工作单位事务中包括的诸操作要么都做，要么都不做。C：一致性（Consistency）：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。一致性状态：数据库中只包含成功事务提交的结果。不一致状态：数据库中包含失败事务的结果。I：隔离性（Isolation）：一个事务内部的操作及使用的数据对其他并发事务是隔离的。也就是说一个事务在执行的时候不知道是否有其他事务和它一起在对相同的数据做操作，事务之间是相对不可见的。D：持续性（Durability）：持续性也称永久性。一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其执行结果有任何影响。事务的并发问题由于事务的隔离性，不同事务若同时相同的数据做操作，可能会引发问题，即事务的并发问题。按照问题解决的难度由低至高可分为四类。丢失修改一个事务对数据对象的修改被另一个事务的修改所覆盖。分为两类：第一类：事务T1、T2同时读取A为10，T1将A减1后提交，T2将A也减1后提交，此时数据库中数据为9。T1的修改被T2覆盖。第一类：事务T1、T2同时读取A为10，T1将A减1后提交，T2将A也减1后回滚，此时数据库中数据为10。T1的修改被T2覆盖。脏读由于一个事物的回滚，使得另一个事务读到的数据无效。事务T1中读A为100，修改A未300，还未提交时事务T2读C为300，但由于T1因某原因进行事务回滚。A又被重置为100。T2读取到的是脏数据。不可重复读在一个事务的两次“读”同一数据之间，有另一个事务的“updata”发生。如在事务T1中第一次读A为100，读B为200，A+B为300，在事务T2中把A修改为200，事务T2第二次读A为200，读B为200，A+B为400。同一事务两次读取的数据不一致。幻读在一个事务的两次“读”同一数据之间，有另一个事务的“insert”发生。如在事务T1中第一次读count(*)为100，事务T2插入一条数据，事务T1中第二次读count(*)为101，同一事务两次读取的数据不一致。封锁类型加锁是解决事务并发问题的常见手段。数据库中的锁从读写的角度可分为两类：共享锁和排它锁。排它锁（X锁）：只允许当前事务T对数据进行“读”、“写”，其它事务对数据R的任何锁请求被拒绝直到T释放R上的X锁。共享锁（S锁）：允许当前事务T对数据R进行“读”，不允许“写“，而其它事务对R的S申请被允许，X请求拒绝。带来的效果是：X锁：数据对象当前只能由一个事务操作。S锁：多个事务允许同时“读”一个数据。封锁协议在运用X锁和S锁对数据对象加锁时，还需要约定一些规则 ，例如何时申请X锁或S锁、持锁时间、何时释放等。称这些规则为封锁协议。对封锁方式规定不同的规则，就形成了各种不同的封锁协议。一级封锁协议对T要“写”的R加X锁，直到T结束。此时可以解决丢失更新。此时仍然会发生：脏读：事务T2可以绕过X锁读取数据，且读取到的是T1回滚的数据。不可重复读：事务T2的两次读之间可以发生T1的”update“。幻读：事务T2的两次读之间可以发生T1的”insert“。二级封锁协议T发生“写”加X锁，直到T结束；（一级封锁协议）T发生“读”R加S锁，读完即释放。此时可以解决丢失修改和脏读。事务T1先对R进行写（加X锁），则事务T2在读时没法加S锁，直至T1结束。事务T2先对R进行读（加S锁），则事务T1在写时需要等待读结束（T1不一定结束）。此时仍然会发生：不可重复读：事务T1在第一次读之后（释放S锁），事务T2进行了”update”操作，事务T1再读得到的数据和上次不一致。幻读：事务T1在第一次读之后（释放S锁），事务T2进行了”insert”操作，事务T1再读得到的数据和上次不一致。三级封锁协议T发生“写”加X锁，直到T结束。T发生“读”加S锁，直到T结束。此时可以解决任何并发问题，因为无论对数据进行读还是写都要加锁：写：先加X锁，之后任何读写都被禁止。读：先加S锁，之后任何写操作都被被禁止。三级封锁协议仅允许不同的事务同时发生读操作。两段锁协议在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁。在释放一个封锁之后，事务不再获得任何其他封锁。满足所有遵守两段锁协议的事务，其并行执行的结果一定是正确的：先加X锁：X锁结束前（在两段锁协议中，不一定要事务结束才能释放X锁）任何锁都不能加上去，X锁结束后此事务不能再进行任何读写操作。先加S锁：S锁结束前，只能对其加S锁，即只允许多个事务同时读。一旦释放一个S锁，便任何锁都加不上去，只能完成为完成的读，不能再进行新的读写操作。满足三级封锁协议的一定满足两段锁协议：先加X锁，两种协议下事务结束之前任何读写都会被禁止。先加S锁，在两段锁协议中，若第一个锁的释放之后紧跟的事件就是事务的结束，此时就是三级封锁协议，即三级封锁协议是两段锁协议的一部分。事务的隔离级别读未提交：READ UNCOMMITTED。对应一级封锁协议。读已提交：READ COMMITTED。对应二级封锁协议。可重复读：REPEATABLE READ。二级封锁协议加上不允许事务读取在该事务开始后新提交的数据。即防止了不可重复读的发生。可串行化：SERIALIZABLE。对应三级封锁协议。MySql特点MySql默认的事务隔离级别是读已提交MySql的事务是自动提交，即即使未事务，MySql也会把每个SQL语句放在一个事务中运行，这个事务是MySql自动添加上去的。MySQL 基础架构分析1.1 MySQL 基本架构概览下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到用户的 SQL 语句在 MySQL 内部是如何执行的。先简单介绍一下下图涉及的一些组件的基本作用帮助大家理解这幅图，在 1.2 节中会详细介绍到这些组件的作用。连接器： 身份认证和权限相关(登录 MySQL 的时候)。查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。优化器： 按照 MySQL 认为最优的方案去执行。执行器: 执行语句，然后从存储引擎返回数据。简单来说 MySQL 主要分为 Server 层和存储引擎层：Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始就被当做默认存储引擎了。1.2 Server 层基本组件介绍连接器连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。查询缓存(MySQL 8.0 版本后移除查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集。连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。所以，一般在大多数情况下我们都是不推荐去使用查询缓存的。MySQL 8.0 版本后删除了缓存的功能，官方也是认为该功能在实际的应用场景比较少，所以干脆直接删掉了。分析器MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。优化器优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优，这篇文章涉及对这部分知识的深入讲解），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。执行器当选择了执行方案后，MySQL 就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果。语句分析查询语句说了以上这么多，那么究竟一条 sql 语句是如何执行的呢？其实我们的 sql 可以分为两种，一种是查询，一种是更新（增加，更新，删除）。我们先分析下查询语句，语句如下：1select * from tb_student A where A.age='18' and A.name=' 张三 ';结合上面的说明，我们分析下这个语句的执行流程：先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。通过分析器进行词法分析，提取 sql 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student,需要查询所有的列，查询条件是这个表的 id=’1’。然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。接下来就是优化器进行确定执行方案，上面的 sql 语句，可以有两种执行方案：12a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。更新语句以上就是一条查询 sql 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？sql 语句如下：1update tb_student A set A.age=&apos;19&apos; where A.name=&apos; 张三 &apos;;我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块式 binlog（归档日志） ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 redo log（重做日志），我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：先查询到张三这一条数据，如果有缓存，也是会用到缓存。然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。更新完成。这里肯定有同学会问，为什么要用两个日志模块，用一个日志模块不行吗?这是因为最开始 MySQL 并没与 InnoDB 引擎( InnoDB 引擎是其他公司以插件形式插入 MySQL 的) ，MySQL 自带的引擎是 MyISAM，但是我们知道 redo log 是 InnoDB 引擎特有的，其他存储引擎都没有，这就导致会没有 crash-safe 的能力(crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。并不是说只用一个日志模块不可以，只是 InnoDB 引擎就是通过 redo log 来支持事务的。那么，又会有同学问，我用两个日志模块，但是不要这么复杂行不行，为什么 redo log 要引入 prepare 预提交状态？这里我们用反证法来说明下为什么要这么做？先写 redo log 直接提交，然后写 binlog，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。如果采用 redo log 两阶段提交的方式就不一样了，写完 binglog 后，然后再提交 redo log 就会防止出现上述的问题，从而保证了数据的一致性。那么问题来了，有没有一个极端的情况呢？假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？ 这个就要依赖于 MySQL 的处理机制了，MySQL 的处理过程如下：判断 redo log 是否完整，如果判断是完整的，就立即提交。如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。这样就解决了数据一致性的问题。总结MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。查询语句的执行流程如下：权限校验（如果命中缓存）—》查询缓存—》分析器—》优化器—》权限校验—》执行器—》引擎更新语句执行流程如下：分析器—-》权限校验—-》执行器—》引擎—redo log(prepare 状态—》binlog—》redo log(commit状态)关系 &amp; 关系模式关系模式相当于一张二维表的框架，在这个框架下填入数据，称为关系模式的一个实例，或者叫关系R。关系模式的形式化定义是：$R(U,D,DOM,F)$R：关系名U：组成该关系的属性名集合D：U中属性所来自的域域：一组具有相同数据类型的值的集合DOM：属性向域的映像集合F：属性间数据的依赖关系集合由于D和DOM域与关系模式的设计无关，因此在讨论关系数据库理论时可以把关系模式看做：$R(U,F)$关系的形式化定义：当且仅当$U$上的一个关系$r$满足$F$时，r称为关系模式$R(U,F)$上的一个关系。范式关系模式的设计直接影响着后续增删查改等的操作。如果设计的不合理就会发生各种各样的问题：数据冗余太大更新异常插入异常删除异常比如对于一个描述学校在校生信息数据库：$Student&lt;U,F&gt;$，$U=\lbrace Sno,Sdept,Mname,Cname,Grade\rbrace$会发生的问题：冗余问题：每个系的系主任姓名重复出现，重复次数与该系所有学生的所有课程成绩次数相同更新问题：如果某系的系主任更换后，该数据库该系中所有的元组都要更新插入异常：如果一个系刚成立，尚无学生，则无法把该系的系主任存入数据库删除异常：如果某个系的学生都毕业了，在删除该系学生的同时，该系系主任的信息也会被删除一个好的模式不能发生插入异常、删除异常和更新异常，数据冗余应该尽可能少。定义范式指的是规范化的关系模式，而规范也就是条件，满足不同的条件可以分别解除上述所说的不同问题。问题发生的原因之所以会发生上诉的问题其实就是由于数据依赖。而数据依赖可以分为两种：函数依赖和多值依赖。但这两种依赖关系不是平级，而是递进的关系，所以我们先介绍函数依赖。函数依赖设$R(U)$是一个属性集$U$上的关系模式，$X$和$Y$是$U$的子集。若对于$R(U)$的任意两个可能的关系$r_1$、$r_2$，若$r_1[x]=r_2[x]$，则$r_1[y]=r_2[y]$，则称$X$决定$Y$，或者$Y$依赖$X$。记作$X \rightarrow Y$。对于$X$、$Y$范围的不同，可以再次分为：非平凡函数依赖：如果$X \rightarrow Y$但$Y \nsubseteq X$，则称$X \rightarrow Y$是非平凡函数依赖平凡函数依赖：如果$X \rightarrow Y$但$Y \subseteq X$，则称$X \rightarrow Y$是非平凡函数依赖。例：$(Sno,Sname) \rightarrow Sname$所以，在关系模式中，平凡函数依赖是一定是可以被满足的，所以我们在以后的讨论中不再关注平凡函数依赖，只关注非平凡函数依赖。而我们对于非平凡函数依赖又可以分为以下几类：完全函数依赖：如果$X \rightarrow Y$，并且对于任意的真子集$X_i$，都无法做到$X_i \rightarrow Y$，则称$Y$对$X$是完全函数依赖。部分函数依赖：如果$X \rightarrow Y$，存在真子集$X_i$，可以做到$X_i \rightarrow Y$，则称$Y$对$X$是部分函数依赖。传递函数依赖：如果$X \rightarrow Y$，$Y \rightarrow Z$且$Y \nrightarrow X$，则称$X$对$X$有传递函数依赖。第一范式在关系模型中的每一个具体关系$R$中，如果每个属性都是不可再分的，则称$R$属于第一范式，记作$R \in 1NF$。第二范式$R \in 1NF$且每一个非主属性完全函数依赖于码，则$R \in 2NF$。依赖有直接依赖和传递依赖。第三范式$R \in 2NF$且$R$中的每个非主属性不传递依赖于主码，则关系$R$是第三范式，$R \in 3NF$。模式分解从低级范式到高级范式的方法是模式分解。举例：对于一个关系$R(SNO,SNA,CNO,GRADE,CNA,TNA,TAGE)$（学号、姓名、课号、成绩、课程名称、教师姓名、教师年龄）。现实语义：如果假设一个教师可以交多门课且一门课仅由一个教师讲授，可得R的函数依赖集：$SNO \rightarrow SNM$$(SNO,CNO) \rightarrow GRADE$$CNO \rightarrow CNA$$CNO \rightarrow TNA$$TNA \rightarrow TAGE$函数依赖图如下：分解为第二范式：$R1&lt;(SNO,SNA),SNO \rightarrow SNA&gt;$$R2&lt;(SNO,CNO,GRADE), (SNO,CNO) \rightarrow GRADE&gt;$$R3&lt;(CNO,CNA,TNA,TAGE),CNO \rightarrow CNA, CNO \rightarrow TNA, TNA \rightarrow TAGE&gt;$分解为第三范式：$R1&lt;(SNO,SNA),SNO \rightarrow SNA&gt;$$R2&lt;(SNO,CNO,GRADE), (SNO,CNO) \rightarrow GRADE&gt;$$R3&lt;(CNO,CNA,TNA),CNO \rightarrow CNA, CNO \rightarrow TNA&gt;$$R3&lt;(CNO,TAGE),CNO \rightarrow TAGE&gt;$第三范式的问题仓库保管$WPE(W#,P#,E#,QNT)$，（ 仓库号，器件号，职工号，数量）。一个职工只能管理一个仓库的某类型器件，一个仓库的某类型器件数量是确定的，一个员工管理的某类型器件数量是一定的。函数依赖：$(W#, P#) \rightarrow QNT$$(E#,P#) \rightarrow QNT$$(W#,P#) \rightarrow E#$$E# \rightarrow W#$函数依赖图：此时关系模式$WPE$有两个侯选码，$(W#,P#)$ ，$(E#,P#)$，假设确定$(E#,P#)$为主码，那么某新职工分配来仓库，处于学习阶段，但没有独立承但任务，即有$E#$但无$P#$，缺少码的组成部分，无法插入到该关系，即插入异常。这是由于主属性$W#$对另一个侯选码$(E#,P#)$的部分函数依赖。BC范式BC范式的定义：每个决定因素都包含码，则$R \in BCNF$。而既然每个决定因素都要包含码，则此时意味着必须放弃某些函数依赖，即失去某些现实语义。如例子中若选择$(E#,P#)$，则只能保存函数依赖中的2和4。多值依赖设$R(U)$是属性集U上的一个关系模式。$X$，$Y$，$Z$是的$U$的子集，并且$Z=U-X-Y$。关系模式$R(U)$中多值依赖（记做，$X \rightarrow \rightarrow Y$）成立，当且仅当对$R(U)$的任一关系$r$，给定的一对$(x,z)$值有一组$Y$的值，这组值仅仅决定于$x$值而与$z$值无关。若$X \rightarrow \rightarrow Y$，$Z$为空，则称$X \rightarrow \rightarrow Y$为平凡的多值依赖。 所以我们以下只讨论非平凡的函数依赖。例比如对于关系模型$Teaching(C,T,B)$便是存在多值依赖（码为全属性）：第四范式如果对于$R$的每个非平凡多值依赖$X \rightarrow \rightarrow Y$，$X$都含有码，则$R$都含有码。多值依赖的解决依然是分解。如上例中分解为：$R(C,T)$$R(C,B)$]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Java基础]]></title>
    <url>%2F2019%2F01-Java%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JVM &amp; JDK &amp; JREJVMJava虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。什么是字节码?采用字节码的好处是什么?在 Java 中，JVM可以理解的代码就叫做字节码（即扩展名为 .class 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，由于字节码并不针对一种特定的机器，因此，Java程序无须重新编译便可在多种不同操作系统的计算机上运行。Java 程序从源代码到运行一般有下面3步：我们需要格外注意的是 .class-&gt;机器码 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的（也就是所谓的热点代码），所以后面引进了 JIT 编译器，而JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 Java 是编译与解释共存的语言。HotSpot采用了惰性评估（Lazy Evaluation）的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是JIT所需要编译的部分。JVM会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9引入了一种新的编译模式AOT（Ahead of Time Compilation），它是直接将字节码编译成机器码，这样就避免了JIT预热等各方面的开销。JDK支持分层编译和AOT协作使用。但是 ，AOT 编译器的编译质量是肯定比不上 JIT 编译器的。总结：Java虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。JDK 和 JREJDK是Java Development Kit，它是功能齐全的Java SDK。它拥有JRE所拥有的一切，还有编译器（javac）和工具（如javadoc和jdb）。它能够创建和编译程序。JRE 是 Java运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java虚拟机（JVM），Java类库，java命令和其他的一些基础构件。但是，它不能用于创建新程序。如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装JDK了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何Java开发，仍然需要安装JDK。例如，如果要使用JSP部署Web应用程序，那么从技术上讲，您只是在应用程序服务器中运行Java程序。那你为什么需要JDK呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。Java和C++的区别都是面向对象的语言，都支持封装、继承和多态Java 不提供指针来直接访问内存，程序内存更加安全Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。Java 有自动内存管理机制，不需要程序员手动释放无用内存异常异常是程序在运行时出现的会导致程序运行终止的错误。这种错误是不能通过编译系统检查出来的。常见的异常的发生原因为系统资源错误和用户操所错误两种。Java把异常信息封装成一个类。当发生某种异常时将某种对应的类作为异常信息抛出。异常的根类时Throwable，其有两个直接子类 Error和Exception。Error是描述系统资源错误的类。Exception是描述用户操作错误的类。发生了Error就是必须修改代码或调整外部环境问题，程序肯定会终止。比如需要开辟一个内存大小为99999999个int的数组。一般来说Error很少发生。发生了Exception就要进行处理，使程序运行下去，如数组越界异常。而Exception又可以分为两种，一种是程序本身存在的问题引发的异常（健壮性不够），即：RuntimeException；一种是程序本身可能没有问题，但遇到诸如文件不存在所导致的错误，Excption中除了RuntimeException外都是此种异常。而RuntimeException是不允许存在的，遇到RuntimeException就说明程序有问题，需要修改代码。受查异常、非受查异常Java语言规范规定派生于Error类或RuntimeException类的异常都称为非受查异常，其余异常都被成为受查异常。受查异常就是必须告诉它的调用者可能会出现异常，让其调用者抛出或者捕获处理，这类异常如果没有在程序中进行异常处理，编译不通过。非受查异常则不需要。声明受查异常（throws）除了Error和RuntimeException的异常都是受查异常，这些异常如：IOException、SQLException等，在可能发生的方法中需要被声明。同时非受查异常最好不要被声明。需要使用throws声明异常后的情况如下：调用一个抛出受查异常的方法：public int read() throws IOException方法中使用throw语句抛出了受查异常。抛出异常（throw）throw可以用于抛出异常对象，一般是受查异常对象。格式如下例：123public static void demo() throws Exception&#123; throw new Exception("出现异常");&#125;return和finally的决斗一旦进入try … catch …的异常捕获结构，无论try和catch的语句块有没有return语句，finally一定会被执行，但是如果finally中还有return语句，return之后的不会被执行。同时后来的return值会覆盖之前的return值。但若未进入异常捕获结构则return后不允许有语句，因为即使有也一定不会被执行。12345678910111213141516171819202122232425262728293031public class InterviewReview &#123; public static void main(String[] args) &#123; System.out.println(test()); &#125; static Integer test() &#123; try &#123; System.out.println("111"); int i = 1 / 0; System.out.println("222"); return 0;// System.out.println("333"); // 报错 &#125;catch (Exception e) &#123; System.out.println("---"); int j = 1 / 0; System.out.println("```"); return 10;// System.out.println("..."); // 报错 &#125; finally &#123; System.out.println("aaa"); return 100;// System.out.println("bbb"); // 报错 &#125; &#125;&#125; /* 111 --- aaa 100*/final修饰类当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。修饰方法只有在想明确禁止该方法在子类中被覆盖的情况下才将方法设置为final的。即父类的final方法是不能被子类所覆盖的。重写的前提是子类可以从父类中继承此方法，如果父类中final修饰的方法同时访问控制权限为private，将会导致子类中不能直接继承到此方法，因此，此时可以在子类中定义方法签名相同的方法，此时不再产生重写与final的矛盾，而是在子类中重新定义了新的方法。（注：类的private方法会隐式地被指定为final方法。）修饰变量final成员变量表示常量，只能被赋值一次，赋值后值不再改变。当final修饰一个基本数据类型时，表示该基本数据类型的值一旦在初始化后便不能发生变化；如果final修饰一个引用类型时，则在对其初始化之后便不能再让其指向其他对象了，但该引用所指向的对象的内容是可以发生变化的。本质上是一回事，因为引用的值是一个地址，final要求值，即地址的值不发生变化。final修饰一个成员变量，必须要显示初始化。这里有两种初始化方式，一种是在变量声明的时候初始化；第二种方法是在声明变量的时候不赋初值，但是要在这个变量所在的类的所有的构造函数中对这个变量赋初值。finalizeObject 类的一个方法，在垃圾回收器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。该方法更像是一个对象生命周期的临终方法，当该方法被系统调用则代表该对象即将“死亡”，但是需要注意的是，我们主动行为上去调用该方法并不会导致该对象“死亡”，这是一个被动的方法（其实就是回调方法），不需要我们调用。static修饰方法在静态方法中不能访问类的非静态成员变量和非静态成员方法。在非静态成员方法中是可以访问静态成员方法/变量的。123456789101112131415public class InterviewReview extends Dad&#123; public static void main(String[] args) &#123; test(); &#125; static void test() &#123; // static方法可以被重新定义 System.out.println("son"); &#125; &#125; class Dad&#123; static void test() &#123; System.out.println("dad"); &#125;&#125;面试题12345678910111213141516171819202122232425262728public class Test extends Base&#123; static&#123; System.out.println("test static"); &#125; public Test()&#123; System.out.println("test constructor"); &#125; public static void main(String[] args) &#123; new Test(); &#125;&#125; class Base&#123; static&#123; System.out.println("base static"); &#125; public Base()&#123; System.out.println("base constructor"); &#125;&#125;/* 父类先于子类、静态先于普通 base static test static base constructor test constructor*/1234567891011121314151617181920212223242526272829303132333435363738public class Test &#123; Person person = new Person("Test"); static&#123; System.out.println("test static"); &#125; public Test() &#123; System.out.println("test constructor"); &#125; public static void main(String[] args) &#123; new MyClass(); &#125;&#125;class Person&#123; static&#123; System.out.println("person static"); &#125; public Person(String str) &#123; System.out.println("person " + str); &#125;&#125;class MyClass extends Test &#123; Person person = new Person("MyClass"); static&#123; System.out.println("myclass static"); &#125; public MyClass() &#123; System.out.println("myclass constructor"); &#125;&#125;/* test static myclass static person static person Test test constructor person MyClass myclass constructor*/首先加载Test类，因此会执行Test类中的static块。接着执行new MyClass()，而MyClass类还没有被加载，因此需要加载MyClass类。在加载MyClass类的时候，发现MyClass类继承自Test类，但是由于Test类已经被加载了，所以只需要加载MyClass类，那么就会执行MyClass类的中的static块。在加载完之后，就通过构造器来生成对象。而在生成对象的时候，必须先初始化父类的成员变量，因此会执行Test中的Person person = new Person()，而Person类还没有被加载过，因此会先加载Person类并执行Person类中的static块，接着执行父类的构造器，完成了父类的初始化，然后就来初始化自身了，因此会接着执行MyClass中的Person person = new Person()，最后执行MyClass的构造器。重载和重写重写参数列表必须完全与被重写方法的相同；返回类型与被重写方法的返回类型可以不相同，但是必须是父类返回值的派生类访问权限不能比父类中被重写的方法的访问权限更低。父类的成员方法只能被它的子类重写。声明为final的方法不能被重写。声明为static的方法不能被重写，但是能够被再次声明。子类和父类在同一个包中，那么子类可以重写父类所有方法，除了声明为private和final的方法。子类和父类不在同一个包中，那么子类只能够重写父类的声明为public和protected的非final方法。重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。但是，重写的方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常。构造方法不能被重写。如果不能继承一个方法，则不能重写这个方法。重载被重载的方法必须改变参数列表（参数个数或类型不一样）；被重载的方法可以改变返回类型；被重载的方法可以改变访问修饰符；被重载的方法可以声明新的或更广的检查异常；方法能够在同一个类中或者在一个子类中被重载。无法以返回值类型作为重载函数的区分标准。区别区别点重载方法重写方法参数列表必须修改一定不能修改返回类型可以修改一定不能修改异常可以修改可以减少或删除，一定不能抛出新的或者更广的异常访问可以修改一定不能做更严格的限制（可以降低限制）抽象类抽象类中可以定义构造器可以有抽象方法和具体方法抽象类中可以定义成员变量有抽象方法的类必须被声明为抽象类，而抽象类未必要有抽象方法抽象一个类只能继承一个抽象类抽象类可以包含静态方法抽象方法不可同时是静态的、不能同时是本地的、也不能同时被synchronized修饰。抽象方法需要子类重写，而静态的方法是无法被重写的，因此二者是矛盾的。本地方法是由本地代码（如 C 代码）实现的方法，而抽象方法是没有实现的，也是矛盾的。synchronized 和方法的实现细节有关，抽象方法不涉及实现细节，因此也是相互矛盾的。接口接口中不能定义构造器方法全部都是抽象方法抽象类中的成员可以是 private、默认、protected、public接口中定义的成员变量实际上都是常量接口中不能有静态方法一个类可以实现多个接口接口和抽象类的区别是什么接口的方法默认是 public，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。接口中除了static、final变量，不能有其他变量，而抽象类中则不一定。一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过extends关键字扩展多个接口。接口方法默认修饰符是public，抽象方法可以有public、protected和default这些修饰符（抽象方法就是为了被重写所以不能使用private关键字修饰！）。从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。备注：在JDK8中，接口也可以定义静态方法，可以直接用接口名调用。实现类和实现是不可以调用的。如果同时实现两个接口，接口中定义了一样的默认方法，则必须重写，不然会报错。基本类型和包装类型1234567891011121314151617181920212223242526public static void testInter() &#123; Integer a = new Integer(200); Integer b = new Integer(200); Integer c = 200; Integer e = 200; int d = 200; Object o = 200; System.out.println("基本类型和数字常量 ==判断" + (o == c)); System.out.println("基本类型和数字常量 equal判断" + c.equals(o)); System.out.println("两个new出来的对象 ==判断" + (a == b)); System.out.println("两个new出来的对象 equal判断" + a.equals(b)); System.out.println("new出的对象和用int赋值的Integer ==判断" + (a == c)); System.out.println("new出的对象和用int赋值的Integer equal判断" + (a.equals(c))); System.out.println("两个用int赋值的Integer ==判断" + (c == e)); System.out.println("两个用int赋值的Integer equal判断" + (c.equals(e))); System.out.println("基本类型和new出的对象 ==判断" + (d == a)); System.out.println("基本类型和new出的对象 equal判断" + (a.equals(d))); System.out.println("基本类型和自动装箱的对象 ==判断" + (d == c)); System.out.println("基本类型和自动装箱的对象 equal判断" + (c.equals(d))); Integer f = 100; Integer g = 100; // 如果在-128到127之间相等的话，它们会共用一块内存 System.out.println(f == g); &#125;自动装箱发生的过程是：基本类型转换为包装类型。自动拆箱发生的过程是：包装类型转换为基本类型。123456789101112131415161718192021222324Integer i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println("i1=i2 " + (i1 == i2));System.out.println("i1=i2+i3 " + (i1 == i2 + i3));System.out.println("i1=i4 " + (i1 == i4));System.out.println("i4=i5 " + (i4 == i5));System.out.println("i4=i5+i6 " + (i4 == i5 + i6)); System.out.println("40=i5+i6 " + (40 == i5 + i6)); /* i1=i2 true i1=i2+i3 true i1=i4 false i4=i5 false 语句i4 == i5 + i6，因为+这个操作符不适用于Integer对象，首先i5和i6进行自动拆箱操作，进行数 值相加，即i4 == 40。然后Integer对象无法与数值进行直接比较，所以i4自动拆箱转为int值40，最终 这条语句转为40 == 40进行数值比较。 i4=i5+i6 true 40=i5+i6 true*/Java 基本类型的包装类中：Byte，Short，Integer，Long，Character，Boolean实现了常量池技术；Float，Double 并没有实现常量池技术。Character缓存了[0,127]之间的数据，Boolean缓存了true和false，其他4种包装类默认创建了数值[-128,127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。int的范围12345678// 补码会进行循环System.out.println(Integer.MAX_VALUE); // 2147483647System.out.println(Integer.MAX_VALUE + 1); // -2147483648System.out.println(Integer.MAX_VALUE + 2); // -2147483647System.out.println(Integer.MIN_VALUE); // -2147483648System.out.println(Integer.MIN_VALUE - 1); // 2147483647System.out.println(Integer.MIN_VALUE - 2); // 2147483646基本类型之间的转换byte、short、int、long：小范围向大范围的可以自动转，大范围向小范围需要强制转。char可以自动转换为int、long，可以强制转换为short、byte。byte、short、int、long都需要强制转换才能转为char。float自动转换为double，double强制转换为float。byte、short、int、long可以自动float和double。反之需要强制转换。+=和-=包含自动转换，即short s1 = 1; s1 += 1;不会报错。对象克隆多层浅拷贝1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class CloneTest&#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Body body = new Body(new Head(new Face(new String("丑")))); Body body1 = (Body) body.clone(); System.out.println("body == body1 : " + (body == body1)); System.out.println("body.head == body1.head : " + (body.head == body1.head)); System.out.println(body.head.face == body1.head.face); System.out.println(body.head.face.name == body1.head.face.name); &#125;&#125;class Body implements Cloneable &#123; public Head head; public Body(Head head) &#123; this.head = head; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Body newBody = (Body) super.clone(); newBody.head = (Head) head.clone(); return newBody; &#125;&#125;class Head implements Cloneable &#123; public Face face; public Head(Face face) &#123; this.face = face; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; Head newHead = (Head)super.clone(); newHead.face = (Face) face.clone(); return newHead; &#125;&#125;class Face implements Cloneable&#123; public Face(String name) &#123; this.name = name; &#125; public String name; @Override protected Object clone() throws CloneNotSupportedException &#123; Face newFace = (Face)super.clone(); newFace.name = new String(this.name); return newFace; &#125;&#125;序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class CloneTest &#123; public static void main(String[] args) &#123; try &#123; Person p1 = new Person("Hao LUO", 33, new Car("Benz", 300)); Person p2 = CloneUtils.clone(p1); // 深度克隆 p2.getCar().setBrand("BYD"); System.out.println(p1); System.out.println(p2); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;class CloneUtils &#123; private CloneUtils() &#123; throw new AssertionError(); &#125; @SuppressWarnings("unchecked") public static &lt;T extends Serializable&gt; T clone(T obj) throws Exception &#123; ByteArrayOutputStream bout = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bout); oos.writeObject(obj); ByteArrayInputStream bin = new ByteArrayInputStream(bout.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bin); return (T) ois.readObject(); &#125;&#125;class Person implements Serializable &#123; private static final long serialVersionUID = -9102017020286042305L; private String name; // 姓名 private int age; // 年龄 private Car car; // 座驾 public Person(String name, int age, Car car) &#123; this.name = name; this.age = age; this.car = car; &#125; // ... getter方法和setter方法 @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + ", car=" + car + "]"; &#125;&#125;class Car implements Serializable &#123; private static final long serialVersionUID = -5713945027627603702L; private String brand; // 品牌 private int maxSpeed; // 最高时速 public Car(String brand, int maxSpeed) &#123; this.brand = brand; this.maxSpeed = maxSpeed; &#125; // ... getter和setter方法 @Override public String toString() &#123; return "Car [brand=" + brand + ", maxSpeed=" + maxSpeed + "]"; &#125;&#125;泛型泛型类123456789101112131415161718192021222324//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123; //key这个成员变量的类型为T,T的类型由外部指定 private T key; //泛型构造方法形参key的类型也为T，T的类型由外部指定 public Generic(T key) &#123; this.key = key; &#125; //泛型方法getKey的返回值类型为T，T的类型由外部指定 public T getKey()&#123; return key; &#125; public static void main(String[] args) &#123; //泛型的类型参数只能是类类型（包括自定义类），不能是简单类型 //传入的实参类型需与泛型的类型参数类型相同，即为Integer. Generic&lt;Integer&gt; genericInteger = new Generic&lt;Integer&gt;(123456); //传入的实参类型需与泛型的类型参数类型相同，即为String. Generic&lt;String&gt; genericString = new Generic&lt;String&gt;("key_vlaue"); System.out.println("key is " + genericInteger.getKey().getClass()); System.out.println("key is " + genericString.getKey().getClass()); &#125; &#125;泛型接口的实现1234//定义一个泛型接口public interface Generator&lt;T&gt; &#123; public T next();&#125;当实现泛型接口的类，未传入泛型实参时：123456789/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; * 如果不声明泛型，如：class FruitGenerator implements Generator&lt;T&gt;，编译器会报错："Unknown class" */class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; @Override public T next() &#123; return null; &#125;&#125;当实现泛型接口的类，传入泛型实参时：1234567891011121314151617/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator&lt;T&gt; * 但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：Generator&lt;T&gt;，public T next();中的的T都要替换成传入的String类型。 */public class FruitGenerator implements Generator&lt;String&gt; &#123; private String[] fruits = new String[]&#123;"Apple", "Banana", "Pear"&#125;; @Override public String next() &#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125;泛型通配符1234567891011121314151617181920212223242526272829303132333435//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123; //key这个成员变量的类型为T,T的类型由外部指定 private T key; //泛型构造方法形参key的类型也为T，T的类型由外部指定 public Generic(T key) &#123; this.key = key; &#125; //泛型方法getKey的返回值类型为T，T的类型由外部指定 public T getKey()&#123; return key; &#125; public static void showKeyValue(Generic&lt;Number&gt; obj)&#123; System.out.println("key value is " + obj.getKey()); &#125; public void showKeyValue1(Generic&lt;?&gt; obj)&#123; System.out.println("key value is " + obj.getKey()); &#125; public static void main(String[] args) &#123; Generic&lt;Integer&gt; gInteger = new Generic&lt;Integer&gt;(123); Generic&lt;Number&gt; gNumber = new Generic&lt;Number&gt;(456); showKeyValue(gNumber); // showKeyValue这个方法编译器会为我们报错： // Generic&lt;java.lang.Integer&gt; cannot be applied to Generic&lt;java.lang.Number&gt; // showKeyValue(gInteger); showKeyValue1(gNumber); // 正常 showKeyValue1(gInteger); // 正常 &#125;&#125;Generic&lt;Integer&gt;不能被看作为Generic&lt;Number&gt;的子类。由此可以看出:同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。类型通配符一般是使用？代替具体的类型实参，注意了，此处？是类型实参，而不是类型形参 。再直白点的意思就是，此处的？和Number、String、Integer一样都是一种实际的类型，可以把？看成所有类型的父类。是一种真实的类型。可以解决当具体类型不确定的时候，这个通配符就是 ? ；当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用 ? 通配符来表未知类型。泛型方法泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。123456789101112131415/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法。 * 2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 * 3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 * 4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException , IllegalAccessException&#123; T instance = tClass.newInstance(); return instance;&#125;泛型”方法”的详细举例12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class GenericTest &#123; //这个类是个泛型类，在上面已经介绍过 public class Generic&lt;T&gt;&#123; private T key; public Generic(T key) &#123; this.key = key; &#125; //我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。 //这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。 //所以在这个方法中才可以继续使用 T 这个泛型。 public T getKey()&#123; return key; &#125; /** * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息"cannot reslove symbol E" * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。 public E setKey(E key)&#123; this.key = keu &#125; */ &#125; /** * 这才是一个真正的泛型方法。 * 首先在public与返回值之间的&lt;T&gt;必不可少，这表明这是一个泛型方法，并且声明了一个泛型T * 这个T可以出现在这个泛型方法的任意位置. * 泛型的数量也可以为任意多个 * 如：public &lt;T,K&gt; K showKeyName(Generic&lt;T&gt; container)&#123; * ... * &#125; */ public &lt;T&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println("container key :" + container.getKey()); //当然这个例子举的不太合适，只是为了说明泛型方法的特性。 T test = container.getKey(); return test; &#125; /** * 这个方法是有问题的，编译器会为我们提示错误信息："UnKnown class 'E' " * 虽然我们声明了&lt;T&gt;,也表明了这是一个可以处理泛型的类型的泛型方法。 * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。 public &lt;T&gt; T showKeyName(Generic&lt;E&gt; container)&#123; ... &#125; */&#125;类中的泛型方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class GenericFruit &#123; class Fruit&#123; public String toString() &#123; return "fruit"; &#125; &#125; class Apple extends Fruit&#123; public String toString() &#123; return "apple"; &#125; &#125; class Person&#123; public String toString() &#123; return "Person"; &#125; &#125; class GenerateTest&lt;T&gt;&#123; //方法中的T和类上声明的T一致 public void show_1(T t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 //由于泛型方法在声明的时候会声明泛型&lt;E&gt;，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。 public &lt;E&gt; void show_3(E t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。 //编译器会报警告：The type parameter T is hiding the type T public &lt;T&gt; void show_2(T t)&#123; System.out.println(t.toString()); &#125; &#125; public static void main(String[] args) &#123; Apple apple = new GenericFruit().new Apple(); Person person = new GenericFruit().new Person(); GenerateTest&lt;Fruit&gt; generateTest = new GenericFruit().new GenerateTest&lt;Fruit&gt;(); //apple是Fruit的子类，所以这里可以 generateTest.show_1(apple); //编译器会报错，因为泛型类型实参指定的是Fruit，而传入的实参类是Person //generateTest.show_1(person); //使用这两个方法都可以成功 generateTest.show_2(apple); generateTest.show_2(person); //使用这两个方法也都可以成功 generateTest.show_3(apple); generateTest.show_3(person); &#125;&#125;静态方法与泛型类中的静态方法使用泛型：静态方法无法访问类上定义的泛型；如果静态方法操作的引用数据类型不确定的时候，必须要将泛型定义在方法上。即：如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法 。12345678910111213ublic class StaticGenerator&lt;T&gt; &#123; .... .... /** * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法） * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。 * 如：public static void show(T t)&#123;..&#125;,此时编译器会提示错误信息： "StaticGenerator cannot be refrenced from static context" */ public static &lt;T&gt; void show(T t)&#123; &#125;&#125;泛型上下边界上边界为泛型添加上边界，即传入的类型实参必须是指定类型的子类型类12345public class Generic&lt;T extends Number&gt;&#123; private T key; public Generic(T key) &#123; this.key = key; &#125; public T getKey()&#123; return key; &#125;&#125;类的成员方法123public void showKeyValue2(Generic&lt;? extends Number&gt; obj)&#123; System.out.println("key value is " + obj.getKey());&#125;泛型方法1234567//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的&lt;T&gt;上添加上下边界，即在泛型声明的时候添加//public &lt;T&gt; T showKeyName(Generic&lt;T extends Number&gt; container)，编译器会报错："Unexpected bound"public &lt;T extends Number&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println("container key :" + container.getKey()); T test = container.getKey(); return test;&#125;限制类C中方法：void setC(T t)。在传入&lt;? extends Fruit&gt;之后：void setC(&lt;? extends Fruit&gt; t)。这时编译器就不知道你传过来的是什么类型，编译不会通过。但是类中的方法可以返回T，因为已经知道了它的上限是A，在调用之后用A来接收一下返回的对象就可以了。12GenerateTest&lt;? extends Fruit&gt; generateTest2 = new GenericFruit().new GenerateTest&lt;&gt;();generateTest2.setC(apple); //报错下边界&lt;? super A&gt;表示传入的只能是A的超类或超接口。此时，类中的方法void setC(T t)可以传入A或A的子类作为参数。但返回时只能返回Object对象。1GenerateTest&lt;? super Apple&gt; generateTest2 = new GenericFruit().new GenerateTest&lt;&gt;();Object object = generateTest2.get();泛型数组sun的说明文档，在java中是”不能创建一个确切的泛型类型的数组”的。也就是说下面的这个例子是不可以的：1List&lt;String&gt;[] ls = new ArrayList&lt;String&gt;[10];而使用通配符创建泛型数组是可以的，如下面这个例子：1List&lt;?&gt;[] ls = new ArrayList&lt;?&gt;[10];这样也是可以的：1List&lt;String&gt;[] ls = new ArrayList[10];下面使用Sun的一篇文档的一个例子来说明这个问题：1234567891011List&lt;String&gt;[] lsa = new List&lt;String&gt;[10]; // Not really allowed. Object o = lsa;Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Unsound, but passes run time store check String s = lsa[1].get(0); // Run-time error: ClassCastException./**这种情况下，由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的，所以可以给oa[1]赋上一个ArrayList而不会出现异常，但是在取出数据的时候却要做一次类型转换，所以就会出现ClassCastException，如果可以进行泛型数组的声明，上面说的这种情况在编译期将不会出现任何的警告和错误，只有在运行时才会出错。而对泛型数组的声明进行限制，对于这样的情况，可以在编译期提示代码有类型安全问题，比没有任何提示要强很多。*/下面采用通配符的方式是被允许的:数组的类型不可以是类型变量，除非是采用通配符的方式，因为对于通配符的方式，最后取出数据是要做显式的类型转换的。1234567List&lt;?&gt;[] lsa = new List&lt;?&gt;[10]; // OK, array of unbounded wildcard type. Object o = lsa; Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Correct. Integer i = (Integer) lsa[1].get(0); // OK内部类成员内部类成员内部类是最普通的内部类，它的定义为位于另一个类的内部，形如下面的形式：1234567891011class Circle &#123; double radius = 0; public Circle(double radius) &#123; this.radius = radius; &#125; class Draw &#123; //内部类 public void drawSahpe() &#123; System.out.println("drawshape"); &#125; &#125;&#125;这样看起来，类Draw像是类Circle的一个成员，Circle称为外部类。成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）。12345678910111213141516171819202122public class Outer &#123; private double radius = 0; private int test = 1; public static int count =1; public Outer(double radius) &#123; this.radius = radius; &#125; class Draw &#123; //内部类 private int test = 2; public void drawSahpe() &#123; System.out.println(radius); //外部类的private成员 System.out.println(count); //外部类的静态成员 System.out.println(Outer.this.test); &#125; &#125; public static void main(String[] args) &#123; Draw draw = new Outer(20).new Draw(); draw.drawSahpe(); &#125;&#125;不过要注意的是，当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：12外部类.this.成员变量外部类.this.成员方法虽然成员内部类可以无条件地访问外部类的成员，而外部类想访问成员内部类的成员却不是这么随心所欲了。在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问：123456789101112131415161718class Circle &#123; private double radius = 0; public Circle(double radius) &#123; this.radius = radius; getDrawInstance().drawSahpe(); //必须先创建成员内部类的对象，再进行访问 &#125; private Draw getDrawInstance() &#123; return new Draw(); &#125; class Draw &#123; //内部类 public void drawSahpe() &#123; System.out.println(radius); //外部类的private成员 &#125; &#125;&#125;成员内部类是依附外部类而存在的，也就是说，如果要创建成员内部类的对象，前提是必须存在一个外部类的对象。创建成员内部类对象的一般方式如下：12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) &#123; //第一种方式： Outter outter = new Outter(); Outter.Inner inner = outter.new Inner(); //必须通过Outter对象来创建 //第二种方式： Outter.Inner inner1 = outter.getInnerInstance(); &#125;&#125; class Outter &#123; private Inner inner = null; public Outter() &#123; &#125; public Inner getInnerInstance() &#123; if(inner == null) inner = new Inner(); return inner; &#125; class Inner &#123; public Inner() &#123; &#125; &#125;&#125;内部类可以拥有private访问权限、protected访问权限、public访问权限及包访问权限。如上面的例子：private：则只能在外部类的内部访问；public：则任何地方都能访问；protected：只能在同一个包下或者继承外部类的情况下访问；默认访问权限：则只能在同一个包下访问。这一点和外部类有一点不一样，外部类只能被public和包访问两种权限修饰。我个人是这么理解的，由于成员内部类看起来像是外部类的一个成员，所以可以像类的成员一样拥有多种权限修饰。局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。12345678910111213class People&#123; public People() &#123; &#125;&#125; class Man&#123; public Man()&#123; &#125; public People getWoman()&#123; class Woman extends People&#123; //局部内部类 int age =0; &#125; return new Woman(); &#125;&#125;匿名内部类匿名内部类应该是平时我们编写代码时用得最多的，在编写事件监听的代码时使用匿名内部类不但方便，而且使代码更加容易维护。下面这段代码是一段线程允许代码：1234567891011public class Test&#123; public static void main(String[] args) &#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread run"); &#125; &#125;); thread.start(); &#125;&#125;匿名内部类是唯一一种没有构造器的类。正因为其没有构造器，所以匿名内部类的使用范围非常有限，大部分匿名内部类用于接口回调。匿名内部类在编译的时候由系统自动起名为Outter$数字.class。一般来说，匿名内部类用于继承其他类或是实现接口，并不需要增加额外的方法，只是对继承方法的实现或是重写。静态内部类静态内部类也是定义在另一个类里面的类，只不过在类的前面多了一个关键字static。静态内部类是不需要依赖于外部类的，这点和类的静态成员属性有点类似，并且它不能使用外部类的非static成员变量或者方法，这点很好理解，因为在没有外部类的对象的情况下，可以创建静态内部类的对象，如果允许访问外部类的非static成员就会产生矛盾，因为外部类的非static成员必须依附于具体的对象。1234567891011121314public class Test &#123; public static void main(String[] args) &#123; //静态内部类是不依赖于外部类的，也就说可以在不创建外部类对象的情况下创建内部类的对象。 Outter.Inner inner = new Outter.Inner(); &#125;&#125; class Outter &#123; public Outter() &#123; &#125; static class Inner &#123; public Inner() &#123; &#125; &#125;&#125;局部内部类和匿名内部类只能访问局部final变量想必这个问题也曾经困扰过很多人，在讨论这个问题之前，先看下面这段代码：1234567891011121314public class Test &#123; public static void main(String[] args) &#123; &#125; public void test(final int b) &#123; final int a = 10; new Thread()&#123; public void run() &#123; System.out.println(a); System.out.println(b); //a = 10; &#125;; &#125;.start(); &#125;&#125;首先我们需要知道：内部类和外部类是处于同一个级别的，内部类不会因为定义在方法中就会随着方法的执行完毕就被销毁。这里就会产生问题：当外部类的方法结束时，局部变量就会被销毁了，但是内部类对象可能还存在（只有没有人再引用它时，才可能死亡）。这里就出现了一个矛盾：内部类对象访问了一个不存在的变量。为了解决这个问题，就将局部变量复制了一份作为内部类的成员变量，这样当局部变量死亡后，内部类仍可以访问它，实际访问的是局部变量的”copy”。这样就好像延长了局部变量的生命周期。那么新问题又出现了：将局部变量复制为内部类的成员变量时，必须保证这两个变量是一样的，也就是如果我们在内部类中修改了成员变量，方法中的局部变量也得跟着改变，怎么解决问题呢？就将局部变量设置为final，对它初始化后，我就不让你再去修改这个变量，就保证了内部类的成员变量和方法的局部变量的一致性。这实际上也是一种妥协。常见的运行时异常java.lang.NullPointerException ：空指针异常；出现原因：调用了未经初始化的对象或者是不存在的对象。java.lang.ClassNotFoundException ：指定的类找不到；出现原因：类的名称和路径加载错误；通常都是程序试图通过字符串来加载某个类时可能引发异常。java.lang.NumberFormatException ：字符串转换为数字异常；出现原因：字符型数据中包含非数字型字符。java.lang.IndexOutOfBoundsException ：数组角标越界异常，常见于操作数组对象时发生。java.lang.ClassCastException ：数据类型转换异常SQLException ：SQL 异常，常见于操作数据库时的 SQL 语句错误。枚举和switch123456789101112public class Test &#123; public static void main(String[] args) &#123; System.out.println(TestEnum.FRI.getClass()); //class TestEnum System.out.println(TestEnum.FRI); // FRI &#125;&#125;enum TestEnum &#123; MON, TUE, WED, THU, FRI, SAT, SUN;&#125;switch中可以跟的类型有byte、short、char、int、String、枚举。没有long。1234567891011121314151617181920212223String str = "200";switch (str) &#123; default: // default 只能定义一次 System.out.println(100); case "100": System.out.println(1000); case "1000": System.out.println(1000);&#125;//str = 200;//输出：// 100// 1000// 1000//因为不能匹配100或1000，所以从defalut口进入。////str = 100;//输出：// 1000// 1000//因为可以匹配100，从第二个口进入。随机数和round12345678// 获得随机数：greater than or equal to 0.0 and less than 1.0double iRandom = Math.random();System.out.println(iRandom);// 获得区间在[0, n)之间的随机整数Random random2 = new Random();int nextInt = random2.nextInt(10);System.out.println(nextInt);123456// 负数：加0.5之后向小的取整System.out.println(Math.round(-11.6));System.out.println(Math.round(-11.5));// 正数：加0.5之后向大的取整System.out.println(Math.round(11.6));System.out.println(Math.round(11.5));String和字符串常量池字符串常量池只是常量池技术在字符串这个类上的实现，但是为了方便叙述，本条知识点使用常量池和字符串常量池等价。String对象的两种创建方式123456789101112// 直接使用双引号声明出来的 String 对象会直接存储在常量池中。// 使用双引号声明时会调用ldc命令，所以其检查的是字符串常量池。String str1 = "abcd";// 对于new String()则会在堆中创建一个String对象，并返回该对象的引用。// Initializes a newly created String object so that it represents the same sequence // of characters as the argument; in other words, the newly created string is a copy // of the argument string. Unless an explicit copy of original is needed, use of this // constructor is unnecessary since Strings are immutable.String str2 = new String("abcd");System.out.println(str1 == str2); //falseintern()String.intern() 是一个 Native 方法，JDK对它的解释是（水平有限，不再翻译）：A pool of strings, initially empty, is maintained privately by the class String. When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned.（笔者注：add的意思不是克隆一份，就是把这个对象的引用放在常量池中，JDK8中字符串常量池可以存放字符串对象，也可以存放字符串对象的引用，返回的引用是指向常量池中的字符串对象）It follows that for any two strings s and t, s.intern() == t.intern() is true if and only if s.equals(t) is true.All literal strings and string-valued constant expressions are interned.大致意思是：如果字符串常量池中已经有了这个字符串，那么直接返回字符串常量池中的它的引用，如果没有，那就将它的引用保存一份到字符串常量池，然后直接返回这个引用。判断字符串是否相等使用equals方法。题1123456String s1 = new String("计算机");String s2 = s1.intern();String s3 = "计算机";System.out.println(s2);//计算机System.out.println(s1 == s2);//false，因为一个是堆内存中的String对象一个是常量池中的String对象System.out.println(s3 == s2);//true，因为两个都是常量池中的String对象2123456String s1 = "Hollis";String s2 = new String("Hollis");String s3 = new String("Hollis").intern();System.out.println(s1 == s2); //falseSystem.out.println(s1 == s3); //true312345678910111213141516171819202122String s = new String("1");// 常量池中有"1"，堆中有字符串"1"，s是堆中中"1"的引用String s2 = "1";// s2是常量池中"1"的引用s.intern();// "1"已经存在常量池中，返回常量池中"1"的引用，但没有被接收System.out.println(s == s2); //falseString s3 = new String("1") + new String("2");// 常量池中有"1"，"2"。new String("1") + new String("2");的底层是使用StringBuffer的append// 方 法将"1"和"2"拼接在一块，然后调用toString方法new出"12"；所以此时的“12”字符串是创建在堆区的；s3.intern();// 常量池中没有"12"，intern后常量池中存放堆中"12"的引用String s4 = "12";// 从常量池中拿"12"，和堆中的"12"是同一个"12"System.out.println(s3 == s4); //true41234567891011String s1 = new String("xy") + "z";// 常量池中有"z"和"xy"，堆中有"xyz"String s2 = s1.intern(); // 常量池中有一个指向堆中"xyz"的引用，s2和这个引用相等，即s2指向堆中的"xyz"System.out.println(s1 == s1.intern()); //true // s1指向堆中"xyz"，s1.intern()也指向堆中的"xyz"System.out.println(s2 == s1.intern()); //true// s2指向堆中"xyz"的引用51234567891011121314String s1 = new String("xy") + "z";// 常量池中有"z"和"xy"，堆中有"xyz"，s1指向堆中的"xyz"String s3 = new String("xyz");// 常量池中有"xyz"，s3指向堆中的第二个"xyz"String s2 = s1.intern();// s2指向常量池中的"xyz"System.out.println(s2 == s3); // falseSystem.out.println(s1 == s1.intern()); //falseSystem.out.println(s2 == s1.intern()); //true61234567891011121314String s1 = new String("xy") + "z";// 常量池中有"z"和"xy"，堆中有"xyz"，s1指向堆中的"xyz"String s2 = s1.intern();// 常量池中有一个指向堆中"xyz"的引用，s2和这个引用相等，即s2指向堆中的"xyz"String s3 = new String("xyz");// 常量池中有一个指向堆中"xyz"的引用，不再在常量池中创建"xyz"，将常量池中的"xyz"复制一份到堆中System.out.println(s2 == s3); // falseSystem.out.println(s1 == s1.intern()); //trueSystem.out.println(s2 == s1.intern()); // true71234567891011121314String s1 = new String("xy") + "z";// 常量池中有"z"和"xy"，堆中有"xyz"，s1指向堆中的"xyz"String s2 = s1.intern();// 常量池中有一个指向堆中"xyz"的引用，s2和这个引用相等，即s2指向堆中的"xyz"String s3 = "xyz";// 常量池中有一个指向堆中"xyz"的引用，不再在常量池中创建"xyz"，s3指向堆中的"xyz"System.out.println(s2 == s3); // trueSystem.out.println(s1 == s1.intern()); //trueSystem.out.println(s2 == s1.intern()); // true812String s1 = "xy" + "z";// 常量池中存在 "xy" "z" "xyz"91234567891011121314String s1 = new String("xy") + "z";// 常量池中有"z"和"xy"，堆中有"xyz"，s1指向堆中的"xyz"String s3 = "xyz";// 常量池中有"xyz"，s3指向常量池中的"xyz"String s2 = s1.intern();// s2指向常量池中的"xyz"System.out.println(s1 == s3); //falseSystem.out.println(s1 == s2); //falseSystem.out.println(s2 == s3); //trueSystem.out.println(s1 == s1.intern()); //falseSystem.out.println(s2 == s1.intern()); //trueString、StringBuilder &amp; StringBuffer可变性简单的来说：String 类中使用 final 关键字修饰字符数组来保存字符串，private final char value[]，所以 String 对象是不可变的。而StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，在 AbstractStringBuilder 中也是使用字符数组保存字符串char[]value 但是没有用 final 关键字修饰，所以这两种对象都是可变的。StringBuilder 与 StringBuffer 的构造方法都是调用父类构造方法也就是 AbstractStringBuilder 实现的。AbstractStringBuilder.java12345678abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; &#125;线程安全性String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder 与 StringBuffer 的公共父类，定义了一些字符串的基本操作，如 expandCapacity、append、insert、indexOf 等公共方法。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是非线程安全的。性能每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。对于三者使用的总结：操作少量的数据: 适用String单线程操作字符串缓冲区下操作大量数据: 适用StringBuilder多线程操作字符串缓冲区下操作大量数据: 适用StringBufferJava中字符串相加，编译的时候会创建StringBuilder类，然后利用StringBuilder的append()方法相加。所以不能在循环里使用+，需要在循环外面使用创建StringBuilder的对象，在循环内进行append()操作。日期类LocalDate1234567891011121314151617181920212223242526// 当前日期LocalDate today = LocalDate.now();System.out.println("Current Date=" + today);// 根据年、月、日创建日期LocalDate firstDay_2014 = LocalDate.of(2014, Month.JANUARY, 1);System.out.println("Specific Date=" + firstDay_2014);// 不合法的参数会报 java.time.DateTimeException// LocalDate feb29_2014 = LocalDate.of(2014, Month.FEBRUARY, 29);// Current date in "Asia/Kolkata", you can get it from ZoneId javadocLocalDate todayKolkata = LocalDate.now(ZoneId.of("Asia/Kolkata"));System.out.println("Current Date in IST=" + todayKolkata);// java.time.zone.ZoneRulesException: Unknown time-zone ID: IST// LocalDate todayIST = LocalDate.now(ZoneId.of("IST"));// Getting date from the base date: 01/01/1970LocalDate dateFromBase = LocalDate.ofEpochDay(365);System.out.println("365th day from base date= " + dateFromBase);// 得到某年的多少天LocalDate hundredDay2014 = LocalDate.ofYearDay(2014, 100);System.out.println("100th day of 2014=" + hundredDay2014);LocalTime1234567891011121314151617181920212223// Current TimeLocalTime time = LocalTime.now();System.out.println("Current Time = " + time);// Creating LocalTime by providing input argumentsLocalTime specificTime = LocalTime.of(12, 20, 25, 40);System.out.println("Specific Time of Day = " + specificTime);// Try creating time by providing invalid inputs// LocalTime invalidTime = LocalTime.of(25,20);// Exception in thread "main" java.time.DateTimeException:// Invalid value for HourOfDay (valid values 0 - 23): 25// Current date in "Asia/Kolkata", you can get it from ZoneId javadocLocalTime timeKolkata = LocalTime.now(ZoneId.of("Asia/Kolkata"));System.out.println("Current Time in IST = " + timeKolkata);// java.time.zone.ZoneRulesException: Unknown time-zone ID: IST// LocalTime todayIST = LocalTime.now(ZoneId.of("IST"));// Getting time from the base date: 00:00:00LocalTime specificSecondTime = LocalTime.ofSecondOfDay(10000);System.out.println("10000th second time = " + specificSecondTime);LocalDateTime123456789101112131415161718192021222324252627// Current DateLocalDateTime today = LocalDateTime.now();System.out.println("Current DateTime1 = " + today);// Current Date using LocalDate and LocalTimetoday = LocalDateTime.of(LocalDate.now(), LocalTime.now());System.out.println("Current DateTime2 = " + today);// Creating LocalDateTime by providing input argumentsLocalDateTime specificDate = LocalDateTime.of(2014, Month.JANUARY, 1, 10, 10, 30);System.out.println("Specific Date = " + specificDate);// Try creating date by providing invalid inputs// LocalDateTime feb29_2014 = LocalDateTime.of(2014, Month.FEBRUARY, 28, 25, 1, 1);// Exception in thread "main" java.time.DateTimeException:// Invalid value for HourOfDay (valid values 0 - 23): 25// Current date in "Asia/Kolkata", you can get it from ZoneId javadocLocalDateTime todayKolkata = LocalDateTime.now(ZoneId.of("Asia/Kolkata"));System.out.println("Current Date in IST = " + todayKolkata);// java.time.zone.ZoneRulesException: Unknown time-zone ID: IST// LocalDateTime todayIST = LocalDateTime.now(ZoneId.of("IST"));// Getting date from the base date: 01/01/1970LocalDateTime dateFromBase = LocalDateTime.ofEpochSecond(10000, 0, ZoneOffset.UTC);System.out.println("10000th second time from 01/01/1970= " + dateFromBase);Instant1234567// Current timestampInstant timestamp = Instant.now();System.out.println("Current Timestamp = " + timestamp);// 转换为 milliseconds from 01/01/1970long epochMilli = timestamp.toEpochMilli();System.out.println(epochMilli);Date &amp; SimpleDateFormat123SimpleDateFormat oldFormatter = new SimpleDateFormat("yyyy/MM/dd");Date date1 = new Date();System.out.println(oldFormatter.format(date1));相互转换12345678910111213141516171819202122232425262728Date now = new Date();LocalDateTime localDateTime = now.toInstant().atZone(ZoneId.systemDefault()).toLocalDateTime();LocalTime localTime = now.toInstant().atZone(ZoneId.systemDefault()).toLocalTime();LocalDate localDate = now.toInstant().atZone(ZoneId.systemDefault()).toLocalDate();System.out.println(localDateTime);System.out.println(localTime);System.out.println(localDate);// LocalTime 和 LocalDate 没有atZone方法Date oldLocalDateTime = Date.from(localDateTime.atZone(ZoneId.systemDefault()).toInstant());System.out.println(oldLocalDateTime);long millis = localDateTime.atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();long time = now.getTime();System.out.println(millis);System.out.println(time);LocalDateTime parseLocalDateTime = Instant.ofEpochMilli(millis).atZone(ZoneId.systemDefault()).toLocalDateTime();LocalDate parseLocalDate = Instant.ofEpochMilli(millis).atZone(ZoneId.systemDefault()).toLocalDate();System.out.println(parseLocalDateTime);System.out.println(parseLocalDate);获取年月日时钟秒1234567LocalDateTime dt = LocalDateTime.now();System.out.println(dt.getYear());System.out.println(dt.getMonthValue()); // 1 - 12System.out.println(dt.getDayOfMonth());System.out.println(dt.getHour());System.out.println(dt.getMinute());System.out.println(dt.getSecond());获得某月第一天/最后一天1234567LocalDate today = LocalDate.now();//本月的第一天LocalDate firstday = LocalDate.of(today.getYear(), today.getMonth(), 1);//本月的最后一天LocalDate lastDay =today.with(TemporalAdjusters.lastDayOfMonth());System.out.println("本月的第一天 " + firstday);System.out.println("本月的最后一天 " + lastDay);格式化日期12345678910111213141516171819DateTimeFormatter dtf1 = DateTimeFormatter.ofPattern("yyyy/MM/dd HH:mm:ss");DateTimeFormatter dtf2 = DateTimeFormatter.ofPattern("yyyy/MM/dd");LocalDateTime ldt = LocalDateTime.now();LocalDate ld = LocalDate.now();System.out.println(ldt);System.out.println(ld);String format1 = ldt.format(dtf1); // 日期格式化为字符串String format2 = ld.format(dtf2); // 日期格式化为字符串System.out.println(format1);System.out.println(format2);LocalDateTime parse1 = LocalDateTime.parse(format1, dtf1); LocalDate parse2 = LocalDate.parse(format2, dtf2);System.out.println(parse1); // 字符串转化为日期System.out.println(parse2); // 字符串转化为日期equals()和hashCode()Java 对于 eqauls 方法和 hashCode 方法是这样规定的：如果两个对象相同（equals 方法返回 true），那么它们的 hashCode 值一定要相同；如果两个对象的 hashCode 相同，它们并不一定相同。equals()需要满足的性质自反性：x.equals(x)必须返回 true对称性：x.equals(y)返回 true 时，y.equals(x)也必须返回 true传递性：x.equals(y)和 y.equals(z)都返回 true 时，x.equals(z)也必须返回 true一致性：当x 和 y 引用的对象信息没有被修改时，多次调用 x.equals(y)应该得到同样的返回值，对于任何非 null 值的引用 x，x.equals(null)必须返回 false。实现高质量的 equals ()使用==操作符检查”参数是否为这个对象的引用”；使用 instanceof 操作符检查”参数是否为正确的类型”；对于类中的关键属性，检查参数传入对象的属性是否与之相匹配；编写完 equals 方法后，问自己它是否满足对称性、传递性、一致性和空值返回false；重写 equals 时总是要重写 hashCode；不要将 equals 方法参数中的 Object 对象替换为其他的类型，在重写时不要忘掉@Override注解。正确使用equals方法推荐使用：Objects.equals(o1, o2)，此方法的底层实现：1234public static boolean equals(Object a, Object b) &#123; // 可以避免空指针异常。如果a==null的话此时a.equals(b)就不会得到执行，避免出现空指针异常。 return (a == b) || (a != null &amp;&amp; a.equals(b));&#125;两者的关系在使用到哈希机制的集合时需要同时重写equles方法和hashCode方法。即重写对象的散列码是为了更好的支持基于哈希机制的Java集合类，例如 Hashtable, HashMap, HashSet 等，如果不重写hashCode()，在使用哈希机制的集合类时会出错。当把对象加入HashSet时，HashSet会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他已经加入的对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。但不同对象的hashCode可能重复，所以哈希机制的集合会在判断hashCode之后再判断一次equals。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Demo&#123; public static void main(String[] args) &#123; Person p1 = new Person("eee", 100); Person p2 = new Person("eee", 100); Person p3 = new Person("aaa", 200); Person p4 = new Person("EEE", 100); HashSet set = new HashSet(); set.add(p1); set.add(p2); set.add(p3); // 打印set System.out.printf("set:%s\n", set); &#125; private static class Person &#123; int age; String name; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public int hashCode()&#123; return name.hashCode() ^ age; &#125; @Override public String toString() &#123; return "Person [age=" + age + ", name=" + name + "]"; &#125; @Override public boolean equals(Object obj)&#123; if(obj == null) return false; //如果是同一个对象返回true，反之返回false if(this == obj) return true; //判断是否类型相同 if(this.getClass() != obj.getClass()) return false; Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125; &#125;&#125;装饰者模式准备工作假设无人驾驶的标准是Oracle公司制定的，Google想使用Java语言来开发无人驾驶系统，那么首先它需要创建一个类实现Oracle公司提供的无人驾驶的接口（接口为AIDriving，类为GoogleAIDriving）。AIDriving1234public interface AIDriving &#123; public void start(); //无人驾驶汽车启动的方法 public void stop(); //无人驾驶汽车停止的方法&#125;GoogleAIDriving12345678public class GoogleAIDriving implements AIDriving &#123; public void start() &#123; System.out.println("Google汽车启动了..."); &#125; public void stop() &#123; System.out.println("Google汽车停止了..."); &#125;&#125;传统方法-继承这个时候国内某汽车制造公司（设为A公司）想使用Google提供的无人驾驶系统。但是Google提供的系统不太适合我国国情，所以A公司的工程师就想在Google系统的基础上进行定制。他们选择的方式是继承GoogleAIDriving，创建一个自己的类：A1GoogleAIDriving。12345678910public class A1GoogleAIDriving extends GoogleAIDriving&#123; public void start() &#123; System.out.println("在中国启动汽车"); super.start(); &#125; public void stop() &#123; System.out.println("在中国停止汽车"); super.stop(); &#125;&#125;装饰者模式但理想很美好，现实很残忍。GoogleAIDriving被定义为一个final类（不能被继承），这个是可以理解的，因为如果GoogleAIDriving不是一个final类，任何继承GoogleAIDriving的类都可以对其start()、stop()方法进行覆盖，如果覆盖时出现bug就可能会出现大问题。所以像启动、停止这种核心功能是不允许汽车制造商随意修改的。A公司的工程师就想到了使用装饰者模式来增强功能（设类为A2GoogleAIDriving）。装饰者模式该怎么做呢？首先，装饰类得和被装饰类实现相同的接口，即AIDriving；第二，在装饰类中定义一个AIDriving类型的属性，即AIDriving car；第三，有一个参数为AIDriving类型的构造函数，即A2GoogleAIDriving(AIDriving car)；第四，装饰类的每个方法都要调用被装饰类相应的方法；第五，使用第三步中的构造函数创建装饰类；第六，在装饰类的方法中自定义功能。代码实现创建装饰类123456789101112131415public class A2GoogleAIDriving implements AIDriving &#123; private AIDriving car; public A2GoogleAIDriving(AIDriving car) &#123; this.car = car; &#125; public void start() &#123; System.out.println("在中国启动汽车..."); car.start(); &#125; public void stop() &#123; System.out.println("在中国停止汽车..."); car.stop(); &#125;&#125;调用装饰类12345678910public class Test &#123; public static void main(String[] args) &#123; GoogleAIDriving car = new GoogleAIDriving(); A2GoogleAIDriving aCar = new A2GoogleAIDriving(car); aCar.start(); /* Console : 在中国启动汽车... Google汽车启动了... */ &#125;&#125;BigInteger&amp;BigDecimalBigInteger理论上可以表示无限大的数字。常用方法：12345678910111213141516171819202122232425BigInteger abs() 返回大整数的绝对值BigInteger add(BigInteger val) 返回两个大整数的和BigInteger and(BigInteger val) 返回两个大整数的按位与的结果BigInteger andNot(BigInteger val) 返回两个大整数与非的结果BigInteger divide(BigInteger val) 返回两个大整数的商double doubleValue() 返回大整数的double类型的值float floatValue() 返回大整数的float类型的值BigInteger gcd(BigInteger val) 返回大整数的最大公约数int intValue() 返回大整数的整型值long longValue() 返回大整数的long型值BigInteger max(BigInteger val) 返回两个大整数的最大者BigInteger min(BigInteger val) 返回两个大整数的最小者BigInteger mod(BigInteger val) 用当前大整数对val求模BigInteger multiply(BigInteger val) 返回两个大整数的积BigInteger negate() 返回当前大整数的相反数BigInteger not() 返回当前大整数的非BigInteger or(BigInteger val) 返回两个大整数的按位或BigInteger pow(int exponent) 返回当前大整数的exponent次方BigInteger remainder(BigInteger val) 返回当前大整数除以val的余数BigInteger leftShift(int n) 将当前大整数左移n位后返回BigInteger rightShift(int n) 将当前大整数右移n位后返回BigInteger subtract(BigInteger val)返回两个大整数相减的结果byte[] toByteArray(BigInteger val)将大整数转换成二进制反码保存在byte数组中String toString() 将当前大整数转换成十进制的字符串形式BigInteger xor(BigInteger val) 返回两个大整数的异或BigDecimal浮点数之间的等值判断，基本数据类型不能用==来比较，包装数据类型不能用 equals 来判断。具体原理和浮点数的编码方式有关。12345float a = 1.0f - 0.9f;float b = 0.9f - 0.8f;System.out.println(a);// 0.100000024System.out.println(b);// 0.099999964System.out.println(a == b);// false具有基本数学知识的我们很清楚的知道输出并不是我们想要的结果（精度丢失），我们如何解决这个问题呢？一种很常用的方法是：使用使用 BigDecimal 来定义浮点数的值，再进行浮点数的运算操作。123456BigDecimal a = new BigDecimal("1.0");BigDecimal b = new BigDecimal("0.9");BigDecimal c = new BigDecimal("0.8");BigDecimal x = a.subtract(b);// 0.1BigDecimal y = b.subtract(c);// 0.1System.out.println(x.equals(y));// trueAPI123456789101112131415BigDecimal(int) 创建一个具有参数所指定整数值的对象。 BigDecimal(double) 创建一个具有参数所指定双精度值的对象。 BigDecimal(long) 创建一个具有参数所指定长整数值的对象。 BigDecimal(String) 创建一个具有参数所指定以字符串表示的数值的对象。add(BigDecimal) BigDecimal对象中的值相加，然后返回这个对象。subtract(BigDecimal) BigDecimal对象中的值相减，然后返回这个对象。multiply(BigDecimal) BigDecimal对象中的值相乘，然后返回这个对象。divide(BigDecimal) BigDecimal对象中的值相除，然后返回这个对象。toString() 将BigDecimal对象的数值转换成字符串。 doubleValue() 将BigDecimal对象中的值以双精度数返回。 floatValue() 将BigDecimal对象中的值以单精度数返回。 longValue() 将BigDecimal对象中的值以长整数返回。 intValue() 将BigDecimal对象中的值以整数返回。我们在使用BigDecimal时，为了防止精度丢失，推荐使用它的 BigDecimal(String) 构造方法来创建对象。12345678910BigDecimal a = new BigDecimal(1.01);BigDecimal b = new BigDecimal(1.02);BigDecimal c = new BigDecimal("1.01");BigDecimal d = new BigDecimal("1.02");System.out.println(a.add(b));System.out.println(c.add(d));输出：2.03000000000000002664535259100375697016716003417968752.03整型包装类值的比较所有整形包装类对象值得比较必须使用equals方法。1234567Integer x = 3;Integer y = 3;System.out.println(x == y);// trueInteger a = new Integer(3);Integer b = new Integer(3);System.out.println(a == b);//falseSystem.out.println(a.equals(b));//falseArrays.asListArrays.asList()将数组转换为集合后,底层其实还是数组。传递的数组必须是对象数组，而不是基本类型。Arrays.asList()是泛型方法，传入的对象必须是对象数组。1234567int[] myArray = &#123; 1, 2, 3 &#125;;List myList = Arrays.asList(myArray);System.out.println(myList.size());//1System.out.println(myList.get(0));//数组地址值System.out.println(myList.get(1));//报错：ArrayIndexOutOfBoundsExceptionint [] array=(int[]) myList.get(0);System.out.println(array[0]);//1当传入一个原生数据类型数组时，Arrays.asList() 的真正得到的参数就不是数组中的元素，而是数组对象本身！此时List 的唯一元素就是这个数组，这也就解释了上面的代码。我们使用包装类型数组就可以解决这个问题。1Integer[] myArray = &#123; 1, 2, 3 &#125;;使用集合的修改方法:add()、remove()、clear()会抛出异常。Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。1234567891011121314151617181920212223242526272829303132private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable &#123; ... @Override public E get(int index) &#123; ... &#125; @Override public E set(int index, E element) &#123; ... &#125; @Override public int indexOf(Object o) &#123; ... &#125; @Override public boolean contains(Object o) &#123; ... &#125; @Override public void forEach(Consumer&lt;? super E&gt; action) &#123; ... &#125; @Override public void replaceAll(UnaryOperator&lt;E&gt; operator) &#123; ... &#125; @Override public void sort(Comparator&lt;? super E&gt; c) &#123; ... &#125;&#125;我们再看一下java.util.AbstractList的remove()方法，这样我们就明白为啥会抛出UnsupportedOperationException。123public E remove(int index) &#123; throw new UnsupportedOperationException();&#125;正确的数组转集合的方法：List list = new ArrayList&lt;&gt;(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))Comparable &amp; ComparatorComparableThis interface imposes a total ordering on the objects of each class that implements it. This ordering is referred to as the class’s natural ordering, and the class’s compareTo method is referred to as its natural comparison method.Lists (and arrays) of objects that implement this interface can be sorted automatically by Collections.sort (and Arrays.sort). Objects that implement this interface can be used as keys in a sorted map or as elements in a sorted set, without the need to specify a comparator.compareTo 方法的返回值有三种情况：e1.compareTo(e2) &gt; 0 即 e1 &gt; e2e1.compareTo(e2) = 0 即 e1 = e2e1.compareTo(e2) &lt; 0 即 e1 &lt; e2满足上述规则的是升序排序，与上诉规则相反则是降序排序。1234567891011121314151617181920212223242526272829303132public class Test &#123; public static void main(String[] args) throws IOException &#123; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(); set.add(new Person(50)); set.add(new Person(30)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person implements Comparable&lt;Person&gt;&#123; private Integer age; public Person(Integer age) &#123; this.age = age; &#125; @Override public int compareTo(Person o) &#123; if(o == null) throw new NullPointerException(); if(age &gt; o.age) return 1; else if(age &lt; o.age) return -1; return 0; &#125; public String toString() &#123; return "Person [age=" + age + "]"; &#125; &#125;Note that null is not an instance of any class, and e.compareTo(null) should throw a NullPointerException even though e.equals(null) returns false.The natural ordering for a class C is said to be consistent with equals if and only if e1.compareTo(e2) == 0 has the same boolean value as e1.equals(e2) for every e1 and e2 of class C. It is strongly recommended (though not required) that natural orderings be consistent with equals. This is so because sorted sets (and sorted maps)without explicit comparators behave “strangely” when they are used with elements (or keys) whose natural ordering is inconsistent with equals. In particular, such a sorted set (or sorted map) violates（违反） the general contract for set (or map), which is defined in terms of（依据） the equals method.For example, if one adds two keys a and b such that (!a.equals(b) &amp;&amp; a.compareTo(b) == 0) to a sorted set that does not use an explicit comparator, the second add operation returns false (and the size of the sorted set does not increase) because a and b are equivalent from the sorted set’s perspective.这段话的意思是如果compareTo规则和equals规则不同就会发生奇怪的问题，即在!a.equals(b) &amp;&amp; a.compareTo(b) == 0这种情况下，不能插入集合中，因为从排序集合判断是否相等使用compareTo的规则。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Test &#123; public static void main(String[] args) throws IOException &#123; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(); set.add(new Person(50)); set.add(new Person(50)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person implements Comparable&lt;Person&gt;&#123; private Integer age; public Person(Integer age) &#123; this.age = age; &#125; @Override public int compareTo(Person o) &#123; if(o == null) throw new NullPointerException(); if(age == o.age) // 模仿 a.compareTo(b) == 0 return 0; if(age &gt; o.age) return 1; return -1; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; @Override public boolean equals(Object obj) &#123; if(obj == null || !(obj instanceof Person)) return false; Person p = (Person)obj; if(this.age == 50 || p.age == 50) &#123; // 模仿 !a.equals(b) return false; &#125; return (this.age == p.age) ? true : false; &#125; @Override public int hashCode() &#123; return age.hashCode(); &#125; &#125;// Person [age=50]// Person [age=90]Comparator使用自然排序需要类实现 Comparable，并且在内部重写 comparaTo 方法。而 Comparator 则是在外部制定排序规则，然后作为排序策略参数传递给某些类，比如 Collections.sort(), Arrays.sort(), 或者一些内部有序的集合（比如 SortedSet，SortedMap 等）。同时存在时采用 Comparator（定制排序）的规则进行比较。使用方式主要分三步：创建一个 Comparator 接口的实现类，并赋值给一个对象。在 compare 方法中针对自定义类写排序规则。将 Comparator 对象作为参数传递给 排序类的某个方法向排序类中添加 compare 方法中使用的自定义类12345678910111213141516171819202122232425262728293031323334public class Test &#123; public static void main(String[] args) throws IOException &#123; Comparator&lt;Person&gt; com = new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; if(o1.getAge() &gt; o2.getAge()) return 1; else if(o1.getAge() &lt; o2.getAge()) return -1; return 0; &#125; &#125;; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(com); set.add(new Person(50)); set.add(new Person(20)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person&#123; private Integer age; public Person(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125;需要注意的一点是，compare的相等规则需要个equals相同。集合概览ListArraylist： Object数组Vector： Object数组，线程安全。LinkedList： 双向链表MapHashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间LinkedHashMap： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。TreeMap： 红黑树SetHashSet（无序，唯一）: 基于 HashMap 实现的，底层采用 HashMap 来保存元素LinkedHashSet： LinkedHashSet 继承与 HashSet，并且其内部是通过 LinkedHashMap 来实现的。TreeSet（有序，唯一）： 红黑树（自平衡的排序二叉树)ArrayList分析ArrayList有三种方式来初始化，构造方法源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 默认初始容量大小 */private static final int DEFAULT_CAPACITY = 10;private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;/** *默认构造函数，使用初始容量10构造一个空列表(无参数构造) */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;/** * 带初始容量参数的构造函数。（用户自己指定容量） */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; //初始容量大于0 //创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; //初始容量等于0 //创建空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; //初始容量小于0，抛出异常 throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;/***构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回*如果指定的集合为null，throws NullPointerException。 */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;细心的同学一定会发现 ：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。 下面在我们分析 ArrayList 扩容时会讲到这一点内容！add12345678910/** * 将指定的元素追加到此列表的末尾。 */public boolean add(E e) &#123;//添加元素之前，先调用ensureCapacityInternal方法 ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true;&#125;ensureCapacityInternal()123456789101112131415161718// 获得容量private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;当我们要 add 进第1个元素到 ArrayList 时，minCapacity为1，在Math.max()方法比较后，minCapacity 为10。elementData.length 为0 （因为还是一个空的 list），因为执行了 ensureCapacityInternal() 方法 ，所以 minCapacity 此时为10。此时，minCapacity - elementData.length &gt; 0成立，所以会进入 grow(minCapacity) 方法。当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0不成立，所以不会进入 （执行）grow(minCapacity) 方法。添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。grow()123456789101112131415161718192021222324252627private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private void grow(int minCapacity) &#123; //oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //若新容量大于MAX_ARRAY_SIZE，执行hugeCapacity()方法来比较minCapacity和MAX_ARRAY_SIZE， //若minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 //MAX_ARRAY_SIZE 即为Integer.MAX_VALUE - 8。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍！“&gt;&gt;”（移位运算符）：&gt;&gt;1 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源我们再来通过例子探究一下grow() 方法 ：当add第1个元素时，oldCapacity 为0，经比较后第一个if判断成立，newCapacity = minCapacity(为10)。但是第二个if判断不会成立，即newCapacity 不比 MAX_ARRAY_SIZE大，则不会进入 hugeCapacity 方法。数组容量为10，add方法中 return true,size增为1。当add第11个元素进入grow方法时，newCapacity为15，比minCapacity（为11）大，第一个if判断不成立。新容量没有大于数组最大size，不会进入hugeCapacity方法。数组容量扩为15，add方法中return true，size增为11。以此类推······如果新容量大于 MAX_ARRAY_SIZE,进入(执行) hugeCapacity() 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果minCapacity大于最大容量，则新容量则为Integer.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 Integer.MAX_VALUE - 8。这里补充一点比较重要，但是容易被忽视掉的知识点：java 中的 length属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.java 中的 length() 方法是针对字符串说的,如果想看这个字符串的长度则用到 length() 这个方法.java 中的 size() 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!System.arraycopy()123456789101112131415/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125;Arrays.copyOf()1234567891011121314public static &lt;T&gt; T[] copyOf(T[] original, int newLength) &#123; return (T[]) copyOf(original, newLength, original.getClass());&#125;public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings("unchecked") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125;个人觉得使用 Arrays.copyOf()方法主要是为了给原有数组扩容。ensureCapacityArrayList 源码中有一个 ensureCapacity 方法不知道大家注意到没有，这个方法 ArrayList 内部没有被调用过，所以很显然是提供给用户调用的，那么这个方法有什么作用呢？1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It&apos;s already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;最好在 add 大量元素之前用 ensureCapacity 方法，以减少增量重新分配的次数我们通过下面的代码实际测试以下这个方法的效果：123456789101112131415161718192021public class EnsureCapacityTest &#123; public static void main(String[] args) &#123; ArrayList&lt;Object&gt; list = new ArrayList&lt;Object&gt;(); final int N = 10000000; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime = System.currentTimeMillis(); System.out.println("使用ensureCapacity方法前："+(endTime - startTime)); list = new ArrayList&lt;Object&gt;(); long startTime1 = System.currentTimeMillis(); list.ensureCapacity(N); for (int i = 0; i &lt; N; i++) &#123; list.add(i); &#125; long endTime1 = System.currentTimeMillis(); System.out.println("使用ensureCapacity方法后："+(endTime1 - startTime1)); &#125;&#125;运行结果：12使用ensureCapacity方法前：4637使用ensureCapacity方法后：241通过运行结果，我们可以很明显的看出向 ArrayList 添加大量元素之前最好先使用ensureCapacity 方法，以减少增量重新分配的次数。LinkedList分析LinkedList是一个实现了List接口和Deque接口的双端链表。 LinkedList底层的链表结构使它支持高效的插入和删除操作，另外它实现了Deque接口，使得LinkedList类也具有队列的特性；LinkedList不是线程安全的，如果想使LinkedList变成线程安全的，可以调用静态类Collections类中的synchronizedList方法：1List list=Collections.synchronizedList(new LinkedList(...));内部结构分析12345678910private static class Node&lt;E&gt; &#123; E item;//节点值 Node&lt;E&gt; next;//后继节点 Node&lt;E&gt; prev;//前驱节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125;这个类就代表双端链表的节点Node。这个类有三个属性，分别是前驱节点，本节点的值，后继结点。构造方法空构造方法：12public LinkedList() &#123;&#125;用已有的集合创建链表的构造方法：1234public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;add方法add(E e) 方法：将元素添加到链表尾部123456789101112131415161718public boolean add(E e) &#123; linkLast(e);//这里就只调用了这一个方法 return true;&#125;/*** 链接使e作为最后一个元素。*/void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode;//新建节点 if (l == null) first = newNode; else l.next = newNode;//指向后继元素也就是指向下一个元素 size++; modCount++;&#125;add(int index,E e)：在指定位置添加元素12345678public void add(int index, E element) &#123; checkPositionIndex(index); //检查索引是否处于[0-size]之间 if (index == size)//添加在链表尾部 linkLast(element); else//添加在链表中间 linkBefore(element, node(index));&#125;linkBefore方法需要给定两个参数，一个插入节点的值，一个指定的node，所以我们又调用了Node(index)去找到index对应的nodeaddAll(Collection c )：将集合插入到链表尾部123public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;addAll(int index, Collection c)： 将集合从指定位置开始插入1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; //1:检查index范围是否在size之内 checkPositionIndex(index); //2:toArray()方法把集合的数据存到对象数组中 Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; //3：得到插入位置的前驱节点和后继节点 Node&lt;E&gt; pred, succ; //如果插入位置为尾部，前驱节点为last，后继节点为null if (index == size) &#123; succ = null; pred = last; &#125; //否则，调用node()方法得到后继节点，再得到前驱节点 else &#123; succ = node(index); pred = succ.prev; &#125; // 4：遍历数据将数据插入 for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; //创建新节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); //如果插入位置在链表头部 if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; //如果插入位置在尾部，重置last节点 if (succ == null) &#123; last = pred; &#125; //否则，将插入的链表与先前链表连接起来 else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true;&#125;上面可以看出addAll方法通常包括下面四个步骤：检查index范围是否在size之内toArray()方法把集合的数据存到对象数组中得到插入位置的前驱和后继节点遍历数据，将数据插入到指定位置addFirst(E e)： 将元素添加到链表头部12345678910111213141516 public void addFirst(E e) &#123; linkFirst(e); &#125;private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f);//新建节点，以头节点为后继节点 first = newNode; //如果链表为空，last节点也指向该节点 if (f == null) last = newNode; //否则，将头节点的前驱指针指向新节点，也就是指向前一个元素 else f.prev = newNode; size++; modCount++;&#125;addLast(E e)： 将元素添加到链表尾部，与 add(E e) 方法一样123public void addLast(E e) &#123; linkLast(e);&#125;根据位置取数据的方法get(int index)： 根据指定索引返回数据123456public E get(int index) &#123; //检查index范围是否在size之内 checkElementIndex(index); //调用Node(index)去找到index对应的node然后返回它的值 return node(index).item;&#125;获取头节点（index=0）数据方法:123456789101112131415161718public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;public E element() &#123; return getFirst();&#125;public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;区别： getFirst()，element()，peek()，peekFirst() 这四个获取头结点方法的区别在于对链表为空时的处理，是抛出异常还是返回null，其中getFirst() 和element() 方法将会在链表为空时，抛出异常element()方法的内部就是使用getFirst()实现的。它们会在链表为空时，抛出NoSuchElementException获取尾节点（index=-1）数据方法:12345678910public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125;public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item;&#125;两者区别： getLast() 方法在链表为空时，会抛出NoSuchElementException，而peekLast() 则不会，只是会返回 null。根据对象得到索引的方法int indexOf(Object o)： 从头遍历找12345678910111213141516171819public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; //从头遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; //从头遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1;&#125;int lastIndexOf(Object o)： 从尾遍历找12345678910111213141516171819public int lastIndexOf(Object o) &#123; int index = size; if (o == null) &#123; //从尾遍历 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (x.item == null) return index; &#125; &#125; else &#123; //从尾遍历 for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1;&#125;检查链表是否包含某对象的方法contains(Object o)： 检查对象o是否存在于链表中123public boolean contains(Object o) &#123; return indexOf(o) != -1;&#125;删除方法remove() ,removeFirst(),pop(): 删除头节点123456789101112public E pop() &#123; return removeFirst();&#125;public E remove() &#123; return removeFirst();&#125;public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;removeLast(),pollLast(): 删除尾节点12345678910public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125;public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l);&#125;区别： removeLast()在链表为空时将抛出NoSuchElementException，而pollLast()方法返回null。remove(Object o): 删除指定元素12345678910111213141516171819202122232425public boolean remove(Object o) &#123; //如果删除对象为null if (o == null) &#123; //从头开始遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //找到元素 if (x.item == null) &#123; //从链表中移除找到的元素 unlink(x); return true; &#125; &#125; &#125; else &#123; //从头开始遍历 for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; //找到元素 if (o.equals(x.item)) &#123; //从链表中移除找到的元素 unlink(x); return true; &#125; &#125; &#125; return false;&#125;当删除指定对象时，只需调用remove(Object o)即可，不过该方法一次只会删除一个匹配的对象，如果删除了匹配对象，返回true，否则false。unlink(Node x) 方法：123456789101112131415161718192021222324252627E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next;//得到后继节点 final Node&lt;E&gt; prev = x.prev;//得到前驱节点 //删除前驱指针 if (prev == null) &#123; first = next;//如果删除的节点是头节点,令头节点指向该节点的后继节点 &#125; else &#123; prev.next = next;//将前驱节点的后继节点指向后继节点 x.prev = null; &#125; //删除后继指针 if (next == null) &#123; last = prev;//如果删除的节点是尾节点,令尾节点指向该节点的前驱节点 &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125;remove(int index)：删除指定位置的元素123456public E remove(int index) &#123; //检查index范围 checkElementIndex(index); //将节点删除 return unlink(node(index));&#125;LinkedList类常用方法测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116public class LinkedListDemo &#123; public static void main(String[] srgs) &#123; //创建存放int类型的linkedList LinkedList&lt;Integer&gt; linkedList = new LinkedList&lt;&gt;(); /************************** linkedList的基本操作 ************************/ linkedList.addFirst(0); // 添加元素到列表开头 linkedList.add(1); // 在列表结尾添加元素 linkedList.add(2, 2); // 在指定位置添加元素 linkedList.addLast(3); // 添加元素到列表结尾 System.out.println("LinkedList（直接输出的）: " + linkedList); System.out.println("getFirst()获得第一个元素: " + linkedList.getFirst()); // 返回此列表的第一个元素 System.out.println("getLast()获得第最后一个元素: " + linkedList.getLast()); // 返回此列表的最后一个元素 System.out.println("removeFirst()删除第一个元素并返回: " + linkedList.removeFirst()); // 移除并返回此列表的第一个元素 System.out.println("removeLast()删除最后一个元素并返回: " + linkedList.removeLast()); // 移除并返回此列表的最后一个元素 System.out.println("After remove:" + linkedList); System.out.println("contains()方法判断列表是否包含1这个元素:" + linkedList.contains(1)); // 判断此列表包含指定元素，如果是，则返回true System.out.println("该linkedList的大小 : " + linkedList.size()); // 返回此列表的元素个数 /************************** 位置访问操作 ************************/ System.out.println("-----------------------------------------"); linkedList.set(1, 3); // 将此列表中指定位置的元素替换为指定的元素 System.out.println("After set(1, 3):" + linkedList); System.out.println("get(1)获得指定位置（这里为1）的元素: " + linkedList.get(1)); // 返回此列表中指定位置处的元素 /************************** Search操作 ************************/ System.out.println("-----------------------------------------"); linkedList.add(3); System.out.println("indexOf(3): " + linkedList.indexOf(3)); // 返回此列表中首次出现的指定元素的索引 System.out.println("lastIndexOf(3): " + linkedList.lastIndexOf(3));// 返回此列表中最后出现的指定元素的索引 /************************** Queue操作 ************************/ System.out.println("-----------------------------------------"); System.out.println("peek(): " + linkedList.peek()); // 获取但不移除此列表的头 System.out.println("element(): " + linkedList.element()); // 获取但不移除此列表的头 linkedList.poll(); // 获取并移除此列表的头 System.out.println("After poll():" + linkedList); linkedList.remove(); System.out.println("After remove():" + linkedList); // 获取并移除此列表的头 linkedList.offer(4); System.out.println("After offer(4):" + linkedList); // 将指定元素添加到此列表的末尾 /************************** Deque操作 ************************/ System.out.println("-----------------------------------------"); linkedList.offerFirst(2); // 在此列表的开头插入指定的元素 System.out.println("After offerFirst(2):" + linkedList); linkedList.offerLast(5); // 在此列表末尾插入指定的元素 System.out.println("After offerLast(5):" + linkedList); System.out.println("peekFirst(): " + linkedList.peekFirst()); // 获取但不移除此列表的第一个元素 System.out.println("peekLast(): " + linkedList.peekLast()); // 获取但不移除此列表的第一个元素 linkedList.pollFirst(); // 获取并移除此列表的第一个元素 System.out.println("After pollFirst():" + linkedList); linkedList.pollLast(); // 获取并移除此列表的最后一个元素 System.out.println("After pollLast():" + linkedList); linkedList.push(2); // 将元素推入此列表所表示的堆栈（插入到列表的头） System.out.println("After push(2):" + linkedList); linkedList.pop(); // 从此列表所表示的堆栈处弹出一个元素（获取并移除列表第一个元素） System.out.println("After pop():" + linkedList); linkedList.add(3); linkedList.removeFirstOccurrence(3); // 从此列表中移除第一次出现的指定元素（从头部到尾部遍历列表） System.out.println("After removeFirstOccurrence(3):" + linkedList); linkedList.removeLastOccurrence(3); // 从此列表中移除最后一次出现的指定元素（从尾部到头部遍历列表） System.out.println("After removeFirstOccurrence(3):" + linkedList); /************************** 遍历操作 ************************/ System.out.println("-----------------------------------------"); linkedList.clear(); for (int i = 0; i &lt; 100000; i++) &#123; linkedList.add(i); &#125; // 迭代器遍历 long start = System.currentTimeMillis(); Iterator&lt;Integer&gt; iterator = linkedList.iterator(); while (iterator.hasNext()) &#123; iterator.next(); &#125; long end = System.currentTimeMillis(); System.out.println("Iterator：" + (end - start) + " ms"); // 顺序遍历(随机遍历) start = System.currentTimeMillis(); for (int i = 0; i &lt; linkedList.size(); i++) &#123; linkedList.get(i); &#125; end = System.currentTimeMillis(); System.out.println("for：" + (end - start) + " ms"); // 另一种for循环遍历 start = System.currentTimeMillis(); for (Integer i : linkedList) ; end = System.currentTimeMillis(); System.out.println("for2：" + (end - start) + " ms"); // 通过pollFirst()或pollLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp1 = new LinkedList&lt;&gt;(); temp1.addAll(linkedList); start = System.currentTimeMillis(); while (temp1.size() != 0) &#123; temp1.pollFirst(); &#125; end = System.currentTimeMillis(); System.out.println("pollFirst()或pollLast()：" + (end - start) + " ms"); // 通过removeFirst()或removeLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp2 = new LinkedList&lt;&gt;(); temp2.addAll(linkedList); start = System.currentTimeMillis(); while (temp2.size() != 0) &#123; temp2.removeFirst(); &#125; end = System.currentTimeMillis(); System.out.println("removeFirst()或removeLast()：" + (end - start) + " ms"); &#125;&#125;HashMap分析HashMap 主要用来存放键值对，它基于哈希表的Map接口实现，是常用的Java集合之一。JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。底层数据结构分析JDK1.8之前JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。JDK 1.8 HashMap 的 hash 方法源码:JDK 1.8 的 hash方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。12345678public class LinkedListDemo &#123; static final int hash(Object key) &#123; int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &gt;&gt;&gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125;对比一下 JDK1.7的 HashMap 的 hash 方法源码.12345678static int hash(int h) &#123; // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。JDK1.8之后相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。类的属性：12345678910111213141516171819202122232425262728public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123; // 序列号 private static final long serialVersionUID = 362498820763181265L; // 默认的初始容量是16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认的填充因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 当桶(bucket)上的结点数大于这个值时会转成红黑树 static final int TREEIFY_THRESHOLD = 8; // 当桶(bucket)上的结点数小于这个值时树转链表 static final int UNTREEIFY_THRESHOLD = 6; // 桶中结构转化为红黑树对应的table的最小大小 static final int MIN_TREEIFY_CAPACITY = 64; // 存储元素的数组，总是2的幂次倍 transient Node&lt;k,v&gt;[] table; // 存放具体元素的集 transient Set&lt;map.entry&lt;k,v&gt;&gt; entrySet; // 存放元素的个数，注意这个不等于数组的长度。 transient int size; // 每次扩容和更改map结构的计数器 transient int modCount; // 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容 int threshold; // 加载因子 final float loadFactor;&#125;loadFactor加载因子loadFactor加载因子是控制数组存放数据的疏密程度，loadFactor越趋近于1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor越小，也就是趋近于0，数组中存放的数据(entry)也就越少，也就越稀疏。loadFactor太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor的默认值为0.75f是官方给出的一个比较好的临界值。给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。thresholdthreshold = capacity * loadFactor，当Size&gt;=threshold的时候，那么就要考虑对数组的扩增了，也就是说，这个的意思就是 衡量数组是否需要扩增的一个标准。Node节点类源码:123456789101112131415161718192021222324252627282930313233343536373839// 继承自 Map.Entry&lt;K,V&gt;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash;// 哈希值，存放元素到hashmap中时用来与其他元素hash值比较 final K key;//键 V value;//值 // 指向下一个节点 Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; // 重写hashCode()方法 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // 重写 equals() 方法 public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125;树节点类源码:12345678910111213141516static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // 父 TreeNode&lt;K,V&gt; left; // 左 TreeNode&lt;K,V&gt; right; // 右 TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; // 判断颜色 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; // 返回根节点 final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125;HashMap源码分析构造方法123456789101112131415161718192021222324252627// 默认构造函数。public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;// 包含另一个“Map”的构造函数public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);//下面会分析到这个方法&#125;// 指定“容量大小”的构造函数public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;// 指定“容量大小”和“加载因子”的构造函数public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;putMapEntries方法：123456789101112131415161718192021222324final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; // 判断table是否已经初始化 if (table == null) &#123; // pre-size // 未初始化，s为m的实际元素个数 float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); // 计算得到的t大于阈值，则初始化阈值 if (t &gt; threshold) threshold = tableSizeFor(t); &#125; // 已初始化，并且m元素个数大于阈值，进行扩容处理 else if (s &gt; threshold) resize(); // 将m中的所有元素添加至HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125;put方法HashMap只提供了put用于添加元素，putVal方法只是给put方法调用的一个方法，并没有提供给用户使用。对putVal方法添加元素的分析如下：①如果定位到的数组位置没有元素 就直接插入。②如果定位到的数组位置有元素就和要插入的key比较，如果key相同就直接覆盖，如果key不相同，就判断p是否是一个树节点，如果是就调用e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // table未初始化或者长度为0，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // (n - 1) &amp; hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中) if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶中已经存在元素 else &#123; Node&lt;K,V&gt; e; K k; // 比较桶中第一个元素(数组中的结点)的hash值相等，key相等 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 将第一个元素赋值给e，用e来记录 e = p; // hash值不相等，即key不相等；为红黑树结点 else if (p instanceof TreeNode) // 放入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 为链表结点 else &#123; // 在链表最末插入结点 for (int binCount = 0; ; ++binCount) &#123; // 到达链表的尾部 if ((e = p.next) == null) &#123; // 在尾部插入新结点 p.next = newNode(hash, key, value, null); // 结点数量达到阈值，转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 跳出循环 break; &#125; // 判断链表中结点的key值与插入的元素的key值是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 相等，跳出循环 break; // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表 p = e; &#125; &#125; // 表示在桶中找到key值、hash值与插入元素相等的结点 if (e != null) &#123; // 记录e的value V oldValue = e.value; // onlyIfAbsent为false或者旧值为null if (!onlyIfAbsent || oldValue == null) //用新值替换旧值 e.value = value; // 访问后回调 afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 结构性修改 ++modCount; // 实际大小大于阈值则扩容 if (++size &gt; threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null;&#125;get方法12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 数组元素相等 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 桶中不止一个节点 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;resize方法进行扩容，会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;HashMap常用方法测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class HashMapDemo &#123; public static void main(String[] args) &#123; HashMap&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); // 键不能重复，值可以重复 map.put("san", "张三"); map.put("si", "李四"); map.put("wu", "王五"); map.put("wang", "老王"); map.put("wang", "老王2");// 老王被覆盖 map.put("lao", "老王"); System.out.println("-------直接输出hashmap:-------"); System.out.println(map); /** * 遍历HashMap */ // 1.获取Map中的所有键 System.out.println("-------foreach获取Map中所有的键:------"); Set&lt;String&gt; keys = map.keySet(); for (String key : keys) &#123; System.out.print(key+" "); &#125; System.out.println();//换行 // 2.获取Map中所有值 System.out.println("-------foreach获取Map中所有的值:------"); Collection&lt;String&gt; values = map.values(); for (String value : values) &#123; System.out.print(value+" "); &#125; System.out.println();//换行 // 3.得到key的值的同时得到key所对应的值 System.out.println("-------得到key的值的同时得到key所对应的值:-------"); Set&lt;String&gt; keys2 = map.keySet(); for (String key : keys2) &#123; System.out.print(key + "：" + map.get(key)+" "); &#125; /** * 另外一种不常用的遍历方式 */ // 当我调用put(key,value)方法的时候，首先会把key和value封装到 // Entry这个静态内部类对象中，把Entry对象再添加到数组中，所以我们想获取 // map中的所有键值对，我们只要获取数组中的所有Entry对象，接下来 // 调用Entry对象中的getKey()和getValue()方法就能获取键值对了 Set&lt;java.util.Map.Entry&lt;String, String&gt;&gt; entrys = map.entrySet(); for (java.util.Map.Entry&lt;String, String&gt; entry : entrys) &#123; System.out.println(entry.getKey() + "--" + entry.getValue()); &#125; /** * HashMap其他常用方法 */ System.out.println("after map.size()："+map.size()); System.out.println("after map.isEmpty()："+map.isEmpty()); System.out.println(map.remove("san")); System.out.println("after map.remove()："+map); System.out.println("after map.get(si)："+map.get("si")); System.out.println("after map.containsKey(si)："+map.containsKey("si")); System.out.println("after containsValue(李四)："+map.containsValue("李四")); System.out.println(map.replace("si", "李四2")); System.out.println("after map.replace(si, 李四2):"+map); &#125;&#125;TreeMap分析123public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable在此分析一下Map的体系结构：AbstractMap是一个实现Map接口的抽象类，它实现了一个Map的骨架，方便开发者来实现一个自己的Map。如果开发者需要实现一个自己的不可变的Map，只需要继承它再实现entrySet方法。如果开发者想需要实现一个自己的可变的Map，在不可变Map的基础上还需要实现put方法，并且在其的iterator上实现remove方法。SortedMap是一个键有序的Map，存在Comparator时使用其规则，否则使用Comparable的规则。NavigableMap是一个导航Map，它含有的方法可以帮助寻找一个键的上一个键，下一个键，或者按键值逆序等。红黑树的特点每个结点都有颜色，红色或者黑色根结点是黑色的每个叶结点是黑色的（设叶结点是NIL，但它不是一个空节点，是一个哨兵）如果一个结点是红色的，则它的两个子结点都是黑色的对每个结点，从该结点到其所有后代结点的简单路径上，均包含相同数目的黑色结点旋转左旋1234567891011121314151617private void rotateLeft(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; r = p.right; p.right = r.left; if (r.left != null) r.left.parent = p; r.parent = p.parent; if (p.parent == null) root = r; else if (p.parent.left == p) p.parent.left = r; else p.parent.right = r; r.left = p; p.parent = r; &#125;&#125;右旋123456789101112131415private void rotateRight(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; l = p.left; p.left = l.right; if (l.right != null) l.right.parent = p; l.parent = p.parent; if (p.parent == null) root = l; else if (p.parent.right == p) p.parent.right = l; else p.parent.left = l; l.right = p; p.parent = l; &#125;&#125;增加123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; if (t == null) &#123; // 如果实体不支持自然排序，有没有传入排序器，报异常。此行代码只做类型检查 compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) // key &lt; t.key t = t.left; else if (cmp &gt; 0) // key &gt; t.key t = t.right; else return t.setValue(value); // key和t.key相等时覆盖 &#125; while (t != null); &#125; else &#123; if (key == null) throw new NullPointerException(); @SuppressWarnings("unchecked") Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // t为空时会走到此步，parent为最后一个经过的有数据的节点 Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e); size++; modCount++; return null; // 返回的是旧的 value&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; // y是x的叔叔结点 Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); // 当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色 // 将父结点和叔叔结点涂黑，将爷爷结点涂红 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); // 当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的右子 // 当前结点的父结点做为新的当前结点，以新当前结点为支点左旋 &#125; else &#123; if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); rotateLeft(x); &#125; // 当前结点的父结点是红色，叔叔结点是黑色，当前结点是其父结点的左子 // 父结点变为黑色，祖父结点变为红色，在祖父结点为支点右旋 setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateRight(parentOf(parentOf(x))); &#125; &#125; else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); // 当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色 // 将父结点和叔叔结点涂黑，将爷爷结点涂红 if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); setColor(y, BLACK); setColor(parentOf(parentOf(x)), RED); x = parentOf(parentOf(x)); // 当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子 // 当前结点的父结点做为新的当前结点，以新当前结点为支点右旋 &#125; else &#123; if (x == leftOf(parentOf(x))) &#123; x = parentOf(x); rotateRight(x); &#125; // 当前结点的父结点是红色,叔叔结点是黑色，当前结点是其父结点的左子 // 父结点变为黑色，祖父结点变为红色，在祖父结点为支点左旋 setColor(parentOf(x), BLACK); setColor(parentOf(parentOf(x)), RED); rotateLeft(parentOf(parentOf(x))); &#125; &#125; &#125; root.color = BLACK;&#125;删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public V remove(Object key) &#123; Entry&lt;K,V&gt; p = getEntry(key); if (p == null) return null; V oldValue = p.value; deleteEntry(p); return oldValue; // 返回旧的value&#125;private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; size--; // If strictly internal, copy successor's element to p and then make p // point to successor. if (p.left != null &amp;&amp; p.right != null) &#123; // s 是后继 Entry&lt;K,V&gt; s = successor(p); // p 拷贝到 s p.key = s.key; p.value = s.value; // p 现在指向需要被删除的结点 p = s; &#125; // p has 2 children // 到了这里，无论原始的p有无孩子，p都是被即将被删除的结点 // Start fixup at replacement node, if it exists. Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); // replacement指向有数据的子树，设为R子树，此子树会替代原始的子树 if (replacement != null) &#123; // 有孩子 // Link replacement to parent // R子树的父亲指向即将被删除的结点的父亲 replacement.parent = p.parent; // 如果即将被删除的结点没有父亲（有孩子） if (p.parent == null) root = replacement; // 把R子树挂上去 else if (p == p.parent.left) p.parent.left = replacement; // 把R子树挂上去 else p.parent.right = replacement; // 到了这步，p已经被替换掉了。将其的连接结点都置空 // Null out links so they are OK to use by fixAfterDeletion. p.left = p.right = p.parent = null; // Fix replacement // R子树上去后，如果是删除的结点是黑色，需要调整 if (p.color == BLACK) fixAfterDeletion(replacement); // 和第39行的区别是：第39行的情况p是一个根结点，而此种情况就p这一个结点 &#125; else if (p.parent == null) &#123; // return if we are the only node. root = null; // 没有孩子，有父亲，是个叶结点 &#125; else &#123; // No children. Use self as phantom replacement and unlink. if (p.color == BLACK) // 转下去分析修复 fixAfterDeletion(p); if (p.parent != null) &#123; if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// x 是上一步的R子树private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; // 真正要修复的情况是：被删除的结点是黑色且升上去的结点也是黑色（此时黑高会减1） // 算法的目的是让x指向的那棵树是红结点且整棵树不违反红黑树的性质 while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; // 总共有四种违反红黑树性质的情况。 // 若被删除的结点树红色，直接删除，无任何影响 // 若被删除的结点是黑色，但是上来的结点是红色，直接将其染黑就行了 if (x == leftOf(parentOf(x))) &#123; // 当前结点是黑+黑且兄弟结点为红色（此时父结点和兄弟结点的子结点为黑） Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); // 把父结点染成红色，把兄弟结点染成黑色，左旋 if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); setColor(parentOf(x), RED); // 旋转不改变x的指向 rotateLeft(parentOf(x)); sib = rightOf(parentOf(x)); &#125; // ---到了这步，x仍然指向这一轮迭代初的结点，sib会转为黑色 // 兄弟结点的两个子结点全为黑色，兄弟结点染红 if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; setColor(sib, RED); // 走到此步，退出循环，x此时为红色 x = parentOf(x); &#125; else &#123; // 兄弟结点是黑色，兄弟的左子是红色，右子是黑色 // 把兄弟结点染红，兄弟左子结点染黑，之后再以兄弟结点为支点解右旋 if (colorOf(rightOf(sib)) == BLACK) &#123; setColor(leftOf(sib), BLACK); setColor(sib, RED); rotateRight(sib); // 调整兄弟结点的指向 sib = rightOf(parentOf(x)); &#125; // 到了这步，兄弟结点是黑色，兄弟结点的右子是红色 // 把兄弟结点染成当前结点父结点的颜色，把当前结点父结点染成黑色， // 兄弟结点右子染成黑色，之后以当前结点的父结点为支点进行左旋 setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; &#125; &#125; else &#123; // symmetric Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); &#125; if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) &#123; setColor(sib, RED); x = parentOf(x); &#125; else &#123; if (colorOf(leftOf(sib)) == BLACK) &#123; setColor(rightOf(sib), BLACK); setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); &#125; setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; &#125; &#125; &#125; setColor(x, BLACK);&#125;Collections和Arrays常见方法Collections排序操作123456void reverse(List list) //反转void shuffle(List list) //随机排序void sort(List list) //按自然排序的升序排序void sort(List list, Comparator c) //定制排序，由Comparator控制排序逻辑void swap(List list, int i , int j) //交换两个索引位置的元素void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面。查找,替换操作12345678910111213141516int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的 int max(Collection coll)//根据元素的自然顺序，返回最大的元素。int min(Collection coll)int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素。int frequency(Collection c, Object o)//统计元素出现次数int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1int lastIndexOfSubList(List source, list target)boolean replaceAll(List list, Object oldVal, Object newVal) //用新元素替换旧元素Arrays排序 : sort()123456789101112131415161718192021222324252627282930313233343536373839int a[] = &#123; 1, 3, 2, 7, 6, 5, 4, 9 &#125;;// sort(int[] a)方法按照数字顺序排列指定的数组。Arrays.sort(a);System.out.println("Arrays.sort(a):");for (int i : a) &#123; System.out.print(i);&#125;// 换行System.out.println();// sort(int[] a,int fromIndex,int toIndex)按升序排列数组的指定范围int b[] = &#123; 1, 3, 2, 7, 6, 5, 4, 9 &#125;;Arrays.sort(b, 2, 6);System.out.println("Arrays.sort(b, 2, 6):");for (int i : b) &#123; System.out.print(i);&#125;// 换行System.out.println();int c[] = &#123; 1, 3, 2, 7, 6, 5, 4, 9 &#125;;// parallelSort(int[] a) 按照数字顺序排列指定的数组(并行的)。同sort方法一样也有按范围的排序Arrays.parallelSort(c);System.out.println("Arrays.parallelSort(c)：");for (int i : c) &#123; System.out.print(i);&#125;// 换行System.out.println();// parallelSort给字符数组排序，sort也可以char d[] = &#123; 'a', 'f', 'b', 'c', 'e', 'A', 'C', 'B' &#125;;Arrays.parallelSort(d);System.out.println("Arrays.parallelSort(d)：");for (char d2 : d) &#123; System.out.print(d2);&#125;查找 : binarySearch()1234567char[] e = &#123; 'a', 'f', 'b', 'c', 'e', 'A', 'C', 'B' &#125;;// 排序后再进行二分查找，否则找不到Arrays.sort(e);System.out.println("Arrays.sort(e)" + Arrays.toString(e));System.out.println("Arrays.binarySearch(e, 'c')：");int s = Arrays.binarySearch(e, 'c');System.out.println("字符c在数组的位置：" + s);比较: equals()1234567char[] e = &#123; 'a', 'f', 'b', 'c', 'e', 'A', 'C', 'B' &#125;;char[] f = &#123; 'a', 'f', 'b', 'c', 'e', 'A', 'C', 'B' &#125;;/** 元素数量相同，并且相同位置的元素相同。 另外，如果两个数组引用都是null，则它们被认为是相等的 。*/// 输出trueSystem.out.println("Arrays.equals(e, f):" + Arrays.equals(e, f));填充 : fill()12345678910111213141516171819int[] g = &#123; 1, 2, 3, 3, 3, 3, 6, 6, 6 &#125;;// 数组中所有元素重新分配值Arrays.fill(g, 3);System.out.println("Arrays.fill(g, 3)：");// 输出结果：333333333for (int i : g) &#123; System.out.print(i);&#125;// 换行System.out.println();int[] h = &#123; 1, 2, 3, 3, 3, 3, 6, 6, 6, &#125;;// 数组中指定范围元素重新分配值Arrays.fill(h, 0, 2, 9);System.out.println("Arrays.fill(h, 0, 2, 9);：");// 输出结果：993333666for (int i : h) &#123; System.out.print(i);&#125;转列表 asList()12345678/** 返回由指定数组支持的固定大小的列表。* （将返回的列表更改为“写入数组”。）该方法作为基于数组和基于集合的API之间的桥梁，与Collection.toArray()相结合 。* 返回的列表是可序列化的，并实现RandomAccess 。* 此方法还提供了一种方便的方式来创建一个初始化为包含几个元素的固定大小的列表如下：*/List&lt;String&gt; stooges = Arrays.asList("Larry", "Moe", "Curly");System.out.println(stooges);转字符串 toString()12345/** 返回指定数组的内容的字符串表示形式。*/char[] k = &#123; 'a', 'f', 'b', 'c', 'e', 'A', 'C', 'B' &#125;;System.out.println(Arrays.toString(k));// [a, f, b, c, e, A, C, B]复制 copyOf()12345678910111213141516171819// copyOf 方法实现数组复制,h为数组，6为复制的长度int[] h = &#123; 1, 2, 3, 3, 3, 3, 6, 6, 6, &#125;;int i[] = Arrays.copyOf(h, 6);System.out.println("Arrays.copyOf(h, 6);：");// 输出结果：123333for (int j : i) &#123; System.out.print(j);&#125;// 换行System.out.println();// copyOfRange将指定数组的指定范围复制到新数组中int j[] = Arrays.copyOfRange(h, 6, 11);System.out.println("Arrays.copyOfRange(h, 6, 11)：");// 输出结果66600(h数组只有9个元素这里是从索引6到索引11复制所以不足的就为0)for (int j2 : j) &#123; System.out.print(j2);&#125;// 换行System.out.println();序列化把变量从内存中变成可存储或传输的过程称之为序列化，把字节序列恢复为Java对象的过程称为对象的反序列化。对象的序列化主要有两种用途：把对象的字节序列永久的保存到硬盘上，通常存放在一个文件中。在网络上传送对象的字节序列。默认序列化1234567891011121314151617181920212223242526272829303132333435363738public class Server &#123; public static void main(String[] args) throws Exception &#123; Path path = Paths.get("test"); Person temp = new Person("陈钰琪", 19, "411x2x19xx1x2x6x1x", 20000d); ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(path.toFile())); out.writeObject(temp); ObjectInputStream in = new ObjectInputStream(new FileInputStream(path.toFile())); Person readObject = (Person)in.readObject(); System.out.println(readObject); &#125;&#125;class Person implements Serializable&#123; private static final long serialVersionUID = -485348963313276072L; private String name; private Integer age; private String id; private Double money; public Person(String name, Integer age, String id, Double money) &#123; this.name = name; this.age = age; this.id = id; this.money = money; &#125; // getter和setter @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + ", id=" + id + ", money=" + money + "]"; &#125;&#125;版本号版本号是为了控制对象的版本而存在的，版本号一致才可认为可以进行对应的序列化和反序列化。比如我们使用上面的代码把一个Person写入temp文件了，然后修改serialVersionUID = 485348963313276072L;，会发现爆出java.io.InvalidClassException。单例的处理1234567891011121314public final class MySingleton implements Serializable&#123; private static final long serialVersionUID = 1L; private MySingleton() &#123; &#125; private static final MySingleton INSTANCE = new MySingleton(); public static MySingleton getInstance() &#123; return INSTANCE; &#125; private Object readResolve() throws ObjectStreamException &#123; // instead of the object we're on, return the class variable INSTANCE return INSTANCE; &#125; &#125;反序列化”组装”一个新对象时，就会自动调用这个readResolve方法来返回我们指定好的对象了，单例规则也就得到了保证。​]]></content>
      <categories>
        <category>应届求职复习</category>
      </categories>
      <tags>
        <tag>应届求职复习</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java邮件发送]]></title>
    <url>%2F2019%2FJava%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%2F</url>
    <content type="text"><![CDATA[Maven依赖12345&lt;dependency&gt; &lt;groupId&gt;javax.mail&lt;/groupId&gt; &lt;artifactId&gt;mail&lt;/artifactId&gt; &lt;version&gt;1.4.7&lt;/version&gt;&lt;/dependency&gt;不要修改版本号，这个版本之间的差异很大。代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Component@EnableConfigurationProperties(MailConfig.class)public class MailVerification &#123; // 收件人地址 private String recipientAddress; private String info; @Autowired private MailConfig mailconfig; public void sendVerCode(String info, String recipientAddress) throws Exception &#123; this.info = info; this.recipientAddress = recipientAddress; //1、连接邮件服务器的参数配置 Properties props = new Properties(); //设置用户的认证方式 props.setProperty("mail.smtp.auth", "true"); //设置传输协议 props.setProperty("mail.transport.protocol", "smtp"); //设置发件人的SMTP服务器地址 props.setProperty("mail.smtp.host", "smtp.163.com"); //2、创建定义整个应用程序所需的环境信息的 Session 对象 Session session = Session.getInstance(props); //设置调试信息在控制台打印出来 session.setDebug(false); //3、创建邮件的实例对象 Message msg = getMimeMessage(session); //4、根据session对象获取邮件传输对象Transport Transport transport = session.getTransport(); //设置发件人的账户名和密码 transport.connect(mailconfig.getSenderAccount(), mailconfig.getSenderPassword()); //发送邮件，并发送到所有收件人地址，message.getAllRecipients() 获取到的是在创建邮件对象时添加的所有收件人, 抄送人, 密送人 transport.sendMessage(msg, msg.getAllRecipients()); //如果只想发送给指定的人，可以如下写法 //transport.sendMessage(msg, new Address[]&#123;new InternetAddress("xxx@qq.com")&#125;); //5、关闭邮件连接 transport.close(); &#125; /** * 获得创建一封邮件的实例对象 * * @param session * @return * @throws MessagingException * @throws AddressException */ private MimeMessage getMimeMessage(Session session) throws Exception &#123; // 创建一封邮件的实例对象 MimeMessage msg = new MimeMessage(session); // 设置发件人地址 msg.setFrom(new InternetAddress(mailconfig.getSenderAddress())); /** * 设置收件人地址（可以增加多个收件人、抄送、密送），即下面这一行代码书写多行 MimeMessage.RecipientType.TO:发送 * MimeMessage.RecipientType.CC：抄送 MimeMessage.RecipientType.BCC：密送 */ msg.setRecipient(MimeMessage.RecipientType.TO, new InternetAddress(recipientAddress)); msg.setRecipient(MimeMessage.RecipientType.CC, new InternetAddress(mailconfig.getSenderAddress())); msg.setSubject("航班管理系统验证码", "UTF-8"); // 设置邮件正文 msg.setContent("您好，您的验证码是： " + info + " ,请在30分钟内完成验证！", "text/html;charset=UTF-8"); // 设置邮件的发送时间,默认立即发送 msg.setSentDate(new Date()); return msg; &#125;&#125;配置文件12345678910111213141516171819202122232425262728293031@ConfigurationProperties(prefix = "as.email")public class MailConfig &#123; private String senderAddress; private String senderAccount; private String senderPassword; public String getSenderAddress() &#123; return senderAddress; &#125; public void setSenderAddress(String senderAddress) &#123; this.senderAddress = senderAddress; &#125; public String getSenderAccount() &#123; return senderAccount; &#125; public void setSenderAccount(String senderAccount) &#123; this.senderAccount = senderAccount; &#125; public String getSenderPassword() &#123; return senderPassword; &#125; public void setSenderPassword(String senderPassword) &#123; this.senderPassword = senderPassword; &#125;&#125;]]></content>
      <categories>
        <category>邮件发送</category>
      </categories>
      <tags>
        <tag>邮件发送</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7下mysql5.6安装和卸载]]></title>
    <url>%2F2019%2Fcentos7%E4%B8%8Bmysql5-6%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[安装卸载mariadb：yum remove maria*下载安装包文件：wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm安装rpm包：rpm -ivh mysql-community-release-el7-5.noarch.rpm安装mysql：yum install mysql-server启动 mysql 服务：systemctl start mysqld.service重启：systemctl restart mysqld.service停止：systemctl stop mysqld.service设置开机启动：systemctl enable mysqld.service设置密码：mysql -u rootuse mysql;update user set password=PASSWORD(&quot;这里输入root用户密码&quot;) where User=&#39;root&#39;;flush privileges;设置root远程主机登录：GRANT ALL PRIVILEGES ON *.* TO root@&quot;%&quot; IDENTIFIED BY &quot;密码&quot;;GRANT ALL PRIVILEGES ON *.* TO &#39;your username&#39;@&#39;%&#39; IDENTIFIED BY &#39;your password&#39;;设置全局编码集卸载查看MySQL的安装情况：rpm -qa|grep -i mysql停止服务：service mysql stop卸载第一步查询出来的所有结果：rpm -ev 名字 --nodeps查找mysql之前使用过的目录：find / -name mysql删除所有mysql之前使用过的所有目录删除配置文件：rm -rf /etc/my.cnf]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>centos7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML基础]]></title>
    <url>%2F2019%2FUML%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[objectAn object is an entity with a well-defined boundary and identity that encapsulates state and behavior.State is represented by attributes and relationships.Behavior is represented by operations, methods, and state machines.An Object Has StateThe state of an object is one of the possible conditions in which an object may exist.The state of an object normally changes over time.An Object Has BehaviorBehavior determines how an object acts and reacts.The visible behavior [bɪ’heɪvjə] of an object is modeled by the set of messages it can respond to (operations the object can perform).An Object Has IdentityEach object has a unique identity, even if the state is identical to that of another object.classA class is a description of a set of objects that share the same properties and behavior. An object is an instance of a class.The Relationship Between Classes and ObjectsA class is an abstract definition of an object. It defines the structure and behavior of each object in the class. It serves as a template for creating objects.Objects are grouped into classes.An object is an instance of a class.What Is an Operation?An operation is the implementation of a service that can be requested from any object of the class to affect behavior.A class may have any number of operations or none at all.Objects Need to CollaborateObjects are useless unless they can collaborate [kəˈlæbəreɪt] together to solve a problem.Each object is responsible for its own behavior and status.No one object can carry out every responsibility on its own.How do objects interact with each other?They interact through messages.What is a message?A specification of a communication between objects that conveys information with the expectation that activity will ensue(跟着发生)One object asks another object to perform an operation.What Is Abstraction?Abstraction can be defined as: Process allowing to focus on most important aspects while ignoring less important detailsAllows us to manage complexity by concentrating on essential aspects making an entity different from othersAbstractionEmphasizes relevant characteristics.Suppresses（抑制） other characteristics.What Is Encapsulation?Encapsulation means to design, produce, and describe software so that it can be easily used without knowing the details of how it works.Also known as information hidingAn analogy:When you drive a car, you don’t have know the details of how many cylinders(汽缸) the engine has or how the gasoline and air are mixed and ignited(点火).Instead you only have to know how to use the controls.Encapsulation allows objects to be viewed as ‘black boxes’It protects an object’s internal state from being corrupted by other objects.Also, other objects are protected from changes in the object implementation.隔离复杂度What Is Inheritance ?Inheritance [ɪnˈherɪtəns]—a way of organizing classesClasses with properties in common can be grouped so that their common properties are only defined once.增加了软件重用的机会PolymorphismPolymorphism—the same word or phrase can be mean different things in different contextsAnalogy（类比）: in English, bank can mean side of a river or a place to put moneyIn Java, two or more classes could each have a method called outputEach output method would do the right thing for the class that it was in.One output might display a number where as a different one might display a name.What Is Polymorphism?消息发送方不需要知道消息接收方属于那个子类同一类族的接收者可以按自己的方式处理消息同一类族的接收者可以按自己的方式处理同一个消息有多种对象可以按自己的方式处理相同的数据What is an Interface?An interface is a collection of operations that specify a service of a class or component.Interfaces formalize（正式化） polymorphismInterfaces support “plug-and-play(即插即用)” architectures小结类定义了对象群体的逻辑结构，包括属性和操作。系统运行时，类作为产生对象的模板，在物理层面是不存在的对象系统运行时必须为每一个需要的对象分配内存、保存数据对象存在于物理层面，每个对象都有自己的数据空间。所有的对象共享同一块代码空间属性Attribute ==状态state == 信息information操作operation == 方法method ==行为behaviour = = 职责responsibilityProcedural ProgrammingThis programming paradigm（范式） is essentially an abstraction of machine /assembly language.Program is organized around procedures.Focus on data structures, algorithms and sequencing of stepsPrograms = Algorithm + Data StructureAn algorithm is a set of instructions for solving a problemA data structure is a construct used to organize data in a specific way.Most computer languages, from early examples like FORTRAN and ALGOL to more recent languages like C and Ada have been imperative or procedural.Object-Oriented ProgrammingA design and programming techniqueSome terminology:object - usually a person, place or thing (a noun)method - an action performed by an object (a verb)type or class - a category of similar objects (such as automobiles)Objects have both data and methodsObjects of the same class have the same data elements and methodsObjects send and receive messages to invoke actionsC语言是一种面向过程的思维方式程序的运行“一切尽在掌握中”：从main()函数的逐条语句开始执行、调用了子程序就必须一层层返回，最终又返回main函数系统需要完成的功能，分配到各个子函数，由main函数统一调度比较面向过程侧重于考虑方法的编写（哪个方法做什么事，不考虑所涉及的数据在哪里）面向对象则致力于将数据和方法先做一个封装（分配一个对象做事，先考虑所需要的数据是否和它在一起）What is modeling?A model is an abstraction of things.Emphasizes relevant characteristics.Suppresses other characteristics.建模目的We build models to better understand the system we are developing.Modeling achieves four aims.模型帮助我们按照实际情况或按照我们所需要的样式对系统进行可视化模型允许我们详细说明系统的结构或行为模型给出了一个指导我们构造系统的模板模型对我们作出的决策进行文档化We build models of complex systems because we cannot comprehend such a system in its entirety.UMLUnified Modeling Language 统一建模语言作用：建立软件模型，可以用UML对软件密集型系统的制品（artifact：软件开发过程中产生的各种各样的产物）进行可视化、详述、构造和文档化。建模语言：提供统一的交流词汇和规则可视化: 通过标准图符构成图形来描述模型通用标准: 成为软件建模的标准语言,并且在其他领域也得到应用。UML的构成Building Blocks of the UMLThe vocabulary of the UML encompasses three kinds of building blocks:Things: the abstractions that are first-class citizens in a model;Relationships: relationships tie these things together;Diagrams: diagrams group interesting collections of things.Things in the UMLThere are four kinds of things in the UML:Structural things: class, interface, collaboration, use case, active class, component, nodeBehavioral things: interaction, state machine, activityGrouping things: packageAnnotational(注释) things: noteThese things are the basic object-oriented building blocks of the UML.Structural things in the UMLthe nouns of UML models.the mostly static parts of a model, either conceptual or physicalCollectively, the structural things are called classifiersStructural things - ClassA class is a description of a set of objects that share the same attributes, operations, relationships, and semantics(语义).A class is represented using a compartmented(间隔间) rectangleA class is comprised of three sections- The first section contains the class name- The second section shows the structure (attributes)- The third section shows the behavior (operations)Representing ObjectsAn object is represented as rectangles with underlined names##### Structural things - InterfaceAn interface is a collection of operations that specify a service of a class or component.Interfaces support “plug-and-play” architectures##### Structural things – Use Casea use case is a description of set of sequence of actions that a system performs that yields an observable result of value to a particular actor.A use case is used to structure(组织) the behavioral things in a model.A use case is realized by a collaboration.Graphically, a use case is rendered as an ellipse [ɪˈlɪps] with solid lines, usually including only its name.##### Structural things - CollaborationIn the context of a system‘s architecture, a collaboration allows you to name a conceptual chunk(大块) that encompasses both static and dynamic aspects.A collaboration names a society of classes, interfaces, and other elements that work together to provide some cooperative [kəʊ’ɒpərətɪv] behavior that’s bigger than the sum of all its parts.You use collaborations to specify the realization of use cases and operations, and to model the architecturally significant mechanisms of your system.A collaboration is also the specification of how an element, such as a classifier (including a class, interface, component, node, or use case) or an operation, is realized by a set of classifiers and associations playing specific roles used in a specific way.Graphically, a collaboration is rendered as an ellipse(椭圆) with dashed lines.##### Structural things – Active Classan active class is a class whose objects own one or more processes or threads and therefore can initiate control activity.Graphically, an active class is rendered as a class with double lines on the left and right; it usually includes its name, attributes, and operations.##### Structural things – ComponentA component is a modular part of the system design that hides its implementation behind a set of external interfaces.系统中遵从一组接口且提供其实现的物理的、可替换的部分。构件是物理抽象，可以替换的文件。类是逻辑抽象，包含属性和方法。逻辑抽象出来的东西用文件写出来，这些源文件就是构件。eg：##### Structural things – Nodea node is a physical element that exists at run time and represents a computational resource, generally having at least some memory and, often, processing capability.A set of components may reside（安置、居住） on a node and may also migrate from node to node.Graphically, a node is rendered as a cube, usually including only its name.#### Behavioral things in the UMLthe verbs of UML models.the mostly dynamic parts of a modelthree primary kinds- Among a set of objects: interaction- For an object: state machine- The sequence of steps: activity##### Behavioral things - Interactionan interaction is a behavior that comprises（包括） a set of messages exchanged among a set of objects within a particular context to accomplish a specific purpose.An interaction involves（包含、涉及） a number of other elements, including messages, action sequences (the behavior invoked by a message), and links (the connection between objects).Graphically, a message is rendered as a directed line, almost always including the name of its operation.&gt; What Is an Interaction Diagram?An interaction diagram shows an interaction, consisting of a set of objects and their relationships, including the messages that may be dispatched（派遣，分发） among them.It models the dynamic aspects of a system.&gt; What Is a Sequence Diagram?A sequence diagram is an interaction diagram that emphasizes the time ordering of messages.The diagram shows- The objects participating in the interaction.- The sequence of messages exchanged.&gt; What Is a Communication Diagram?A communication diagram emphasizes the organization of the objects that participate in an interaction.The communication diagram shows- The objects participating in the interaction.- Links( physical or conceptual connection among objects) between the objects.- Messages passed between the objects.##### Behavioral things - State machinea state machine is a behavior that specifies the sequences of states an object or an interaction goes through during its lifetime in response to events, together with its responses to those events.A state machine involves a number of other elements, including states, transitions, events, and activities.Graphically, a state is rendered as a rounded rectangle, usually including its name and its substates（子状态）, if any（如果有）.Behavioral things - Activityan activity is a behavior that specifies the sequence of steps a computational process performsIn an activity, the focus is on the flows among steps without regard to which object performs each step.A step of an activity is called an action.Graphically, an action is rendered as a rounded rectangle with a name indicating its purpose. States and actions are distinguished by their different contexts.#### Grouping things in the UML##### Grouping things - Package- Grouping things are the organizational parts of UML models.- Structural things, behavioral things, and even other grouping things may be placed in a package.- Unlike components (which exist at run time), a package is purely conceptual (meaning that it exists only at development time).- Graphically, a package is rendered as a tabbed folder, usually including only its name and, sometimes, its contents.#### Annotational things in the UML##### Annotational things - NoteAnnotational things are the explanatory(解释性的) parts of UML models.These are the comments（解释） you may apply to describe, illuminate（阐释）, and remark about any element in a model.There is one primary kind of annotational thing, called a note.A note is simply a symbol for rendering constraints and comments attached to an element or a collection of elements.Graphically, a note is rendered as a rectangle with a dog-eared corner, together with a textual or graphical comment.### Relationships in the UMLThere are four kinds of relationships in the UML:- Association- Dependency- Generalization- Realization#### What Is an AssociationThe semantic relationship between two or more classes that specifies connections among their instances- A structural relationship, specifying that objects of one thing are connected to objects of another#### Relationships: DependencyA relationship between two model elements where a change in one may cause a change in the other.Non-structural, “using” relationship.#### Relationships: GeneralizationA relationship among classes where one class shares the structure and/or behavior of one or more classesDefines a hierarchy of abstractions in which a subclass inherits from one or more superclasses- Single inheritance- Multiple inheritancean “is-a-kind of” relationship#### Relationships: RealizationOne classifier serves as the contract that the other classifier agrees to carry out### Diagrams in the UMLThe UML1.x includes nine such diagrams:- Use-case diagrams: to illustrate requirement.- Class diagrams: to illustrate logical structure.- Object diagrams: to illustrate objects and links.- State diagrams: to illustrate behavior.- Component diagrams: to illustrate physical structure of the software.- Deployment diagrams: to show the mapping of software to hardware configurations.- Interaction diagrams (i.e., collaboration and sequence diagrams): to illustrate behavior.- Activity diagrams: to illustrate the flow of events in a use-case.A diagram is a view into a modelA model is a complete description of a system from a particular perspective## 规则命名规定对要素(事物)、关系、图命名。例如：student为一个类的名字范围UML成员所定义的内容起作用的上下文环境。可视性UML成员能被其他成员引用的方式。三种：- public（+）：公共- protected（#）：保护- private（-）：私有完整性保证事物正确、一致地相互联系。执行运行或模拟动态模型的含义是什么## UML的公共机制UML的公共机制有：- 规范说明- 修饰- 通用划分- 扩展机制### 规格说明，pecificationUML对每一个元素都有确定的图形表示符号，但对该图形符号还有语法、语义的文字说明。例如，Actor：参与者，UML表示为：### 修饰，adornment图形符号表示一个元素的主要特征，此外，可以加上修饰，表示该元素的其它特征。例如：矩形框表示一个类，有类名，属性，操作等。但也可增加“可视性” 等修饰。### 通用划分（common division）一种保证不同抽象概念层次的机制。有两种通用划分的形式：抽象-实例：例如，类-对象，用例-具体用例接口-实现：接口表示约定，实现表示对约定的实施## Extension mechanism of the UML- Stereotype- Tagged value- Constraint### Extension mechanism - StereotypesA stereotype is an extension of the vocabulary of the UML, allowing you to create new kinds of building blocks similar to existing ones but specific to your problem.Stereotypes must be based on certain existing types or classes in the metamodel. Stereotypes may extend the semantics, but not the structure of pre-existing types and classes. Certain stereotypes are predefined in the UML, others may be user defined.### Extension mechanism - Tagged ValuesMany kinds of elements have detailed properties that do not have a visual notation. In addition, users can define new element properties using the tagged value mechanism.A tagged value is an extension of the properties of a UML element, allowing you to create new information in that element’s specification.A tagged value is a keyword-value pair that may be attached to any kind of model element. The keyword is called a tag.Common examples of tagged values are：- {Author = (Dave,Ron)}- {Version Number = 3}- {Location = d:\java\uml\examples}- {Location = Node: Middle Tier}### Extension mechanism - ConstraintA constraint is an extension of the semantics of a UML elements, allowing you to add new rules or to modify existing ones.Constraints may be written as free-form text. If you want to specify your semantics more precisely, you can use the UML’s Object Constraint Language (OCL).### 小结- Modeling Comments - use notes- Modeling New Building Blocks - use stereotype.- Modeling New Properties - use tagged values.- Modeling New Semantics - use constraint## UML的4+1视图## UML可以用在系统开发的各个阶段- 业务模型：业务用例图，活动图，状态图，实体图；- 需求模型：用例图，活动图，状态图等- 逻辑模型：类图，交互图，活动图，状态图等- 设计模型：类图，交互图，活动图，状态图等- 实现模型：构件图等- 测试模型：用例图，类图，交互图等## 用例A sequence of actions a system performs that yields an observable result of value to a particular actorUML中用例用椭圆表示，使用动宾结构或主谓结构命名。### 用例的特点- 用例从使用系统的角度描述系统中的信息，即站在系统外部查看系统功能，不反映功能的实现方式。- 用例描述用户提出的一些可见需求，对应一个具体的用户目标。- 用例反映系统与用户的一次交互过程，应该具有交互的信息的传递。- 用例是对系统行为的描述，属于UML的动态建模部分。- 通过读卡机，储户插入ATM卡- ATM系统从卡上读取银行ID、帐号、并验证帐号。- 储户键入密码，系统检验密码。- 储户按确认键，输入取款金额。- ATM把帐号和取款金额传递给银行系统，取回帐户余额。- ATM输出现金，并显示帐户余额。- ATM记录事务到日志文件。## What Is an Actor- Actors are not part of the system.- Actors represent roles a user of the system can play(扮演).- They can represent a human, a machine, or another system.- They can actively interchange（交换） information with the system.- They can be a giver of information.- They can be a passive recipient of information.Actors are EXTERNAL.### 参与者参与者(actor)是指系统以外的、需要使用系统或与系统交互的事物，包括: 人、设备、外部系统等。其它译名有: 活动者、执行者、行动者等。例，一个银行业务系统中的参与者：1. 客户：从系统获取信息并执行金融交易2. 管理人员：创建系统的用户，获取并更新信息3. 厂商：接受作为转账支付结果的资金4. Mail系统：与系统交互，发送或接收邮件An actor represents a role that a human, hardware device, or another system can play.UML中的Actor实际上是一个版型化的类, 可以有三种表示形式：由于Actor实际上是一个类, 因此它们之间可以存在一定的关系,如：## 脚本脚本(scenario)在UML中指贯穿用例的一条单一路径，用来显示用例中的正常和特殊情况。系统在某个特定的执行期内所发生的一系列事件。其它译名：情景、场景、情节、剧本。每个用例有一系列脚本，包括一个主要脚本，以及几个次要脚本。相对于主要脚本，次要脚本描述了执行路径中的异常或可选择的情况。## 用例之间的关系用例与参与者之间：关联(association)关系。用例之间的关系有：泛化(generalization)、包含(include)、扩展(extend)等。### 关联关系参与者与用例之间是关联关系，表示参与者与用例之间具有使用，交互信息的关联。### 泛化关系泛化关系代表一般与特殊的关系，与继承类似。在泛化关系中，子用例继承了父用例的行为和含义，子用例也可以增加新的行为和含义或覆盖父用例中的行为和含义。### 包含关系包含关系是指一个用例（基本用例）的行为包含了另一个用例（包含用例）的行为。包含关系是依赖关系的版型。### 扩展关系扩展关系的基本含义与泛化关系类似，但对扩展用例有更多限制, 即基本用例必须声明若干“扩展点”，扩展用例只能在扩展点上增加行为和含义，以扩展到新用例。扩展关系是依赖关系版型。### 关系比较- 扩展关系的基本用例是 well formed 的。一个基本用例执行时，可以执行或不执行扩展用例。- 包含关系的基本用例可以不是或是 well formed 的。执行基本用例时，一定会执行包含用例。- 需要重复处理两个或多个用例时吗，可以考虑包含关系。- 处理正常行为的变型且只是偶而描述时，可以考虑只使用泛化关系。- 处理正常行为的变型且希望采用更多控制方式时，可以在基本用例中设置扩展点，使用扩展关系。## 用例的描述- 用例描述是指对一个用例的功能进行的文字描述，是参与者与系统交互动作序列的说明。- 用例描述才是用例的主要部分，是后续的交互图分析和类图分析必不可少的部分。- 用例采用自然语言描述参与者与系统的交互行为，要易于理解，其读者是开发人员、用户、项目经理、测试人员等。### 错误描述### 正确描述### 用例规约的主要组成- 用例名称- 用例标识- 涉及的参与者- 描述- 用例的规格说明- 前置条件 PreConditions- 后置条件 PostConditions- 正常事件流 Flow of events- 备选事件流 Alternate flow- 其它- 非功能需求、设计约束、尚存在的问题#### 前置、后置条件-1- 前置条件约束在用例开始前系统的状态- 把它们看做是看门人，它阻止参与者触发该用例直到满足所有条件- 说明在用例触发之前什么必须为真- 后置条件约束用例执行后系统的状态- 用例执行后什么必须为真- 对于有多个事件流的用例，则应该有多个后置条件#### 事件流描述要点- 只书写“可观测”的语句、- 系统通过ADO建立数据库连接，传送SQL查询语句，从“商品表”查询商品的详细信息……- 系统按照查询条件搜索商品的详细信息- 使用主动语句- 句子必须以参与者或系统作为主语- 出纳员接收顾客的付款—顾客的付款数可能高于商品总额- 出纳员录入顾客所付的现金总额- 系统显示出应找还给顾客的余额，打印付款收据- 不要涉及界面细节- 会员从下拉框中选择类别- 会员在相应文本框中输入查询条件- 会员点击“确定”按钮- 分支和循环- 分支：参与者的选择- 分支：另一条成功线路- 分支：系统进行验证- 循环：直接描述## 寻找用例的方法- start with actors, then identify what they want to do What functions will the actor want from the system- 系统是否存储和检索信息- Are any actors notified when the system changes ?- Are there external events that notify the system ?- 哪个参与者触发了活动？Which actors trigger activity ?## 用例的常见问题分析### 用例的粒度问题对于一个目标系统进行用例分析后得到的用例数目有多少比较合适?- 用例要有路径，路径要有步骤；而这一切都是可观测的- 最常犯错误：粒度过细，陷入功能分解。过细的粒度，一般都会导致技术语言的描述，而不再是业务语言。如把步骤当用例，或者把系统活动当用例。## 用例模型- 用例模型包括：- 系统边界- 参与者- 用例- 用例图- 用例描述- 是面向对象设计的输入- 是开发部门与顾客之间的合同- 是软件设计部门与软件工程师之间的合同- 是开发部门领导、非直接开发人员，了解系统的主要信息来源## 交互图的概念- 交互图(interaction)：用来描述对象之间及对象与参与者之间的动态协作关系，以及协作过程中行为次序的图形文档。- 交互图的类型：顺序图，协作图- 交互图的作用：用于描述用例的行为，显示该用例中所涉及的对象和这些对象之间的消息传递情况。## 顺序图的概念顺序图(sequence diagram)：用来描述为了完成确定事务，对象之间按照时间进行消息交互的顺序关系。### 对象及命名### 生命线表示对象存在的时间，对象下面一条虚线表示。### 控制焦点(Focus of Control, FOC)小矩形，表示这个时间段内对象将执行操作。#### 激活期- 休眠的对象收到一个消息时，开始活动，称为激活- 激活的对象要么执行自己的代码，要么在等待另一个对象的返回- 激活期外，对象处在休眠期，什么事都不做，但它仍然存在，等待消息的激活### 消息带箭头的连线，表示对象之间传输的信息。#### 消息解释对象之间传输的信息。消息有以下类型：##### 调用消息（procedure call）- 调用消息(也称为同步消息)的发送者把控制传递给接收者，然后停止活动，等到消息接收者放弃或返回控制。- 调用消息必有一个与之配对的返回消息, 但是可以不用画出.#### 异步消息异步消息的发送者通过消息把信号传递给接收者，然后继续自己活动，不等待接收者返回消息或控制。#### 返回消息返回消息表示从过程调用返回。如果是从过程调用返回，则返回消息是隐含的，可以不画出来。对于非过程调用，如果有返回消息，必须画出来。#### 消息的语法格式- display (x,y) 简单消息- p:= find (specs) 嵌套消息，消息带返回值、- [x&lt;0]5: invert (x,color) 条件消息- [i:=1..n]: update() 循环消息### 建立顺序图1. 从用例中识别交互过程;2. 识别参与交互过程的对象;3. 为每一个对象设置生命线,并确定对象的存在期限;哪些对象存在于整个交互过程，哪些对象在交互过程中被创建和销毁。4. 从引发交互的初始消息开始,在对象生命线上依次画出交互的消息;### Use Case：Register New Member1. The customer fills out an application form containing the customer’s name, address and phone number and gives this to the clerk.2. The clerk issues a request to add a new member.3. The system asks for data about the new member.4. The clerk enters the data into the system.5. Reads in data, and if the member can be added, generates an identification number for the member and remembers information about the member. Informs the clerk if the member was added and outputs the member’s name, address, phone and id.6. The clerk gives the user his identification number.### Use Case：Adding New Book1. The library receives a shipment of books from the publisher2. The clerk issues a request to add a new book.3. The system asks for the identifier, title, and author name of the book.4. The clerk generates the unique identifier, enters the identifier, title, and author name of a book.5. The system attempts to enter the information in the catalog and informs the clerk about the result. It then asks if the clerk wants to enter information about another book.6. The clerk answers in the affirmative or in the negative.7. If the answer is in the affirmative, the system goes to Step 3. Otherwise, it exits.## 用例：借书- 参与者：图书管理员- 事件流：1. 管理员进入图书借阅界面，用例开始。2. 管理员输入借书证上的读者编号。3. 系统检验借书证合法性吗，如果正确,则显示借阅者(姓名、学院、年级等信息)及其以前所借图书的信息。- A1：借书证编码有错。- A2: 如果该借阅者所借图书已经超期，则提示，本次拒借。4. 管理员输入图书条码。5. 系统显示所借图书的信息。6. 管理员确认借书，系统保存借书信息（包括时间，读者号，图书编号等）。7. 用例结束。## 协作图- 协作图的概念：用来描述系统的行为是如何由系统的成分协作实现的图，各对象之间消息联系的结构关系。- 协作图样式和元素：### 建立协作图1. 从用例中识别交互过程;2. 识别参与交互过程的对象;3. 确定对象之间的链，以及链上的消息;4. 从引发交互的初始消息开始,将随后每个消息附在相应的链上;### 顺序图与协作图的异同- 顺序图和协作图都属于交互图,用来描述对象之间的动态关系。- 顺序图强调消息的时间顺序，协作图强调参与交互的对象的组织关系。- 顺序图和协作图在语义上是等价的，两者可以相互转换。#### 写出Class A伪代码## 图书馆还书处理的交互图用例：还书参与者：图书管理员事件流：- 管理员进入图书借阅界面，用例开始。- 系统要求输入读者编号及所还图书的条码。管理员输入相应信息。- 系统显示所还图书的图书、读者信息、借书记录信息。- 图书管理员确认还书（登记还书时间）。- 用例结束。### 识别交互过程读者在还书时，先由管理员把借书证上的读者编号及所借图书的图书编号扫描给系统，系统接收到这个信息，则显示这个该读者信息,以及这本书的信息、借书记录信息。管理员确认还书,则系统登记还书信息，并返回还书成功信息，还书过程完成。### 画图## 类的概念类的定义：类(class): 具有相似结构、行为和关系的一组对象。缩略表示：## 类的版型### 边界类边界类位于系统与外界的交界处,承担系统与外界的信息交互功能。边界类处在用例图中，参与者与用例的关联处，可以根据用例图发现边界类。### 实体类实体类对应着现实中的客观实物，用来保存信息，一般对应着数据表、文件等。实体类可以从现实中存在的客观事物，以及需要持久存放的信息两方面来发现。### 控制类控制类负责其他类工作的类，控制调控的作用。一个用例中最少会有一个控制类，用来控制用例中的事件顺序，也可以在多个用例之间共用。控制类较少接收消息，发出较多(控制)消息。## 类之间的关系### 关联模型元素之间的一种语义联系,它是对具有共同的结构特性、行为特性、关系和语义的链接（link，对象之间物理上或概念上的连接）的描述。关联可以分为单向关联，双向关联。#### 关联的特性- 关联名：用来描述关联的作用。- 关联的角色：关联的两端可以以某种角色参与关联。- 关联的多重性：表示可以有多少个对象参与该关联。- 关联类：通过关联类描述关联的属性，操作，及其它信息。- 增加关联类的准则- 有某个属性与关联相关- 关联类的实例具有依赖于关联的生命期- 两个概念之间有多对多关联，并且存在与关联自身相关的信息- ##### 关联的约束通过约束加强关联的含义。例如，“帐户”不能同时与“人”和“公司”有关联。- 限定关联通过限定符(qualifier)来规定关联的限定关系。#### 关联的种类- 一元(自返)关联- 二元关联- 三元关联三元关联是功能齐全的关联，可以有关联类。- 多元关联编程语言不能表示多元关联，需要提升为一个类### 聚集和组合#### 聚集聚集(aggregation): 表示类之间一种松散的整体与部分的组成关系，是一种特殊的关联。#### 组合组合(composition)：表示类之间一种紧密的整体与部分的组成关系，也是一种特殊的关联。#### 聚集与组合的区别- 聚集松散，组合紧密- 一个部分事物对象可以属于多个聚集对象,但一个部分事物对象仅能属于一个组合对象- 聚集的对象生命周期可以不同,但组合对象则是同存同亡。### 泛化泛化(generalization)：表示事物之间的一般与特殊的关系；也可以称为继承关系。泛化关系除了表示类与类之间的关系之外，还可以表示参与者、用例、包、构件、接口等建模元素之间的关系。### 依赖依赖(dependency): 表示两个元素X、Y，如果X的变化必然导致Y的变化，则称Y依赖X。依赖关系不仅限于类，用例、包、构件之间都可以存在依赖关系。 如果类A和类B有关联关系，那么就有依赖关系。只表示出关联关系，不用表示出依赖关系。依赖关系本身不生成专门的实现代码。### 派生属性和派生关联派生属性和派生关联的概念：可以从其它属性或关联计算推演得到的属性和关联。在派生的名字前面加/，以示区别。派生容易产生不一致，应注意。#### 抽象类和接口抽象类：只有声明，没有具体实现，不能实例化；接口：不包含属性，只有方法声明## 类图类图(Class Diagram): 是由类，相关建模元素（接口、包），及其关系构成的图，用来描述类之间的静态关系。类图在系统中处在核心位置。也是UML中最为重要的一种图。售票系统的类图：顾客可多次订票，但每一次订票只能由一个顾客来执行。有两种订票方式：个人票或套票；前者只是一张票，后者包括多张票。每一张票不是个人票就是套票中的一张，但是不能又是个人票又是套票中的一张。每场演出都有多张票可供预定，每张票对应一个唯一的座位号。每次演出用剧目名、日期和时间来标识。### 类图的抽象层次在系统的不同开发阶段，类图可以具有不同的抽象程度。随着开发的深入，类图应该越来越详细、具体。可以分为：概念层，说明层，实现层。### 构造类图#### 寻找类的方法- 根据用例描述中的名词确定候选类。- 根据边界类、控制类和实体类的划分来帮助发现类。- 参考设计模式来确定类。- 根据软件开发过程的指导寻找类。#### 构造类图时注意- 不要试图使用所有的符号，20％的建模元素能满足80％的建模需求。- 不要过早陷入细节, 根据不同阶段，采用不同层次类图，逐步细化。- 构造完成要将模型与目标问题对照验证其是否合理，是否反应了应用领域的实际情况。## 对象图&gt; 对象图的概念对象图表示一组对象及其它们之间的联系。对象是系统的详细状态在某一时刻的快照，通常用来表示复杂类图的一个实例。&gt; 说明- 对象图并不在任何时间都是必须的；- Rose2003不支持对象图。## 类的关系具有四种- 关联：表示类中对象之间的链接关系- 组成：表示事物之间的整体和部分关系，（聚合，组合）- 泛化：表示事物的一般和特殊关系- 依赖：事物之间的因果关系## 状态图状态图(state chart diagram)：用来描述一个特定的对象所有可能的状态，以及由于各种事件的发生而引起的状态之间的转移和变化。## 状态图的要素—–状态### 概念是指对象在其生命周期中，满足某些条件、执行某些活动、或等待某些事件时的一个状况（时间段）。### 状态的表示和要素- 状态的表示：用圆角的矩形框表示状态。- 状态的要素：包括状态名，进入/退出动作、内部转移，子状态等。eg:### 状态的类型初态、终态、中间状态、组合状态、历史状态等。一个状态图只能有一个初态，但是结束状态可能有多个，也可以没有终态。#### 组合状态和子状态嵌套在另一个状态中的状态称为子状态;包含子状态的状态称为组合状态.#### 历史状态历史状态是伪状态, 其目的是记住从组合状态中退出时所处的子状态, 当再次进入组合状态时, 可以直接进入这个子状态, 而不是再从组合状态的初态开始.- 浅(shallow)历史状态，只记住最外层组合状态的历史- 深(deep)历史状态, 可以记住任意深度的组合状态的历史.## 状态图的要素—–转移转移(transition): 是一个状态向另外一个状态的转换（瞬时变化）。转移是两种状态之间的一种关系，表示对象将在第一个状态执行一定的动作，并在某个特定事件发生且满足某个特定的警戒条件时进入第二个状态。转移的格式：event-name [‘(‘parameters’)’] [‘[’guard-condition’]’] [’/’action]对于一个给定的状态，最终只能产生一个转移，因此从一个状态出发的几个转移之间应该是互斥的，包括：事件不同；事件相同但警戒条件互斥。## 状态图的要素—–事 件### 概念事件(event)：是指在确定的时间和位置所发生的对于对象起作用的事情。事件的发生将引起一些动作，使对象发生状态的转移。动作（action）：动作是对象类中一个操作的执行，动作具有原子性和不可中断特性。### 描述事件名称[参数表]- 字符串，常为接收对象类中的一个操作。- 事件的形式参数，可以省略### 事件的类型- 调用事件(call event)：是表示对操作的调用- 变化事件(change event)：因满足某种条件（参量变化）而引起的事件，变化条件用when表示。(由满足布尔表达式而引起的事件，不断测试表达式，直到表达式为真)- 时间事件：满足某一时间表达式而引起的事件,时间事件用after,when表示。## 状态图的作用用来描述一个对象在其生命周期中所表现出来的状态和行为。当在系统建模过程中需要描述某个事物或对象的不同状态，以及状态之间转移的事件和动作时，用状态图。 但状态图并不是对每一个对象都需要的。## 如何绘制状态图1. 选择对象与视点2. 寻找主要的状态3. 确定状态之间的转移（换）4. 细化状态内的活动与转换5. 用组合状态来展开细节## 活动图活动图(activity diagram)是UML的动态视图之一，用来描述系统的工作流程和并发行为。活动图是状态图的一个变体，活动图中一个活动结束后将立即进入下一个活动（不需要事件的触发）。### 使用活动图- 活动图的用途是对人类组织的现实世界中的工作流程建模。- 也可以对具体操作建模，用于描述计算过程的细节。- 活动图有助于理解系统高层活动的执行行为，而不涉及建立交互图所必须的消息传送细节。- 软件公司可以用活动图对一个软件的开发过程建模；- 会计师事务所可以用活动图对任意数目的财务往来进行建模；- 贸易公司可以用活动图对订单批准过程进行建模；- 科研人员还可以对诸如求Fibonacci数列第n个数的数值之类的操作进行建模。## 活动图的要素### 活动是活动图主要结点,用两边为弧的条形框表示,中间填活动名 。### 活动流（控制流）描述活动之间的有向关系，反映一个活动向另外一个活动之间的转移。用带箭头的实线表示。### 分支表示从一个活动按照某种条件转移到几个不同的活动。### 分叉和汇合表示并发的同步行为，用同步杆表示。分叉表示一个控制流被多个控制流替代，替代后的控制流是并发的。汇合与分叉含义相反。### 泳道是活动图中的区域划分，每一个泳道代表一个责任区域。一个泳道中包括一组相关活动。### 对象流反映活动与对象之间的依赖关系，表示对象对活动的作用或活动对对象的影响，用依赖关系表示。## 活动图的用途活动图具有广泛地用途,在软件建模中,活动图可以用来：- 描述工作流：也被称为业务流程，通常对于涉及众多参与者的非常复杂的业务流程建模，简单的业务流程，用例文本就够用了。总之，分析理解用例。- 用户下订单后，填写收货信息，选择支付方式，如果用户想要取消订单或订单超过了时限则该订单取消，否则系统处理付款，生成送货单，然后由供应商发货，修改订单项状态，然后等所有的订单项全都送货完毕，这样一笔订单就完成了。-描述算法流程例绘制一张活动图，描述登录电子邮件系统的细节。状态图与活动图的比较都是对系统的动态行为建模描述对象不同状态图：描述对象状态及状态之间的转移；活动图：描述从活动到活动的控制流。使用场合不同状态图：描述对象在其生命期中的行为状态变化；状态图中的动作和事件对应类模型中对象上的操作。活动图：描述工作流程的过程变化。分析用例、理解涉及多个用例的工作流程等。OOADWhat is Analysis ?Analysis is investigation of the problem and requirements, rather than a solution.For example, if a new online trading system is desired,how will it be used? What are its functions?requirements analysis ：an investigation of the requirementsWhat is design?Design is a conceptual solution that fulfills the requirements 概念性的、满足 需求的解决方案Design is a conceptual solution that fulfills the requirements。What is OOAfinding and describing the objects or concepts in the problem domainWhat is OODdefining software objects and how they collaborate to fulfill the requirementsFor example, Airplane example of object and class discoveryOOAin the case of the flight information system, some of the concepts include：Plane, Flight, and Pilot.OODa Plane software object may have a tailNumber attribute and a getFlightHistory() method.OOAD Simple ExampleRudimentary（最基本的过程） processDice game exampleStep1: Use CasePlayer is requested to roll the dice.System presents results:If the dice face value totals (&gt;=)seven, player wins; otherwise, player losesStep2: Domain ModelOOA的结果体现在领域模型中，显示重要的领域概念或者对象What is domain model?a visual representation of conceptual classes or real-situation(真实) objects in a domain.Domain models have also been called conceptual models , domain object models, and analysis object models.有哪些概念类呢？Step3: InteractionsAssignment of responsibilities among objectsSequence or Communication diagrams在现实里，是Player扔的骰子。在软件设计中，由DiceGame 对 象 扔 骰 子dice (给Dice 对象发送一个消息)。 软件设计需要从真实世界的事物中获取一些灵感、启发，但是，不能完全模仿真实世界。Step4: Design Class Diagrams (DCD)Software classes（软件类） with methods according to responsibilities and attributes according to visibilitythe domain model showing real-world classesthis diagram shows software classesObject Oriented AnalysisIdentifying objects 识别对象Organising the objects: 组织对象classifying the objects identified, so similar objects can later be defined in the same class.Identifying relationships between objects: 定义对象之间的关系this helps to determine inputs and outputs of an object.Defining operations of the objects: 定义对象的操作the way of processing data within an object.Also known as ‘responsibility assignment’这一步，主要在设计阶段完成Defining objects internally: 定义对象内部细节information held within the objects.名词法定义概念名词法定义概念类The system controls a recycling machine for returnable bottles, cans and crates. The machine can be used by several customers at the same time and each customer can return all three types of item on the same occasion. The system has to check, for each item, what type has been returned.The system will register how many items each customer returns and when the customer asks for a receipt, the system will print out what was deposited , the value of the returned items and the total return sum that will be paid to the customer.recycling machinebottles, cans, and cratesmachinecustomers, customertypes of item, item, type, returned itemssystemreceipt(收据)return sum分析模型法用于描述系统规格说明一个健壮、稳定的模型，必须与实现环境无关实现环境的任何变化，不会影响到系统的逻辑结构分析模型能够关注到系统的信息、行为、展示（输入/出）等特性特性：Behaviour - Information - PresentationThe model is defined in information - behaviour - presentationspace.分析模型的语义An entity object models information that shows the state of a system. This information is often used to record the effects of operations and therefore is related to the behaviors of the system.A boundary/interface object models inputs and outputs and operations that process them.A control object models functionality/operations regarding to validate and decide whether to process and pass information from the interface object to the entity object or the way around.分析模型的使用Identifying interface objectsfunctions directly related to actorsIdentifying entity objectsinformation used in an use case and functions of processing the informationIdentifying control objectsfunctions that link interface objects and entity objects1.4 分析模型案例：废品回收机Identifying interface objects：Printer Customer PanelIdentifying entity objectsCrate, Bottle, CanDeposit itemReceipt basisIdentifying control objectsDeposit item receiverCRCClasses (of objects) 类Responsibilities (of the objects in each class) 职责Collaborations (with objects in other classes) 协作In UML, these will be examples of “associations”Domain ModelsA domain model is a representation of real-world conceptual classesnot a representation of software components.not a set of diagrams describing software classes,not software objects with responsibilities.A domain model is a visual representation of conceptual classes or real-world objects in a domain of interestThey have also been called conceptual models, domain object models, and analysis object models.Domain Modeling GuidelinesA Common Mistake in Identifying Conceptual ClassesPerhaps the most common mistake when creating a domain model is to represent something as an attribute when it should have been a concept.A rule of thumb (经验法则)to help prevent this mistake is:If we do not think of some conceptual class X as a number or text in the real world, X is probably a conceptual class, not an attribute.As an example, should store be an attribute of Sale, or a separate conceptual class Store?In the real world, a store is not considered a number or text - the term suggests a legal entity, an organization, and something occupies space. Therefore, Store should be a concept.As another example, consider the domain of airline reservations. Should destination be an attribute of Flight, or a separate conceptual class Airport?In the real world, a destination airport is not considered a number or text—it is a massive thing that occupies space. Therefore, Airport should be a concept.What are System Sequence Diagrams?A system sequence diagram (SSD) is a picture that shows, for a particular scenario of a use case, the events that external actors generate, their order and inter-system （与系统交互）eventsAll systems are treated as a black box; the emphasis of the diagram is events that cross the system boundary from actors to systemsGuidelineDraw an SSD for a main success scenario of each use case, and frequent or complex.alternative scenariosThe Relationship between SSDs and Use Cases?Why draw SSD?Basically, a software system reacts to three things:external events from actors (humans or computers),timer events,faults or exceptions (which are often from external sources).It is useful to know what, precisely, are the external input events— the system events. They are an important part of analyzing system behaviorBefore proceeding to a detailed design of how a software application will work, it is useful to investigate and define its behavior as a “black box.“System behavior is a description of what a system does, without explaining how it does it.One part of that description is a system sequence diagram(SSD)Other parts include the use cases and system operation contractsWhat is Contract?(契约)Example : enterItemOperation: enterItem(itemID:ItemID,quantity:integer)Cross References: Process SalePreconditions: There is a sale underwayPostconditions:A SalesLineItem instance sli was created(instance creation)sli was associated with current Sale(association formed)sli.quantity became quantity(attribute modification)Sli was associated with a ProductDescription, based on itemID match (association formed)分层架构可以做到关注分离（separation of concerns），减少耦合和依赖性，增强内聚性封装和分解了相关的复杂性某些层可以被替换（例如UI层）较低层可以被复用通过逻辑划分，有助于团队开发Designing Objects(对象设计)Static modeling (Design Class Diagram, Package)Dynamic modeling (Sequence and Communication Diagram)Principles of responsibility assignmentDesign PatternGRASPGeneral Responsibility Assignment software patterns.Doing responsibilities of an object include:doing something itself, such as creating an object or doing a calculationinitiating action in other objectscontrolling and coordinating activities in other objectsKnowing responsibilities of an object include:knowing about private encapsulated dataknowing about related objectsknowing about things it can derive or calculateFor example“a Sale is responsible for creating SalesLineItems” (a doing),“a Sale is responsible for knowing its total” (a knowing).GRASPGRASP - CreatorProblem:Who creates an A?SolutionAssign class B the responsibility to create an instance of class A if one of these is true (the more the better):B “contains” or compositely aggregates A.B records A.B closely uses A.B has the initializing data for A.GRASP - Information ExpertProblem:What is a basic principle by which to assign responsibilities to objects?SolutionAssign a responsibility to the class that has the information needed to fulfill it.GRASP - Low CouplingProblem:How to reduce the impact of change?SolutionAssign responsibilities so that (unnecessary) coupling remains low.Use this principle to evaluate alternatives.DiscussionWhat is Coupling ？面向对象语言中，TypeX到TypeY耦合的常见形式？GRASP - ControllerProblem:What first object beyond the UI layer receives and coordinates (“controls”) a system operation?SolutionAssign the responsibility to an object representing one of these choices:Represents the overall “system,” a “root object,” a device that the software is running within, or a major subsystem (these are all variations of a facade controller). 外观控制器Represents a use case scenario within which the system operation occurs (a use case or session controller)，Handler. 会话控制器GRASP - High CohesionProblem:How to keep objects focused, understandable, and manageable, and as a side effect, support Low Coupling?SolutionAssign responsibilities so that cohesion remains high.Use this to evaluate alternatives.OO设计的原则开闭原则(Open/Closed Principle, OCP)Liskov替换原则(Liskov Substitution Principle, LSP)依赖倒置原则(Dependency Inversion Principle, DSP)接口分离原则(Interface Segregation Principle, ISP)GoF设计模式的分类创建型：抽象了创建对象的过程，使得系统不依赖于系统中的对象是如何创建、组合和表示的。例如：Factory method, Singleton.结构型：描述如何组合类和对象。例如：Adapter，Façade行为型：描述算法和对象间职责的分配。主要考虑对象之间的通信方式。例如：Iterator, Visitor]]></content>
      <categories>
        <category>UML</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot]]></title>
    <url>%2F2019%2Fspringboot%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-单表DQL]]></title>
    <url>%2F2019%2F04-%E5%8D%95%E8%A1%A8DQL%2F</url>
    <content type="text"><![CDATA[数据准备12345678910111213141516171819create table product( pid int primary key, pname varchar(20), price double, category_id varchar(32));INSERT INTO product(pid,pname,price,category_id) VALUES(1,'联想',5000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(2,'海尔',3000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(3,'雷神',5000,'c001');INSERT INTO product(pid,pname,price,category_id) VALUES(4,'JACK JONES',800,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(5,'真维斯',200,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(6,'花花公子',440,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(7,'劲霸',2000,'c002');INSERT INTO product(pid,pname,price,category_id) VALUES(8,'香奈儿',800,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(9,'相宜本草',200,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(10,'面霸',5,'c003');INSERT INTO product(pid,pname,price,category_id) VALUES(11,'好想你枣',56,'c004');INSERT INTO product(pid,pname,price,category_id) VALUES(12,'香飘飘奶茶',1,'c005');INSERT INTO product(pid,pname,price,category_id) VALUES(13,'果9',1,NULL);简单查询查询表的所有字段信息：select * from 表名;查询表中某字段信息：select 字段1, 字段2 from 表名;去掉重复值：select distinct 字段1, 字段2, ... from 表名;若有多个字段则所有字段相等才被算为重复值。查询结果是表达式（运算查询）：将商品的价格+10元进行显示，select pname,price+10 from product;别名查询，使用的关键字是as（as可以省略的）：表别名：select * from product as p;列别名：select pname as pn from product;条件查询符号含义&gt; &lt; &lt;= &gt;= = &lt;&gt;!=大于、小于、大于(小于)等于、不等于BETWEEN …AND…显示在某一区间的值(含头含尾)(也可以是日期)IN(set)显示在in列表中的值，例：in(100,200)LIKE ‘张%’%代表零个或多个任意字符，_代表一个字符。例如：first_name like ‘_a%’IS NULL / IS NOT NULL判断为空/不为空and多个条件同时成立or多个条件任一成立not不成立，例：where not(salary&gt;100);例查询商品名称为“花花公子”的商品所有信息：SELECT * FROM product WHERE pname = &#39;花花公子&#39;查询价格为800商品：SELECT * FROM product WHERE price = 800查询价格不是800的所有商品：SELECT * FROM product WHERE price != 800SELECT * FROM product WHERE price &lt;&gt; 800SELECT * FROM product WHERE NOT(price = 800)查询商品价格大于60元的所有商品信息：SELECT * FROM product WHERE price &gt; 60;查询商品价格在200到1000之间所有商品：SELECT * FROM product WHERE price &gt;= 200 AND price &lt;=1000;SELECT * FROM product WHERE price BETWEEN 200 AND 1000;查询商品价格是200或800的所有商品：SELECT * FROM product WHERE price = 200 OR price = 800;SELECT * FROM product WHERE price IN (200,800);查询含有’霸’字的所有商品：SELECT * FROM product WHERE pname LIKE &#39;%霸%&#39;;查询以’香’开头的所有商品：SELECT * FROM product WHERE pname LIKE &#39;香%&#39;;查询第二个字为’想’的所有商品：SELECT * FROM product WHERE pname LIKE &#39;_想%&#39;;查询没有分类的商品：SELECT * FROM product WHERE category_id IS NULL;查询有分类的商品：SELECT * FROM prod quct WHERE category_id IS NOT NULL查询所有价格大于2000的电脑商品或者价格大于1000的服装商品：SELECT * FROM product WHERE (price &gt; 2000 AND category_id=&#39;c001&#39;) OR (price &gt;1000 AND category_id=&#39;c002&#39;);排序查询SELECT * FROM 表名 ORDER BY 排序字段 ASC|DESC;ASC： 升序 (默认)DESC：降序例：查询所有商品信息，使用价格排序(降序)：SELECT * FROM product ORDER BY price DESC;在价格排序(降序)的基础上，以分类排序(降序)：SELECT * FROM product ORDER BY price DESC, category_id DESC;显示商品的价格(去重复)，并排序(降序)：SELECT DISTINCT price FROM product ORDER BY price DESC;聚合查询聚合函数SELECT不仅可以作用于字段，还可以作用于聚合函数。count(…)：统计指定列不为NULL的记录行数；sum(…)：计算指定列的数值和，如果指定列类型不是数值类型，那么计算结果为0；max(…)：计算指定列的最大值，如果指定列是字符串类型，那么使用字符串排序运算；min(…)：计算指定列的最小值，如果指定列是字符串类型，那么使用字符串排序运算；avg(…)：计算指定列的平均值，如果指定列类型不是数值类型，那么计算结果为0；例：查询商品的总条数：SELECT COUNT(*) FROM product;查询价格大于200的商品总条数：SELECT COUNT(*) FROM product WHERE price &gt; 200;查询分类为’c001’的商品价格总和：SELECT SUM(price) FROM product WHERE category_id = &#39;c001&#39;;查询分类为’c002’商品的平均价格：SELECT AVG(price) FROM product WHERE category_id = &#39;c002&#39;;查询商品的最大价格和最小价格：SELECT MAX(price),MIN(price) FROM product;分组分组查询是指使用group by字句对查询信息进行分组。​ SELECT 字段1, 字段2… FROM 表名 GROUP BY 分组字段 HAVING 分组条件;HAVING：分组操作中的having子语句，是用于在分组后对数据进行过滤的，作用类似于where条件。与where的区别:having是在分组后对数据进行过滤。where是在分组前对数据进行过滤。having后面可以使用聚合函数过滤数据。where后面不可以使用聚合函数。例：统计各个分类商品的个数：SELECT category_id ,COUNT(*) FROM product GROUP BY category_id;统计各个分类商品的个数,且只显示个数大于1的信息：SELECT category_id, COUNT(*) FROM product GROUP BY category_id HAVING COUNT(*) &gt; 1;分页查询由于数据量很大，显示屏长度有限，因此对数据需要采取分页显示方式。例如数据共有30条，每页显示5条。格式：SELECT 字段1，字段2... FROM 表明 LIMIT M, N;M: 整数，表示从第几条索引开始，计算方式 （当前页-1）*每页显示条数N: 整数，表示查询多少条数据例：SELECT 字段1，字段2... FROM 表明 LIMIT 0,5;SELECT 字段1，字段2... FROM 表明 LIMIT 5,5;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-DDL与DML]]></title>
    <url>%2F2019%2F03-DDL%E4%B8%8EDML%2F</url>
    <content type="text"><![CDATA[操作数据库创建数据库create database 数据库名;例：CREATE DATABASE db1;create database 数据库名 charset 字符集;例：CREATE DATABASE db2 CHARSET utf8;删除数据库drop database 数据库名使用数据库查看数据库的定义信息show create database 数据库名;操作表创建表1234567CREATE TABLE &lt;表名&gt;( 字段名1 类型(长度) [列级完整性约束条件], 字段名2 类型(长度) [列级完整性约束条件], ... 字段名n 类型(长度) [列级完整性约束条件] [,&lt;表级完整性约束条件&gt;]);先不涉及约束条件，后面会有详细分析。1234CREATE TABLE category ( cid INT PRIMARY KEY, #分类ID cname VARCHAR(100) #分类名称);查看表查看数据库中的所有表：SHOW TABLES;查看表结构：DESC 表名;删除表drop table 表名修改表名rename table 表名 to 新表名;增改删增向表中插入某些字段：insert into 表 (字段1,字段2,字段3..) values (值1,值2,值3..);向表中插入所有字段，字段的顺序为创建表时的顺序：insert into 表 values (值1,值2,值3..);注意：值与字段必须对应，个数相同，类型相同值的数据大小必须在字段的长度范围内除了数值类型外，其它的字段类型的值必须使用引号引起。（建议单引号）如果要插入空值，可以不写字段，或者插入 null。改更新所有记录的指定字段：update 表名 set 字段名=值, 字段名=值, ...;更新符号条件记录的指定字段：update 表名 set 字段名=值, 字段名=值, ... where 条件;注意：列名的类型与修改的值要一致修改值得时候不能超过最大长度除了数值类型外，其它的字段类型的值必须使用引号引起删删除所有数据：delete from 表名;或者truncate table 表名;delete 一条一条删除，不清空auto_increment记录数。truncate 直接将表删除，重新建表，auto_increment将置为零，从新开始。删除某些数据：delete from 表名 where 条件操作表结构添加列：alter table 表名 add 列名 类型(长度) [约束];ALTER TABLE category ADD cdesc VARCHAR(20);删除列：alter table 表名 drop 列名;ALTER TABLE category DROP cdesc;修改列名：alter table 表名 change 旧列名 新列名 类型(长度) 约束;ALTER TABLE category CHANGE cdesc description VARCHAR(30);修改列的类型长度及约束：alter table 表名 modify 列名 类型(长度) 约束;ALTER TABLE category MODIFY cdesc VARCHAR(50) NOT NULL;修改表的字符集：alter table 表名 character set 字符集;ALTER TABLE category CHARACTER SET gbk;数据完整性指数据库中存储的数据是有意义的或正确的。实体完整性若属性A是基本关系R的主属性，则属性A不能取空值。参照完整性若属性（或属性组）F是基本关系R的外码，它与基本关系S的主码相对应，则对于R中每个元组在F上的值必须为：或者取空值（S的每个属性值均为空值）。或者等于S中某个元组的主码值。EMP(E#, ESEX, D#) -参照关系； DEPT(D# ,DNAME,LOCATION) -被参照关系用户定义的完整性针对某一具体关系数据库的约束条件，它反映某一具体应用所涉及的数据必须满足的语义要求。约束主键约束唯一标识一条记录的属性值。主键必须是唯一的值。主键列不能是 NULL 值。每个表都应该有且只能有一个主键。添加主键约束。方式一：创建表时，在字段描述处，声明指定字段为主键1234567CREATE TABLE Persons( Id_P int PRIMARY KEY, LastName varchar(255), FirstName varchar(255), Address varchar(255), City varchar(255));方式二：创建表时，在表级约束区域，声明指定字段为主键格式：[constraint 名称] primary key (字段列表)关键字constraint可以省略，如果需要为主键命名，constraint不能省略。字段列表需要使用小括号括住，如果有多字段需要使用逗号分隔。这时多个字段联合构成主键。1234567CREATE TABLE Persons( FirstName varchar(255), LastName varchar(255), Address varchar(255), City varchar(255), [CONSTRAINT pk_PersonID] PRIMARY KEY (FirstName,LastName));方式三：创建表之后，通过修改表结构，声明指定字段为主键ALTER TABLE Persons ADD [CONSTRAINT 名称] PRIMARY KEY (字段列表)1234567CREATE TABLE Persons( FirstName varchar(255), LastName varchar(255), Address varchar(255), City varchar(255));ALTER TABLE Persons ADD PRIMARY KEY (FirstName);撤销主键约束：ALTER TABLE Persons DROP PRIMARY KEY自动增长列设置某列的值自动增长。使用 auto_increment（自动增长列）关键字。自动增长列类型必须是整形。自动增长列必须为键(一般是主键)。添加自动增长：1234567CREATE TABLE Persons( P_Id int PRIMARY KEY AUTO_INCREMENT, LastName varchar(255), FirstName varchar(255), Address varchar(255), City varchar(255));添加数据时，可以不设置值，也可以设置成null，数据库将自动维护主键值：INSERT INTO Persons (FirstName,LastName) VALUES (&#39;Bill&#39;,&#39;Gates&#39;);INSERT INTO Persons (P_Id,FirstName,LastName) VALUES (NULL,&#39;Bill&#39;,&#39;Gates&#39;);修改起始值ALTER TABLE Persons AUTO_INCREMENT=100;非空约束约束不接受NULL值，意味着如果不向字段添加值，就无法插入新记录或者更新记录。添加方式方式一：创建表，下面的 SQL 语句强制 “Id_P” 列和 “LastName” 列不接受 NULL 值1234567CREATE TABLE Persons( Id_P int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255));方式二：修改表结构ALTER TABLE student MODIFY LastName varchar(255) NOT NULL删除非空约束ALTER TABLE student MODIFY LastName varchar(255);唯一约束UNIQUE约束唯一标识数据库表中的每条记录。PRIMARY KEY拥有自动定义的UNIQUE约束。每个表可以有多个 UNIQUE 约束，但是每个表只能有一个 PRIMARY KEY 约束。添加唯一约束方式1：创建表时，在字段描述处，声明唯一1234567CREATE TABLE Persons( Id_P int UNIQUE, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255));方式2：创建表时，在约束区域，声明唯一12345678CREATE TABLE Persons( Id_P int, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), CONSTRAINT 名称 UNIQUE (Id_P));方式3：创建表后，修改表结构，声明字段唯一ALTER TABLE Persons ADD [CONSTRAINT 名称] UNIQUE (Id_P);删除唯一约束ALTER TABLE Persons DROP INDEX 约束名称如果添加唯一约束时，没有设置约束名称，默认是当前字段的字段名。默认约束在添加数据中，如果该字段不指定值，采用默认值处理。添加方式方式一： 创建表，字段处声明1234567CREATE TABLE Persons( Id_P int, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255) DEFAULT '北京', City varchar(255));方式二： 修改表结构ALTER TABLE Persons MODIFY Address VARCHAR(255) DEFAULT &#39;北京&#39;;删除方式ALTER TABLE Persons MODIFY Address VARCHAR(255);外键约束参照关系对应的表是从表。被参照关系对应的表是主表。声明外键约束创建表时添加。12345678CREATE TABLE Persons( Id_P int, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255) DEFAULT &apos;北京&apos;, City varchar(255), [CONSTRAINT FK_DEPTNO] FOREIGN KEY (Address) REFERENCES CITY(Address));修改表结构alter table 从表 add [constraint 名称] foreign key (外键字段) references 主表 (主表主键);删除外键alter table 从表 drop foreign key 外键名称;备份 &amp; 恢复备份恢复&gt;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-进程的描述与控制]]></title>
    <url>%2F2019%2F02-%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[进程概念前趋图数据结构中的有向无环图。箭头表示进程之间执行的先后关系。结点表示一个程序或一个进程，甚至一条语句。程序的并发执行不存在前趋关系的程序之间才有可能并发执行。特征：间断性：程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间形成了相互制约的关系，进而导致并发程序具有“执行-暂停-执行”这种间断性的活动规律。失去封闭性：由于资源共享，所以当某程序的运行影响资源的状态时，其他程序的运行环境就会被破坏。不可再现性：计算结果与并发程序各自执行速度有关。即同一程序，使用相同输入、在相同环境下运行，却可能获得完全不同的结果。进程的定义在多道程序环境下，程序的执行属于并发执行，此时他们将失去其封闭性，并具有间断性，以及运行结果的不可再现性。由此，决定了通常的程序是不能参与并发执行的。为了能使程序并发执行，引入了进程。进程实体：程序+数据+进程控制块（Process Control Block，PCB）。进程：运行态的进程实体是就是进程，是系统进行资源分配和调度的一个独立单位。PCB是为了使程序能并发执行而诞生的一种数据结构，它用来控制和管理进程。由于数据和程序本来就存在，所以创建/撤销进程也就是创建/撤销PCB。至于如何并发执行，见下面的进程同步。区别于作业：进程是程序在数据集上的一次作执行，作业是用户提交给系统的一个任务，包含一个或多个进程。进程的特点动态性：由创建而产生，由调度而执行，由撤销而消亡。并发性：进程的重要特征，操作系统的重要特征。独立性：独立运行、独立分配资源、独立接受调度。异步性：按各自独立、不可预知的速度向前推进。PCBPCB中保存的信息进程标识符。用于唯一的标识某个进程。外部标识符：不仅可以标识进程，还指明其父进程、子进程以及拥有该进程的用户。内部标识符：方便系统使用进程，仅能标识进程。处理机状态。用于在进程切换时保存处理机中各个寄存器的内容。以便在该进程重新调度时能再从断点执行。进程调度信息。进程状态：指明进程的状态，方便进程调度和对换时的依据。进程优先级：进程优先级高的更容易获得处理机。进程调度所需信息：保存的内容和进程调度算法有关，如进程等待了多久CPU，使用了多长CPU。事件：进程因何由执行状态转变为阻塞状态，即阻塞原因。进程控制信息。程序和数据的地址。进程同步的通信机制。资源清单。进程已分配到的除处理机之外的资源。链接指针。用于指向下一个PCB的首地址。用于进程调度。PCB的组织方式线性方式：所有的PCB都保存在一张表中，每次寻找PCB都在表中查找。效率低。链接方式：把具有相同状态的PCB链接起来。索引方式：把具有相同状态的PCB保存在相应的表中。OS内核系统态 &amp; 用户态对于处理机来说，根据其执行的指令不同，可以将其分成系统态（管态、内核态）和用户态。处理机处于系统态时可以执行任意的指令，访问所有的寄存器和存储区，而处于用户态的时候会受到相应的限制。所以计算机中的程序可以分成系统程序和用户程序，用户程序运行在用户态，这样就可以防止用户程序对操作系统进行破坏。指令分类操作系统把CPU指令分成两类：特权指令：在系统态执行的指令。执行几乎不受限制，如启动外部设备、设置系统时钟等。非特权指令：在用户态执行的指令。限制较多，比如不能操作硬件等。内核概念现代操作系统采用分层设计模式，不同权重的程序分别设置在不同的层次中。通常与硬件紧密相关的程序、设备驱动程序和运行频率高的程序等放置在高级别层次中，操作系统会将它们常驻内存，这些程序便被称为OS内核。OS内核运行在系统态中。内核的功能不同操作系统的内核在功能上有一定的差异，但是一般都包含两类功能：支撑功能中断处理：是指计算机运行过程中，出现某些意外情况需主机干预时，机器能自动停止正在运行的程序并转入处理新情况的程序，且处理完毕后又返回原被暂停的程序继续运行。人机交互、设备驱动和进程调度等都需要依赖中断处理。时钟管理：系统中很多活动都需要用到时钟，如定时任务、时间片轮转调度算法等。原语操作：原语是若干条机器指令构成的，用以完成特定功能的一段程序。而原语操作便是原语的执行，其在执行期间是不可分割的。资源管理功能进程管理：进程的创建、撤销、调度等操作。存储器管理：空间的分配、撤销、逻辑地址转换为物理地址等。设备管理：进行设备分配、缓和CPU和I/O速度不匹配矛盾的缓冲管理等。进程的生命周期进程的创建为新进程申请内部标识符，同时从PCB集合中索取一个空白的PCB。为新进程分配其运行所需的资源。这些资源直接来自操作系统或者父进程。初始化PCB。如处理机状态信息、标识符和进程优先级等。若就绪队列还能接受进程，则插入就绪队列。不能接受则执行相应处理机制。进程的终止从PCB集合中获得某进程的PCB，并读出该进程的状态。若进程正处于执行状态，应立即终止该进程的执行。若此进程有子进程则一并终止，防止其成为不可控进程。将进程拥有的所有资源归还给其父进程或操作系统。将被终止的进程从所在队列或链表（指PCB的组织方式）中移出，等待其他程序收集信息，释放空间等。三种基本状态就绪状态：分配到出处理机之外的其他所有必要资源。此时可运行，但其他进程正在占用CPU。执行状态：就绪状态的进程获得CPU，正在执行的状态。阻塞状态：进程发出的请求没有及时得到满足而无法继续执行的状态，此时会引起进程调度，OS把处理机分配给其他就绪进程，原进程暂停。挂起进程暂停执行或不接受调度的状态。原因有如下几点：用户的需要：用户想暂停正在的进程，观察其状态或修改程序等。父进程请求：父进程为了完成某项任务，协调其各子进程间的活动。负荷调节的需要：系统压力过大或实时操作系统不能很好的满足可靠性时会挂起一些进程。操作系统的需要：操作系统挂起某些进程来更方便的检查系统资源。挂起和阻塞不同在于阻塞是客观条件不能得到满足，即资源不足引起暂停。挂起是主观需要引起暂停。进程同步进程同步的主要任务是使并发执行的诸进程之间能有效的共享资源和相互合作，从而使程序的执行具有可再现性。同步 &amp; 互斥并发执行的诸进程之间既有独立性又有制约性。独立性：各进程都可独立地向前推进；制约性：由于资源共享和进程合作引起的进程之间的相互依赖和相互制约的关系。可归结为互斥和同步。同步：两个或多个事件的发生有着某种时序上的关系。按照这种时序关系进行能保证各任务安全的完成。互斥：资源的使用要排它使用，防止冲突（不同时使用，但无先后次序。一种特殊同步）。临界资源 &amp; 临界区临界资源：需要被各进程互斥访问的资源。临界区：各进程中访问临界资源的代码。若能保证各进程互斥地进入自己的临界区，便可以保证互斥地访问临界资源，进而保证进程同步。常用的方式有硬件同步机制和信号量机制。同步准则空闲让进：当无进程处于临界区时，应当允许一个进程进入自己的临界区。忙则等待：当有进程处于临界区时其他请求就如临界区的进程必须等待。有限等待：对要求访问临界资源的进程，应保证在有限的时间内能进入自己的临界区。让权等待：当进程不能进入临界区时，应立即释放处理机避免进程陷入“忙等”的状态。硬件同步机制关中断当进程在临界区执行期间，计算机系统不响应中断，因此不会引发调度，临界资源只会被一个进程占据，这样就不会发生进程同步问题。利用Test-and-Set指令实现互斥指令的描述如下：123456boolean TS(boolean *lock)&#123; boolean old; old = *lock; *lock = true; return old;&#125;为临界资源设置一个布尔变量lock = false。在进程进入临界区之前利用TS指令测试，如果得到的值为false表示资源未被使用，如果得到的值为true，则一直测试到结果为false。使用TS指令实现互斥描述如下：1234567do&#123; ... while (TS(&amp;lock)); ... lock = false; ...&#125;while(true);利用Swap指令实现互斥指令描述如下：123456void swap(boolean *a, boolean *b)&#123; boolean temp; temp = *a; *a = *b; *b = temp;&#125;为每个临界资源设置一个全局变量lock=false。每个进程设置一个局部变量key。实现互斥的描述如下：12345678910do&#123; ... key = true; do&#123; swap(&amp;lock, &amp;key); &#125;while(key != false) critical section; lock = false; ...&#125;缺点关中断：效率低下且不适用于多处理机系统。且其他进行会”忙等“，不符合让权等待。TS指令 &amp; Swap指令：其他进行会”忙等“，不符合让权等待。信号量机制整型信号量整型信号量是一个用于描述资源数目的整型量（S）。但除了初始化以外，仅能通过两个原子操作来访问。wait(S)：P操作1234wait(S)&#123; while(S &lt;= 0); S--;&#125;signal(S)：V操作123signal(S)&#123; S++;&#125;P操作用于分配资源，V操作用于释放资源。记录型信号量整型信号量未遵循让权等待原则。只要S &lt;= 0就会不断的循环。此时需要增加一个进程链表指针链接等待进程。数据结构的描述：1234typedef struct&#123; int value; //资源数 struct process_control_block *list; //阻塞队列&#125; semaphore;wait(S)：12345wait(semaphore *S)&#123; S-&gt;value--; if(S-&gt;value &lt; 0) block(S-&gt;list);&#125;signal(S)：12345signal(semaphore *S)&#123; S-&gt;value++; if(S-&gt;value &lt;= 0) wakeup(S-&gt;list);&#125;当进程被阻塞时会被加入阻塞对列，资源被满足时唤醒阻塞对列中的某个资源。AND型信号量记录型信号量只能解决共享一个临界资源的情况，若有多个临界资源则需要使用多个记录型信号量。但是信号量越多，系统死锁的概率越大，且大量的同步操作会给系统的管理带来麻烦。AND型信号量的思想是一次性分配进程所需的全部资源，如果有一个没有分配成功，则其他所有可能为之分配的资源亦不分配。Swait(S)：123456789101112Swait(S1, S2, ..., Sn)&#123; while(true)&#123; if(Si &gt;= 1 &amp;&amp; ... &amp;&amp; Sn &gt;= 1)&#123; for(i = 1; i &lt;= n; i++) Si--; break; &#125;else&#123; 把进程阻塞在请求未能得到满足的资源Si所对应的阻塞队列里，同时把进程的程序计数器（放 置CPU下一条要执行的指令地址）放置在本操作的开始处（下一次再调度到此进程，需要再次 检查所有的资源）。 &#125; &#125;&#125;Ssignal(S)：12345678Ssignal(S1, S2, ..., Sn)&#123; while(true)&#123; for(i = 1; i &lt;= n; i++)&#123; Si++; 唤醒等待Si资源的阻塞队列。 &#125; &#125;&#125;信号量集之前的信号量都是一次申请或释放某资源一份，若申请或释放N份资源需要进行N次操作，效率比较低下。此外，当资源数量低于某一下限值时，为了系统安全，就不能再予以分配。所以产生信号量集解决以上问题。描述如下：Swait(S1, t1, d1, ..., Sn, tn, dn)：当Si &gt;= ti时Si = Si - di。（di &gt;= ti）Ssignal(S1, d1, ..., Sn, dn)：Si = Si + di。特殊的信号量集：Swait(S1, d, d)：每次申请d份资源，资源少于d时不分配。Swait(S, 1, 1)：退化成一般的记录型信号量。Swait(S, 1, 0)：S &gt;= 1时运行多个进行进入特定区。S &lt;= 0时禁止进程进入特定区。管程直接使用信号量机制会把大量的同步操作分散在各个进程中，这会增加系统死锁的概率并且不方便系统的管理。而管程就是把代表共享资源的数据结构和对共享数据结构的操作（包括同步机制）封装起来以更好的为进程使用。这时所有请求访问共享资源的进程都只能通过管程间接访问，同时管程每次只允许一个进程进入管程。此时的管程可以使用面相对象的操作来完成整型信号量的功能。但是此时无法解决“让权等待”的问题，所以再按照面相对象的思想将block和wakeup操作封装起来来解决这个问题，即构成条件变量。条件变量的操作如下：condition.wait()：使进程在因某条件不能满足时阻塞在其所对应的条件变量上。condition.signal()：唤醒因某条件不能满足而阻塞的进程。可以很容易看出来，设置不同的条件变量能使由不同原因等待的进程阻塞在不同的队列中。使用时把signal()操作放在函数/过程的最后，这样保证在唤醒其他进程后本进程能直接退出而不再产生冲突。管程的描述如下：123456789101112131415161718/* 1、局部数据和条件变量组成管程内的数据结构。 2、过程/函数1~过程/函数k组成管程内的一组过程对管程内的数据结构进行操作。 3、初始化代码：对管程内的数据结构进行初始化。*/Monitor monitor_name&#123; share variable declartions; //共享变量说明 condition declarations; //条件变量说明 &#123; //管程主体 initialization code; //初始化代码 ... &#125; public: //能被进程调用的过程 void P1(...)&#123;...&#125; void P2(...)&#123;...&#125; ... void Pn(...)&#123;...&#125;&#125;信号量的应用互斥访问资源设某共享资源的信号量是mutex，PA和PB进程并发时需互斥访问。12345678910111213141516171819semaphore mutex = 1;PA()&#123; while(1)&#123; ... wait(mutex); ... signal(mutex); ... &#125;&#125;PB()&#123; while(1)&#123; ... wait(mutex); ... signal(mutex); ... &#125;&#125;利用信号量实现前趋关系123456789101112P1（）&#123;...V(f1);V(f1);V(f1);&#125;P2（）&#123;P(f1)；... V(f2);&#125;P3（）&#123;P(f1)；... V(f3);&#125;P4（）&#123;P(f1)；... V(f4);&#125;P5（）&#123;P(f2)；... V(f5);&#125;P6（）&#123;P(f3);P(f4);P(f5);...;&#125;main()&#123; semaphore f1=f2=f3=f4=f5=0； Cobegin P1(); P2();P3(); P4();P5(); P6(); Coend&#125;在并发时，如果P1的功能代码未执行完，f1为0，每次对f1进行V操作能使P2、P3、P4运行一个。其他亦然。生产者—消费者问题问题描述：多个生产者进程生产产品以供多个消费者消费。通过由n个环形缓冲区构成的缓冲池（循环队列），把多个生产者和多个消费者联系起来。不允许消费者进程到一个空缓冲区去取产品，也不允许生产者进程向一个已装满产品且尚未取走的缓冲区中投放产品。分析：任何时刻，只能有一个进程在缓冲区中操作。对于“生产者”而言，缓冲区满则应等待。对于“消费者”而言，缓冲区空则应等待。利用记录型信号量解决问题12345678910111213141516171819202122232425262728293031int in = 0, out = 0;//in指向此次生产的产品应该放置的位置。out指向此次消费的产品所在的位置。item buffer[n];//缓存区大小为n，地址为[0, n-1]。semaphore mutex = 1, empty = n, full = 0; //mutex用于互斥访问缓存区void producer()&#123; do&#123; produce an item nextproducer; ... wait(empty); //消耗一个empty，当empty&lt;=0时等待 wait(mutex); buffer[in] = nextproducer; in = (in+1) % n; signal(mutex); signal(full); //增加一个full &#125;while(true);&#125;void consumer()&#123; do&#123; wait(full); //消耗一个full，当full&lt;=0时等待 wait(mutex); nextconsumer = buffer[out]; out = (out+1) % n; signal(mutex); signal(empty); //增加一个empty ... &#125;while(true);&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;互斥信号量 &amp; 资源信号量互斥使用的资源设置一个互斥信号量，资源数为1。资源信号量的资源数和资源的意义有关。资源信号量的资源为1时退化成互斥信号量。在使用时互斥信号量的P操作需要紧邻其对应共享资源的临界区使用，否则可能造成同步问题。比如互换上面代码的第8行和第9行之后，若生产者进程和消费者进程都只有一个，且生产者通过了P(mutex)，阻塞在P(empty)，消费者通过了P(full)，阻塞在P(mutex)，此时生产者等待消费者的V(empty)，消费者等待生产者的V(mutex)，发生死锁。而V操作不需要注意顺序。利用AND型信号量解决问题123456789101112131415161718192021222324252627int in = 0, out = 0;//in指向此次生产的产品应该放置的位置。out指向此次消费的产品所在的位置。item buffer[n];//缓存区大小为n，地址为[0, n-1]。semaphore mutex = 1, empty = n, full = 0; //mutex用于互斥访问缓存区void producer()&#123; do&#123; produce an item nextproducer; ... Swait(empty, mutex); //消耗一个empty，当empty&lt;=0时等待 buffer[in] = nextproducer; in = (in+1) % n; signal(empty, mutex); //增加一个full &#125;while(true);&#125;void consumer()&#123; do&#123; wait(full, mutex); //消耗一个full，当full&lt;=0时等待 nextconsumer = buffer[out]; out = (out+1) % n; signal(full, mutex); //增加一个empty ... &#125;while(true);&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;利用管程解决问题12345678910111213141516171819202122232425262728293031323334353637383940414243Monitor monitor&#123; item buffer[n]; int in = 0, out = 0, count = 0; condition notfull, notempty; public: void static put(item x)&#123; if(count &gt;= n) cwait(notfull); //阻塞在队列满的条件下 buffer[in] = x; in = (in+1) % n; count++; csignal(notempty); &#125; void static get(item &amp;x)&#123; if(count &lt;= 0) cwait(notempty); //阻塞在队列空的条件下 x = buffer[out]; out = (out+1) % n; count--; csignal(notfull); &#125;&#125;void producer()&#123; item x; while(true)&#123; ... produce an item in nextproducer; monitor.put(x); &#125;&#125;void consumer()&#123; item x; while(true)&#123; monitor.get(x); consume the item in nextconsumer; ... &#125;&#125;void main()&#123; ConcurrentBegin produce();consumer(); ConcurrentEnd;&#125;哲学家进餐问题问题描述：五个哲学家坐在圆桌前，每人一份饭，每个哲学家两侧各有一支筷子,只有拿到左右两只筷子才能进餐，哲学家处于吃饭和思考两种状态。分析同一时刻一只筷子只能有一个哲学家拿起。只有获得两个筷子后才能进餐。如果每个哲学家都拿起一只筷子，都饿死。并行程度：五只筷子允许两人同时进餐。利用AND型信号量解决问题每次必须拿到两只筷子才能拿起，否则不拿起筷子。12345678semaphore chopstick[5] = &#123;1, 1, 1, 1, 1&#125;;do&#123; ... Swait(chopstick[i], chopstick[(i+1) % 5]); ... Ssignal(chopstick[i], chopstick[(i+1) % 5]); ...&#125;读者-写者问题问题描述：写者向共享数据区放数据，读者从共享数据区读数据。多个读者可同时读取数据，多个写者不能同时写数据。分析：读者进入共享数据区，写者必须等待。读者进入共享数据区，读者可以进入。写者进入共享数据区，读者必须等待。利用记录型信号量解决问题1234567891011121314151617181920212223242526272829semaphore readmutex = 1, writemutex = 1;int readcount = 0;void reader()&#123; do&#123; wait(readmutex); if(readcount == 0) wait(writemutex); readcount++; signal(readmutex); ... //read opreation wait(readmutex); readcount--; if(readcount == 0) signal(writemutex); signal(readmutex); &#125;while(true);&#125;void writer()&#123; do&#123; wait(writemutex); //当写者进入共享数据区，reader会阻塞在 ... //write operation signal(writemutex); &#125;while(true);&#125;void main()&#123; ConcurrentBegin reader();writer(); ConcurrentEnd;&#125;代码分析：最开始并发的时候：假如读者先抢到资源，readcount == 0，P(writemutex)，writer()会阻塞在第20行，但其他reader()仍可以运行，只是不会再P(writemutex)。同时每个reader()都readcount++，直到readcount == 0时V(writemutex)，然后writer()才有可能能进入。此时读者进程和写者进程进入共享数据区的个数都为0，即又是重新开始。假如写者先抢到资源，P(writemutex)，此时readcount == 0，所有reader()阻塞在第7行。此时读者进程和写者进程进入共享数据区的个数都为0，即又是重新开始。综上，完成了要求。读者-写者问题拓展问题描述：拓展就是又增加一个条件，最多只允许RN个读者同时读。利用信号量集解决问题123456789101112131415161718192021semaphore L = RN, mx = 1; //L用来控制访问数，mx控制写者访问时所有读者阻塞void reader()&#123; do&#123; Swait(L, 1, 1); //第RN+1个读者进入时会阻塞 Swait(mx, 1, 0);//mx &gt;= 1时才可以进入 ... //read operation Ssignal(L, 1); &#125;while(true);&#125;void writer()&#123; do&#123; Swait(mx, 1, 1; L, RN, 0); //mx &gt;= 1 &amp;&amp; L &gt;= RN时进入 ... //write operation Ssignal(mx, 1); &#125;while(true);&#125;void main()&#123; ConcurrentBegin reader();writer(); ConcurrentEnd;&#125;代码分析：最开始并发的时候：假如读者先抢到资源，L = L - 1，写者阻塞在第12行，但其他reader()仍可以运行，直至没有读者进程在访问共享数据区。当所有的读者进程都退出时，共享数据区中停留的个进程数都为0，即重新开始。假如写者先抢到资源，mx = mx - 1，所有读者进程和其他写者进程都要被阻塞，写者进程退出时，共享数据区中停留的个进程数都为0，即重新开始。理发师问题问题描述：一把理发椅，N把等待座位。理发师为理发椅上的顾客理发，没有顾客就在理发椅上睡觉，有一个顾客时需要叫醒理发师，多个顾客时需要在等待座位上等候。分析：理发椅上只能有一位顾客。等待座位是有限缓冲区。只要存在顾客，理发师就不能睡觉。利用记录型信号量解决问题：123456789101112131415161718192021222324semaphore customer = 0, barber = 0, mutex = 1; //barber使理发师只能为一个顾客服务int waiting = 0;void barber()&#123; while(true)&#123; wait(customer); //没有顾客的时候理发师睡觉 wait(mutex); waiting –= 1; //等待的人少一个 signal(mutex); signal(barber); ...//获得被激活进程的信息并给相应的顾客剪发 &#125;&#125;void customer()&#123; wait(mutex); if(waiting &lt; CHAIRS)&#123; //顾客到来的时候，还有座位就进去等待 waiting += 1; signal(mutex); signal(customer); wait(barber); ... //将被激活进程的信息发送给barber() &#125;else&#123; signal(mutex); &#125;&#125;代码分析在最开始并发的时候barber()会等待到有顾客时才醒来。顾客一来就需要访问waiting，所以获得mutex。如果位置不够就立即释放mutex。如果位置够，就让等待的人加1，再释放mutex。然后顾客人数customer += 1来激活理发师进程。理发师进程激活后会V(barber)，然后等待着的customer()进程争夺资源，争夺到P(barber)的进程将被激活进程的信息发送给barber()，barber()获得被激活进程的信息并给相应的顾客剪发。进程通信概念进程之间合作完成工作不仅仅需要有时序关系，还需要进程信息交互，比如刚才的理发师问题中就设计到了信息交互。从概念上说进程通信是指进程之间的信息交换，所以信号量机制本身就涉及到了信息交换，不过我们把这种信息交换叫做低级进程通信，因为其效率低且需要用户大量的干预。真正的进程通信需要满足使用方便且能高效传输大量数据的需求。共享存储器系统基于共享数据结构的通信方式：诸进程公用某些数据结构来实现进行通信 ，如生产者—消费者问题中的有界缓冲区，属于低级通信方式。基于共享存储区的通信方式：在存储器中划出一块共享存储区，诸进程通过对共享存储区中数据的读或写实现通信，此时数据的形式、位置和访问控制仍是进程实现。适用于传输大量数据，属于高级通信。管道通信系统所谓“管道”，是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件，又名pipe文件。向管道提供输入的发送进程（即写进程）以字符流形式将大量的数据送入管道，而接收进程（即读进程），可从管道中接收数据。管道通信系统必须满足以下三个要求：互斥：管道的使用必须互斥。因为存数据和取数据可归于写文件的添加和删除。同步：写进程把一定数量的数据写入管道后去睡眠，读进程读完后将其唤醒。读进程读空的管道时需要睡眠。确定对方存在：如果写进程不存在，读进程就会一直等待。如果读进程不存在，写进程写完数据后也会一直等待，所以通信双方必须同时存在。消息传递系统指进程可以利用一组通信命令（原语）把数据封装在消息中传送，不需要显示的指定共享存储区或数据结构等。它隐藏了通信的细节，也是目前使用最广泛的进程间通信机制。通常有两种实现方式：直接通信方式：OS提供原语给进程使用。间接通信方式：借助共享中间实体（称为邮箱）完成进程间的通信。和共享存储器系统的区别是进程不再需要指定数据的形式、位置和访问控制等，信箱内部自有实现。客户机-服务器系统前三种都是单机下的通信机制，这种是网络环境中的通信机制。主要有套接字和RPC两种方式。套接字：一个套接字是一个通信标识类型的数据结构，包含了通信目的地址、通信端口号、通信的网络协议、进程自身的地址以及对外提供的系统调用等。使用套接字可以在不同主机上的进程建立连接进而进行通信。RPC：Remote Procedure Call，它是一个通信协议，可以使本地进程调用其他主机的进程对程序员表现为常规方法调用。线程线程的由来进程解决了程序不能并发执行的问题，但是由于进程是拥有资源的基本单位，所以在创建、撤销和切换时所需的时空开销很大，因为处理机势必要付出更大的代价来保存现场。所以把拥有资源和独立运行两项功能分开，让线程作为独立运行的基本单位，进程作为拥有资源的基本单位。不过线程也拥有一些能保证其独立运行的资源，如TCB。TCB（Thread Control Block）所有用于控制和管理线程的信息都会被记录在线程控制块中，通常包含：线程标识符：每个线程都有唯一的线程标识符。处理机信息：包括程序计数器、状态寄存器、通用寄存器的内容。线程运行状态：线程和进程一样也有多种运行状态，就绪、阻塞、运行等。详见103-网络编程。优先级：和调度算法有关，优先级越高，得到处理机的机会越大。线程专有存储区：用于在线程切换时保存现场状态和保存线程的统计信息。信号屏蔽：屏蔽某些发送给线程的信号。堆栈指针：线程调用别的过程时需要保存局部变量和返回地址等来供返回时能继续执行。线程的实现线程是为了解决进程调度时过于笨重的问题，所以在不同的环境中实现线程的方式不同。根据内核能否感知到线程的存在可分为内核支持线程（Kernel Supported Threads，KST）和用户级线程（User Level Threads，ULT）。它俩的区别是能否直接调用系统服务，前者可以而后者需要借助中间系统。内核支持线程若线程是由内核直接调度，线程资源也是保存在内核空间，就可以说此类线程为内核支持线程。此类线程的创建、撤销和切换等操作都是在内核空间完成的，此时线程可以直接调用系统服务。一种可能的实现方式是在创建进程时分配一个任务数据区（Per Task Data Area，PTDA），各个线程的TCB保存在其中即可。不过仅实现内核支持线程的系统对用户进程创建的线程很不友好，每次线程调度处理机都要从用户态转换到核心态。用户级线程用户级线程是指线程虽客观存在但对内核来说是透明的，此时不能再直接调用系统服务，间接调用系统服务需要有中间系统的支持，通常的中间系统有运行时系统和内核控制线程。运行时系统：把创建线程、撤销线程和线程同步等只能由OS内核完成的操作封装起来作为运行时系统，而运行时系统停留在用户空间供其他进程调用来实现线程调度。内核控制线程：这种线程又被称作轻量进程（Light Weight Process，LWP），它既可以共享进程的资源，又可以使用内核提供的服务。虽然下图中LWP和用户线程是1对1关系，但实际上多个用户级线程可以复用一个LWP，但每个轻型线程都要连接到一个内核线程中。所以此种方式系统需要同时实现内核支持线程。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-MySQL环境安装]]></title>
    <url>%2F2019%2F02-MySQL%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装MySQLMySQL有两种安装方式，解压配置和安装程序安装。在这使用解压配置但是资源里有使用安装程序安装的教程。解压至指定目录解压至自己选定的目录，一般不选择系统盘。我是解压至D盘根目录：D:\mysql-5.5\。写配置文件123456789#设置字符集为utf8 character-set-server = utf8basedir = D:/mysql-5.5 #指定为自己选定的目录datadir = D:/mysql-5.5/data #指定为选定目录下的data文件夹[client] #设置客户端字符集default-character-set = utf8[WinMySQLadmin] Server = D:/mysql-5.5/bin/mysqld.exe #指定至mysqld.exe文件配置环境变量安装和配置在管理员下的cmd命令下进入%MYSQL_HOME%/bin目录执行mysqld -install。如果想要卸载服务执行命令mysqld -remove。启动服务net start mysql第一次进入mysql -u root。mysql&gt; update mysql.user set password=PASSWORD(‘root’) where User=’root’;mysql&gt; flush privileges;后续进入mysql -u username -p按提示输入密码退出exit停止服务net stop mysql查看编码集mysql&gt; show variables like ‘%char%’;1234567891011121314mysql&gt; show variables like &apos;%char%&apos;;+--------------------------+------------------------------+| Variable_name | Value |+--------------------------+------------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | D:\mysql-5.5\share\charsets\ |+--------------------------+------------------------------+8 rows in set (0.01 sec)编码集如图上表示编码集配置正确。安装SQLyogSQLyog是一个可视化操作数据库工具。解压后就可使用：点击SQLyog.exe连接数据库使用]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-操作系统引论]]></title>
    <url>%2F2019%2F01-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%95%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[操作系统的定义操作系统（Operating System，简称OS）是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。主要作用是管理硬件设备来提高利用率和吞吐量，同时为用户和应用系统提供易于使用的接口。提高利用率：使系统中各设备的空闲时间尽可能短。提高吞吐量：使单位时间内完成的业务更多。提供易于使用的接口：即是方便使用计算机资源。例如没有操作系统，操纵计算机可能需要用户输入二进制代码，有了操作系统，用户可以点击图标，操作系统就会将其转换成二进制代码。操作系统的目标方便性：即对用户和应用程序提供易于使用的接口。有效性：提高利用率和吞吐量。可扩充性：计算机硬件和体系结构等都在不断发展中，OS需要有好的可扩充性来满足不断发展的需求。开放性：为了使计算机的应用环境从单机转换成网络，OS需要满足相应的软硬件标准来实现设备的互联。操作系统的作用提供易于使用的接口，如Shell、图形界面等。管理计算机所有的资源，负责计算机系统全部资源的分配、控制、调度和回收。隐蔽硬件特性，如计算2*3，某些机器的实现是使用加法器做2+2+2，而有的机器是乘法器实现2*3。操作系统屏蔽这些细节，用户只需要输入2*3就能完成。未配置操作系统的计算机系统人工操作：程序员把程序和数据通过穿孔的方式记录在纸带上，再启动机器读入纸带，运行完成并取走计算结果后，才允许下一个用户上机。缺点：用户独占整机：计算机上的资源为上机用户独占。设备空闲率高：用户装卡，卸卡等人工操作时，设备资源是空闲的。脱机输入/输出（Off-Line I/O）：为了解决人机矛盾及CPU、I/O等设备之间速度的不匹配。它是先把纸带通过输入设备在外围机（与主机相比处于次要地位的计算机）的控制下输入到磁带上，当CPU需要这些信息时再从磁带上高速地调取。类似的，在输出时把信息输出到磁盘中，在外围机的控制下通过输出设备输出。也就是说主机直接对磁盘进行操作，输入输出和程序运行脱离。減少了CPU的空闲时间：主机不必依赖输入输出，可以从磁盘中读取数据。提升了I/O速度：主机读取信息不再是从卡片中读取，从磁盘读取速度较快。批处理系统为了提升计算机资源的利用率和提升计算机的吞吐量研发出了批操作系统。基础概念作业：程序+数据+作业说明书（系统根据说明书来对程序的运行进行控制）。周转时间：从作业进入系统到作业完成退出系统所用的时间。平均周转时间：同时参与系统运行的几个作业的周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NT_i]$带权周转时间：作业的周转时间（$T$）和系统为它提供服务的时间（$T_S$）。$W=\frac{T}{T_s}$平均带权周转时间：同时参与系统运行的几个作业的带权周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NW_i]$单道批处理系统设计一个常驻内存的程序（监督程序），操作员有选择地把若干作业合成一批，安装输入设备上，并启动监督程序，然后由监督程序自动控制这批作业运行，从而减少部分人工干预，有效地缩短了作业运行前的准备时间，相对的提高CPU的利用率。同一时刻只有一个硬件在运行。特点：自动性、顺序性、单道性。缺点：I/O的慢速与CPU 的高速不匹配，且输入时需要CPU等待。用户交互性差。作业安装输入后，就不能再交互。多道批处理系统把一个以上的作业存放在主存中，并且同时处于运行状态，使这些作业共享处理机和外部设备等其它系统资源。对于一个单处理机系统来说，作业同时处于运行状态只是宏观的概念，其含义是指每个作业都已开始运行，但尚未完成。就微观而言，在任意特定时刻，处理机上运行的作业只有一个。特点：多道性、无序性、调度性。优缺点：优点：资源利用率高、系统吞吐量大。缺点：作业仍然要排队处理，所以平均周转时间长、无交互能力。此时如何调度程序已经不是再用一张简单的流程图能说明了，第二章会有介绍。下图只是说明处理器利用率高。举例证明资源利用率高和系统吞吐量大设内存中有三道程序 A、B、C，它们的计算和I/O操作的时间如下表所示：程序操作ABC计算306020I/O403040计算101020单道多道分时系统批处理系统中，作业一旦提交就不能进行更改，所以人机交互性很差。为了满足人机交互的需求诞生分时系统。每一个用户通过一台终端与计算机相连，以交互式的命令使用系统，采用分享CPU的方法，由于CPU的速度比人在终端输入指令的时间快得多，所以用户感到自己独占了整个计算机系统。系统规定一个称之为“时间片”的时间单位，所有终端用户轮流享用一个时间片的CPU。需要解决的问题：及时接受：所有终端用户输入的信息都要能够被及时的送到处理器上。所以主机会以很快的速度循环扫描各个终端。每个终端也要拥有缓存区来保存输入的信息。及时处理：用户需要能对自己的作业及其允许及时地实施控制。所以所有的作业必须驻留在内存中，因此批作业系统不能被使用。它采用的方式是：作业直接进入内存。但每个用户只连续使用一个“时间片”的时间，对所有用户进行循环。这样每个用户都能及时地与自己的作业进行交互。分时系统与多道批处理系统的不同特性多路性：允许多个用户共享一台计算机，提高资源利用率。独立性：每个用户之间互不干扰，感觉就是一个人在独占一台计算机。及时性：用户的请求能在很短的时间内得到回应。交互性：用户可以通过终端和计算机进行及时交互。实时系统指系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。实时系统强调程序运行的时间，它需对接收到的某些信号做出及时地反应。大多数的实时系统是专用系统，如：工业（武器）控制系统、信息查询系统、多媒体系统、嵌入式系统等。最大的特点就是可靠性：系统必须高度可靠，因为任何可能的差错都可能带来灾难性后果，所以系统一般都有多级容错措施。按是否周期执行分类：周期性实时任务：如外部设备周期性地发出状态信号给计算机使其状态能被实时感知。非周期性实时任务：提交给系统时需要指定开始截止时间和完成截止时间。硬实时任务&amp;软实时任务：硬实时任务（Hard Real-time Task）：截止时间到达时任务必须完成，比如武器控制系统。软实时任务（Soft Real-time Task）：截止时间到达时任务没有完成没有太大影响，比如多媒体系统。进程和线程进程：在系统中能独立运行并作为资源分配的基本单位。线程：独立运行的基本单位，比进程更小，基本上不拥有系统资源。通常在一个进程中包含了若干个线程。操作系统的基本特性并发：宏观上是多个进程同时运行，微观上是每一时刻只有一道进程在执行。共享：系统中的资源可供内存中多个并发执行的进程（线程）共同使用。有两种共享方式：互斥共享方式，如打印机；同时访问方式，如共享文件夹、网络资源。虚拟：通过某种技术把一个物理实体变为若干个逻辑上的对应物。这样可以避免一个进程单独占用某个物理设备，一个物理设备被分配给多个进程便可以提升物理设备的使用率。不确定性（异步性）：进程以人们不可预知的速度向前推进，即为进程的不确定性。这样的话很可能是先进入内存的作业后完成；而后进入内存的作业先完成。尽管如此，但只要有合理的进程同步方式且运行环境相同，作业经多次运行，都会获得完全相同的结果。因此，异步运行方式是允许的。操作系统的结构传统操作系统结构无结构OS：关注功能的实现和获得高的效率操作系统是为数众多的一组过程的集合，各过程之间可以相互调用，在操作系统内部不存在任何结构。程序设计的技巧，只是如何编制紧凑的程序，以便于有效地利用内存。操作系统既庞大又杂乱，缺乏清晰的程序结构。程序错误很多，给调试工作带来很多困难；另一方面也使程序难以阅读和理解，增加了维护人员的负担。模块化结构OS模块化程序设计技术，是最早（20世纪60年代）出现的一种程序设计技术。该技术是基于“分解”和“模块”原则来控制大型软件的复杂度的。将OS按其功能划分为若干个具有一定独立性和大小的模块。每个模块具有某方面的管理功能，并规定好各模块间的接口， 使各模块之间能通过该接口实现交互，然后再进一步将各模块细分为若干个具有一定管理功能的子模块。（会导致模块之间的依赖关系很重，OS结构不清晰）若子模块较大时，再进一步将它细分。分层式结构OS：改进设计方式，使每一步设计都是建立在可靠的基础上一层一层地自底向上增添软件层，每一层都实现若干功能，最后总能构成一个能满足需要的OS。每一层都仅使用其底层所提供的功能和服务，这样可使系统的调试和验证都变得容易。一旦发现错误后，通常该错误只会局限于某一层，因为它与所有其高层的软件无关，而此层以下的各层软件，又都经过仔细的调试，bug修复较为容易。客户/服务器结构为了提高OS的灵活性和可扩充性而将OS划分为两部分。一部分是用于提供各种服务的一组服务器（进程），所有这些服务器（进程）都运行在用户态。当有一用户进程（现在称为客户进程）要求读文件的一个盘块时，该进程便向文件服务器（进程）发出一个请求；当服务器完成了该客户的请求后，便给该客户回送一个响应。另一部分是内核，用来处理客户和服务器之间的通信， 即由内核来接收客户的请求，再将该请求送至相应的服务器；同时它也接收服务器的应答， 并将此应答回送给请求客户。此外，在内核中还应具有其它一些机构，用于实现与硬件紧密相关的和一些较基本的功能。面向对象结构（20世纪80年代）该技术是基于“抽象”和“隐蔽”原则来控制大型软件的复杂度的。所谓对象，是指在现实世界中具有相同属性、服从相同规则的一系列事物的抽象，而把其中的具体事物称为对象的实例。OS中的各类实体如进程、线程、消息、存储器等，都使用了对象这一概念，相应地，便有进程对象、线程对象、 存储器对象等。由于隐蔽了表示实体的数据和操作，因而可以改变对象的表示而不会影响其它部分， 从而可以方便地改变老的对象和增加新的对象。继承性。继承性是面向对象技术所具有的重要特性。继承性是指子对象可以继承父对象的属性，这样，在创建一个新的对象时， 便可减少大量的时空开销。正确性和可靠性。由于对象是构成操作系统的基本单元，可以独立地对它进行测试，这样，比较易于保证其正确性和可靠性，从而比较容易保证整个系统的正确性和可靠性。微服务结构（20世纪90年代）能有效支持多处理机，适用于分布式系统环境。以微内核为操作系统核心，以客户/服务器为基础，采用了面向对象的程序设计方法。所谓微内核技术，是指精心设计的、能实现现代OS核心功能的小型内核，它与一般的OS(程序)不同， 它更小更精炼，它不仅运行在核心态，而且开机后常驻内存， 它不会因内存紧张而被换出内存。微内核并非是一个完整的OS， 而只是为构建通用OS提供一个重要基础。在微内核OS结构中，通常都采用了客户/服务器模式，因此OS的大部分功能和服务，都是由若干服务器来提供的， 如文件服务器、作业服务器和网络服务器等。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-关系型数据库绪论]]></title>
    <url>%2F2019%2F01-%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%AA%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[数据、数据库、数据库管理系统数据：描述事物的符号记录称为数据，如文字、图形、图象、声音、学生的档案记录、货物的运输情况等。数据的含义称为数据的语义，数据与其语义是不可分的。数据库：数据按一定的方式组织、描述和存储后形成的数据集合叫做数据库。数据库具有三个特点：永久存储：不随程序的结束而结束。有组织：数据之间有一定的格式，可以通过格式知道数据所代表的的意义。可共享：数据库里的信息不是只为某一用户或某一程序所使用。数据库管理系统：数据库管理系统是位于用户与操作系统之间的一层用来管理数据库的软件。常用的数据库管理系统有MySQL、Oracle、Redis、MongoDB等。关系数据库系统数据库是由数据按某种形式组织所形成，按照不同的组织方式可以分为不同的类型。所以关系型数据库就是指以关系数学模型来组织数据的数据库，关系数学模型中以二维表的形式来描述数据。也就是一个关系对应一个二维表。实体-联系实体：客观存在并可相互区别的事物。二维表非首行。属性：实体所具有的某一特性。二维表的一格。码：唯一标识实体的属性。域：属性的取值范围。实体型：用实体名及其属性名集合来抽象和刻画同类实体。实体集：同型实体的集合称为实体集联系：现实世界中事物内部以及事物之间的联系在信息世界中反映为实体内部的联系和实体之间的联系。SQLDDL、DML、DCL、DQL常见的关系数据库系统有MySQL、Oracle等，可以使用结构化查询语言（Structured Query Language，SQL）进行操作。不同的数据库生产厂商都支持SQL语句，但都有特有内容（称为方言）。SQL可分为四类：数据定义语言（Data Definition Language，DDL）：用来定义数据库中的对象：数据库，表，列等。关键字有create、alter、drop、 show等。数据操作语言（Data Manipulation Language，DML）：用来对数据库中表的记录进行更新。关键字有insert、delete、update等。数据查询语言（Data Query Language，DQL）：用来查询数据库中表的记录。关键字：select，from，where等。数据控制语言（Data Control Language，DCL）：用来定义数据库的访问权限和安全级别，及创建用户。关键字有grant、revoke等。SQL通用语法SQL语句可以单行或多行书写，以分号结尾，可使用空格和缩进来增强语句的可读性。MySQL数据库的SQL语句不区分大小写，关键字建议使用大写。例如：SELECT * FROM user。使用/* ... */的方式完成注释。数据类型类型描述int整型double浮点型varchar变长字符串型（指定为10个字节长度，存储abc只占用3个字节）char定长字符串型（指定为10个字节长度，存储abc也占用10个字节）datetimeYYYY-MM-DD HH:MM:SS（1000-01-01 00:00:00~ 9999-12-31 23:59:59）实体型之间的联系一对一联系：如果对于实体集A中的每一个实体，实体集B中至多有一个实体与之联系，反之亦然，称实体集A与实体集B有一对一联系。记为1：1。一对多联系：如果对于实体集A中的每一个实体，实体集B中有n个实体（n≥0）与之联系，反之，对于实体集B中的每一个实体，实体集A中至多只有一个实体与之联系，称实体集A与实体B有一对多联系。记为1：n。多对多联系：如果对于实体集A中的每一个实体，实体集B中有n个实体（n≥0）与之联系，反之，对于实体集B中的每一个实体，实体集A中有m个实体（m≥0）与之联系，称实体集A与实体B有多对多联系。记为m：n。多对多联系能经由一个中间表拆分成两个一对多关系。Entity-Relationship ModelE-R图提供了表示实体型、属性和联系的方法。先把需求转化成E-R图，可以方便的化简和建表。实体型：用矩形表示，矩形框内写明实体名。属性：用椭圆形表示，并用无向边将其与相应的实体连接起来。联系：用菱形表示，菱形框内写明联系名，并用无向边分别与有关实体连接起来，同时在无向边旁标上。联系的类型: 1：1、1：n或m：n。联系本身也是一种实体型，也可以有属性。如果一个联系具有属性，则这些属性也要用无向边与该联系连接起来。E-R图转换成关系转换原则：实体和联系分别转换为关系，再合并具有相同主键的关系。实体转换为关系：一个实体型 转换成 一个关系。实体型的名称 转换成 构成关系的名称。实体型的属性 转换成 构成关系的属性（也叫字段）。实体型的主键 转换成 关系的主键。联系转换为关系：一个联系 转换成 一个关系。与该联系相关联的各实体的码属性以及联系本身的属性 构成 关系的属性。联系转换为关系的码的取决于联系的类型。1：1联系，任一实体的码。1：n联系，n端实体的码。m：n联系，双方实体的码相同码的关系合并为一个关系。E-R图实例数据：科室：科名，科地址，科电话病房：病房号，床位号医生：姓名，职称，年龄，工作证病人：病历号，姓名，性别，诊断联系：一个科室有多个病房、多个医生一个病房只能属于一个科室一个医生只属于一个科室，但可负责多个病人的诊治一个病人的主管医生只有一个E-R图转换科室（科名，地址，电话）医生（医生名，职称，年龄，工作证号）病房（病房号，床位号）病人（病历号，姓名，性别，诊断）负责（床位号，科名）拥有（医生名，科名）诊治（病历号，医生名）合并科室（科名，地址，电话）医生（医生名，职称，科名，年龄，工作证号）病房（床位号，病房号，科名）病人（病历号，姓名，性别，诊断，医生名）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Spring入门]]></title>
    <url>%2F2019%2F01-Spring%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring - 概述（00）Spring概述Spring是一个一站式框架。它为Java EE开发的三层架构中每一层都提供了解决方案Web层：Spring MVC；Service层：Spring的Bean管理，Spring声明式事务；DAO层：Spring的JDBC模板，Spring的ORM模块。（后期会用Mybatis替换Spring的DAO层）Spring下载Spring现在是在github上托管的开源项目：地址。Spring各版本下载：地址。Spring环境搭建我的Spring文集中使用的是Spring 4.2版本，下方这张图是Spring官方给的架构图，想运行Spring项目，必须得导入Core Container中的包，但是也需要日志包。## Spring初体验123public interface UserDao &#123; public void save();&#125;12345public class UserDaoImpl implements UserDao&#123; public void save() &#123; System.out.println("UserService执行了..."); &#125;&#125;123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:p="http://www.springframework.org/schema/p" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- Spring的入门的配置==================== --&gt; &lt;bean name="userDao" class="com.isjinhao.Demo1.UserDaoImpl" &gt;&lt;/bean&gt; &lt;/beans&gt;12345678910111213141516171819import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Test &#123; //传统方法的获得UserDao对象 @org.junit.Test public void test1() &#123; UserDao dao = new UserDaoImpl(); dao.save(); &#125; //通过Spring获得UserDao对象 @org.junit.Test public void test2() &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("applicationContext.xml"); UserDao bean = (UserDao)applicationContext.getBean("userDao"); bean.save(); &#125;&#125;开发的一个规则是在后期维护的时候少修改源代码。如果没有Spring我们更换UserDao的实现类，比如更换为UserMybatisDaoImpl，我们在源代码中就要改为UserDao dao = new UserMybatisDaoImpl();。但有了Spring之后就只需要修改配置文件中的class为xxx.UserMybatisDaoImpl，被Spring管理的类叫做bean。## DI（Dependency Injection）### 依赖关系1234567Class A&#123; &#125;Class B&#123; A a; public void xxx()&#123; &#125;&#125;如果在类B中使用到了类A，就说类B依赖类A，上图就是其中一种情况。### Spring解决依赖123public interface UserDao &#123; public void save();&#125;123456789101112public class UserDaoImpl implements UserDao&#123; private String name; public void save() &#123; System.out.println("UserService执行了..." + name); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;1234567891011121314&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:p="http://www.springframework.org/schema/p" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- Spring的入门的配置==================== --&gt; &lt;bean name="userDao" class="com.isjinhao.Demo1.UserDaoImpl"&gt; &lt;property name="name" value="isjinhao" /&gt; //name的值和属性名称相同 &lt;/bean&gt; &lt;/beans&gt;1234567891011import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Test &#123; //通过Spring获得UserDao对象 @org.junit.Test public void test2() &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("applicationContext.xml"); UserDao dao = (UserDao)applicationContext.getBean("userDao"); dao.save(); &#125;&#125;所谓解决依赖，就是在使用时给其设置一个被依赖的对象，如果不使用Spring，设置name的值需要把dao转换为UserDaoImpl，再使用setName()方法，但是用了Spring我们就能在配置文件中设置，Spring帮我们完成设置。此时就叫做依赖注入。## ApplicationContext继承体系bean配置id &amp; namename和id的功能类似，作用如图：从语法上说name属性可以不唯一，而id必须唯一，但是实际使用时name标签和id标签通常都标识唯一值，而且优先使用name。初始化时执行的方法 &amp; 销毁的时候执行的方法init-method=””：指定的方法在bean被创建时执行。destroy-method=””：指定的方法在bean被销毁时创建的，但要求bean是单例的且手动关闭工厂。bean的作用域bean标签有一个属性scope=””，可以设置bean的作用范围，五种值如下：singleton ：默认的，Spring会采用单例模式创建这个对象。prototype ：多例模式。request ：应用在web项目中，Spring创建这个类以后，将这个类存入到request范围中。session ：应用在web项目中，Spring创建这个类以后，将这个类存入到session范围中。globalsession ：应用在web项目中，必须在porlet环境下使用。但是如果没有这种环境，相当于session。（笔者不懂，抄过来的…）]]></content>
      <categories>
        <category>SSM</category>
      </categories>
      <tags>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高德API使用-查询市内公交]]></title>
    <url>%2F2019%2F%E9%AB%98%E5%BE%B7API%E4%BD%BF%E7%94%A8-%E6%9F%A5%E8%AF%A2%E5%B8%82%E5%86%85%E5%85%AC%E4%BA%A4%2F</url>
    <content type="text"><![CDATA[POJOlocation.java1234567891011121314151617181920212223242526272829package pojo;public class Location &#123; private String key; private String location; private String city; public String getLocation() &#123; return location; &#125; public void setLocation(String location) &#123; this.location = location; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public String getKey() &#123; return key; &#125; public void setKey(String key) &#123; this.key = key; &#125; @Override public String toString() &#123; return "Location [key=" + key + ", location=" + location + ", city=" + city + "]"; &#125;&#125;RoutePojo.java12345678910111213141516171819202122232425262728293031package pojo;import java.util.List;public class RoutePojo &#123; private long time; // 秒 private double cost; // 元 private List&lt;SegmentPojo&gt; segments; // 分段信息 public long getTime() &#123; return time; &#125; public void setTime(long time) &#123; this.time = time; &#125; public double getCost() &#123; return cost; &#125; public void setCost(double cost) &#123; this.cost = cost; &#125; public List&lt;SegmentPojo&gt; getSegments() &#123; return segments; &#125; public void setSegments(List&lt;SegmentPojo&gt; segments) &#123; this.segments = segments; &#125; @Override public String toString() &#123; return "RoutePojo [time=" + time + ", cost=" + cost + ", segments=" + segments + "]"; &#125;&#125;SegmentPojo.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package pojo;/** * 一段路径。RoutePojo的一段，有步行、公交、地铁 * @author ISJINHAO */public class SegmentPojo &#123; private String type; private String start; private String end; private String vias; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; public String getStart() &#123; return start; &#125; public void setStart(String start) &#123; this.start = start; &#125; public String getEnd() &#123; return end; &#125; public void setEnd(String end) &#123; this.end = end; &#125; public String getVias() &#123; return vias; &#125; public void setVias(String vias) &#123; this.vias = vias; &#125; @Override public String toString() &#123; return "SegmentPojo [type=" + type + ", start=" + start + ", end=" + end + ", vias=" + vias + "]"; &#125;&#125;查询经纬度，由经纬度查询市内公交123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263package test;import java.util.ArrayList;import java.util.List;import org.apache.http.HttpEntity;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClientBuilder;import org.apache.http.util.EntityUtils;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.JSONObject;import pojo.Location;import pojo.RoutePojo;import pojo.SegmentPojo;public class GaoDeUtils &#123; private static CloseableHttpClient httpClient = HttpClientBuilder.create().build(); /** * @param origin * 起点经纬度 * @param dst * 终点经纬度 * @param city * 城市名 * @param strategy * 0：最快捷模式; 1：最经济模式; 2：最少换乘模式; 3：最少步行模式; 5：不乘地铁模式 * @param dateTime（可选） * 日期时间，格式：2014-03-19 22:34 * @return */ public static RoutePojo cityInnerGuide(String origin, String dst, String city, String strategy, String... dateTime) &#123; String url = "https://restapi.amap.com/v3/direction/transit/integrated?strategy=" + strategy + "&amp;origin=" + origin + "&amp;destination=" + dst + "&amp;key=d4393e4b379c905601d89f62b8c0c0aa&amp;city=" + city; // 处理日期时间 int argsNum = dateTime.length; if (argsNum &gt; 1) &#123; return null; &#125; else if (argsNum == 1) &#123; url = url + "&amp;date=" + dateTime[0].split(" ")[0] + "&amp;time=" + dateTime[0].split(" ")[1]; &#125; // 创建Get请求 HttpGet httpGet = new HttpGet(url); // 响应模型 CloseableHttpResponse response = null; try &#123; // 由客户端执行(发送)Get请求 response = httpClient.execute(httpGet); // 从响应模型中获取响应实体 HttpEntity responseEntity = response.getEntity(); if (responseEntity == null) return null; // 整个结果 JSONObject result = JSON.parseObject(EntityUtils.toString(responseEntity)); // 和路径有关的信息 JSONObject routes = result.getJSONObject("route"); // 查询出来的路径个数// int ways = Integer.parseInt(result.getString("count")); // 所有路径的详细信息 JSONArray transits = routes.getJSONArray("transits"); // for (int i = 0; i &lt; ways; i++) &#123; // 一条路径 JSONObject route = (JSONObject) transits.get(0); RoutePojo rp = new RoutePojo(); // 此路径的花费 rp.setCost(Double.valueOf(route.getString("cost"))); // 此路径的时间 rp.setTime(Long.valueOf(route.getString("duration"))); // 每条路径的分段 JSONArray segments = (JSONArray) route.get("segments"); // 每条路径经过的 段数 int segmentsSize = segments.size(); List&lt;SegmentPojo&gt; segList = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; segmentsSize; j++) &#123; // 每个子段。每个子段都包含三种方式：步行、地铁、公交。地铁和公交不会同时存在。 JSONObject path = (JSONObject) segments.get(j); // 解析 步行 SegmentPojo segWalking = new SegmentPojo(); segWalking.setType("WALKING"); // 如果需要换乘，解析为JSONObject。如果不需要换乘解析为JSONArray try &#123; JSONObject walking = path.getJSONObject("walking"); JSONArray steps = walking.getJSONArray("steps"); int stepSize = steps.size(); String instructions = ""; for (int k = 0; k &lt; stepSize; k++) &#123; JSONObject step = (JSONObject) steps.get(k); String instruction = step.getString("instruction"); instructions = instructions + "`" + instruction; &#125; segWalking.setVias(instructions.substring(1)); &#125; catch (Exception e) &#123; segWalking.setVias("在此站换乘！"); &#125; segList.add(segWalking); // 解析 出租车 // JSONArray taxi = path.getJSONArray("taxi"); int flag = 0; // 如果是公交车，解析为JSONArray，不是公交车，解析为JSONObject try &#123; path.getJSONArray("exit"); &#125; catch (Exception e) &#123; flag = 1; &#125; SegmentPojo segBus = new SegmentPojo(); // 获得bus和sub的信息，字段都是 bus JSONObject bus = path.getJSONObject("bus"); JSONArray buslinesHelp = (JSONArray) bus.getJSONArray("buslines"); if (buslinesHelp.size() &lt; 1) &#123; break; &#125; JSONObject buslines = (JSONObject) buslinesHelp.get(0); JSONArray viaStops = buslines.getJSONArray("via_stops"); // 处理bus和sub的公交经停 String vias = ""; int viaSize = viaStops.size(); for (int k = 0; k &lt; viaSize; k++) &#123; JSONObject stop = (JSONObject) viaStops.get(k); vias = vias + "`" + stop.getString("name"); &#125; if (vias.length() &gt; 0) segBus.setVias(vias.substring(1)); // 设置公交路线 segBus.setName(buslines.getString("name")); // 处理公交车 if (flag == 0) &#123; segBus.setType("BUS"); // 设置起点 JSONObject departureStop = buslines.getJSONObject("departure_stop"); segBus.setStart(departureStop.getString("name")); // 设置终点 JSONObject arrivalStop = buslines.getJSONObject("arrival_stop"); segBus.setEnd(arrivalStop.getString("name")); segList.add(segBus); &#125; else if (flag == 1) &#123; segBus.setType("SUB"); JSONObject exitObject = path.getJSONObject("exit"); // 设置起点 JSONObject departureStop = buslines.getJSONObject("departure_stop"); // 不用换站使用JSONArray解析，换站使用JSONObject解析 try &#123; JSONObject entranceObject = path.getJSONObject("entrance"); segBus.setStart(departureStop.getString("name") + "`" + entranceObject.getString("name")); &#125; catch (Exception e) &#123; segBus.setStart(departureStop.getString("name") + "`在此站换乘！"); &#125; // 设置终点 JSONObject arrivalStop = buslines.getJSONObject("arrival_stop"); segBus.setEnd(arrivalStop.getString("name") + "`" + exitObject.getString("name")); segList.add(segBus); &#125; &#125; rp.setSegments(segList); return rp; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * * @param keyWords * 关键字，务必尽量准确 * @param types * 所有地点：all 交通运输类：150000 机场类：150100 火车站类：150200 公交车：150700 地铁类 150500 * 轻轨类：150600 * @param city * 限定查询的城市 * @return */ public static Location getLocation(String keyWords, String types, String city) &#123; Location loc = new Location(); loc.setKey(keyWords); String url = "https://restapi.amap.com/v3/place/text?keywords=" + keyWords + "&amp;city=" + city + "&amp;key=d4393e4b379c905601d89f62b8c0c0aa&amp;offset=1&amp;page=1&amp;extensions=all"; if (!"all".equals(types)) &#123; url = url + "&amp;types=" + types; &#125; // 创建Get请求 HttpGet httpGet = new HttpGet(url); // 响应模型 CloseableHttpResponse response = null; try &#123; // 由客户端执行(发送)Get请求 response = httpClient.execute(httpGet); // 从响应模型中获取响应实体 HttpEntity responseEntity = response.getEntity(); if (responseEntity == null) return null; JSONObject result = JSON.parseObject(EntityUtils.toString(responseEntity)); System.out.println(result); if ("0".equals(result.getString("count"))) return null; // 获得第一个poi JSONObject poi = (JSONObject) result.getJSONArray("pois").get(0); // 经纬度 String location = poi.getString("entr_location"); // 结构化城市名：省（直辖市）`市（直辖市）`县区 String structureName = poi.getString("pname") + "`" + poi.getString("cityname") + "`" + poi.getString("adname"); loc.setLocation(location); loc.setCity(structureName); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; if("[]".equals(loc.getLocation())) return null; return loc; &#125;&#125;]]></content>
      <categories>
        <category>高德API</category>
      </categories>
      <tags>
        <tag>高德API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AOE网和关键路径]]></title>
    <url>%2F2019%2FAOE%E7%BD%91%E5%92%8C%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[软件开发文档用图]]></title>
    <url>%2F2019%2F%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3%E7%94%A8%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[系统流程图表达的是数据在系统各部件之间流动的情况，但不表达对数据进行加工处理的控制过程。基本思想：用图形符号以黑盒子形式描绘组成系统的每个部件（程序，文档，数据库，人工过程等），表达数据在系统各部件之间流动的情况。符号装配厂供货流程图某装配厂有一座存放零件的仓库，仓库中现有的各种零件的数量以及每种零件的库存量临界值等数据记录在库存清单主文件中。当仓库中零件数量有变化时，应该及时修改库存清单主文件，如果哪种零件的库存量少于它的库存量临界值，则应该报告给采购部门以便订货，规定每天向采购部门送一次订货报告。该装配厂使用一台小型计算机处理更新库存清单主文件和产生订货报告的任务。零件库存量的每一次变化称为一个事务，由放在仓库中的CRT终端输入到计算机中；系统中的库存清单程序对事务进行处理，更新存储在磁盘上的库存清单主文件，并且把必要的订货信息写在磁带上。最后，每天由报告生成程序读一次磁带，并且打印出订货报告。人工销售教材流程图计算机售书系统流程图e-r图https://isjinhao.github.io/2019/01-%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%AA%E8%AE%BA/数据流图符号通过图形的方法，从数据传递和数据处理的角度，刻画数据流从输入到输出的移动变换过程。数据流三个重要属性：数据流名字数据组成流向银行取款过程的数据流图数据流程图分层顶层流图仅包含一个数据处理，它代表被开发系统。它的输入流是该系统的输入数据，输出流是系统所输出数据底层流图是指其数据处理不需再做分解的数据流图，它处在最底层中间层流图则表示对其上层父图的细化。它的每一数据处理可能继续细化，形成子图商场业务处理系统的分层数据流图商场进货时，先发订货单给供应商，供应商收到订货单，将商品发给商场，商场货到付款，供应商收款后，将收据发给商场；当顾客到商场采购商品时，先下购物订单，商场查询库存中是否有此种商品，若有则发货给顾客；若没有，则向供应商订货，货到之后再销售给顾客；顾客收到货物之后付款，商场开收据给顾客；商场对货物的管理方面要求知道每种货物详细的销售情况。绘制L0层数据流图首先从问题的描述中提取数据流图中的源（终）点、数据处理、数据流和数据存储四种成份。分析源（终）点：将商场的购、销业务系统看成一个整体，外部的与这个系统有交往的对象（机构、人员、或外部系统）是“供应商，和“顾客”，二者是商场购销系统源点和终点。分析数据处理：在顶层数据流图的处理中，用一个整体来表示分析数据流：供应商方 $\rightarrow$ 商场：发货单、货款收据顾客 $\rightarrow$ 商场：订单、货款商场 $\rightarrow$ 供货商：订货单、货款商场 $\rightarrow$ 顾客：货物、收据分析数据存储库存信息暂存订单（缺货订单）采购订单商品销售历史资金帐目绘制L1层数据流图商店业务处理的主要数据处理是销售、采购、会计三大数据处理，三者之间的数据流：销售 $\rightarrow$ 采购：订货通知销售 $\rightarrow$ 会计：收款单会计 $\rightarrow$ 销售：收据采购 $\rightarrow$ 销售：到货通知采购 $\rightarrow$ 会计：付款单绘制L2层数据流图销售细化采购细化教务管理系统某校准备开发一个学生成绩管理系统。在该系统中，教务人员录入学生信息、课程信息和成绩信息，学生可以随时查询自己所选课程的成绩。由于学生成绩属于敏感信息，系统必须提供必要的安全措施以防非法存取。绘制L0层数据流图源点终点：教务人员（源点）；学生（终点）数据处理：将系统当成一个整体“学生成绩管理”数据流：学生信息、课程信息和成绩；（教务人员录入时）查询请求、查询结果（学生查询时）数据文件：成绩文件、学生文件、课程文件。教务人员维护学生信息和课程信息，并登录学生的选课成绩；学生查询自己的成绩单。绘制L1层数据流图“学生信息”是教务人员需要录入的一个信息，因此加入一个加入“录入学生信息” ；同样得到“录入课程信息”、“登记成绩”两个数据处理。另外，数据流“查询请求”和“查询结果”应该由数据处理“查询成绩”来完成。对第 0 层 DFD 的加工“学生成绩管理“进行展开。数据处理：录入学生信息录入课程信息登记学生成绩查询学生成绩数据存储：增加这些数据流对应的数据存储，即“学生”、“课程”和“成绩” ，最后得到如图所示的第 1 层 DFD 。绘制L2层数据流图继续分解第 1 层 DFD 中的加工“查询学生成绩”数据处理：分解为“合法性检查”和“查询成绩”数据文件：合法的查询条件状态转换图语法在状态图中：初态用实心圆表示；终态用一对同心圆（内圆为实心圆）表示。中间状态用圆角矩形表示，可以用两条水平横线把它分成上、中、下3个部分。上面部分为状态的名称（必须）；中间部分为状态变量的名字和值（可选）；下面部分是活动表（可选）。活动表的语法格式事件名(参数表)/动作表达式。在活动表中经常使用下述3种标准事件：entry, exit和do。entry事件指定进入该状态的动作；exit事件指定退出该状态的动作；do事件则指定在该状态下的动作。活动表中的动作表达式描述应做的具体动作。事件表达式的语法事件说明［守卫条件］／动作表达式其中事件说明的语法为：事件名(参数表)。举例结构图模块关系一个方框表示一个模块；一个模块指向另一个模块的箭头或直线，表示前一模块对后一模块的调用；调用直线边的小箭头，表示调用时从一个模块传给另一个模块的数据，也指出了传送方向。四种模块从下属模块取得数据，经过处理，再传入上级模块从上级模块获得数据，经过处理，再传送给下属模块加工模块。从上级模块获得数据，经过处理，转换成其他形式，再送回上级模块对所有下属模块进行协调和管理的模块医院管理系统选择/循环调用变换型SCDFD第一级分解后 SC 的数据流传入分支的分解传出分支的分解中心加工分支的分解事务型SCDFD分解系统设置控制器分解密码处理控制器程序流程图符号(a) 选择(分支)； (b) 注释； (c) 预先定义的处理； (d) 多分支； (e) 开始或停止； (f) 准备； (g) 循环上界限； (h) 循环下界限； (i) 虚线； (j) 省略符； (k) 并行方式； (l) 处理； (m) 输入输出； (n) 连接； (o) 换页连接； (p) 控制流例子盒图符号例子PAD图符号顺序(先执行P1后执行P2)；选择(IF C THEN P1 ELSE P2);CASE型多分支；WHILE型循环(WHILE C DO P);UNTIL型循环(REPEAT P UNTIL C)；语句标号；定义PAD 描述的示例判定表例子检查发货单判定表判定树程序图从流程图导出程序图]]></content>
      <categories>
        <category>软件项目管理</category>
      </categories>
      <tags>
        <tag>软件项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件工程和项目管理]]></title>
    <url>%2F2019%2F%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%92%8C%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[软件危机软件危机指在计算机软件的开发和维护过程中，所遇到的一系列严重问题。软件危机主要包括的问题：如何开发软件如何维护软件软件危机的典型表现：发费用和进度难以估算和控制，大大超过预期的资金和规定日期软件需求分析不够充分，用户不满意“已经完成”的软件系统。软件质量难于保证软件维护困难难以改正程序中的错误难以根据用户的需要在原有程序中增加一些新的功能。通常没有保留适当的文档资料。文档的作用：软件开发管理人员：用于管理和评价软件开发工程的进展状况软件开发人员：用于开发人员对各个阶段的工作都进行周密思考、全盘权衡、从而减少返工。并且可在开发早期发现错误和不一致性，便于及时加以纠正软件维护人员：软件维护的依据开发成本逐年上升，软件开发生产率提高的速度，远远跟不上计算机应用迅速普及深入的趋势。产生软件危机的原因软件本身的特点软件与硬件不同抽象性。软件生产没有明显的制造过程，难以衡量开发进展，也难以控制软件质量。问题的隐蔽性。没有硬件的磨损、老化问题，但存在开发早期在分析、设计阶段的错误，修改难度较大。软件与一般程序不同软件远比一般程序规模庞大，复杂性高。而复杂性包括实际问题的复杂性和程序逻辑结构的复杂性。大型软件开发既有技术问题，还有社会问题。如：开发团队成员分工合作、技术与管理的矛盾、软件开发人员对软件应用的领域知识的了解。包括的社会因素有：组织机构、体制、管理方式、观念、人的心理素质等。软件开发与维护的方法不正确对用户需求的获取不正确用户的原因分析人员的原因，对分析人员的要求：沟通能力、归纳总结能力、经验。软件开发不是编写程序。一个完整的软件产品由一整套完整的配置组成，程序只是其中的一个组成部分。软件开发过程包括多个阶段，每个阶段的产品都是最终的完整的软件产品的一部分。软件开发只要依靠个别编程高手就能完成。轻视软件维护。软件维护约占软件费用55%-75%，包括修改软件运行的错误；对软件进行改进和功能扩充。其他产生软件危机的原因软件开发尚未完全摆脱手工艺的开发方式。软件成本相当昂贵，主要依靠大量复杂的、高强度的脑力劳动。软件的开发和运行常常受到计算机系统的限制，对计算机系统有着不同程度的依赖性。软件的本质特性复杂性一致性软件不能独立存在，需要依附于一定的环境（如硬件、网络以及其他软件）软件必须遵从认为的惯例并适应已有的技术和系统软件需要随接口不同而改变，随时间推移而变化，而这些变化是不同人设计的结果可变性：软件需要不断的进行调整来满足用户的需求不可见性软件是一种“看不见，摸不着”的逻辑实体，不具有空间的形体特征。开发人员可以直接看到程序代码，但是源代码并不是软件本身。软件是以机器代码的形式运行，但是开发人员无法看到源代码是如何执行的。软件开发面临的挑战消除软件危机的途径彻底消除“软件就是程序”的错误观念。充分认识到软件开发是一种组织良好、管理严密、各类人员协同配合、共同完成的工程项目，不是个人独立的劳动。推广和使用在实践中总结出来的软件开发的成功技术和方法。开发和使用更好的软件工具“软件工程”的方法理论是摆脱软件危机的一个主要出路。即按工程化的原则和方法组织软件开发工作是有效的，是摆脱软件危机的一个主要出路。软件开发的误区只要是编程高手，即使是不懂软件工程，也能编出很好的软件。软件是服务于大众，却是由个性化的开发人员完成的。如果个性化太强，程序就无法阅读，其他人员也就无法维护。例：国内 80 年代涌现出来的众多汉字操作系统均是由编程高手完成的。只要拥有一套讲述如何开发软件的书籍，并了解了书中的标准与示例，就可以解决软件开发中遇到的任何问题。软件是用来解决现实问题的，现实问题的特殊性对规范提出了挑战（要进行适应）。软件技术是发展的，没有祖传秘方。就像拥有食谱并不能成为名厨一样，软件开发需要实践。只要拥有最好的开发工具、最好的计算机，一定能做出优秀的软件。硬件环境只是必要条件，人才是充分条件，软件是人在一定的约束条件下创造出来的。因人因事而异。软件开发时，如果进度慢，落后于计划，可以增加更多的程序员来解决。Brook法则：当人数增加后，项目所需的工作量将不成比例的增加。因为需要增加管理、协调、通信等工作。软件的定义软件 = 程序 + 数据 + 文档软件：计算机可以接受的一系列指令，运行时可以提供所要求的功能和性能。数据：使得程序能够适当地操作信息的数据结构文档：描述程序的研制过程、方法和使用的图文资料。软件工程1968 年，第一届NATO会议：为了经济地获得可靠的且能在实际机器上有效地运行的软件，而建立和使用完善的工程原理。1993 年，IEEE/CS：将系统化的、规范的、可度量的方法应用于软件的开发、运行和维护的过程，即将工程化应用于软件中。软件工程便是对上述提到的各种方法的研究。另一个角度的看软件工程本质特性软件工程关注于大型程序的构造。软件工程的中心课题是控制复杂性主要考虑：如何分解和集成。为什么要分解： G .Miller（美国认知心理学家乔治·米勒）, “7±2 ” 原则，即短时间内人的记忆广度大约为7±2个单位。比如在记忆圆周率的时候只能记忆7±2位，超过这个范围需要分组记忆。软件经常变化开发软件的效率非常重要和谐地合作是开发软件的关键软件必须有效地支持它的用户在软件工程领域中是由具有一种文化背景的人替具有另一种文化背景的人创造产品扩展定义：软件 = 知识＋程序 + 数据 + 文档软件工程的基本原理用分阶段的生命周期计划严格管理坚持进行阶段评审实行严格的产品控制基线：基线（baseline）控制采用现代程序设计技术结果应能清楚地审查开发小组的人员应该少而精承认不断改进软件工程实践的必要性软件工程方法学软件工程包括“管理”和“技术”两方面内容：管理：对人、财、物的合理使用和配置；技术：指软件开发中采用的方法、工具和过程。软件工程方法学：通常把在软件生命周期全过程中使用的一整套技术方法的集合称为方法学（methodology），也称为范型（paradigm）。三要素软件工程过程：规定了完成各项任务的工作步骤。软件工程方法：完成软件开发的各项任务的技术方法，为软件开发提供了“如何做”的技术。如项目计划与估算、软件系统需求分析、数据结构、系统总体结构的设计、算法过程的设计、编码、测试以及维护等。软件工程工具：计算机辅助软件工程 CASE（computer Aided sottware Engineering），为软件工程方法提供自动或半自动的软件支撑环境。软件工程方法软件工程方法学思想传统方法学采用结构化技术（结构化分析、结构化设计和结构化实现）来完成软件开发的各项任务；把软件生命周期划分为若干个阶段，按顺序完成每个阶段的任务；每个阶段开始和结束都有严格的标准，对任何两个相邻的阶段而言，前一个阶段的结束标准就是后一阶段的开始标准；每一个阶段结束之前都必须进行正式严格的技术审查和管理复审优点分解任务，分工合作，降低整个软件开发工程的困难；采用科学的管理技术和良好的技术方法对每个阶段成果都进行严格的审查。保证了软件的质量。缺点把数据和操作人为地分离成两个独立的部分，增加了软件开发与维护的难度。面向对象方法学模拟人类习惯的思维方式，使开发软件的方法与过程尽可能接近人类认识世界解决问题的方法与过程，从而使描述问题的问题空间（也称为问题域）与实现解法的解空间（也称为求解域）在结构上尽可能一致。要点如下：把对象（object）作为融合了数据及在数据上的操作行为的统一的软件构件。把所有对象都划分成类（class ）。按照父类（或称为基类）与子类（或称为派生类）的关系，把若干个相关类组成一个层次结构的系统（也称为类等级）。对象彼此间仅能通过发送消息互相联系。和传统方法学的区别是：传统方法学强调自顶向下顺序地完成软件开发的各阶段任务。面向对象方法是主动地多次反复迭代的演化过程。软件生命周期软件定义时期确定软件开发工程必须完成的总目标；确定工程的可行性；导出实现工程目标应该采用的策略及系统必须完成的功能；估计完成该项工程需要的资源和成本，并且制定工程进度表。通常分为问题定义、可行性研究和需求分析三个阶段。问题定义阶段要解决的问题是什么？可行性研究阶段对于上一个阶段所确定的问题有行得通的解决办法吗？需求分析为了解决这个问题，目标系统必须做什么。用正式文档准确地记录对目标系统的需求，这份文档通常称为规格说明书（specification）。软件开发时期具体设计和实现前一个时期定义的软件，通常分为四个阶段。总体设计（概要设计）根据需求分析，设计软件的体系结构；定义结构中的组成模块。详细设计（模块设计）对每个模块要完成的工作进行具体的描述，为源程序编写打下基础。编写设计说明书，提交评审。与总体设计统称系统设计。程序编写（Coding, Programming）把软件设计转换成计算机可以接受的程序代码。软件测试（Testing）按规定的各项需求，逐项进行有效性测试，决定已开发的软件是否合格，能否交付用户使用，包括单元测试和组装测试。与程序编写统称系统实现。运行维护（软件维护）时期使软件持久的满足用户的需要，包括：改正性维护：运行中发现了软件中的错误需要修正。适应性维护：为了适应变化了的软件工作环境，需做适当变更。完善性维护：当用户有新的要求时，应该及时改进软件以满足用户的要求。预防性维护: 即修改软件为将来的维护活动预先做准备。软件过程软件过程是为了获得高质量软件所需要完成的一系列任务的框架，它规定了完成各项任务的工作步骤。软件过程描述为了开发出客户需要的软件，什么人（who）、在什么时候（when）、做什么事（what）以及怎样（how）做这些事以实现某一个特定的具体目标。通常用软件生命周期模型来描述。ISO 9000的定义：使用资源将输入转化为输出的活动所构成的系统。 “系统”是相互关联或相互作用的一组要素。软件生命周期模型指软件项目从需求定义直至软件经使用后废弃为止，跨越整个生存周期的系统开发、运作和维护所实施的全部过程、活动和任务的结构框架。瀑布模型从上一阶段接受本阶段的工作对象，作为输入；利用输入，完成本阶段活动的内容。本阶段的工作成果作为输出传入下一阶段。实际的瀑布模型增加了一个评审活动，评审每个阶段完成的活动，若得到确认，则进行下一阶段的活动；否则返回前一阶段，甚至更前阶段返工。特点阶段间具有顺序性和依赖性。推迟实现的观点。质量保证的观点。优点可强迫开发人员采用规范的方法；严格地规定了每个阶段必须提交的文档；要求每个阶段的所有产品都必须经过质量保证小组的仔细验证；缺点无法解决软件需求不明确或不准确的问题；可能导致最终开发的产品不能真正满足用户需要。瀑布模型比较适合开发需求明确的软件。快速原型模型原型是快速实现和运行的早期版本，反映最终系统部分重要特性。常见的原型实例：人机界面；系统主要功能。快速原型就是快速开发一个能用的版本再后期修改。获得用户的基本需求说明，据此快速建立一个小型软件系统。用户试用，对其评价；开发人员按照用户的意见快速地修改原型系统，获得新的原型版本，再请用户试用，如此反复，直到满足用户的要求；用户确认原型系统之后，开发人员据此书写规格说明文档，进行下一步开发。优点通常能反映用户真实需求；软件产品的开发基本上是线性顺序进行的。增量（渐增）模型把软件产品作为一系列的增量构件来设计、编码、集成和测试。每个构件由多个相互作用的模块构成，并且能够完成特定的功能。使用增量模型时，第一个阶段的增量构件往往实现软件的基本需求，提供最核心的功能；后面的增量构架逐渐添加系统的功能。注意事项增量构件规模适中；分解的约束条件是当把新构件集成到现有软件中时，所形成的产品必须是可测试的；软件体系必须是开放的，即在对现有系统添加新增量构件时，不能破坏系统原有功能。优点能在较短的时间内，提供可完成部分工作的初步产品给用户；用户有较为充裕的时间学习和适应新产品。缺点对开发人员技术能力要求较高，要求能从系统整体出发正确划分增量构件，并进行分别开发，最后能很好地集成这些构件。一种风险更大的增量模型有可能提高开发速度，但需要密切地监控整个开发过程，否则会有构件无法集成到一起的风险。螺旋模型大型软件开发面临的重要问题：软件风险，如：产品交付给用户之后，用户不满意；开发进度落后，开发成本超出预算；产品完成前关键的开发人员跳槽；在产品投人市场前，竞争对手发布了一个功能相近，价格更低的软件 …构建原型能使某些类型的风险降到最低。优点强调可选方案和约束条件，有利于已有软件的重用，也有助于把软件质量作为软件开发的一个重要目标；减少了过多测试（浪费资金）或测试不足（产品故障多）所带来的风险；维护是一个周期，与开发并没有本质区别缺点需要开发人员具有相当丰富的风险评估经验和专门知识；进行风险分析的费用可能较大。适合大型软件开发。各种模型的比较模型优点缺点瀑布模型规范，文档驱动系统可能不满足客户真正的需求快速原型克服了瀑布型的缺点增量模型开发早期回报明确，易于维护要求开放的软件体系结构螺旋模型风险驱动，适用于大型项目开发风险分析人员需要有经验且经过充分训练软件工程工具软件开发的基本策略软件复用利用已有的软件制品，直接组装或合理修改形成新的软件系统，从而提高开发效率和产品质量，降低维护成本。软件复用不仅仅是代码复用，函数库、类库、模板（文档、网页）、设计模式、组件、框架。分而治之软件工程是一项解决问题的工程活动，通过对问题进行研究分析，将一个复杂的问题分解成可以理解并能够处理的若干小问题，然后再逐个解决。逐步演进软件开发应该遵循软件的客观规律，不断进行迭代式增量开发，最终交付符合客户价值的产品。优化折中软件工程师应该把优化当成一种责任，不断改进和提升软件质量；但是优化是一个多目标的最优决策，在不可能使所有目标都得到优化时，需要进行折中实现整体最优。ISO9126 质量模型功能性适合性：当软件你在指定条件下使用，其满足明确和隐含要求功能的能力。准确性：软件提供给用户功能的精准度能不能满足要求互操作性：软件与其他系统进行交互的能力安全性：软件保护信息和数据的安全能力可靠性成熟性：软件产品避免因软件中错误开发而导致失效的能力容错性：软件防止外部接口错误扩散而导致系统失效的能力可恢复性：系统失效后，重新恢复原有功能和性能的能力易用性易理解性：软件显示的信息要清晰、准确且易懂，使用户能够快速理解软件。易学习性：软件使用户能学习其应用的能力易操作性：软件产品使用户能易于操作和控制它的能力。吸引性：软件具有的某些独特的、能让用户眼前一亮的属性。效率时间特性：在规定的条件下，软件产品执行其功能时能够提供适当的响应时间效和处理时间以及吞吐率的能力。资源利用：软件系统在完成用户指定的业务请求所消耗的系统资源，诸如CPU占有率、内存占有率、网络带宽占有率等。可维护性易分析性：软件提供辅助手段帮助开发人员定位缺陷原因并判断出修改之处。易改变性：软件产品使得指定的修改容易实现的能力。稳定性：软件产品避免由于软件修改而造成意外结果的能力。易测试性：软件提供辅助性手段帮助测试人员实现其测试意图。可移植性适应性：软件产品无需做任何相应变动就能适应不同运行环境的能力。易安装性：在平台变化后成功安装软件的难易程度共存性：软件产品在公共环境与其共享资源的其他系统共存的能力。替换性：软件系统的升级能力，包括在线升级、打补丁升级等。可行性研究的目的说明该软件开发项目的实现在技术上、经济上和社会条件上的可行性；评述为合理地达到开发目标可能选择的各种方案。用最小的代价在尽可能短的时间内确定问题是否能够并且值得解决。可行性研究最根本任务是对以后的行动方针提出建议，一般占预期工程总成本的 5%-10%。可行性研究的基本内容技术可行性：使用现有的技术能实现这个系统吗？主要考虑：开发风险；资源；相关技术的发展经济可行性：这个系统的经济效益能超过它的开发成本吗？系统经济效益 = 新系统增加的收入＋ 新系统节省的费用考虑：成本——效益分析、长期的公司经营策略、对其他单位或产品的影响、开发所需的成本和资源、潜在的市场前景操作可行性：系统的操作方式在用户组织内行得通吗？其他：法律可行性、社会效应、管理问题等技术可行性对系统的性能、可靠性、可维护性以及生产率等方面的信息进行评价。通过技术可行性的分析，将为新系统提交技术可行性评估。以指明为完成系统的功能和性能需要什么技术？需要哪些材料、方法、算法、或者过程等。技术可行性分析方法：数学模型和优化技术、概率和统计、排队论、控制论等方法。经济可行性进行成本效益分析，评估项目的开发成本。操作可行性一个地区、一个行业乃至一个国家计算机应用发展的客观道路及规律客观发展规律，各阶段是不能超越的结合实际分析本单位、本部门、本行业的实际情况，参照国内外经验教训，实事求是地规划本企业信息系统的发展。可行性研究的任务可行性研究的目的是建立目标系统的逻辑模型。通常软件软件开发项目是要实现目标系统的物理模型，即确定待开发软件系统的系统元素，并将功能和数据结构分配到这些系统元素中。它是软件实现的基础。但是目标系统的物理模型是由它的逻辑模型经实例化，即具体到某个业务领域而得到的。与物理模型不同，逻辑模型忽视机制和细节，只描述系统要完成的功能和要处理的数据。为此，该阶段的主要任务是，借助于当前系统的逻辑模型导出目标系统的逻辑模型，也就是解决目标系统“做什么”的问题。其实系统的开发过程就是根据需要解决的问题，建立一个有信息技术支撑、与解决问题相关的、数据处理的、可运行的计算机模型。具体模型到逻辑模型举例可行性研究的定义了解客户的要求及现实环境，从技术、经济和社会因素等三方面研究并论证本软件项目的可行性，编写可行性研究报告，制定初步项目开发计划。可行性分析的描述手段：系统流程图、数据流图可行性研究报告功能说明软件项目的实现在技术上、经济上和社会因素上的可行性，评述为合理地达到开发目标可供选择的各种可能的实现方案，说明并论证所选定实施方案的理由。成本／效益分析从经济角度分析开发一个特定的新系统是否划算，帮助客户负责人作出是否投资的决定。主要包括成本估计和成本效益分析。成本估计包括开发成本和运行成本开发成本代码行技术：根据经验和历史数据，估算实现一个功能需要多少源程序行数，用每行代码的平均成本乘以行数。任务分解技术：将软件开发工程分解成若干个相对独立的任务，分别估算，然后累加得出总成本。按阶段分解按功能分解自动估计成本技术：采用自动估计成本的软件工具，需要有长期搜集的大量历史数据为基础，并需要良好的数据库系统支持。运行成本取决于系统的操作费用（操作人员数、工作时间、消耗的物资等）和维护费用。需求定义需求是人们要解决的问题某个问题或达到某种目的的需要。是系统或其组成部分为满足某种书面规定（合同、标准、规范等）所要具备的能力。需求将作为系统开发、测试、验收、提交的正式文档的依据。需求的内容需求是系统为满足客户期望的目标而完成的行为需求要体现出对问题领域的清晰理解给出系统的使用场景和上下文需求定义涵盖如下内容为什么要设计此系统系统由谁使用系统要做什么系统涉及哪些信息对解决方案有什么额外补充如何使用该系统质量需要达到何种程度需求内容来源干系人：干系人是任何和系统有关的人，如：资方、客户、系统用户、领域专家、项目研发团队。识别干系人可以从以下几个方面来判别：产品谁来用、输入谁提供、输出谁要、谁监管、影响谁、奖励谁、惩罚谁。业务过程：对现有业务过程的分析有助于识别业务问题并改进找出并列举当前业务过程中的问题分析问题的本质，可能是遗漏的，可能不好用，可能有新需求分析改进的机会分析改进的实质组织规章制度：分析规章制度有益于确定业务规则和约束条件业务规则：描述对业务过程的要求，如支撑系统的业务过程的结构、控制、行为效果约束：对系统开发过程的管理限制，主要涉及经济、政治、技术和环境四个方面，具体包括项目资源、时间、目标环境级现有系统：分析现有系统有助于了解未来系统的工作数据需求分析软件需求指用户对所开发的软件在功能、性能、环境、可靠性等各方面的要求。需求分析主要回答待开发的系统必须“做什么”，并用 《 需求规格说明书 》 的形式准确、详细、规范地表达出来。需求分析阶段，系统分析员的主要关注点是“做什么（ what ) ” ，不是“怎样做（ how）”；需求分析阶段，系统分析员应该给出软件需求规格书。需求分析的任务确定对系统的综合要求分析系统的数据要求导出系统的逻辑模型修正系统开发计划确定对系统的综合要求功能需求。指定系统必须提供的服务。性能需求。指定系统必须满足的定时约束或容量约束等。可靠性和可用性需求。应定量指定。出错处理需求。指环境错误，非系统本身的错误。接口需求。常见的接口需求：用户接口需求；硬件接口需求；软件接口需求；通信接口需求。常见的约束：精度；工具和语言约束；设计约束；应该使用的标准；应该使用的硬件平台。逆向需求。指定系统不应该做什么，将来可能提出的要求。分析建模结构化分析（Structured Analysis，SA）是面向数据流进行分析的方法，主要建立以下几种模型：实体关系图（Entity-Relationship Diagram，E-R图）来创建数据模型，描述系统中所有重要的数据对象；数据流图（Data Flow Diagram，DFD）：用来创建功能模型，描述了信息流和数据转换；状态转换图（State-Transition Diagram，STD）用来创建行为模型，描述系统状态如何响应外部事件，而进行转换。面向对象分祈方法（OOA）所建立的摸型对象模型（Object model）：定义实体，描述系统的静态结构，定义“对谁做”动态模型（Dynamic model）：描述对象之间的交互过程，规定“何时做”功能模型（Functional model） ：描述内部数据的处理，指明系统应“做什么”数据词典DD 是对数据流图中包含的所有元素的定义的集合，使得每个图形元素的名字都有一个精确的、严格的定义。数据流图和词典结合在一起，能清楚地表达数据处理的要求，构成了“需求说明书”定义数据的方法举例北京某高校可用的电话号码有以下几类：校内电话号码由4位数字组成，第1位数字不是0；校外电话又分为本市电话和外地电话两类，拨校外电话需先拨0，若是本市电话则再接着拨8位数字(第1位不是0)，若是外地电话则拨3位区码再拨8位电话号码(第1位不是0)。请用定义数据字典的方法，定义上述的电话号码。电话号码 = [校内电话号码|校外电话号码]校内电话号码 = 非零数字+ 3 位数字 //后面继续定义校外电话号码 = [本市号码|外地号码]本市号码 = 数字零+8位数字外地号码 = 数字零+3位数字+8位数字非零数字 = [1|2|3|4|5|6|7|8|9]数字零＝03位数字＝3{数字}3 //3至3个数字8位数字 = 非零数字+7位数字7位数字 = 7{数字}7数字＝[0|1|2|3|4|5|6|7|8|9]DD定义数据流数据流名：说明：简要介绍作用即它产生的原因和结果。数据流来源：来自何方。数据流去向：去向何处。数据流组成：数据结构。数据量流通量：数据量，流通量数据流定义数据流：购物单别名：无简述：学生购书时填写的项目来源：学生去向：审查并开发票组成：学号+姓名+书号+数量数据流量：1000次/周高峰值：开学期间1000次/天DD定义数据元素数据元素，又叫数据项，指数据处理中最小的，不可再分的单位。描述包括：数据元素名类型：数字（离散值，连续值），文字（编码类型）长度取值范围相关的数据元素及数据结构举例数据元素名：商品编号别名：描述：唯一的描述库存库清单中一个特定商品的关键域定义：商品编号 = 8 {字符} 8位置：订货报表订货信息库存清单DD定义数据存储数据文件名：简述：存放的是什么数据输入数据：输出数据：数据文件组成：数据结构存储方式：顺序，直接，关键码存取频率：举例数据文件名：库存记录别名：无简述：存放库存所有可供货物的信息组成：货物名称+编号+生产厂家+单价+库存量组织方式：索引文件，以货物编号为关键字查询要求：要求能立即查询DD定义数据处理处理名编号：DFD中的编号激活条件处理逻辑：此处理的子项执行频率例子数据处理名：登记报名单编号：1激活条件：收到报告单数据处理组成：1.1：检查报告单1.2：编准考证号1.3：登记考生执行频率：2000次/日软件设计的目标软件需求：解决“做什么”。软件设计：解决“怎么做”。软件设计的任务：以软件需求规格说明书为依据，着手实现软件的需求，并将设计的结果反映在“设计规格说明书”文档中。软件设计的重要性：是软件开发阶段的第一步，最终影响软件实现的成败和软件维护的难易程度。软件设计的两个阶段第一阶段：概要设计（总体设计）根据软件需求，设计软件系统结构和数据结构，确定程序的组成模块及模块之间的相互关系。回答“概括地说，系统应该如何实现？”。其重要性是：站在全局高度，从较抽象的层次上分析对比多种可能的系统实现方案和软件结构，从中选出最佳方案和最合理的软件结构，从而用较低成本开发出较高质量的软件系统。第二阶段：详细设计（过程设计）确定模块内部的算法和数据结构；选定某种过程的表达形式来描述各种算法；产生精确描述各模块程序过程的详细文档，并进行评审。SA和SD概要设计的任务制定规范：为软件开发小组制定在进行软件设计，应该共同遵守的标准，以便协调组内各员的工作。设计软件系统结构（简称软件结构）将系统按功能划分成模块确定每个模块的功能确定模块之间的调用关系确定模块之间的接口，即模块之间传递的信息评价模块结构的质量处理方式设计功能设计：确定实现功能法，评估算法的性能．性能设计：确定实现性能需求必须的算法和模块间的控制方式数据结构及数据库设计可靠性设计编写概要设计文档概要设计评审软件设计的过程软件设计的原理模块化采取自顶向下的方式，逐层把软件系统划分成若干可单独命名和可编址的部分，即“ 模块” ，每个模块完成一个特定的子功能；所有模块按某种方法组成一个整体，完成整个系统所要求的功能。软件系统就是通过这些模块的组合来实现。模块化是在逻辑和无理上将整个系统分解成多个更小的部分，其实质是“分而治之”，即将一个复杂问题分解成若干个简单问题，然后再逐个解决。自顶向下，逐步求精的基本思想将功能、信息的说明分为多个层次，最高层也最抽象 ― 仅仅只是概念性地描述功能或信息，不提供功能的内部工作情况或信息的内部结构；设计者从最高层开始，仔细推敲，进行功能和信息的细化，给出下层实现的细节；随着每个后续细化逐步的完成，提供越来越多的细节，最终得出用程序设计语言表达的程序。模块独立系统分解的目标：高内聚、低耦合。内聚性是一个模块或子系统内部的依赖程度。如果一个模块或子系统含有许多彼此相关的元素，并且它们执行类似任务，那么其内聚性比较高；如果一个模块或子系统含有许多彼此不相关的元素，其内聚性就比较低。耦合性是两个模块或子系统之间依赖关系的强度。如果两个模块或 子系统是松散耦合的，二者相互独立，那么当其中一个发生变化时对另一个产生的影响就很小；如果两个模块或子系统是紧密耦合的，其中一个发生变化就可能对另一个产生较大影响。耦合性也称块间的联系。是对软件系统结构中，各模块间相互联系紧密程度的一种度量。无直接藕合两个模块没有直接关系，模块独立性最强。数据耦合属松散耦合。一模块访问另一模块时，通过数据参数交换输入、输出信息。控制藕合模块之间传递的是控制信息（如开关、标志、名字等），控制被调用模块的内部逻辑。特征耦合两个模块通过传递数据结构加以联系，或都与一个数据结构有关系，则称这两个模块间存在特征耦合。可能出现的情况：当把整个数据结构作为参数传递时，被调用的模块虽然只需要使用其中的一部分数据元素，但实际可以使用的数据多于它真正需要的数据，这将导致对数据访问失去控制。“住户情况”是一个数据结构，图中模块都与此数据结构有关。“计算水费”和“计算电费”本无关，由于引用了此数据结构产生依赖关系。公共环境耦合一组模块引用同一个公用数据区（也称全局数据区、公共数据环境）。公共数据区指：全局数据结构。共享通讯区。内存公共覆盖区等公共耦合存在的问题：软件可理解性降低诊断错误困难软件可维护性差软件可靠性差内容耦合有下列情况之一的。是最不好的耦合形式！控制耦合改为数据耦合将被调用模块内的判定上移到调用模块中进行被调用模块分解成若干单一功能模块特征耦合修改为数据耦合内聚性巧合内聚块内各组成成份在功能上是互不相关的。逻辑内聚把几种相关功能（逻辑上相似的功能）组合在一模块内，每次调用由传给模块的参数确定执行哪种功能。时间内聚模块完成的功能必须在同一时间内执行，这些功能只因时间因素关联在一起。如：]初始化系统模块系统结束模块、紧急故障处理模块等过程内聚模块内各处理成分相关，且必须以特定次序执行。通信内聚模块内各部分使用相同的输入数据，或产生相同的输出结果。顺序内聚模块完成多个功能，各功能都在同一数据结构上操作，每一功能有唯一入口。功能内聚模块仅包括为完成某个功能所必须的所有成分。模块所有成分共同完成一个功能，缺一不可。启发规则改进软件结构，提高模块独立性：通过模块分解或合并，降低耦合提高内聚模块规模适中：在考虑模块的独立性同时，为了增加可理解性，模块的大小最好在 50-150 条语句左右，可以用 1-2 页打印纸打印，便于人们阅读与研究。模块过大：可理解程度下降模块过小：开销大于有效操作系统接口复杂深度、宽度、扇出和扇入适中将模块的影响限制在控制范围内：使任一模块的作用域在其控制域内作用域是指受模块内一个判定影响的所有模块的集合控制域是指这个模块本身及其所有的下属模块的集合模块 C 的控制范围： C 、 D 、 E 、 F 、 G 、 H 。如果模块 C 作出的决策影响了模块 L ，L超出了 C 的控制范围降低模块接口的复杂性：接口传递信息应简单且和模块功能一致。模块的接口要简单、清晰、含义明确，便于理解，易于实现、测试与维护。设计单入口单出口的模块：不要使模块间出现内容耦合。模块功能可预测：如果一个模块可以当作一个黑盒子，相同输入产生相同输出，其功能为可预测的。若模块带有内部“存储器”，其功能可能是不可预测的，难理解、难测试、难维护。单一的模块具有高内聚。但模块功能过分局限，可使用范围将过分狭窄，缺乏灵活性和扩充性。描绘软件结构的图形具层次图和 HIPO 图描述软件的层次结构。层次图中，一个方框代表一个模块，方框间的连线表示调用关系。 HIPO图=层次图+ IPO 图结构图…结构程序设计经典定义：如果一个程序的代码块仅仅通过顺序、选择和循环这 3 种基本控制结构进行连接，而且每个代码块只有一个入口和一个出口，则称这个程序是结构化的。比较全面的定义：结构程序设计是尽可能少用 GOTO 语句的程序设计方法，最好仅仅在检测出错误时才使用 GOTO 语句，而且应该总是使用前向的 GOTO 语句。SP主要原则使用语言中的顺序、选择、重复等有限的基本控制结构表示程序逻辑。选用的控制结构只准许有一个入口和一个出口。复杂结构应该用基本控制结构进行组合嵌套来实现。严格控制 GOTO 语句，仅在下列情形才可使用。用一个非结构化的程序设计语言去实现一个结构化的构造。在某种可以改善而不是损害程序可读性的情况下。五种基本的结构化控制结构控制流图符号“ O ”为程序图的结点，表示一个或多个无分支的语句；箭头为边，表示控制流的方向。边和结点圈定的封闭范围叫做区域。程序图的基本元素从图论的观点看，它是一个可以用 G = &lt; N , E ＞来表示的有向图。其中：N一结点；E一有向边，指明程序的流程；包含条件的结点称为判定结点；环路复杂性V ( G ) ＝流图中区域数（包括图外区域）V ( G ) ＝判定结点数＋ 1V ( G )= E - N + 2编码选择程序设计语言从软件工程的角度，根据程序设计语言发展的历程，大致分为 4 类：第一代语言：从属于机器的语言第二代语言：汇编语言第三代语言：高级程序设计语言第四代语言（4GL）编码风格编码风格是指一个人编制程序时所表现出来的特点、习惯、逻辑思路等。良好编码风格包括：程序内部应该有很好的文档：如标识符、注释良好，程序文档结构易读易理解。数据说明应易于理解和维护语句结构尽可能简单直观输入输出风格遵守人机界面设计准则效率满足用户需求即可软件测试的基础什么是软件测试？是为了发现错误而执行程序的过程。发现错误是为了更正错误，最终得到一个高质量的软件系统。软件测试的对象：整个软件定义、开发周期的产品测试用例：通常指测试数据和预期的输出结果软件测试存在的矛盾用户希望通过软件测试暴露软件中隐藏的错误和缺陷，以考虑是否可接受该产品。软件开发者希望通过软件测试表明软件产品中不存在错误，已正确地实现了用户的要求。软件测试目的测试是为了发现错误而执行程序的过程好的测试用例是极可能发现至今为止尚未发现的错误的测试方案；成功的测试是发现了至今未发现的错误的测试总之，测试的目的是以最少的时间和人力，系统地找出软件中潜在的各种错误和缺陷；测试附带的收获是它能证明软件的功能和性能与需求说明相符合。注意：测试不能表明软件中不存在错误，它只能说明软件中存在错误。软件测试的准则所有测试都能追溯到用户需求应该远在测试开始之前就制定出测试计划应该把 Pareto原理应用到软件测试中群集现象： 80 ％的错误可能是由 20 ％的模块造成的从“小规模”测试开始，逐步过渡到“大规模”测试穷举测试是不可能的测试只能证明程序有错，不能证明程序没有错误应由独立的第三方从事测试工作测试步骤单元（模块）测试：检查各各程序模块是否有错误，能发现编码和详细设计的错误。集成测试（子系统和系统测试）：测试模块（子系统）接口，发现软件设计和需求说明的错误。确认（验收）测试：检查软件是否满足用户的需要以及文档资料是否完整、准确平行运行：同时运行新、旧系统单元测试模块接口测试在单元测试的开始，应对通过被测模块的数据流进行测试。测试项目：调用本模块的输入参数是否正确；本模块调用子模块时，输入给子模块的参数是否正确；输出给标准函数的参数是否正确；全局量的定义和用法在各摸块中是否一致；与外部设备的输入输出是否正确局部数据结构测试测试项目：不正确或不一致的数据类型说明使用尚未赋值或尚未初始化的变量错误的初始值或错误的缺省值变量名拼写错或书写错不一致的数据类型全局数据对模块的影响重要的执行通路测试白盒测试错误处理测试着重测试以下可能发生的错误：出错的措述是否难以理解出错的描述是否能够对错误定位显示的错误与实际的错误是否相符对错误条件的处理正确与否在对错误进行处理之前，错误条件是否已经引起系统的干预等边界测试重点检查刚好等于、大于或小于边界值的数据;对运行时间有要求的模块，还要专门进行关键路径测试，以确定最坏情况下和平均意义下影响模块运行时间的因素。代码审查人工测试源程序。参与者：程序的设计者、编写者、测试者没有直接参与系统开发，但有力的程序员。方法：研究设计说明书，一起审查程序代码如何实现设计，从中发现问题。注意：通常代码审查和机器测试结合使用。计算机测试单元测试通常在编码阶段进行。常用机器测试，即通过运行模块发现问题。两个重要概念：驱动程序（ driver ) ：相当于被测试模块的“主程序”，接收测试数据，把这些数据传送给被测试的模块，并且输出相关结果。存根程序（stub）：代替被测试模块所调用的模块。不需要具有子模块所有功能，但不允许什么事情也不做。集成测试在单元测试之后，将模块组装成系统，为发现并排除模块在连接中可能出现的问题，而进行的测试。需要考虑：模块连接时穿越模块接口的数据是否会 丢失；一个模块对另一个模块是否会产生不利的影响；各子功能组合起来，能 否达到预期要求的父功能全局数据结构是否有问题；单个模块的误差累积起来，是 否会放大至不能接受的程度。集成测试的两种方式非渐增式组装方式对每个模块分别进行单元测试，再把所有模块组装成一个完整的系统进行的测试，从而得到要求的软件系统。渐增式组装方式先对模块进行单元测试，然后将测试后的模块逐步组装成较大的系统；在组装的过程中边连接边测试，以发现连接过程中产生的问题；最后组装成为要求的软件系统。自顶向下的渐增方式将模块按系统程序结构，沿控制层次自顶向下进行组装。不需要驱动模块，需要存根模块自底向上结合的渐增方式从程序模块结构最底层的模块开始组装和测试。不再需要存根程序，需要驱动模块。组合策略：把低层模块组合成实现某个特定的软件子功能的族；用驱动程序协调测试数据的输入和输出;对由模块组成的子功能族进行测试;去掉驱动程序，没软件结构自下向上移动，把子功能族组合起来形成更大的子功能族。混合渐增测试衍变的自顶向下的增殖测试：先对输入／输出模块和引入新算法模块进行测试；再自底向上组装成为功能相当完整且相对独立的子系统；然后由主模块开始自顶向下进行增殖测试。自底向上 - 自顶向下的增殖测试：先对含读操作的子系统自底向上直至根结点模块进行组装和测试；再对含写操作的子系统做自顶向下的组装与测试。确认测试又称有效性测试。验证软件的功能、性能及其它特性是否与用户的要求一致。确认测试的基础 ：软件需求规格说明书确认测试的主要工作：有效性测试与软件配置审查主要参与人员：以用户为主确认测试范围通常采用黑盒测试，验证被测软件是否满足用户需求。测试计划：包括测试种类及进度安排；测试步骤：描述具体的测试用例测试目的：确定软件的特性是否与需求相符；所有的文档都是正确且便于使用；其它软件需求。测试结果：与预期的结果相符；与预期的结果不符：要提交一份问题报告。软件配置复查目的：保证软件配置的所有成分都齐全；各方面的质量都符合要求；具有维护阶段所必需的细节；而且已经编排好分类的目录。应当严格遵守用户手册和操作手册中规定的使用步骤，以便检查这些文档资料的完整性和正确性。α测试和β测试α测试：由用户在开发环境下进行的测试。主要评价软件产品的:FLURPS(即功能、局域化、可使用性、可靠性、性能和支持）β测试：由最终用户在实际使用环境下进行的测试，这些用户定期返回有关错误信息给开发者。注意：只有当α测试达到一定的可靠程度时，才开始β测试。自盒测试技术白盒测试执行的要求：对程序模块的所有独立的执行路径至少测试一次对所有的逻辑判定，取“真”与取“假”的两种情况都至少测试一次；在循环的边界和运行界限内执行循环体；测试内部数据结构的有效性。逻辑覆盖语句覆盖使得每一可执行语句至少执行一次。判定覆盖运行被测程序，使得程序中每个判断的取真分支和取假分支至少经历一次。条件覆盖使得程序中每个判断的每个条件的可能取值至少执行一次。判定一条件覆盖使得判断中每个条件的所有可能取值至少执行一次，每个判断中的每个分支至少执行一次。即同时满足判断覆盖和条件覆盖。条件组合覆盖使得每个判断的所有可能的条件取值组合至少执行一次。点覆盖如果连通图G的子图G′是连通的，而且包含G的所有结点，则称G′是G的点覆盖。点覆盖标准和语句覆盖标准是相同的。边覆盖要求选取足够多测试数据，使得程序执行路径至少经过流图中每条边一次。通常边覆盖和判定覆盖是一致的。路径覆盖覆盖程序中所有可能的路径。控制结构测试基本路径测试以环形复杂度为基础，导出基本可执行路径集合，设计测试用例的方法。测试用例要保证程序的每个可执行语句至少执行一次。步骤由程序流程图导出程序控制流图，并计算其环路复杂度：确定程序的独立路径什么是独立路径？流图中，一条独立路径是至少包含一条在其它独立路径中从未有过的边的路径。独立路径条数是确保程序中，每个可执行语句至少能被执行一次所必需的测试用例数目的上界。独立路径条数＝程序环路复杂性 V ( G )黑盒测试技术黑盒测试主要是为了发现以下错误：是否有不正确或遗漏了的功能？能否正确地接受输入？能否正确的输出结果？是否有数据结构错误或外部数据库访问错误？性能上是否能够满足要求？是否有初始化或终止性错误？几种黑盒测试技术：等价类划分边界值分析错误推测法因果图等价划分把所有可能的输入数据（包括有效或无效的），划分成若干数据类（等价类），然后从每个数据类中选取少数有代表性的数据做为测试用例。这种方法完全不考虑程序的内部结构，只依据程序的规格说明来设计测试用例。步骤1：划分等价类等价类是指输入数据的子集合。在该子集合中，各输入数据对于发现程序中的错误都是等效的。根据程序功能说明，确定有效和无效的等价类等价类划分原则若规定了取值范围，或输入值的个数，则可以确立一个有效等价类和两个无效等价类。如果规定了输入数据的一组值，而且程序要对每种输入数据分别处理，则可为每种输入值确立一个有效等价类，此外针对这组值确立一个无效等价类，它是所有不允许的输入值的集合。若规定了输入值的集合，或者是规定了“必须如何”的条件，则可确立一个有效等价类和一个无效等价类。如果规定输入数据为整型，则可划分出正整、零和负整数三个有效类，其他数据为无效类如果程序处理对象是表格，则应使用空表、含一项和多项的表。如果确知，已划分的等价类中各元素在程序中的处理方式不同，则应将此等价类进一步划分成更小的等价类。步骤2：根据等价类设计测试用例在确立了等价类之后，建立等价类表，列出所有划分出的等价类。测试用例的选择原则为每一个等价类规定一个唯一编号；设计一个新的测试用例，使其尽可能多地覆盖尚未被覆盖的有效等价类，重复这一步，直到所有的有效等价类都被覆盖为止；设计一个新的测试用例，使其仅覆盖一个尚未被覆盖的无效等价类，重复这一步，直到所有的无效等价类都被覆盖为止。某报表处理系统系统规定日期由年、月的 6 位数字字符组成，前 4 位代表年，后两位代表月。设日期限制在 1990 年 1 月至 1999 年 12 月，即系统只能对该段时期内的报表进行处理。如果用户输入的日期不在此范围内，则显示输入错误。现用等价类划分法设计测试用例，来测试程序的“日期检查功能”。为合理等价类设计测试用例不合理等价类设计测试用例边界值分析边界是指，对于输入和输出等价类而言，稍高和稍低于其边界值的一些特定情况。经验得知，大量的错误是发生在输入或输出范围的边界上，而不是在输入范围的内部。边界值分析方法思想：确定边界之后，选取正好等于、刚刚大于或刚刚小于边界的值做为测试数据，而不是选取等价类中典型值或任意值做为测试数据。通常总是与等价划分技术联合使用，是等价划分方法的补充。假设一个数据库产品规范要求该产品能够处理从1到1000中间的任何数量的记录。请首先为其划分等价类，并利用等价类划分和边界值分析技术为其设计测试用例，并说明每个测试用例属于某等价类成员还是属于边界值或是邻接边界值。等价类等价类1：少于1个记录等价类2：1到1000个记录等价类3：多于1000个记录测试用例测试用例1：0个记录 //等价类1成员且邻接边界值测试用例2：1个记录 //边界值测试用例3：2个记录 //邻接边界值测试用例4：100个记录 //等价类2的成员测试用例5：999个记录 //邻接边界值测试用例6：1000个记录 //边界值测试用例7：1001个记录 //等价类3成员且邻接边界值因果图因果图是借助图形来设计测试用例的一种系统方法。它适用于被测程序具有多种输入条件，程序的输出又依赖于输入条件的各种组合的情况。因果图是一种简化了的逻辑图，它能直观地表明程序输入条件（原因）和输出动作（结果）之间的相互关系。利用因果图产生测试用例的基本步骤分析软件规格说明书中，哪些是原因（即输入条件或输入条件的等价类），哪些是结果（即输出条件）并给每个原因和结果赋予一个标识。分析软件规格说明书中所描述的语义，找出原因与结果之间、原因与原因之间对应的是什么关系？根据这些关系画出因果图。由于语法或环境的限制，有些原因与原因之间、原因与结果之间的组合情况不可能出现。为表明这些特殊情况，在因果图上用一些记号标明约束或限制条件。把因果图转换为判断表把判断表的每一列拿出来作为依据，设计测试用例。在因果图中出现的基本符号通常在因果图中用 Ci 来表示原因，用Ei表示结果其基本符号如下图所示。其中各结点表示状态，可取值为 “0”或“1”。“0”表示某状态不出现，“1”表示某状态出现。主要的原因和结果之间的关系如下:恒等：表示原因与结果之间是一对一的对应关系。若原因出现，则结果出现。若原因不出现，则结果也不出现。非：表示原因与结果之间的一种否定关系。若原因出现，则结果不出现。若原因不出现，反而结果出现。或：表示若几个原因中有一个出现，则结果出现，而当这几个原因都不出现时，结果才不出现。与：表示若几个原因都出现，则结果才出现若几个原因中有一个不出现，结果就不出现。例设有一个处理单价为5角钱饮料自动售货机其规格说明为，若投入5角钱或1元钱的硬币 ，再按下橙汁或啤酒按钮，则相应的饮料就送出来；若售货机 没有零钱找，则一个显示零钱已找完的红灯亮，这时在投入1元硬币并按下按钮后，饮料不送出来而且1元硬币也退出来;若有零钱找，则应显示零钱找完的红灯灭， 在送出饮料的同时退还5角硬币。序号原因序号结果1售货机有零钱找2.1售货机零钱找完灯亮2投入1元硬币2.2退还1元硬币3投入5角硬币2.3退还5角硬币4按下橙汁按钮2.4送出橙汁饮料5按下啤酒按钮2.5送出啤酒饮料序号中间结点11投入1元硬币且按下饮料按钮12按下橙汁或啤酒的按钮13应当找5角零钱并且售货机有零钱找14钱已付请软件维护的定义软件维护是指在软件运行或维护阶段对软件产品所进行的修改。分为四类：改正性维护在软件交付使用后，由于开发时测试得不彻底或不完全，在运行阶段会暴露一些开发时未能测试出来的错误。为了识别和纠正软件错误，改正软件性能上的缺陷，避免实施中的错误使用，应当进行的诊断和改正错误的过程，这就是改正性维护。适应性维护随着计算机技术的飞速发展和更新换代，软件系统所需的外部环境或数据环境可能会更新和升级。为了使软件系统适应这种变化，需要对软件进行相应的修改，这种维护活动称为适应性维护。扩充与完善性维护在软件的使用过程中，用户往往会对软件提出新的功能与性能要求。为了满足这些要求，需要修改或再开发软件，以扩充软件功能、增强软件性能、改进加工效率、提高软件的可维护性。这种情况下进行的维护活动叫做完善性维护。预防性维护采用先进的软件工程方法，对需要维护的软件或软件中的某一部分重新进行设计、编制和测试。软件的可维护性指纠正软件系统出现的错误和缺陷，以及为满足新的要求进行修改、扩充或压缩的容易程度。衡量软件质量的几个主要质量特性：可理解性：人们通过阅读源代码和相关文档，了解程序功能及其如何运行的容易程度。可靠性：表明一个程序按照用户的要求和设计目标，在给定的一段时间内正确执行的概率。可测试性：表明诊断和测试的容易程度。可修改性：表明程序容易修改的程度。可移植性：表明把程序从一种计算环境转移到另一种计算环境的难易程度。可重用性：指同一个软件（或软件成份）不做修改或稍加改动，就可以在不同环境中多次重复使用。软件再工程过程预防性维护也称为软件再工程逆向工程软件的逆向工程是分析程序，力图在比源代码更高的抽象层次上建立程序表示的过程，是一个设计恢复的过程，逆向工程工具可以从已有的程序中抽取数据结构、体系结构和程序设计信息。正向工程应用现代软件工程的概念、原理、技术和方法，重新开发现有的某个应用系统。软件再工程软件再工程是一个工程过程，它将逆向工程、重构和正向工程组合起来，旨在对现存的大量软件系统进行挖掘、整理，重新获得设计信息，用这些信息改建或重构现有的系统，以改进它的综合质量；或者得到有用的软件构件，对已有软件构件进行维护以延长其生存期。再工程的基础是系统理解，包括对运行系统、源代码、设计、分析、文档等的全面理解。但在很多情况下，由于各类文档的丢失，只能对源代码进行理解，即程序理解。典型的软件再工程过程模型定义了库存目录分析、文档重构、逆向工程、代码重构、数据重构和正向工程6类活动。]]></content>
      <categories>
        <category>软件项目管理</category>
      </categories>
      <tags>
        <tag>软件项目管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运输层]]></title>
    <url>%2F2019%2F%E8%BF%90%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[网络层完成了“主机到主机”的通信，但主机间的通信并不是最后的结果，产生和消耗数据的并不是主机，而是某项网络应用，真正通信的是两个应用“进程”。“进程”就是“正在进行的程序”。而“进程到进程的通信”正是传输层的功能。但这不是全部，更重要的，传输层的任务是为从源主机到目的主机提供可靠的，低价格的数据传输。可靠性，低价格是两个关键词，或者为了更明显一些，可以有第三个关键词，拥塞控制。其实可靠性与拥塞控制本质上是一个词。可靠性、低价格、拥塞控制使传输层成为整个协议体系的核心与灵魂。如果没有传输层，就没有可靠的数据传输，网络层也将失去意义。传输服务传输层的服务与网络层服务很相似，为何要分为两个层呢？答案就是“可靠性”。网络层并不提供可靠性，路由器可以丢失分组，用户无法控制中间的网络设备，用户不能选择性能更好的路由器或质量更好的数据链路，那么如何保证数据可以正常传输呢？添加一个传输层，传输层应该检测到各种问题，并采取补救措施，从而提供可靠的数据传输。传输层就是要弥补网络层技术、设计的各种缺陷。用个不恰当的比方，传输层就是“填坑的”，将网络层与应用层之间的坑、沟填平。传输层服务前，是遍布坑、沟的公路，传输层服务后，是平坦的公路。再谈谈“低价格”这个关键词。如果在设计网络时，由网络层提供可靠性，会如何呢？如果由网络层提供可靠性，就要在中间网络的千万个路由器上添加可靠性的功能，系统的复杂性会提高数据传输的成本，那就与电话通信网的成本差别不大。可靠性由通信网提供还是由端计算机提供，二者的价格差别可太大了。可靠性由端计算机提供，才有了低成本的数据传输，低价格才是计算机网络将其他通信技术淘汰的本质。要低价格，可靠性就要放置在端计算机内部。显然放置在操作系统内部更加合理，直接由操作系统对应用程序提供可靠的数据传输服务，是非常自然的选择。传输层封装在端计算机的操作系统内，用个不恰当的比方，如同封装在房间内的电线，在装修时已经埋好了，只是提供了许多插座，这个插座接洗衣机，那个插座接冰箱，那个插座接电视，等等。对计算机网络来说，“可靠性”的关键是什么？或者反过来，造成数据传输不可靠的最主要的原因是什么？是网络拥塞，当网络拥塞时，路由器就会丢弃数据包。传输层需要具有“调控网络”的功能。我们说，传输层在端主机内，而端主机是无法控制中间的网络设备的，“调控网络”从何谈起呢？后面会说到网络拥塞如同现实生活的堵车，根本的解决办法是不让车上路，所有的车都不上路，路就不堵了。“调控网络”是说所有端计算机内的传输层要能感知到网络的状态，能感知到当前通信网的态势，网络拥塞，就少发数据，网络通畅，就多发数据。尤其是网络拥塞时，要少发数据，让中间网络尽快恢复传输能力。端口最常用的进程到进程的通信方式是客户机与服务器模式。我们这里说的客户机与服务器都是指一个应用进程，而不是机器。客户机，请求服务，主动发起呼叫的进程。服务器，提供服务，被动等待的进程。总是客户机呼叫服务器，绝不可能是服务器呼叫客户机。在生活中，总是你给消防队打电话，绝不可能是消防队给你打电话。某一项服务，就是一项网络应用。端主机完全可以同时有多项网络应用，如同时打开浏览器浏览网页，打开 QQ 聊天。标识不同的网络应用进程的标识符称为协议端口号 (protocol port number)，简称为端口 (port)。端口是一个 16 位的标识符。客户机用一个临时端口号定义自己。客户机可以随机选择一个端口号使用。服务器也需要用一个端口号来定义自己，但是服务器不能随机选用一个端口号。为什么呢？假设消防队随机使用一个电话号码，当发生火灾时，人们向哪打电话呢？服务器必须使用一个预先定义的，众所周知的端口号，就如同消防队使用119，急救中心使用 120 一样。端口范围划分熟知端口，端口号范围是 0~1023。由 ICANN 分配和控制。注册端口，端口号范围是 1024~49151，ICANN 不分配也不控制，但必须在 ICANN 登记以防止重复。通常为没有熟知端口号的应用程序使用的。动态端口，端口号范围是 49152~65535，这范围的端口号即不用指派，也不需注册，可以由任何进程使用。最初的建议是客户机使用的临时端口号应该在这个范围，但许多程序员可没有遵守这个建议。注意：端口号只具有本地意义，只是为了标志本计算机应用层中的各进程。复用与分用某台主机中可能有多个应用进程同时分别和网络上的许多其他主机中的某个或多个应用进程通信。这表明运输层有一个很重要的功能：复用（multiplexing）和分用（demultiplexing）。当一个实体接受来自多个源的输入时，就称为复用（multiplexing） （多到一）。而当一个实体将数据交到多个源时，就称为分用（demultiplexing）（一到多）。UDP用户数据报协议 UDP（User Datagram Protocol）是无连接不可靠的传输层协议。它只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和校验和的功能。校验和功能是可选的，如果不选择校验功能，就全填入 0。UDP 缺点是不可靠，优点是开销小。发送数据之前不需要建立连接。这对某些实时应用是很重要的。网络出现拥塞时，不调整，不降低发送速率。UDP 用户数据报首部如下图：源端口和目的端口号，各占 16 位，标志应用进程，总长度为 UDP 的总长度，UDP 首部加 UDP 数据的长度，校验和计算下面介绍。### 校验和UDP 的校验和功能是可选的，如果不选择校验和功能，就全填入 0，否则，计算校验和。计算时包含三个部分，伪首部，首部，数据部分，注意计算校验和是包含了数据部分的。如下图：#### 计算 UDP 检验和的例子二进制反码计算规则：0 + 0 = 10；0 + 1 = 1； 1 + 1 = 0TCPTCP格式一个 TCP 报文段分为首部和数据两部分，首部的前 20 个字节是固定的，后面有 4n 字节是根据需要而增加的选项 (n 是整数)。因此 TCP 首部的最小长度是 20 字节。而 TCP 的全部功能都体现在它首部中各字段的作用：- 源端口和目的端口字段：各占 2 字节。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。- 序号字段：占 4 字节。TCP 连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。- 确认号字段：占 4 字节，是期望收到对方的下一个报文段的数据的第一个字节的序号。- 窗口字段：占 2 字节，用来让对方设置发送窗口的依据，单位为字节。- 数据偏移（即首部长度）：占 4 位，它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。- 保留：占 6 位，保留为今后使用。- 控制：占 6 位，定义了 6 种不同的控制位或标志。在同一时间可设置位或多位标志位。分别是 URG、ACK、PSH、RST、SYN、FIN。- 检验和：占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部。- 紧急指针字段：占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。- 选项字段：长度可变。TCP 最初只规定了一种选项，即最大报文段长度 MSS。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节。”### 差错控制TCP 是可靠的传输层协议。就是说 TCP 向应用层交付的是按顺序的，没有差错的，没有丢失的数据。TCP 通过 3 种机制进行差错控制：检验和，确认与超时。#### 检验和TCP 规定每个报文段都必须使用 16 位的检验和。TCP 检验计算时包含三个部分，伪首部，首部，数据部分，注意计算校验和是包含了数据部分的。计算方 法同 UDP 一样。#### 确认和超时TCP 采用确认的方式来证实收到报文。接收方可以在合适的时候单独发送确 认报文，也可以在自己有数据要发送时把确认信息捎带上。TCP 使用肯定的累积确认。先解释“肯定”，ACK 就是“肯定”的意思。就是只在正确的情况下才发送确认。当发生丢弃，丢失，重复这些错误时，就什么也不做。“报喜不报忧”，注意，当发生错误时，不发送确认。这样，对方收不到确认，重传定时器就会超时，触发重传。 再解释“累积”，就是表示的累积效果，确认号字段值表示的是希望接收的下一个字节的序号。例如确认号为 301，是表示 301 号字节之前的数据都正确接收了，希望接收的下一个字节是 301 号字节。#### 重传定时器差错控制的核心就是重传机制。TCP 使用确认-超时重传机制。具体说，TCP 每发送一个报文段，就设置一个重传定时器，当重传时间到，但还没有收到确认，就要重传这一报文段。重传定时器的值怎么设是 TCP 最复杂的事情之一。后面我们会解释原因，现在我们只要知道，重传定时器的值的估算要尽可能的准确，定时器的值不像加班费，越大越好，也不是越小越好，是越准确越好。首先，很自然的想法，重传定时器的值应该是“一个往返时延再多一点”。“一个往返时延”如何确定？举例，8 点测了一次往返时延，8:05 又测一次，间隔 5 分钟，测了 10 次，往返时延应该用哪次测量的值呢？显然，用哪一次的也不合适，应该是某种“平均值”。下面介绍的这个算法的目标是使估计值更加“平滑”，我们将往返时延估计值记作 RTTs。这个算法中，历史的累积效应权重更大一些，占比 7/8，新测量值的权重小，占比1/8。下图是 RTT 样本与 RTT 估计值示意图，蓝色的是各次的测量值，红色的是RTT 的估计值。说完“一个往返时延”，再说“多一点”。这一点Δ怎么算呢？取样本值到平滑线的距离为Δ，|RTTs-新样本|，显然，每个样本点到平滑线都有一个Δ，就是Δ1，Δ2，Δ3，Δ4，···，取哪个Δ合适呢？显然，用哪一个Δ也不合适，还应该是某种“平均值”。算法也是给出一种“平滑平均值”，记作 RTTD。这个算法中，历史的累积效应权重更大一些，占比 3/4，新测量值的权重小，占比 1/4。总的RTO计算公式：$RTO=RTTs + 4 \ast RTTD$### 流量控制TCP 是全双工通信，TCP 为每个方向的数据传输使用两个窗口，发送窗口和接收窗口。双向通信就有四个窗口，为简化讨论，只讨论单向数据传输。#### 发送窗口下图是一发送窗口例子，TCP 中的窗口以字节为单位。TCP 的传输实际是一个一个的报文段，但控制窗口的变量是以字节为单位。TCP 中只使用一个重传计时器。为方便说明，字节编号取得很小。发送窗口的后沿（left wall）只能向前移动（关闭 closes），前沿可向前移动（opens），也可收缩（shrinks），但 TCP 标准不赞成收缩。接收窗口下图是一接收窗口例子。实际上，接收窗口永远不会收缩。通常，接收方 TCP 等待应用进程来取数据。就是说，分配给接收方的缓存可能包含已接收且确认的数据字节，它们在正等待应用进程将它们拉走。接收窗口总是小于缓冲区的大小。接收窗口通常称为 rwnd，rwnd = 缓冲区大小 – 正在等待被拉走的字节数，如下图：rwnd = 40 。#### 窗口如何滑动TCP 通过滑动窗口机制实现流量控制。我们先忽略差错、拥塞等其他因素，且只简化讨论一个方向的数据传输。下图描述了一个例子，总是客户端发送数据，服务器确认。客户端是发送方，发送窗口，使用序号字段，服务器是接收方，接收窗口，使用确认号和窗口两个字段，窗口字段值是 rwnd 的值。假设发送方的缓冲区与接收方的缓冲区大小都是 800 字节。1. 第 1 个报文段，客户端发给服务器，SYN 报文段，seq=100。三次握手建立连接的第一个报文，请求连接，并通告初始序号是 seq=100。2. 第 2 个报文段，服务器发给客户端，SYN+ACK 报文段，ack=101，rwnd=800。三次握手建立连接的第二个报文，窗口值通告 rwnd=800。3. 第3个报文段，客户端发给服务器，ACK报文段。客户端通告rwnd=2000，表示客户端的接收缓冲区的大小，我们忽略这个值，只讨论单向传输。3. 第 4 个报文段，客户端发给服务器，数据报文段，seq=101。客户端发送一数据报文段，携带 200 字节数据，数据字节编号 101~300，序号字段填写第 1个数据字节的编号 seq=101。发送窗口前沿在 901，后沿在 101，显示已发送 200字节数据，正等待确认。4. 第 5 个报文段，服务器发给客户端，ACK 报文段，ack=301，rwnd=600。服务器收到 101~300 号字节，共 200 字节数据，接收窗口调整，后沿向前滑动 200 字节，表示已收好 200 字节。向客户端发送 ACK 确认，确认字段值 ack=301，表示 301 号之前数据收好，下一个希望接收的字节是 301 号字节。注意，此刻 200 字节数据仍在接收缓冲区内，服务器的应用进程还没将它们拉走，接收窗口的大小 rwnd= 800 – 200 = 600。报文段中通告的窗口值为 600。5. 第 6 个报文段，客户端发给服务器，数据报文段，seq=301。客户端收到确认 ack=301，rwnd=600。客户端知道服务器已经收好 101~300 号字节，就可以删除这些数据，发送窗口调整，后沿向前滑动 200 字节，至01 处。但前沿不能向前滑动，因为现在接收方通告的 rwnd=600，前沿=301+600=901。客户端发送数据报文段，携带 300 字节数据，数据字节编号 301~600，序号字段eq=301。6. 第 7 个报文段，服务器发给客户端，ACK 报文段，ack=601，rwnd=400。服务器收到第二次的 301~600 号字节数据，共 300 字节数据。接收窗口调整，后沿向前滑动 300 字节，至 601 处。因 TCP 使用累积确认，向客户端发送的确认为 ack=601，表示 601 号之前所有数据收好，下一个希望接收的字节是 601 号字节。注意，此刻 200+300=500 字节数据仍在接收缓冲区内。这时，服务器的应用进程拉走 100 字节数据，接收缓冲区的 101~200 号字节空间被释放，但 201~601的 400 字节数据滞留在接收缓冲区内。接收窗口的大小 wnd= 800 – 400 = 400。通告窗口值为 rwnd=400。客户端收到确认 ack=601，rwnd=400。客户端知道服务器已经收好 601 号之前的数据，就可以删除这些数据，发送窗口调整，后沿向前滑动至 601 处。因为现在接收方通告的 rwnd=400，前沿=601+400=1001。前沿向前滑动至 1001 处。7. 第 8 个报文段，服务器发给客户端，ACK 报文段，ack=601，rwnd=600。服务器的应用进程又拉走 200 字节数据，接收缓冲区的 201~400 号字节空间被释放，但 401~601 的 200 字节数据仍滞留在接收缓冲区内。接收窗口的大小 rwnd= 800 – 200 = 600。通告窗口值为 400。对于确认来说，服务器现在收好的是 601 号字节之前的数据，确认为 ack=601，表示希望接收的下一个字节是 601 号字节。客户端收到确认 ack=601，wnd=600。客户端知道服务器已经收好 601 号之前的数据，发送窗口的后沿就在 601 处，不需滑动。因为现在接收方通告的rwnd=600，前沿=601+600=1201。前沿向前滑动至 1201 处。### 糊涂窗口综合症假如 TCP 发送的报文段只含有 1 个字节的数据，那么意味着为发送 1 字节的数据，而发送了 41 个字节的报文段，20 个字节的 TCP 首部和 20 个字节的 IP首部。此时的效率是 1/41。这一现象称为糊涂窗口综合症（Silly Window Syndrome）。糊涂窗口综合症是怎样产生的呢?#### 由发送方产生的糊涂窗口综合症（Syndrome Created by the Sender）如果发送方 TCP 正在为一个产生数据很缓慢的应用程序服务，例如一次产生 1 字节数据，就有可能产生糊涂窗口综合症。解决方法是使用 Nagle 算法。##### Nagle 算法1. 发送方 TCP 把它从应用进程收到的第一块数据发送出去，即使只有 1 字节。2. 在发送一个报文段后，发送方 TCP 就在输出缓存中累积数据并等待，直至收到接收方发来的确认，或者已积累了足够的数据已达到报文段的最大长度时，就立即发送一个报文段。3. 重复步骤 2。Nagle 算法之巧妙，在于其巧妙地平衡了应用程序产生数据速度和网络传输速度。如果应用程序比网络速度快，报文段就大（最大报文段长度），如果应用程序比网络速度慢，报文段就小。#### 由接收方产生的糊涂窗口综合症（Syndrome Created by the Receiver）如果接收方 TCP 正在为一个消耗数据很缓慢的应用程序服务，例如一次消耗 1 字节数据，接收方每次发送 rwnd=1 的通告，就有可能产生糊涂窗口综合症。解决方法的是推迟确认。报文到达时，不立即发送确认，接收方等待一段时间，直到输入缓存有足够的空间（或者接收缓存已有一个最长报文段的空间，或者接收缓存已有一半空闲的空间），就发送确认报文。但推迟确认不能超过 500ms。### 拥塞控制拥塞控制是 TCP 协议中最重要的一部分。理解 TCP 的拥塞控制，关键在于真正理解网络拥塞这一现象，理解了拥塞，以后的内容都会顺理成章的很好理解。#### 拥塞概述两个主机，通过中间的一个传输网，连接在一起。正是因为中间有网络，就有了网络拥塞问题。谈网络拥塞之前，先回忆一下路由器的原理。网络层的路由器是一种“尽力而为”的机制。当超过路由器的能力时，路由器就将会丢弃数据报。假设路由器每秒能转发 1000 个数据报，此刻来了 1200 个数据报，路由器就将后 200 个数据报丢弃。注意：当没有超过路由器的负载能力时，路由器是不会丢弃数据报的。换一句话说，就是某个路由节点拥塞了，才会丢弃数据报。怎么解决拥堵呢？很明显有两种方案，用公路网来打比方就是增加路的数量和减少驶入公路网的车。从协议的角度考虑，自然是做不到增加路的数量，所以我们就要控制发送到网络中的数据量。#### 传输网络当网络拥塞时，如同城市交通堵塞，南城的人去不了北城，北城的人一样也去不了南城，路都堵死了，谁也走不了。也就是说，拥塞时，网络外围的所有主机，发送的数据包都会被丢掉，所以一定不会有返回的 ACK 确认，超时定时器一定会闹响。也就是说，网络拥塞时，所有主机都会超时。这样问题就解决了，简单归纳为一句话，超时就表示网络拥塞。&gt; 超时就表示网络全拥塞。因为 TCP 协议中以超时做为网络拥塞的判断依据，重传定时器的值需要估算合适，这很重要。值估算小了，实际网络不拥塞，确产生了超时重传，误判为拥塞，就不能充分使用网络的传输能力。值估算大了，实际网络已经拥塞，确没有产生超时重传，误判为通畅，就会使拥塞更加恶化，最终通信崩溃。在日常的生活中，城市的交通堵塞一定是渐渐堵死的，绝无可能在前一分钟，全城都是通畅的，后一分钟，全城所有的道路都堵死。总是开始时某些路段堵死，然后慢慢扩大，最后全部堵死。如果在某些路段堵死的时候，就开始疏导，有可能不会演变为全堵死。同理在计算机网络中，也很难相信，在前一分钟，所有的路由器都负载很轻，后一分钟，所有的路由器都超负载。应该是，某些路由器超负载了，其他路由器正常，这时后续的数据包就会自动绕路。假设某主机，连续发送了 2，3，4，5号数据包，2 号数据包碰到超负荷的路由器，被路由器丢弃，3，4，5 号数据包绕路到达目的主机，目的主机发送了 3 个 ACK 确认，请求 2 号数据包。当发送方收到 3 个重复 ACK 时，就会判断，网络是部分拥塞的，前面的数据包堵死在路上，后面的数据包绕路走了，已经到达目的地。简单归纳为一句话，3 个重复ACK 就表示网络部分拥塞，我称为半拥塞。&gt; 3 个重复 ACK 就表示网络半拥塞。至此，外围的主机有了推测中间传输网络状态的办法，这两个事件就标志着网络的两种状态。用两个事件标志两种网络状态的方法，需要认真领会。TCP 的拥塞控制不能算闭环，没有一个具体的设备发出一个网络拥塞的信号，因为拥塞是全网的状态，不是某一个路由器的状态。一个路由器超载，可以绕其他路由器。TCP 的拥塞控制也不能算开环，“超时”与“3ACK”这两个事件确实反馈了中间传输网络的状态，为决策提供了依据。了解了网络现在的状态，就好办了。全拥塞有全拥塞的处理办法，半拥塞有半拥塞的处理办法。#### 拥塞窗口在上文中，讨论过 TCP 的流量控制，发送方窗口大小是由接收方的可用缓存空间（rwnd）决定的，就是由接收方指示发送方应当使用多大的窗口，这当然可以保证接收方不会溢出。但是，这个方法没考虑网络的存在，上文说过，要调控网络拥塞，就要根据当前网络的状态，调整发送到网络中的数据量。也就是说，TCP 需要一个控制变量，即TCP 发送方使用拥塞窗口 cwnd （Congestion Window）作为控制变量，根据当前网络的拥塞程度，拥塞窗口的大小动态地变化，调整发送的数据量。这样一来发送窗口大小不仅取决于接收方通告的接收窗口 rwnd，还取决于网络的拥塞状况 cwnd，进而 实际的发送窗口 = min（ rwnd , cwnd ）#### 拥塞检测TCP 的发送方使用两个事件作为判断网络全拥塞和半拥塞的依据。超时表示网络全拥塞。3 次重复 ACK 表示网络半拥塞。##### 超时上文已经解释过拥塞的现象，我们现在简单理解为：发送方的超时事件就表示中间网络全部堵死了。发送方 TCP 在整个连接期间，只维护一个 RTO 计时器。发送方发送段 1 和 段 2，计时器启动，接收方发回 ACK，发送方收到 ACK 后，计时器清零。在启动计时器，发送段 3，段 4，段 3 丢失，段 4 到达，接收方将段 4 存储下来，因为段 3 丢失，接收方留出一个间隙，表明数据是不连续的，接收方只能再发送对段 2 的确认 ACK。发送方收到确认，但因为不是对段 3，段 4 的确认，计时器不能清零，计时器超时，就会重传段 3，并重启计时器，这次段 3 正常到达，接收方发送 ACK，发送方收到，将计时器清零。三次重复 ACK（3dupACKs）三次重复 ACK，也称做“快重传”（Fast retransmission）。如下图：发送方发送 2 个段后，正常收到 ACK，这个 ACK 是原始的 ACK，超时计时器清零。发送方再发送 4 个段，并再次启动超时计时器，段 3 丢失，段 4，5，6 到达。当接收方收到失序的数据段时，立即发送 ACK。接收方会发出 3 个重复的 ACK。发送方收到三个重复的 ACK，就立即重传丢失的报文段，而不等待计时器超时，并重启计时器。这一规则称为“快重传”，目前的 TCP 都遵守这规则。三次重复 ACK，显然是某个报文段丢失了，后面的报文段正常到达。这就表示网络有堵死的地方，造成丢失，其他部分通畅，后面的报文段绕行了通畅的路径。我们现在简单理解为：发送方收到三次重复 ACK，就表示中间网络半堵死。#### 拥塞控制策略TCP 拥塞策略基于两个阶段，慢启动（slow-start，SS）阶段和拥塞避免（congestion avoidance，CA）阶段。在慢启动阶段，发送方从非常慢的速率开始，很快达到一个门限值。当到达门限值，进入拥塞避免阶段。##### 慢启动（SS, Slow start）指数增大，拥塞窗口 cwnd 从 1 个最大报文段 MSS 开始。每收到一个 ACK 确认，拥塞窗口增加一个 MSS。慢启动算法开始很慢，但它是以指数增大的。按 ACK 计算， cwnd = cwnd + 1。如图，从 cwnd=1 开始，第 1 个 ACK 到达后，cwnd 加 1，就是 2。这时，就可发送 2 个段，相应的回来 2 个 ACK，对于每个 ACK，cwnd 加 1，就是 4 了。是按指数增大的。慢启动不能无限制的指数增大，有一个门限值来终止慢启动。发送方有一个慢开始门限 ssthresh（slow-start threshold）的变量，当拥塞窗口大小达到阈值时，慢启动停止，开始拥塞避免阶段。##### 拥塞避免（CA，Congestion avoidance）加法增大，在慢启动阶段，当拥塞窗口达到慢开始门限 ssthresh 的值时，慢启动停止，进入拥塞避免阶段。此时，拥塞窗口按加法增大。每次整个“窗口”的所有段都被确认后，拥塞窗口增加 1。举例，发送方以 cwnd=4 开始，此刻发送方只能发 4 个段，在 4 个 ACK 到达后，拥塞窗口才加 1。如果按往返时延 RTT 观察，拥塞窗口是每一轮次加 1。按 ACK 计算， cwnd = cwnd + ( 1 / cwnd )按 RTT 计算， cwnd = cwnd + 1拥塞控制策略的转换在拥塞避免阶段，拥塞窗口加法增大。拥塞避免阶段会一直持续下去吗？继续下去，会是什么情况？显然，拥塞避免阶段继续下去，网络只会有处于通畅，半拥塞，全拥塞三种状态中的一种。就如同城市交通一样，只会是不堵车，部分堵死，全部堵死这三种情况之一。通畅：标志是无事件发生。拥塞避免阶段继续，拥塞窗口继续按加法增大。半拥塞：标志事件是：发送方收到三次重复 ACK（3dupACKs）。处理办法是：ssthresh 门限值设为此刻 cwnd 的一半 ssthresh = cwnd / 2将拥塞窗口设为门限值。 cwnd = ssthresh进入拥塞避免阶段。全拥塞标志事件是：发送方超时。处理办法是：ssthresh 门限值设为此刻 cwnd 的一半 ssthresh = cwnd / 2将拥塞窗口重新设置设为 1。 cwnd = 1进入慢启动阶段拥塞举例：连接管理TCP 是一种面向连接的协议。TCP 以全双工方式传送数据。在 TCP 中，面向连接的传输需要经过三个阶段：连接建立，数据传输，连接断开。TCP 连接采用客户服务器方式。主动发起连接建立的应用进程叫做客户(client)，被动等待连接建立的应用进程叫做服务器(server)。连接建立TCP 建立连接的过程叫做三次握手（three-way handshaking）。服务器首先打开一个端口，端口处于监听态，称为被动打开。客户端发起连接请求，连接到服务器的打开的端口上，连接就建立了。客户端发送第 1 个报文段，SYN 标志置 1，SYN 是请求同步的意思，SYN 报文段是控制报文，只在每个方向的第 1 个报文里出现。客户随机选择一个数字作为初始序号，假设为 x。TCP协议规定：SYN 报文段不能携带数据，但要消耗掉一个序号。服务器发送第 2 个报文段，SYN，ACK 置 1。SYN 标志表示服务器方的请求同步，并且服务器设置自己的初始序号，假设为 y。ACK 置 1 表示包含确认，这个确认是对客户端 SYN 报文的确认，所以确认号=x+1，表示序号 x+1 之前的报文都收好了，希望收到序号为 x+1 的报文段。客户端发送第 3 个报文段，ACK 标志置 1。这个报文段仅仅是一个 ACK 段，通常不携带数据。这个段是客户端发出的，序号就是 x+1。ACK 置 1 表示包含确认，这是对服务器 SYN 报文的确认，确认号=y+1，表示服务器发送的序号 y+1 之前的报文都收好了，希望收到服务器发送的序号为 y+1 的报文段。要特别注意教材中的这句话，并需要真正理解。TCP 的标准规定，ACK 报文段可以携带数据。但如果不携带数据则不消耗序号。举例：客户端发送的第 1 个 SYN 报文段，序号为 8000，服务器发送的第 2 个 SYN+ACK 报文段，序号为 15000，此后，客户端发送了第 3 个报文段，未携带数据，第 4 个报文段，携带 100 字节数据，问客户端发送的第 3，4 个报文段的序号是什么？解析：第 3 个报文段，序号为 8001，因为序号 8000 已经被 SYN 报用掉了。 第 4 个报文段，序号仍然是 8001，注意不是 8002，因为第 3 个报文段是一个 ACK 报文段，并且没携带数据，所以不消耗序号，就是说第 3 个报文的序号 8001 没有被用掉，在第 4 个报文中继续使用。数据传输连接建立后，可进行双向的数据传输。客户端和服务器都可以发送数据和确认。TCP 连接使用了序号和确认号的机制。序号TCP 把要发送的数据都按字节编上号。两个方向的编号是相互独立的。编号并不是从 0 开始，而是使用一个随机数作为初始编号，初始编号在建立连接的第一个 SYN 报文段里通告给对方。每个 TCP 报文段都有序号字段，序号字段值是这个报文段中第一个数据字节的编号。TCP 报文的序号字段值是这个报文段中第一个数据字节的编号。确认号TCP 使用确认机制。当报文段中 ACK 标志置 1，报文的确认号字段有效，TCP 的确认是累计确认，确认号字段值是完全接收好的数据的最后一个字节的编号+1，表示此值前的数据已收好，期望接收的下一字节是此值。举例，确认号是5644，表示从开始到 5643 号字节的数据都已收好，希望接收 5644 号字节。TCP 是累积确认。确认号字段值是期望接收的下一个字节的编号。举例：客户端发送一报文段，序号 8001，确认号 15001，携带 1000 字节数据。服务器发送的下一个报文段，序号，确认号是多少？服务器的回复携带 2000 字节数据，则客户端发送的再下一个报文，序号，确认号是多少？解析：因第 1 个报文的确认号 15001，是期望接收的下一个报文段的序号，所以，服务器发送的下一个报文段的序号是 15001。因第 1 个报文的序号 8001，携带 1000 字节数据，服务器收到了 8001-9000 编号的 1000 字节数据，确认号是9001，表示 9001 号字节之前的数据已经收好，希望接收的下一个字节是 9001号字节。同理，第 3 个报文，序号为 9001，确认号是 17001。连接断开数据传输结束后，客户端和服务器任一方都可以发起断开连接。一般来说客户端发起断开连接。TCP 连接释放过程是四次握手。正常情况下，客户端发起连接断开的请求。客户端发送第 1 个报文段，FIN 标志置 1，FIN 是请求结束的意思，表示客户端方向数据传输结束。假设这个段的序号是 u，在此图中，FIN 报文段值只是控制报文，没携带数据。TCP 规定，FIN 报文段即使不携带数据，它也消耗掉一个序号。服务器发送第 2 个报文段，ACK 报文段，确认它收到了客户端的 FIN 报文段，假设其序号为 v，确认号= u+1。服务器发送第 3 个报文段，FIN 报文段，两个标志 FIN，ACK 置 1，FIN 表示服务器方向数据传输结束，确认仍是对第 1 个报文段的确认，确认号= u+1。注意，其序号仍然是 v，原因是第 2 个报文段运用了下述的规则 2，其序号 v 没有消耗，继续使用。客户端发送第 4 个报文段，ACK 报文段，ACK 标志置 1，确认是对服务器 FIN 报文段的确认，确认号= v+1。其序号是 u+1，原因第 1 个报文段运用了规则 3，序号 u 被消耗掉了，所以现在序号是 u+1。TCP 连接管理的三规则规则 1：TCP 规定，SYN 报文段不能携带数据，但要消耗掉一个序号规则 2：TCP 的标准规定，ACK 报文段可以携带数据。但如果不携带数据则不消耗序号。规则 3：TCP 规定，FIN 报文段即使不携带数据，它也消耗掉一个序号。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络层-网络构建]]></title>
    <url>%2F2019%2F%E7%BD%91%E7%BB%9C%E5%B1%82-%E7%BD%91%E7%BB%9C%E6%9E%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[自治系统Autonomous System，AS。每个AS由一组通常处在相同管理控制下的路由器组成。一个ISP中的路由器以及连接他们的线路可以构成一个AS，一个ISP也可以将他们的网络划分成多个AS。每个AS由一个唯一的ASN来标识。所以在构建网络的时候，我们需要对 AS 内的网络和 AS 之外的网络进行区分。这两个统称为路由协议。内部网关协议Interior Gateway Protocol （IGP），用于自治系统（AS）内部的路由交换也叫做域内路由选择（intradomain routing），如 RIP 和 OSPF 协议外部网关协议Exterior Gateway Protocol （EGP），用于不同自治系统（AS）之间的路由交换，也叫做域间路由选择（interdomain routing），目前使用最多的是 BGP-4。路由选择算法分类常用的分类是：每个路由器知道的是全局的信息还是分散的信息？全局的所有的路由器具有完整的拓扑和链路费用信息“链路状态(L-S)”算法应用于RIP协议分散的路由器只知道物理连接的邻居和到邻居的链路费用迭代的计算过程，与邻居交换信息“距离向量(D-V)”算法应用于OSPF协议RIP协议基于距离向量的分布式路由选择协议，规定：“距离”为到目的网络所经过的路由器数。从一路由器到直接连接的网络的距离定义为 1。RIP允许一个通路最多包含15个路由器，多于15个路由器时不可达。RIP不能在两个网络之间同时使用多条路由，它选择一个具有最少路由器的路由，具有相同路径长度的路规定先入为主。特点仅和相邻路由器交换信息。交换的信息是当前本路由器所知道的全部信息，即自己的路由表。按固定的时间间隔交换路由信息，例如，每隔 30 秒。距离向量算法收到相邻路由器（其地址为 X）的一个 RIP 报文：先修改此 RIP 报文中的所有项目：将“下一跳”字段中的地址都改为 X，并将所有的“距离”字段的值加 1。对修改后的 RIP 报文中的每一个项目，重复以下步骤：若项目中的目的网络不在路由表中，则将该项目加到路由表中。否则若下一跳字段给出的路由器地址是同样的，则将收到的项目替换原路由表中的项目否则若收到项目中的距离小于路由表中的距离，则进行更新否则，什么也不做。若 3 分钟还没有收到相邻路由器的更新路由表，则将此相邻路由器记为不可达的路由器，即将距离置为16（距离为16表示不可达）。返回。举例一开始，各路由表只有到相邻路由器的信息：路由器 B 收到相邻路由器 A 和 C 的路由表：修改 A 的路由表，将 RIP 报文中的所有项目下一跳的字段都改成 A ，距离增加 1。目的网络距离下一跳12A23A33A修改 C 的路由表，将 RIP 报文中的所有项目下一跳的字段都改成 C ，距离增加 1。目的网络距离下一跳42C62C将 B 原来不可达的项目加入到B的路由表中，加入后B的路由表：目的网络距离下一跳31-41-12A22A62C修改 收到的目的网络原本在B路由器中且下一跳的字段和原B路由表项目中的字段一致 的项目，发现不用修改。修改 B 可达，A和C也可达的项目，发现收到项目中的距离小于路由表中的距离，则进行更新，否则不更新。则修改后B的路由表是：目的网络距离下一跳31-41-12A22A62CRIP 协议的优缺点RIP 存在的一个问题是当网络出现故障时，要经过比较长的时间才能将此信息传送到所有的路由器。即好消息传播得快，而坏消息传播得慢。RIP 协议最大的优点就是实现简单，开销较小。RIP 限制了网络的规模，它能使用的最大距离为 15（16 表示不可达）。路由器之间交换的路由信息是路由器中的完整路由表，因而随着网络规模的扩大，开销也就增加。好消息传播得快，坏消息传播得慢在正常情况下，R1中项目表示到网1距离为1，R2中项目表示到网1距离为2。R2收到 R1 的项目后修改R2的项目为：1 2 R1，R2发现到网1的下一跳为R1，和原路由表一致，修改原路由表该项目为：1 2 R1。R1 说：“我到网 1 的距离是 16 （表示无法到达），是直接交付”。但 R2 在收到 R1 的更新报文之前，还发送原来的报文，因为这时 R2 并不知道 R1 出了故障。我们列出一个网1出现故障后的交换表：R1R2正常1 1 -1 2 R1故障1 16 -1 2 R1第1次1 3 R21 16 R1第2次1 16 R21 4 R1第3次1 5 R21 16 R1………这样不断更新下去，直到 R1 和 R2 到网 1 的距离都增大到 16 时，R1 和 R2 才知道网1是不可达的。RIP协议的位置RIP 协议使用运输层的用户数据报 UDP进行传送（使用 UDP 的端口 520）。因此 RIP 协议的位置应当在应用层。但转发 IP 数据报的过程是在网络层完成的。这时有一个困惑，RIP是网络层协议，可是为什么用UDP封装？因为路由器虽然是网络层设备，但并不代表他只具备物理层、链路层、网络层功能，他还具备一些应用层的功能，当遇到RIP报文这类应用层的协议，他也能够解封。然后读取RIP报文中的下一跳路由。RIP2 协议的报文格式RIP2由RIP而来，属于RIP协议的补充协议，提升装载的信息量，增加安全性。OSPF协议开放最短路径优先协议OSPF （Open Shortest Path First）。RIP 协议的问题以跳数评估的路由并非最优路径最大跳数16导致网络尺度小收敛速度慢更新发送全部路由表浪费网络资源要点向本自治系统中所有路由器发送信息，这里使用的方法是洪泛法。发送的信息就是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息。“链路状态”就是说明本路由器都和哪些路由器相邻，以及该链路的“度量”（metric）。只有当链路状态发生变化时，路由器才用洪泛法向所有路由器发送此信息。链路状态数据库由于各路由器之间频繁地交换链路状态信息，因此所有的路由器最终都能建立一个链路状态数据库。这个数据库实际上就是全网的拓扑结构图，它在全网范围内是一致的（这称为链路状态数据库的同步）。OSPF 的链路状态数据库能较快地进行更新，使各个路由器能及时更新其路由表。OSPF 的更新过程收敛得快是其重要优点。Dijkstra 算法123456初始化10261+无穷+无穷第1步02412+无穷第2步023124第3步023126路径：1 -&gt; 4 -&gt; 5 -&gt; 2 -&gt; 3 -&gt; 6OSPF 的区域(area)为了使 OSPF 能够用于规模很大的网络，OSPF 将一个自治系统再划分为若干个更小的范围，叫作区域。每一个区域都有一个 32 bit 的区域标识符（用点分十进制表示）。区域也不能太大，在一个区域内的路由器最好不超过 200 个。 同时 OSPF 划分为两种不同的区域：划分区域的好处就是将利用洪泛法交换链路状态信息的范围局限于每一个区域而不是整个的自治系统，这就减少了整个网络上的通信量。在一个区域内部的路由器只知道本区域的完整网络拓扑，而不知道其他区域的网络拓扑的情况。OSPF 使用层次结构的区域划分。在上层的区域叫作主干区域(backbone area)。主干区域的标识符规定为0.0.0.0。主干区域的作用是用来连通其他在下层的区域。 图中的R3、R4、R6、R7是主干路由器。OSPF 载体OSPF 不用 UDP 而是直接用 IP 数据报传送。OSPF 构成的数据报很短。这样做可减少路由信息的通信量。数据报很短的另一好处是可以不必将长的数据报分片传送。分片传送的数据报只要丢失一个，就无法组装成原来的数据报，而整个数据报就必须重传。OSPF 的五种分组类型类型1，问候（Hello）分组。类型2，数据库描述（Database Description）分组。类型3，链路状态请求（Link State Request）分组。类型4，链路状态更新（Link State Update）分组，用洪泛法对全网更新链路状态。类型5，链路状态确认（Link State Acknowledgment）分组。BGP协议BGP 是不同自治系统的路由器之间交换路由信息的协议。 BGP 较新版本是 2006 年 1 月发表的 BGP-4，可以将 BGP-4 简写为 BGP。每一个自治系统的管理员要选择至少一个路由器作为该自治系统的“BGP 发言人” 。一般说来，两个 BGP 发言人都是通过一个共享网络连接在一起的，而 BGP 发言人往往就是 BGP 边界路由器，但也可以不是 BGP 边界路由器。一个 BGP 发言人与其他自治系统中的 BGP 发言人要交换路由信息，就要先建立 TCP 连接，然后在此连接上交换 BGP 报文以建立 BGP 会话（session），利用 BGP 会话交换路由信息。使用 TCP 连接能提供可靠的服务，也简化了路由选择协议。使用 TCP 连接交换路由信息的两个 BGP 发言人，彼此成为对方的邻站或对等站。BGP报文打开（Open）报文，用来与相邻的另一个BGP发言人建立关系。更新（Update）报文，用来发送某一路由的信息，以及列出要撤消的多条路由。保活（Keepalive）报文，用来确认打开报文和周期性地证实邻站关系。通知（Notificaton）报文，用来发送检测到的差错。ICMPIP协议只有一种报文格式：IP报文功能：传递上层数据缺乏：应付可能出现差错的能力网际控制报文协议 ICMP (Internet Control Message Protocol)IP的辅助协议为IP提供差错报告机制同时为其它层（TCP/UDP、应用）提供辅助功能ICMP 报文的种类有两种，即 ICMP 差错报告报文和 ICMP 询问报文。格式差错报告报文终点不可达源点抑制(Source quench)时间超过参数问题改变路由（重定向）(Redirect)询问报文回送请求和回答报文时间戳请求和回答报文PINGPing发送一个ICMP 报文；回声请求消息给目的地并报告是否收到所希望的ICMPecho （ICMP回声应答）。它是用来检查网络是否通畅或者网络连接速度的命令。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络层-数据通信]]></title>
    <url>%2F2019%2F%E7%BD%91%E7%BB%9C%E5%B1%82-%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[网络通信分类不同主机间的数据通信可以分为三种：两个主机属于同一个网、两个主机属于相邻的两个网中、两个主机属于不相邻的两个网络中。其中第一类是链路层所解决的问题，而后两类都是网络需要解决的问题，图示如下。为了叙述方便，博主将第二类情况简称“两个网”，第三类情况简称“三个网”，但实际上“三个网”的理论可以推广到“n个网”中。传统的IP地址划分传统的IP地址划分规则中，地址由两个部分组成：网络号 + 主机号。具有相同网络号的IP地址属于同一个网络。同时网络被划分为5类：但是并不是所有的主机号都能被用来标识主机，主机号全为0的IP地址被称为网络地址，标识一个网络。主机号全为1的地址被称为广播地址，用于向某个网络的所有主机广播。例：主机 212.111.44.136 所在网络的广播地址为212.111.44.255。而对于任意一个主机若想向其所在的网络中广播都可以使用255.255.255.255。按照这个划分我们可以得到各类地址的特性：### 各类地址特性#### A类地址- 前1字节标识网络地址，后3字节标识主机地址- 每个网络最多可容纳（$2^{24} －2$）台主机- 从高位起，前1位为“0”，第1字节用十进制表示的取值范围为“0～127”- 具有A类地址特征的网络总数为126个#### B类地址- 前2字节标识网络地址，后2字节标识主机地址- 每个网络最多可容纳（$2^{16} －2$）台主机- 从高位起，前2位为“10”，第1字节用十进制表示的取值范围为“128～191”- 具有B类地址特征的网络总数为 $2^{14} －1$ 个#### C类地址- 前3字节标识网络地址，后1字节标识主机地址- 每个网络最多可容纳254台主机- 从高位起，前3位为“110”，第1字节用十进制表示的取值范围为“192～223”- 具有C类地址特征的网络总数为 $2^{21} －1$个#### D类地址- 多播通信地址（multicast address）- 从高位起，前4位为“1110”，第1字节用十进制表示的取值范围为“224－239”，用于标识multicast通信地址- 后28位用于区分不同的multicast组#### E类地址- 从高位起，前4位为“1111”，第1字节用十进制表示的取值范围为“240－255”，用于标识E类地址- 后28位留作它用## 划分子网早期的 IP 地址的设计确实不够合理。会存在如下问题：- IP 地址空间的利用率有时很低。- 给每一个物理网络分配一个网络号会使路由表变得太大因而使网络性能变坏。- 两级的 IP 地址不够灵活。- 网络很快就被分配完了。所以从 1985 年起在 IP 地址中又增加了一个“子网号字段”，使两级的 IP 地址变成为三级的 IP 地址。但划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。其实现思路就是从主机号借用若干个比特作为子网号 subnet-id，而主机号 host-id 也就相应减少了若干个比特。CIDR划分子网后仍然没有解决IP V4的问题，1992年互联网的三大危机：B类地址耗尽路由表爆炸IP地址整体耗尽无分类域间路由选择，Classless Inter-Domain Routing，是为解决上述危机而开发的一种方案。在CIDR技术中，IP 地址由两部分组成，网络前缀 + 主机号。CIDR 还使用“斜线记法”(slash notation)，它又称为CIDR记法，即在IP地址后面加上一个斜线“/”，然后写上网络前缀所占的比特数（这个数值对应于三级编址中子网掩码中比特 1 的个数）。CIDR 将网络前缀都相同的连续的 IP 地址组成“CIDR地址块”。128.14.32.0/20 表示的地址块共有 212 个地址（因为斜线后面的 20 是网络前缀的比特数，所以主机号的比特数是 12）。这个地址块的起始地址是 128.14.32.0。在不需要指出地址块的起始地址时，也可将这样的地址块简称为“/20 地址块”。128.14.32.0/20 地址块的最小地址：128.14.32.0。128.14.32.0/20 地址块的最大地址：128.14.47.255全 0 和全 1 的主机号地址一般不使用。路由聚合一个 CIDR 地址块可以表示很多地址，这种地址的聚合常称为路由聚合，它使得路由表中的一个项目可以表示很多个（例如上千个）原来传统分类地址的路由，减少了路由器之间的路由信息交换。路由聚合也称为构成超网。（super netting）。这个 ISP 共有 6 个 C 类网络。如果不采用 CIDR 技术，则在与该 ISP 的路由器交换路由信息的每一个路由器的路由表中，就需要有 64 个项目。但采用地址聚合后，只需用路由聚合后的 1 个项目 206.0.64.0/18 就能找到该 ISP。 需要注意的是若是因特网中某路由器想标识该ISP，只需要记录206.0.64.0/18，但是对于ISP内的路由器还是会将各子地址块的网络地址记录。### 最长前缀匹配- 使用 CIDR 时，路由表中的每个项目由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。- 应当从匹配结果中选择具有最长网络前缀的路由：最长前缀匹配（longest-prefix matching）。- 网络前缀越长，其地址块就越小，因而路由就越具体。- 最长前缀匹配又称为最长匹配或最佳匹配。## 网关如果把计算机网络与快递网络做类比，假设东北大学是一个网络，西南大学是一个网络，东北大学想向西南大学寄点东西那么它需要通过自己学校的驿站寄到西南大学的驿站。网络之间进行通信的时候也需要有一个这种“驿站”。这便是网关。默认网关就是为主机转发分组的路由器网络接口，就是主机的第一跳路由器，网关就是你邮信时需要找到的校园邮筒的地址，即默认网关是在网关中选一个。主机 H1 的默认网关是路由器的 E0 接口。“两个网”时，需要正确配置网关。网关是主机的第一跳路由器。举例：假设主机 H2 的 E0 接口 IP 地址 100.16.0.1，掩码 255.255.0.0，E1 接口 IP 地址 100.17.0.1，掩码 255.255.0.0：主机 H1 本地连接 IP 地址 100.16.0.2，掩码 255.255.0.0，默认网关 100.16.0.1。主机 H3 的默认网关是什么呢？100.16.0.1。主机 H5 的默认网关又是什么？是100.17.0.1。在“多个网”时，多个网络如何互联？我们看下面的网络拓扑图，这是 3 个路由器连接了 4 个网络。假设网 1 内部有一个主机 H1，网 1 内部只有一个路由器 R1，因此默认网关只能设为 R1 的 15.0.0.4，再配置好 IP 地址，就可以与外网通信了。假设网 2 内部有一个主机 H3，在网 2 内有两个路由器 R1 和 R2，可以任选一个做默认网关，假设选 R2，默认网关设为 20.0.0.9，再配置好 IP 地址，就可以与外网通信了。再讨论如何配置路由器。路由器不傻，只要配置好路由器接口的 IP 地址，路由器会从接口的 IP 地址计算出网络地址，也就是说路由器能看清自己身边的网络。至于路由器是怎么看到的，在网络层-网络构建中会解释。## 数据转发之前说了这么多都是在做铺垫，本篇博文主要想介绍的一点是路由器是如何转发不同网络中的数据包。算法如下：1. 从收到的分组的首部提取目的 IP 地址 D。2. 先用各网络的子网掩码和 D 逐位相“与”，看是否和相应的网络地址匹配。若匹配，则将分组直接交付。否则就是间接交付，执行3。3. 若路由表中有目的地址为 D 的特定主机路由，则将分组传送给指明的下一跳路由器；否则，执行4。4. 对路由表中的每一行的子网掩码和 D 逐位相“与”，若其结果与该行的目的网络地址匹配，则将分组传送给该行指明的下一跳路由器；否则，执行5。5. 若路由表中有一个默认路由，则将分组传送给路由表中所指明的默认路由器；否则，执行6。6. 报告转发分组出错。R1的路由表：| 目的网络地址 | 子网掩码 | 下一跳 || :———–: | :————-: | :—-: || 128.30.33.0 | 255.255.255.128 | 接口0 || 128.30.33.128 | 255.255.255.128 | 接口1 || 128.30.36.0 | 255.255.255.0 | R2 |R2的路由表：| 目的网络地址 | 子网掩码 | 下一跳 || :———–: | :————-: | :—-: || 128.30.33.0 | 255.255.255.128 | R1 || 128.30.33.128 | 255.255.255.128 | 接口0 || 128.30.36.0 | 255.255.255.0 | 接口1 |在上图中，若H1（128.30.33.13）想给H3（128.30.36.12）发送数据，我们来分析一下具体的过程：1. 主机 H1 首先将本子网的子网掩码 255.255.255.128与分组的 IP 地址 128.30.36.12 逐位相“与”（AND 操作）。即255.255.255.128 AND 128.30.36.12 得到 128.30.36.0，发现不等于128.30.33.0，所以他要将数据报发送到它的默认网关（128.30.33.1）上。2. R1收到这个地址后，会遍历所有的子网掩码，进行按位与后再和对应的网络地址做比对。可以得到转发给R2计算过程如下：1. 255.255.255.128 AND 128.30.36.12 = 128.30.36.0 不等于 128.30.33.02. 255.255.255.128 AND 128.30.36.12 = 128.30.36.0 不等于 128.30.33.128、3. 255.255.255.0 AND 128.30.36.12 等于 128.30.36.03. R1收到这个地址后，会遍历所有的子网掩码，进行按位与后再和对应的网络地址做比对。可以得到转发给接口1。4. 然后便是链路层需要解决的问题。### ARP深入只要主机或路由器要和本网络上的另一个已知 IP 地址的主机或路由器进行通信，ARP 协议就会自动地将该 IP 地址解析为链路层所需要的硬件地址。可以分为四种情况：- 发送方是主机，要把IP数据报发送到本网络上的另一个主机。这时用 ARP 找到目的主机的硬件地址。- 发送方是主机，要把 IP 数据报发送到另一个网络上的一个主机。这时用 ARP 找到本网络上的一个路由器的硬件地址。剩下的工作由这个路由器来完成。- 发送方是路由器，要把 IP 数据报转发到本网络上的一个主机。这时用 ARP 找到目的主机的硬件地址。- 发送方是路由器，要把 IP 数据报转发到另一个网络上的一个主机。这时用 ARP 找到本网络上的一个路由器的硬件地址。剩下的工作由这个路由器来完成。## IP数据报的格式- 版本：占 4 位，指 IP 协议的版本目前的 IP 协议版本号为 4 （即 IPv4）。- 首部长度：占 4 位，可表示的最大数值是 15 个单位（一个单位为 4 字节）因此 IP 的首部长度的最大值是 60 字节。- 区分服务：占 8 位，用来获得更好的服务在旧标准中叫做服务类型，但实际上一直未被使用过。1998 年这个字段改名为区分服务。只有在使用区分服务（DiffServ）时，这个字段才起作用。在一般的情况下都不使用这个字段。- 总长度——占 16 位，指首部和数据之和的长度，单位为字节，因此数据报的最大长度为 65535 字节。总长度必须不超过最大传送单元 MTU。- 标识（identification）：占 16 位，它是一个计数器，用来产生数据报的标识。- 标志（flag）：占 3 位，目前只有前两位有意义。标志字段的最低位是 MF（More Fragment）。MF = 1 表示后面“还有分片”。MF = 0 表示最后一个分片。标志字段中间的一位是 DF（Don’t Fragment）。只有当 DF=0 时才允许分片。- 片偏移(13 位)指出：较长的分组在分片后某片在原分组中的相对位置。片偏移以 8 个字节为偏移单位。- 生存时间（8 位）记为 TTL（Time To Live）：数据报在网络中可通过的路由器数的最大值。- 协议（8 位）：指出此数据报携带的数据使用何种协议，即运输层协议。- 首部检验和（16 位）字段只检验数据报的首部不检验数据部分。- 源地址和目的地址都各占 4 字节。## NAT### 私有地址在现在的网络中，IP地址分为公网IP地址和私有IP地址。公网IP是在Internet使用的IP地址，而私有IP地址则是在局域网中使用的IP地址。私有IP地址是一段保留的IP地址。只使用在局域网中，无法在Internet上使用。- A类私有地址：10.0.0.0～10.255.255.255- B类私有地址：172.16.0.0～172.31.255.255- C类私有地址：192.168.0.0～192.168.255.255这些地址可以在任何组织或企业内部使用，和其他Internet地址的区别就是，仅能在内部使用，不能作为全球路由地址。这就是说，出了组织的管理范围这些地址就不再有意义，无论是作为源地址，还是目的地址。对于一个封闭的组织，如果其网络不连接到Internet，就可以使用这些地址而不用向 IANA（The Internet Assigned Numbers Authority，互联网数字分配机构，是负责协调一些使Internet正常运作的机构） 提出申请，而在内部的路由管理和报文传递方式与其他网络没有差异。对于有Internet访问需求而内部又使用私有地址的网络，就要在组织的出口位置部署NAT网关，在报文离开私网进入Internet时，将源IP替换为公网地址，通常是出口设备的接口地址。一个对外的访问请求在到达目标以后，表现为由本组织出口设备发起，因此被请求的服务端可将响应由Internet发回出口网关。出口网关再将目的地址替换为私网的源主机地址，发回内部。这样一次由私网主机向公网服务端的请求和响应就在通信两端均无感知的情况下完成了。依据这种模型，数量庞大的内网主机就不再需要公有IP地址了。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链路层]]></title>
    <url>%2F2019%2F%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[相邻计算机网络中链路层的功能是“相邻节点间的数据传输”。这句话什么意思呢？我们先讨论“相邻”一词，再讨论“数据传输”。两台主机，用一根网线相连是相邻。多台主机，用一根网线相连，仍然是相邻。这根线缆退化成一个节点，这样的设备称为集线器。通过集线器相连的多台主机也是相邻。集线器没有任何智能，等同于线缆。在集线器上增加简单的智能控制功能，就是交换机。通过交换机相连的多台主机也是相邻。交换机将计算机互联在一起，构成局域网。所以“相邻节点间的数据传输”换一种说法就是“构建局域网”，再换一种说法就是“局域网内的主机都是邻居关系”。链路层的功能就是构建局域网。相邻这一概念很重要，主机间的数据传输可以分为两种情况，一种是两个主机在同一个局域网内，两主机是相邻关系，简称内网通信，另一种是两个主机在两个不同的网络里，可称外网通信，两种数据传输原理完全不同。本篇博文只关注内网通信。## 链路层解决的问题数据传输就是将一台主机内的数据传输到另一台主机，物理层解决了比特转换为电磁信号传输的问题，但这不是数据传输的全部问题，还有一些问题，例如：- 物理层传输中的数据有可能出错，如何处理？- 发送方与接收方的速度可能不匹配，如何调节？- 数据如何封装成数据帧，然后传输，如何传输封装？- 发生碰撞该怎么办？针对这些问题制定的解决方案称为数据链路层的通信协议。物理链路+通信协议构成了我们要研究的数据链路。## 循环冗余码循环冗余码（CRC）在很多地方都被用来校验传输的数据是否出错，至于其如何证明，博主也未曾探究，下文介绍冗余码的思想和计算方法。如果发送方只传输 87，接收方收到 82，接收方是无法判断 82 是不是发送方发送的数据，就是说无法判断 82 是对还是错。怎么办？发送方与接收方事先商量好一个数，例如 15，发送时先计算 87 除 15 的余数，为 12，将这个余数与 87 一起发送，即 8712，接收时先计算 82 除 15 的余数，为 7，不等于 12，就认为传输的数据出错，这样检错的概率并非百分之百，例如87 错成 72 就检测不出来，但总体来说，检错概率已经非常高了。CRC 计算方法第一，CRC 有一个生成多项式 P(x)，其作用等同于除数 15，将其写成比特串，转化规则如图：- 第二，如果 P(x) 的比特串是 n 位，在发送数据后补 n-1 个 0。例如 P(x)为 1101，就要补 000。- 第三，做模2除法。注意模二除法不是二进制除法。- 第四，用余数替换补的 0，形成发送数据，101001001。- 第五，接收方用接收数据 101001001 除以 P(x)1101，如果能整除，就表示没有错（等同与原理中的余数相同），如果不能整除，就表示出错了（等同与原理中的余数不相等）。## 停止等待协议（Stop-and-Wait protocol）如果两个主机间数据传输时，接收方的速度永远不会低于发送方的速度；传输的数据帧不会出错，也不会丢失，完全理想化的数据传输，那就没有什么问题，当然也不需要解决问题的办法，也就不需要协议。现在假设，没有差错，但是接收方的速度低于发送方的速度，怎么办？显然控制的思路只能是快的一方牵就慢的一方，就是由慢的一方指挥快的一方。具体来说，就是发送方每发送一帧就停下来，等待；收到 ACK 发送下一帧，接收方则是等待，收到数据帧，发送 ACK（确认 Acknowledgment ），等待下一帧。停下来，等待就是停止等待协议的由来。停止等待协议当然不仅仅需要这一个问题，其需要解决的问题如下：- 接收方的速度低于发送方的速度；- 传输的数据帧可能出错；- 数据帧可能丢失，确认帧 ACK 也可能丢失；确认号接收方收到一个数据帧，并校验正确，给发送方一个确认 ACKn，ACKn 表示“第 n-1 号帧已经收到，现在期望接收第 n 号帧”。确认号是接收方预期接收的下一帧的序号。差错数据帧出错时，接收方收到一个数据帧，校验时发现数据帧出错，接收方丢弃此数据帧，此外不做任何事，即不发送 ACK。发送方发送完数据帧后在停止等待 ACK，然而此时不会有 ACK，发送方就等死在这里了。重传定时器发送方设计一个重传定时器的机制，发送方每发送一个数据帧，就启动一个倒计时的重传定时器，如果在超时 timeout 之前收到确认，就关闭定时器并发送下一帧。如果超时，就重传之前的帧。丢失接收方收到一个数据帧，校验正确发送 ACK，等待接收下一帧，如果确认帧丢失，发送方收不到确认，超时后重传旧帧，而接收方在等待新帧，此刻发送方与接收方的状态不同步，如何区分新帧与重传的帧？帧编号停等协议使用序号和确认号，以区分重传的数据帧。发送方发送帧时使用序号，接收方使用确认号。信道利用率停止等待协议的优点是简单，但缺点是信道利用率太低。信道利用率公式：$U=\frac{T_D}{T_D+RTT+T_A}$，其中：- $T_D$：数据帧传输时延- $RTT$：数据帧+确认帧传播时延- $T_A$：确认帧传输时延举例：假设主机甲与主机乙使用停等协议传输数据，若甲乙之间的单向传播延迟是 15ms，数据帧长为 1000 字节，信道宽带为 100Mbps，乙每收到一个数据帧立即利用一个短帧（忽略其发送时延）进行确认，则信道利用率为：发送一个数据帧到 100Mbps 链路所需时间为：$T_D = \frac{1000 \ast 8bits}{100 \ast 10^6bit/s }= 80\mu s$。发送方在 t=0 时刻发送，15ms 后第 1 个比特到达主机乙，15.08ms 时主机乙收到最后一比特，开始发送确认帧，由于确认帧很短，我们忽略其发送时延，在30.08ms 时，确认帧到达主机甲，总时间周期为T𝐷 + RTT + T𝐴(忽略) = 30.08ms，信道利用率为0.0027。信道利用率为 0.27%，就是说发送方只有百分之0.27的时间是忙的。停止等待协议信道利用率太低了。## GBN 协议我们讨论一个可以获得较高信道利用率的协议：连续 ARQ 协议(Go-back-NProtocol)，或称 GBN 协议，也称为滑动窗口协议（Sliding Window Protocol）。发送方在接收到确认之前，发送一组数据帧，而不是发送一个数据帧就停止等待确认。### 确认号在 GBN 协议中，采用累积确认的方式，确认号是希望接收的下一个分组序号。举例，ACK7 表示序号 6 以内的所有帧都已正确收到了，等待接收 7 号帧。### 发送窗口在 GBN 协议中，发送一组帧，然后停止等待确认。发送窗口定义了最多可以发送多少个数据帧。举例如下图：一个大小为 7 的窗口，窗口左侧是已确认，已丢弃的帧，窗口内有色的是已发送的，尚未收到确认的帧，0，1，2，3 号帧，发送方需要等待，可称为未完成帧，窗口内无色的是可发送还未发送的帧，是 4，5，6 号帧，窗口右侧是不能发送的帧。描述发送窗口需 3 个变量：- $S_f$：发送窗口，第一个未完成分组。完成指的是发送方接收到确认方的确认帧。- $S_n$：发送窗口，下一个待发送分组。- $S_{size}$：发送窗口，大小。当 ackNo 大于等于 $S_f$ 且小于 $S_n$ 的无错 ACK 到达时，发送窗口可以滑动一个或多个槽。举例，当发送方收到 $ACK_6$，表示 4，5 号帧已正确接收，窗口滑动，状态如下图。接收窗口在 GBN 协议中，接收窗口大小总是 1。只有序号在接收窗口内的数据帧才接收。任何失序的分组都会被丢弃，需要重发。描述接收窗口控制只需 1 个变量 $R_n$，表示其期待下一次接收的帧，重传定时器在 GBN 协议中，只使用一个计时器。接收窗口大小总是 1。当定时器超时，发送方重发所有未完成分组。例如，假设发送方已经发送了分组 6（$S_n=7$），但是唯一的计时器终止。如果 $S_f=3$，这意味着分组 3、4、5 和 6 没有被确认；发送方回退并重发分组 3、4、5 和 6。发送方发送分组。发送方会开启唯一的计时器。$S_n$ 的值增长，（$S_n=S_n+1$）如果达到窗口值进入阻塞状态。如果 ACK 到达，其 ackNo 与一个未完成分组有关，那么发送方滑动窗口（令 $S_f=ackNo$），并且如果所有未完成分组都被确认（$ackNo=S_n$），那么关闭计时器。如果并不是所有未完成分组都被确认，那么重新开启计时器。如果超时发生，发送方重发所有未完成分组并重新开启计时器。接收方如果 $seqNo=R_n$ 的无错分组到达，之后窗口滑动，$R_n=（R_n+1）$。$ackNo=R_n$的 ACK 被发送。如果 seqNo 在窗口之外的无错分组到来，分组被丢弃，但是 $ackNo=R_n$的 ACK 被发送。发送窗口的最大值当用 n 个比特进行帧编号时，接收窗口的大小为 1，则只有在发送窗口的大小$W_T ≤ 2^n − 1$时，连续 ARQ 协议才能正确运行。例如，当采用 2bit 编码时，发送窗口的最大值是 3 而不是 4。下图比较 4 与 3 两种情况。如果窗口的大小是 4 并且所有确认都丢失，发送方将会重传旧的所有 4 个帧。但是接收方等待接收的是新的 0 号帧，由于窗口匹配，接收 0 号帧，接收方认为接收的是新的 0 号帧，这是一个错误。如果窗口大小为 3 并且所有三个确认都丢失，那么超时并且重发所有 3 个分组，接收方现在期待 3 号帧，而不是 0 号帧，因此重传分组被正确丢弃。不会产生错误。为能正确区分重传的帧，应保证在$W_T+W_R$的窗口内不出现重复序号，即$W_T + W_R ≤ 2^n$，我们将 WT 和 WR 拼接在一起，在$W_T + W_R$窗口内如果出现重复序号，就会发生上述的错误，如果不出现重复的序号，就不会发生上述的错误。GBN 协议的接收窗口为 1，所以发送窗口最大为$2^n − 1$## CSMA/CD共享信道有一个基本问题，碰撞 （Collision）。若某时刻两帧同时发出，会相互重叠，结果使信号无法辨认，称为碰撞。如下图便是碰撞：碰撞的结果是两个帧都变得无用。解决碰撞的思路大致有两类：- 一类思路是将工作做在前面，预防碰撞，即受控接入：各主机不能任意发送数据，必须服从一定的控制。如令牌环网，拥有令牌的主机可发送数据，没有令牌的主机只能接收数据，令牌如击鼓传花般依次传递。- 另一类思路是将工作做在后面，撞就撞吧，做好事故的处理，即随机接入：所有主机都可以根据自己的意愿随机地发送数据。CSMA/CD（Carrier Sense Multiple Access with Collision Detection）载波监听多点接入/碰撞检测。载波监听（Carrier Sense）指监测信道上有无数据信号传输，监测方法是判断基带上是否有脉冲二进制 0 或 1。多点接入（Multiple Access）同时有多个站点连接在信道上。显然，使用随机接入的方式是无法避免碰撞的。在随机接入的情况下，需要完成几项工作：- 尽量减少碰撞- 是否碰撞有明确结论- 碰撞之后的事故处理CSMA/CD 协议完成这些工作的原理，简缩为三句口诀。- 先听后发- 边发边听- 冲突重发### 先听后发我们当然希望尽量减少碰撞，想个什么办法呢？就是在发送数据帧之前，先监听信道。“载波监听”就是“发送前先监听”，如果信道上有数据帧，当然就先不发送数据帧，否则一发送数据帧就产生碰撞，碰撞了就毫无意义。当监听信道时，如果信道忙有数据帧，站点回去睡一段随机时间，然后再回来监听信道，这种策略称非坚持型 CSMA。当监听信道时，如果信道忙有数据帧。站点不是回去睡一会，而是蹲守在这儿，继续监听直到信道空闲，这种策略称坚持型 CSMA。当监听到信道空闲下来时，站点立即就发送数据，称 1-坚持型 CSMA。当监听到信道空闲下来时，站点并不立即发送数据，先抛一次硬币，如果是字就发，如果是花就不发，就是说以概率 p 发送数据，称 p-坚持型 CSMA。### 边发边听站点发出数据帧后，是否碰撞需要有明确的结论。就需要“碰撞检测”（Collision Detection）。如何检测呢？站点检测信道上的信号电压大小，当几个站同时在总线上发送数据时，总线上的信号电压摆动值将会增大（互相叠加）。当检测到的信号电压摆动值超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞，“碰撞检测”也称为“冲突检测”。假设 A 站点与 B 站点是网络最远的两端，从 A 站点发出一数据帧，到达 B站点的所花费的时间为$\tau$，A 站点发出一数据帧，就在即将到达 B 站的时刻，B站发出一数据帧，立即发生碰撞，碰撞信号继续到达 A 站，A 站在经过时间 $2\tau$（两倍的端到端传播时延）发现碰撞。所以，$发送站点监听时间&gt;2\tau$，就可以得到是否碰撞的明确结论。$2\tau$ 也即称为争用期，或碰撞窗口。所以为得到是否碰撞的明确结论，只需要$监听时间&gt;2\tau$就可以了。冲突重发发生碰撞，两个数据帧都损坏，当然需要重发。但是如果两个站点都立即重发数据帧，又会再次碰撞，两个站点发送时刻最好能够错开一些。CSMA/CD 协议使用截断二进制指数退避算法，发生碰撞的站在停止发送数据后，要推迟（退避）一个随机时间才能再发送数据。重传次数 k，$k=Min[重传次数,10]$从整数集合$[0,1,…,(2^k-1)]$中随机地取出一个数，记为 r。重传所需的时延就是 r 倍的基本退避时间。基本退避时间一般是取为争用期。当重传达 16 次仍不能成功时即丢弃该帧，并向高层报告。使用 CSMA/CD 协议后不能进行全双工通信而只能进行双向交替通信（半双工通信）。每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率。10BASE-T 以太网10Base-T以太网使用的是1-坚持型CSMA / CD。10BASE-T 以太网不用同轴电缆而用无屏蔽双绞线，降低了成本，还增加了一种可靠性非常高的设备，叫做集线器（hub）。正是这两个原因，使得 10BASE-T以太网拥有很低的成本和很高的可靠性，迅速在局域网中占据了统治地位。10BASE-T 以太网定义：争用期的长度为 51.2 us，而$监听时间 &gt; 2 \tau$ 便等价于$发送数据帧的时间 &gt; 2\tau$。可得：$\frac{帧长L}{10Mbps}&gt;51.2 \mu s$，即$L &gt; 512bit$。最短帧长 64 字节。帧间最小间隔为 9.6us，因为要给双方留下缓冲时间。站点到集线器的距离不超过 100m，为了保证双绞线上的信号不会出错。如果数据帧太长就会出现有的主机长时间不能发送数据，而且有的发送数据可能超出接收端的缓冲区大小，造成缓冲溢出。为避免单一主机占用信道时间过长，规定了以太网帧的数据部分最大长度为1500。网卡在主机内部，需要 10BASE-T 的网络接口板又称为通信适配器（adapter）或网络接口卡 NIC(Network Interface Card)，或“网卡”。网络适配器的重要功能：对数据进行串行/并行传输的转换编码与译码即曼彻斯特编码与译码。链路管理主要是 CSMA/CD 协议的实现。数据的封装与解封封装以太网帧。网卡的第一，第二项功能属于物理层的功能。第三项 CSMA/CD 协议的原理上文也介绍了，在此主要介绍一下以太网帧，也称 MAC 帧。网络适配器工作在数据链路层和物理层。生产网卡时，在网卡的 ROM 固化了 6 字节的 MAC 地址，因此 MAC 地址也叫做硬件地址(hardware address)或物理地址。MAC 地址唯一标识了一块网卡。MAC 地址字段是 6 字节（48 位），前三个字节（即高位 24 位），是生产厂家标识，称为组织唯一标识符，后三个字节（即低位 24 位）由厂家自行指派的产品串号，称为扩展唯一标识符，必须保证串号没有重复。网卡将上一层交下来的数据加上首部和尾部，成为以太网的帧。接收时将以太网的帧剥去首部和尾部，然后送交上一层。常用的以太网 MAC 帧格式有两种标准：DIXEthernetV2 标准和 IEEE 的 802.3 标准，最常用的 MAC 帧是以太网 V2 的格式。### 网卡工作要点- 适配器从网络层获得一个分组，加上以太网的首部和尾部，组成以太网帧，放入适配器的缓存中，准备发送。- 若适配器检测到信道空闲，就发送这个帧。若检测到信道忙，则继续检测并等待信道转为空闲（加上 96 比特时间），然后发送这个帧。- 在发送过程中继续检测信道，若一直未检测到碰撞，就顺利把这个帧成功发送完毕。若检测到碰撞，则中止数据的发送，并发送人为干扰信号。- 在中止发送后，适配器就执行指数退避算法，等待 r 倍 512 比特时间后，返回到步骤 2。对于检查出的无效 MAC 帧就简单地丢弃。以太网不负责重传丢弃的帧。早期以太网采用无源的总线结构。现在采用以太网交换机的星形结构成为以太网的首选拓扑。总线以太网使用 CSMA/CD 协议，以半双工方式工作。以太网交换机以全双工方式工作，不使用共享总线，没有碰撞问题，因此不使用CSMA/CD 协议。但仍然采用以太网的帧结构。## 网桥与交换机我们看下面一个拓扑，某学院有三个系，各自有一个以太网，三个以太网是三个独立的碰撞域，如果用集线器连成一个更大的以太网，同时也形成一个更大的碰撞域。连接的范围扩大了，但碰撞也多了，能不能只扩大范围，不扩大碰撞呢？### 网桥有一种网络设备，称为网桥（bridge），能只扩大范围，不扩大碰撞。网桥工作在数据链路层，其内部维护一张转发表，根据 MAC 地址转发数据帧。当网桥收到一个帧时，根据此帧的目的 MAC 地址，检索转发表，然后再转发帧到接口。我们看下面的一个拓扑图，先不考虑网桥的转发表是怎么来的，先看一下网桥 B1 和网桥 B2 的转发表的最终形态，可以看出，转发表的本质就是拓扑图的描述，推想一下，这是必然的，网桥若要正确转发数据帧，就需要知道各主机与其的位置关系。那么，这张转发表又是怎么来的呢？网桥 B1 和网桥 B2 刚上电时，其内部转发表都是空表，这时，主机 A 给主机 B 发送一数据帧，网桥 B1 的接口 1 收到这帧，网桥 B1 能判断出主机 A 在它的接口 1 侧，但判断不出主机 B 在哪侧，首先转发，把帧向网桥除接口 1 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“A 接口 1”填入转发表，网桥 B1 就学到 1 个条目。网桥 B2 收到网桥 B1 的转发帧，网桥 B2 也能判断出主机 A 在它的接口 1 侧，但判断不出主机 B 在哪侧，首先转发，把帧向网桥除接口 1 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“A 接口 1”填入转发表，网桥 B2 也学到 1 个条目。接下来，第二个数据帧是主机 F 给主机 C 发送的，网桥 B2 的接口 2 收到这帧，网桥 B2 能判断出主机 F 在它的接口 2 侧，但判断不出主机 C 在哪侧，首先转发，把帧向网桥除接口 2 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“F 接口 2”填入转发表，网桥 B2 就学到 2 个条目。网桥 B1 收到网桥 B2 的转发帧，网桥 B1 也能判断出主机 F 在它的接口 2 侧，但判断不出主机 C 在哪侧，首先转发，把帧向网桥除接口 2 以外的所有接口转发此帧（这样做可保证找到目的站）。第二，将“F 接口 2”填入转发表，网桥 B1 也学到 2 个条目。第三个数据帧是主机 B 给主机 A 发送的，网桥 B1 的接口 1 收到这帧，网桥B1 能判断出主机 B 在它的接口 1 侧，由于已经学到 2 个条目，网桥 B1 由前 2个条目，知道主机 A 在接口 1 侧的，所以不转发。第二，将“B 接口 1”填入转发表，网桥 B2 就学到 3 个条目。因为网桥 1 没转发，网桥 B2 没收到任何数据帧，网桥 B2 仍维持着 2 个条目。经过一段时间，各主机发送了很多数据帧，网桥 B1 和网桥 B2 就学习到了完整的转发表。但是需要注意，在下图中三个碰撞域内是可以进行通信，但是跨碰撞域之后还是会产生碰撞。如A给D发消息时，B和C不能进行通信。交换机网桥只有 2 个接口，可是谁规定网桥只能有 2 个接口呢，网桥也可以有更多接口，这就是以太网交换机，以太网交换机（switch）实质上就是一个多接口的网桥。通常都有十几个或更多的接口。每个接口都直接与一个单台主机或另一个以太网交换机相连，工作在全双工方式。以太网交换机工作原理也是按转发表转发数据帧，工作在数据链路层，是第二层交换机，其内部的帧交换表（又称为地址表）是通过自学习算法自动地逐渐建立起来的。我们看下面的一个拓扑图，先不考虑交换机的转发表是怎么来的，先看一下交换机的转发表的最终形态，可以看出，转发表的本质就是拓扑图的描述，推想一下，这是必然的，交换机若要正确转发数据帧，就需要知道哪个接口与哪个主机相连。那么，这张转发表又是怎么来的呢？交换机启动时，其内部转发表是空表。A 先向 B 发送一帧，交换机收到帧后，先执行转发功能。查找交换表，如果没有查到，洪泛，交换机向除接口 1 以外的所有的接口广播这个帧。再执学习发功能，把这个帧的源地址 A 和接口 1 写入交换表中。当所有主机都发送过数据帧后，交换机就将交换表学完整了。考虑到可能有时要在交换机的接口更换主机，或者主机要更换其网络适配器，这就需要更改交换表中的项目。为此，在交换表中每个项目都设有一定的有效时间。过期的项目就自动被删除。以太网交换机的这种自学习方法使得以太网交换机能够即插即用，不必人工进行配置，因此非常方便。交换机工作原理是按转发表（MAC 表）转发数据帧，转发表的本质就是拓扑图的描述。要把交换机转发表的本质牢固的记住：交换机就是要知道哪个接口与哪个主机相连。### MAC 表抖动与广播风暴网桥和交换机的使用可能会发生一下问题，我们以网桥举例：- 会发生 MAC 表抖动（flapping）的问题：就是说同一个MAC地址在一台交换机上的两个及以上接口都学习到，导致MAC地址表中关于此MAC地址与交换机的端口对应不断改变。- 数据帧会循环兜圈子，形成广播风暴。在拓扑图上，我们可以看到 帧F 到 网桥1 的时候将 F 转发出去，设为 F1，此时 网桥1 学习 到MACA（主机A的MAC地址）在下方接口。F1 到 F2 是 网桥2 学习到 MACA 在 上方接口，但是 帧F 到达 网桥2 的时候网桥2学习到MACA在下方接口，这便是MAC表抖动。同样的 F2 到 网桥1 的时候 网桥1 学习到 MACA 在上方接口，也会发生抖动。（注意：F、F1、F2的MAC地址一致）如果数据帧按照我们上面所述的方式运行，他们会在网桥1和网桥2之间不停的转圈。至于交换机自然也会出现上述的问题。解决的办法，就是在逻辑上将环打断，环打断就是棵树。一句话，就是将环打断生成树，简称为“生成树”。在网桥或交换机上运行生成树协议 STP（Spanning Tree Protocol）。生成树协议的要点是：不改变网络的实际拓扑，但在逻辑上则切断某些链路，使得从一台主机到所有其他主机的路径是无环路的树状结构，从而消除了兜圈子现象。无线局域网与 CSMA/CAIEEE802.11是一个有固定基础设施的无线局域网WLAN（Wireless Local Area Network）的国际标准。简单地说，802.11 就是无线以太网的标准：使用星形拓扑，其中心叫做接入点 AP(Access Point)，在 MAC 层使用 CSMA/CA 协议，802.11 无线局域网又称为 Wi-Fi（Wireless-Fidelity，意思是“无线保真度”）。以下讨论都是这种无线局域网。无线局域网最小构件是基本服务集 BSS（Basic Service Set），基本服务集里面的基站叫做接入点 AP（AccessPoint，AP 的逻辑功能等同与以太网的集线器），一个基本服务集通过接入点 AP 连接到一个主干分配系统 DS（Distribution System），然后再接入到另一个基本服务集，构成了一个扩展的服务集 ESS。无线局域网没有碰撞检测无线局域网逻辑上也是共享信道，采用的也是随机接入的思路。但是，无线局域网与有线局域网有一个重要的差异，无线局域网没有碰撞检测（Collision Detection）。“碰撞检测”要求一个站点在发送本站数据的同时，还必须不间断地检测信道，但接收到的信号强度往往会远远小于发送信号的强度，在无线局域网的设备中要实现这种功能就花费过大。隐蔽站问题，如下图，有 ABCD 四个站，但 A 只知道有 B，不知道有 CD。A 和 C 互相检测不到对方的无线信号时，都以为 B 是空闲的，都向 B 发送数据，结果发生碰撞。隐蔽站问题使“碰撞检测”失去意义。由于以上两个原因，无线局域网没有碰撞检测。为什么没有碰撞检测就成为问题了呢？因为没有碰撞检测引发了两个问题：怎么确定发出的数据帧是否发生碰撞，是否碰撞要有明确的结论，这个结论怎么下？在碰撞发生时，就没有感觉，撞了发送方也不会停止发送数据，仍发送数据，直到发送完才停止。不是“撞-停”的情况，而是“撞撞撞撞撞撞···”的情况，碰撞的损失过大。这两个问题都需要解决。先说第一个问题，是否碰撞的结论怎么下？无线网使用了停止等待协议，由接收方发送 ACK 帧来表示正确收到数据帧，否则引发超时重传。再说第二个问题，对于这个问题的解决办法，当然就是“尽量不碰撞”。无线网为了“尽量不碰撞”，设计了一个复杂的协议 CSMA/CA。注意，CSMA/CA协议只能做到“尽量少碰撞”，做不到“完全不碰撞”。第一个问题仍需解决，无线网的 CSMA/CA 替代不了无线网的停等协议。CSMA/CA 协议无线局域网没有碰撞检测，所以有线的 CSMA/CD 就被阉割为 CSMA，可不甘心，还想进一步的减少碰撞，就又加了一个 CA（Collision Avoidance 碰撞避免）功能。802.11 就使用 CSMA/CA 协议。而在使用 CSMA/CA 的同时，还增加使用停止等待协议。帧间间隔 IFS所有的站在完成发送后，必须再等待一段很短的时间（继续监听）才能发送下一帧。这段时间的通称是帧间间隔 IFS（Inter Frame Space）。SIFS，即短（Short）帧间间隔，长度为 28us，使用 SIFS 的帧类型有：ACK 帧、CTS 帧。DIFS，即分布协调功能帧间间隔，长度为 128us。DIFS 用来发送数据帧和管理帧。争用窗口（二进制指数退避）信道从忙态变为空闲时，任何一个站要发送数据帧时，不仅都必须等待一个DIFS 的间隔，而且还要进入争用窗口，各站就要执行退避算法。802.11 使用二进制指数退避算法。这样做就减少了发生碰撞的概率。但其避退算法和CSMA/CD的有区别。第i次退避就在$2^{2+i}$个时隙中随机地选择一个。这就是说，第1次退避是在8个时隙（而不是2个）中随机选择一个，而第2次退避是在16个时隙（而不是4个）中随机选择一个。 这样做的目的是减少碰撞。发送算法如下：如果某站点检测到信道空闲，会等待一个DIFS发送该帧。否则该站点选取一个随机值进行避退，并且在检测到信道忙的时候递减该值。当检测不忙的时候计数值保持不变。当计数值减为0的时候（此时信道一定为空闲），该站点发送整个数据帧并等待确认。如果发送方收到确认，发送站点知道他的帧被目的站正确接收了，如果该站点要发送另一帧它需要从第二步开始进行。如果未收到，执行回退算法，此次会在一个更大的范围里选取。需要注意，上图中的退避区间内退避算法得到的计数值不一定在减少。冻结指的就是再次检测到信道忙的时候不再减少计数值。### 信道预约为了更好地解决隐蔽站带来的碰撞问题，802.11 允许要发送数据的站对信道进行预约。有线与无线的对比无线局域网与有线局域网都是使用随机接入的方式，都是无法绝对避免碰撞的。在这种情况下，都需要考虑以下问题：尽量减少碰撞、是否碰撞要有明确结论、碰撞之后的事故处理。简单做一对比：无线网中碰撞造成的损失更大，就需要在减少碰撞的方面做更多的工作，精心设计了 CSMA/CA 协议，包含帧间间隔，争用窗口（二进制指数退避），信道预约三种机制，但仍无法完全避免碰撞。由于没有碰撞检测，是否碰撞的明确结论，由接收方发送 ACK 确认帧机制。碰撞事故处理是空，是因为将重发中的二进制指数退避已经融合到 CSMA/CA 协议中。802.11 局域网的 MAC 帧802.11 帧共有三种类型：控制帧、数据帧和管理帧。只简单讨论数据帧。数据帧的三大部分，MAC 首部，共 30 字节。帧的复杂性都在帧的首部。帧主体，数据部分不超过 2312 字节，通常都是小于 1500 字节。帧检验序列 FCS 是尾部，共 4 字节。802.11 数据帧最特殊的地方就是有四个地址字段。地址 4 用于自组网络（博主暂未接触）。我们在这里只讨论前三种地址。地址 1 总是帧将访问的下一个设备的地址，地址 2 总是帧离开的前一个设备的地址，如果地址 1 没有定义最后的目的地址，地址 3 就是最后的目的站点的地址，如果地址 2 没有定义原始源地址，地址 3 就是原始源站点地址。站点 A 向 B 发送数据帧，但这个数据帧必须经过 AP 转发。首先站点 A 发送数据帧到 AP1，然后 AP1 把数据帧发送给 B。举例：A-&gt;AP1 时：ARPARP（Address Resolution Protocol），根据 IP 地址查询MAC 地址。ARP 协议的工作原理如下图，有 ARP 请求（Request）和 ARP 回答（Reply）两个报文。ARP 报文封装成 Mac 帧，是 Mac 帧的负载，mac 帧类型值 0806 指示 mac 帧的数据部分是 ARP 报文。ARP 请求（Request）是广播，ARP 回答（Reply）是单播，见下图：ARP 请求报文所封装的 Mac 帧，目的 Mac 地址是 FF-FF-FF-FF-FF-FF，这 个地址是广播地址，交换机就会广播这个帧。ARP 请求报文和校园广播的大喇叭是不是很像呢？如果目的主机也在你的网络里，你用大喇叭喊它，要来它的mac 地址，就可以封装 mac 帧了。注意，ARP 直接封装为 MAC 帧，不是封装为 IP 报。从这点看，我个人更赞同将 ARP 理解为链路层协议。报文格式：RARPARP 是设备通过自己知道的IP地址来获得自己不知道的物理地址的协议。假如一个设备不知道它自己的IP地址，但是知道自己的物理地址，应该怎么办呢？RARP（逆地址解析协议）正是针对这种情况的一种协议。RARP以与ARP相反的方式工作。RARP发出要反向解析的物理地址并希望返回其对应的IP地址，应答包括由能够提供所需信息的RARP服务器发出的IP地址。虽然发送方发出的是广播信息，RARP规定只有RARP服务器能产生应答。许多网络指定多个RARP服务器，这样做既是为了平衡负载也是为了作为出现问题时的备份。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-data-redis]]></title>
    <url>%2F2019%2Fspring-data-redis%2F</url>
    <content type="text"><![CDATA[配置properties1234567redis.host=redis.port=6379redis.pass=redis.database=0redis.maxIdle=300redis.maxWait=3000redis.testOnBorrow=trueapplicationContext-redis.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:property-placeholder location="classpath*:properties/*.properties" /&gt; &lt;!-- redis 相关配置 --&gt; &lt;bean id="poolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxIdle" value="$&#123;redis.maxIdle&#125;" /&gt; &lt;property name="maxWaitMillis" value="$&#123;redis.maxWait&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;redis.testOnBorrow&#125;" /&gt; &lt;/bean&gt; &lt;bean id="JedisConnectionFactory" class="org.springframework.data.redis.connection.jedis.JedisConnectionFactory" p:host-name="$&#123;redis.host&#125;" p:port="$&#123;redis.port&#125;" p:password="$&#123;redis.pass&#125;" p:pool-config-ref="poolConfig" /&gt; &lt;bean id="redisTemplate" class="org.springframework.data.redis.core.RedisTemplate"&gt; &lt;property name="connectionFactory" ref="JedisConnectionFactory" /&gt; &lt;property name="keySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;/property&gt; &lt;property name="valueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;/property&gt; &lt;property name="hashKeySerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;/property&gt; &lt;property name="hashValueSerializer"&gt; &lt;bean class="org.springframework.data.redis.serializer.StringRedisSerializer" /&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import java.util.List;import java.util.Set;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath*:spring/applicationContext-redis.xml")public class MySpringDataJedis &#123; @Autowired private RedisTemplate redisTemplate; @Test public void test01() &#123; // 设置String redisTemplate.boundValueOps("user").set("张三丰"); // 取String String str = (String)redisTemplate.boundValueOps("user").get(); System.out.println(str); // 删除 redisTemplate.delete("user"); &#125; @Test public void test02() &#123; // 设置Set redisTemplate.boundSetOps("nameset").add("曹操"); redisTemplate.boundSetOps("nameset").add("刘备"); redisTemplate.boundSetOps("nameset").add("孙权"); // 获取Set Set&lt;String&gt; nameset = redisTemplate.boundSetOps("nameset").members(); for(String e : nameset) System.out.println(e); // 删除值 redisTemplate.boundSetOps("nameset").remove("孙权"); // 获取Set nameset = redisTemplate.boundSetOps("nameset").members(); for(String e : nameset) System.out.println(e); // 删除 redisTemplate.delete("nameset"); &#125; @Test public void test03() &#123; // 右压栈：新加入的元素放在右端 redisTemplate.boundListOps("namelist1").rightPush("刘备"); redisTemplate.boundListOps("namelist1").rightPush("关羽"); redisTemplate.boundListOps("namelist1").rightPush("张飞"); List&lt;String&gt; list = redisTemplate.boundListOps("namelist1").range(0, 10); for(String e : list) System.out.println(e); // 左压栈：新加入的元素放在左端 redisTemplate.boundListOps("namelist2").leftPush("刘备"); redisTemplate.boundListOps("namelist2").leftPush("关羽"); redisTemplate.boundListOps("namelist2").leftPush("张飞"); list = redisTemplate.boundListOps("namelist1").range(0, 10); for(String e : list) System.out.println(e); // 从索引从 0开始 String s = (String) redisTemplate.boundListOps("namelist1").index(1); System.out.println(s); // 移出指定个数的 某值 redisTemplate.boundListOps("namelist1").remove(1, "刘备"); list = redisTemplate.boundListOps("namelist1").range(0, 10); for(String e : list) System.out.println(e); // 删除 redisTemplate.delete("namelist1"); redisTemplate.delete("namelist2"); &#125; @Test public void test04() &#123; redisTemplate.boundHashOps("namehash").put("a", "唐僧"); redisTemplate.boundHashOps("namehash").put("b", "悟空"); redisTemplate.boundHashOps("namehash").put("c", "八戒"); redisTemplate.boundHashOps("namehash").put("d", "沙僧"); Set s = redisTemplate.boundHashOps("namehash").keys(); System.out.println(s); List values = redisTemplate.boundHashOps("namehash").values(); System.out.println(values); // 根据KEY提取值 Object object = redisTemplate.boundHashOps("namehash").get("b"); System.out.println(object); // 根据KEY移除值 redisTemplate.boundHashOps("namehash").delete("c"); &#125;&#125;]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机体系结构]]></title>
    <url>%2F2019%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[github的速度太慢，请耐心等待一下…]]></content>
      <categories>
        <category>体系结构</category>
      </categories>
      <tags>
        <tag>体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM-Maven-Dubbo搭建SOA开发环境]]></title>
    <url>%2F2019%2FSSM-Maven-Dubbo%E6%90%AD%E5%BB%BASOA%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[整体结构安装zookeeper第一步：安装 jdk把 zookeeper 的压缩包上传到 linux 系统。解压缩压缩包进入 zookeeper 目录，创建 data 文件夹。进入 conf 目录 ，把 zoo_sample.cfg 改名为 zoo.cfg打开 zoo.cfg , 修改 data 属性：dataDir=%zookeepe_home%/datazookeeper 服务启动：./zkServer.sh start服务关闭：./zkServer.sh stop查看状态：./zkServer.sh status创建工程pom工程：parent、managerjar工程：common、dao、interface、pojowar工程：service、web其中interface和service是聚合在manager下的（new maven module），manager、dao、interface、pojo、web是独立的Maven工程的（mew maven project）。除parent外所有的project的父工程都是parent。工程配置文件parent：用来管理整个项目的版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 集中定义依赖版本号 --&gt; &lt;properties&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;pagehelper.version&gt;5.0.0&lt;/pagehelper.version&gt; &lt;servlet-api.version&gt;2.5&lt;/servlet-api.version&gt; &lt;dubbo.version&gt;2.8.4&lt;/dubbo.version&gt; &lt;zookeeper.version&gt;3.4.7&lt;/zookeeper.version&gt; &lt;zkclient.version&gt;0.1&lt;/zkclient.version&gt; &lt;mybatis.version&gt;3.2.8&lt;/mybatis.version&gt; &lt;mybatis.spring.version&gt;1.2.2&lt;/mybatis.spring.version&gt; &lt;mybatis.paginator.version&gt;1.2.15&lt;/mybatis.paginator.version&gt; &lt;mysql.version&gt;5.1.32&lt;/mysql.version&gt; &lt;druid.version&gt;1.0.9&lt;/druid.version&gt; &lt;commons-fileupload.version&gt;1.3.1&lt;/commons-fileupload.version&gt; &lt;freemarker.version&gt;2.3.23&lt;/freemarker.version&gt; &lt;activemq.version&gt;5.11.2&lt;/activemq.version&gt; &lt;security.version&gt;3.2.3.RELEASE&lt;/security.version&gt; &lt;solrj.version&gt;4.10.3&lt;/solrj.version&gt; &lt;ik.version&gt;2012_u6&lt;/ik.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;$&#123;zkclient.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.28&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.11.0.GA&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;$&#123;pagehelper.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.paginator.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.csource.fastdfs&lt;/groupId&gt; &lt;artifactId&gt;fastdfs&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 文件上传组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;$&#123;commons-fileupload.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 缓存 --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.7.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;$&#123;freemarker.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;$&#123;activemq.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 身份验证 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-web&lt;/artifactId&gt; &lt;version&gt;4.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-config&lt;/artifactId&gt; &lt;version&gt;4.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.penggle&lt;/groupId&gt; &lt;artifactId&gt;kaptcha&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-cas&lt;/artifactId&gt; &lt;version&gt;4.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jasig.cas.client&lt;/groupId&gt; &lt;artifactId&gt;cas-client-core&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;!-- 排除log4j包冲突 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- solr客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.solr&lt;/groupId&gt; &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt; &lt;version&gt;$&#123;solrj.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.janeluo&lt;/groupId&gt; &lt;artifactId&gt;ikanalyzer&lt;/artifactId&gt; &lt;version&gt;$&#123;ik.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;version&gt;4.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xml-apis&lt;/groupId&gt; &lt;artifactId&gt;xml-apis&lt;/artifactId&gt; &lt;version&gt;1.4.01&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt;pojo：不用依赖其他的任何包123456789&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-pojo&lt;/artifactId&gt;&lt;/project&gt;common：提供工具类，依赖pojo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-common&lt;/artifactId&gt; &lt;!-- 工具类工程: 1,抽取公共坐标 2,存放工具类 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 文件上传组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;dom4j&lt;/groupId&gt; &lt;artifactId&gt;dom4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;xml-apis&lt;/groupId&gt; &lt;artifactId&gt;xml-apis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;dao：依赖pojo和common123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-dao&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- Mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- MySql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- pojo --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- common --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;manager：配置tomcat插件，依赖dao12345678910111213141516171819202122232425262728293031323334353637383940&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-manager&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;china-software-cup-interface&lt;/module&gt; &lt;module&gt;china-software-cup-service&lt;/module&gt; &lt;/modules&gt; &lt;!-- 后台管理聚合父工程: 1,抽取子工程公共坐标 2,聚合管理子工程(统一打包,部署,启动) 父工程: tomcat插件 9000 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-dao&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 服务启动端口:从9000开始 --&gt; &lt;port&gt;9000&lt;/port&gt; &lt;!-- /把项目发布tomcat服务器ROOT目录下.--&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt;interface：依赖pojo123456789101112131415161718&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-manager&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-interface&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;service：依赖pojo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-manager&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-service&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!-- service: 1,spring 2,dao 3,pojo 4,common 5,发布服务:dubbo,zookeeper --&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-pojo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;web：依赖interface12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-parent&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;china-software-cup-web&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!-- 运营商表现层: 1,servlet 2,服务接口 3,spring 4,引入服务:dubbo,zookeeper --&gt; &lt;dependencies&gt; &lt;!-- Spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;china-software-cup-interface&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 前台启动端口:从8080开始 --&gt; &lt;port&gt;8080&lt;/port&gt; &lt;!-- /把项目发布tomcat服务器ROOT目录下. --&gt; &lt;path&gt;/&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;service的web.xml12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;china-software-cup-service&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 加载spring容器 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:spring/applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;/web-app&gt;web的web.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;china-software-cup-web&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 指定加载的配置文件 ，通过参数contextConfigLocation加载--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt;DAO层配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd"&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location="classpath*:properties/*.properties" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" destroy-method="close"&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;" /&gt; &lt;property name="maxActive" value="10" /&gt; &lt;property name="minIdle" value="5" /&gt; &lt;/bean&gt; &lt;!-- 配置 Mybatis的工厂 --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置pojo别名 --&gt; &lt;property name="typeAliasesPackage" value="csc.pojo"&gt;&lt;/property&gt; &lt;!-- 配置分页插件 --&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;bean class="com.github.pagehelper.PageInterceptor"&gt; &lt;property name="properties"&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt; &lt;value&gt;helperDialect=mysql&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="csc.mapper" /&gt; &lt;/bean&gt;&lt;/beans&gt;service层配置12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;!-- 指定Dubbo发布服务的端口 --&gt; &lt;dubbo:protocol name="dubbo" port="20881"&gt;&lt;/dubbo:protocol&gt; &lt;!-- 服务的名称 --&gt; &lt;dubbo:application name="china-software-cup-service"/&gt; &lt;!-- 指定注册中心 --&gt; &lt;dubbo:registry address="zookeeper://59.110.143.226:2181"/&gt; &lt;!-- 发布服务器 --&gt; &lt;dubbo:annotation package="csc.service.impl" /&gt; &lt;!-- 配置服务端 超时时间30秒 --&gt; &lt;dubbo:provider timeout="30000"&gt;&lt;/dubbo:provider&gt;&lt;/beans&gt;web层配置123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:property-placeholder location="classpath:config/application.properties" /&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults="true"&gt; &lt;bean class="com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter"&gt; &lt;property name="supportedMediaTypes" value="application/json"/&gt; &lt;property name="features"&gt; &lt;array&gt; &lt;value&gt;WriteMapNullValue&lt;/value&gt; &lt;value&gt;WriteDateUseDateFormat&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!-- 放行静态资源 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 引用dubbo 服务 --&gt; &lt;dubbo:application name="china-software-cup-web" /&gt; &lt;dubbo:registry address="zookeeper://59.110.143.226:2181"/&gt; &lt;dubbo:annotation package="csc.controller" /&gt; &lt;!-- 配置消费端超时时间 30秒 --&gt; &lt;dubbo:consumer timeout="30000"&gt;&lt;/dubbo:consumer&gt;&lt;/beans&gt;dubbo配置提供服务的是service，服务消费者是web。service配置1234567891011121314&lt;!-- 指定Dubbo发布服务的端口 --&gt;&lt;dubbo:protocol name="dubbo" port="20881"&gt;&lt;/dubbo:protocol&gt;&lt;!-- 服务的名称 --&gt;&lt;dubbo:application name="china-software-cup-service"/&gt; &lt;!-- 指定注册中心，ip是自己zookeeper的ip --&gt;&lt;dubbo:registry address="zookeeper://59.110.143.226:2181"/&gt;&lt;!-- 发布服务器 --&gt;&lt;dubbo:annotation package="csc.service.impl" /&gt; &lt;!-- 配置服务端 超时时间30秒 --&gt;&lt;dubbo:provider timeout="30000"&gt;&lt;/dubbo:provider&gt;web配置12345&lt;!-- 引用dubbo 服务 --&gt;&lt;dubbo:application name="china-software-cup-web" /&gt;&lt;!-- ip是自己zookeeper的ip --&gt;&lt;dubbo:registry address="zookeeper://59.110.143.226:2181"/&gt;&lt;dubbo:annotation package="csc.controller" /&gt;执行流程]]></content>
      <categories>
        <category>JavaWeb</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中基础的关键字]]></title>
    <url>%2F2019%2FJava%E4%B8%AD%E5%9F%BA%E7%A1%80%E7%9A%84%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[staticstatic方法就是没有this的方法。在static方法内部不能调用非静态方法，反过来是可以的。而且可以在没有创建任何对象的前提下，仅仅通过类本身来调用static方法。这实际上正是static方法的主要用途。这段话虽然只是说明了static方法的特殊之处，但是可以看出static关键字的基本作用，简而言之，一句话来描述就是：方便在没有创建对象的情况下来进行调用（方法/变量）。很显然，被static关键字修饰的方法或者变量不需要依赖于对象来进行访问，只要类被加载了，就可以通过类名去进行访问。static可以用来修饰类的成员方法、类的成员变量，另外可以编写static代码块来优化程序性能。static方法static方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。举个简单的例子：在上面的代码中，由于print2方法是独立于对象存在的，可以直接用过类名调用。假如说可以在静态方法中访问非静态方法/变量的话，那么如果在main方法中有下面一条语句：MyObject.print2();。此时对象都没有，str2根本就不存在，所以就会产生矛盾了。同样对于方法也是一样，由于你无法预知在print1方法中是否访问了非静态成员变量，所以也禁止在静态成员方法中访问非静态成员方法。而对于非静态成员方法，它访问静态成员方法/变量显然是毫无限制的。因此，如果说想在不创建对象的情况下调用某个方法，就可以将这个方法设置为static。我们最常见的static方法就是main方法，至于为什么main方法必须是static的，现在就很清楚了。因为程序在执行main方法的时候没有创建任何对象，因此只有通过类名来访问。static变量static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。static成员变量的初始化顺序按照定义的顺序进行初始化。static代码块static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。12345678910111213class Person&#123; private Date birthDate; public Person(Date birthDate) &#123; this.birthDate = birthDate; &#125; boolean isBornBoomer() &#123; Date startDate = Date.valueOf(&quot;1946&quot;); Date endDate = Date.valueOf(&quot;1964&quot;); return birthDate.compareTo(startDate)&gt;=0 &amp;&amp; birthDate.compareTo(endDate) &lt; 0; &#125;&#125;isBornBoomer是用来这个人是否是1946-1964年出生的，而每次isBornBoomer被调用的时候，都会生成startDate和birthDate两个对象，造成了空间浪费，如果改成这样效率会更好：12345678910111213141516class Person&#123; private Date birthDate; private static Date startDate,endDate; static&#123; startDate = Date.valueOf(&quot;1946&quot;); endDate = Date.valueOf(&quot;1964&quot;); &#125; public Person(Date birthDate) &#123; this.birthDate = birthDate; &#125; boolean isBornBoomer() &#123; return birthDate.compareTo(startDate)&gt;=0 &amp;&amp; birthDate.compareTo(endDate) &lt; 0; &#125;&#125;static关键字的误区static关键字会改变类中成员的访问权限吗？Java中的static关键字不会影响到变量或者方法的作用域。在Java中能够影响到访问权限的只有private、public、protected（包括包访问权限）这几个关键字。能通过this访问静态成员变量吗？静态成员变量虽然独立于对象，但是不代表不可以通过对象去访问，所有的静态方法和静态变量都可以通过对象访问（只要访问权限足够）。123456789101112public class Main &#123; static int value = 33; public static void main(String[] args) throws Exception&#123; new Main().printValue(); &#125; private void printValue()&#123; int value = 3; System.out.println(this.value); //33 &#125;&#125;static能作用于局部变量么？static是不允许用来修饰局部变量。常见的笔试面试题这段代码的输出结果是什么？12345678910111213141516171819202122232425262728public class Test extends Base&#123; static&#123; System.out.println("test static"); &#125; public Test()&#123; System.out.println("test constructor"); &#125; public static void main(String[] args) &#123; new Test(); &#125;&#125; class Base&#123; static&#123; System.out.println("base static"); &#125; public Base()&#123; System.out.println("base constructor"); &#125;&#125;/* 父类先于子类、静态先于普通 base static test static base constructor test constructor*/这段代码的输出结果是什么？12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123; Person person = new Person(&quot;Test&quot;); static&#123; System.out.println(&quot;test static&quot;); &#125; public Test() &#123; System.out.println(&quot;test constructor&quot;); &#125; public static void main(String[] args) &#123; new MyClass(); &#125;&#125;class Person&#123; static&#123; System.out.println(&quot;person static&quot;); &#125; public Person(String str) &#123; System.out.println(&quot;person &quot;+str); &#125;&#125;class MyClass extends Test &#123; Person person = new Person(&quot;MyClass&quot;); static&#123; System.out.println(&quot;myclass static&quot;); &#125; public MyClass() &#123; System.out.println(&quot;myclass constructor&quot;); &#125;&#125;/* test static myclass static person static person Test test constructor person MyClass myclass constructor*/首先加载Test类，因此会执行Test类中的static块。接着执行new MyClass()，而MyClass类还没有被加载，因此需要加载MyClass类。在加载MyClass类的时候，发现MyClass类继承自Test类，但是由于Test类已经被加载了，所以只需要加载MyClass类，那么就会执行MyClass类的中的static块。在加载完之后，就通过构造器来生成对象。而在生成对象的时候，必须先初始化父类的成员变量，因此会执行Test中的Person person = new Person()，而Person类还没有被加载过，因此会先加载Person类并执行Person类中的static块，接着执行父类的构造器，完成了父类的初始化，然后就来初始化自身了，因此会接着执行MyClass中的Person person = new Person()，最后执行MyClass的构造器。final修饰类当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。修饰方法只有在想明确禁止该方法在子类中被覆盖的情况下才将方法设置为final的。即父类的final方法是不能被子类所覆盖的，也就是说子类是不能够存在和父类一模一样的方法的。final修饰的方法表示此方法已经是“最后的、最终的”含义，亦即此方法不能被重写（可以重载多个final修饰的方法）。此处需要注意的一点是：因为重写的前提是子类可以从父类中继承此方法，如果父类中final修饰的方法同时访问控制权限为private，将会导致子类中不能直接继承到此方法，因此，此时可以在子类中定义方法签名相同的方法，此时不再产生重写与final的矛盾，而是在子类中重新定义了新的方法。（注：类的private方法会隐式地被指定为final方法。）123456789101112131415161718192021222324252627public class B extends A &#123; public static void main(String[] args) &#123; &#125; public void getName() &#123; &#125;&#125;class A &#123; /** * 因为private修饰，子类中不能继承到此方法，因此，子类中的getName方法是重新定义的、 * 属于子类本身的方法，编译正常 */ private final void getName() &#123; &#125; /* 因为pblic修饰，子类可以继承到此方法，导致重写了父类的final方法，编译出错 public final void getName() &#123; &#125; */&#125;修饰变量final成员变量表示常量，只能被赋值一次，赋值后值不再改变。当final修饰一个基本数据类型时，表示该基本数据类型的值一旦在初始化后便不能发生变化；如果final修饰一个引用类型时，则在对其初始化之后便不能再让其指向其他对象了，但该引用所指向的对象的内容是可以发生变化的。本质上是一回事，因为引用的值是一个地址，final要求值，即地址的值不发生变化。final修饰一个成员变量（属性），必须要显示初始化。这里有两种初始化方式，一种是在变量声明的时候初始化；第二种方法是在声明变量的时候不赋初值，但是要在这个变量所在的类的所有的构造函数中对这个变量赋初值。当函数的参数类型声明为final时，说明该参数是只读型的。即你可以读取使用该参数，但是无法改变该参数的值。abstract抽象类和抽象方法都使用关键字abstract。抽象类中可以有已被实现的方法。抽象方法必须存在于抽象类中。继承抽象类的子类要不实现其全部的抽象方法，要不子类也要被说明为abstract的。抽象类不能用来实例化对象，只能引用其子类的实例。抽象类作为方法返回值的时候，需要返回一个继承抽象类并实现所有抽象方法的子类对象。被final、static、private群殴的abstractfinal：被abstract修饰的方法强制子类重写，被final修饰的不让子类重写，所以他俩是矛盾的。static：被static修饰的方法可以使用类名被调用，而抽象方法不能直接被调用，不需要子类实现抽象方法就可以使用类名来调用和抽象方法不能直接被调用矛盾。private：被private修饰的方法不能被继承自然不能被重写。而abstract修饰的方法必须被子类实现。instanceof判断某对象是不是某类或其父类的对象。判断某对象是不是某接口或其父接口的实现类的对象。其实如a instanceof B。只要B类的对象引用能引用a就是true，否则是false。但是a的类型和B必须在一条继承链中，否则会编译错误。参考https://www.cnblogs.com/xiaoxi/p/6392154.htmlhttps://www.cnblogs.com/dolphin0520/p/3799052.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常]]></title>
    <url>%2F2019%2F%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[异常介绍异常是程序在运行时出现的会导致程序运行终止的错误。这种错误是不能通过编译系统检查出来的。常见的异常的发生原因为系统资源错误和用户操所错误两种。Java把异常信息封装成一个类。当发生某种异常时将某种对应的类作为异常信息抛出。异常的根类时Throwable，其有两个直接子类Error和Exception。Error是描述系统资源错误的类。Exception是描述用户操作错误的类。发生了Error就是必须修改代码或调整外部环境问题，程序肯定会终止。比如需要开辟一个内存大小为99999999个int的数组。一般来说Error很少发生。发生了Exception就要进行处理，使程序运行下去，如数组越界异常。而Exception又可以分为两种，一种是程序本身存在的问题引发的异常（健壮性不够），即：RuntimeException；一种是程序本身可能没有问题，但遇到诸如文件不存在所导致的错误，Excption中除了RuntimeException外都是此种异常。而RuntimeException是不允许存在的，遇到RuntimeException就说明程序有问题，需要修改代码。受查异常、非受查异常Java语言规范规定派生于Error类或RuntimeException类的异常都称为非受查异常，其余异常都被成为受查异常。受查异常就是必须告诉它的调用者可能会出现异常，让其调用者抛出或者捕获处理，这类异常如果没有在程序中进行异常处理，编译不通过。非受查异常则不需要。声明受查异常（throws）除了Error和RuntimeException的异常都是受查异常，这些异常如：IOException、SQLException等，在可能发生的方法中需要被声明。同时非受查异常最好不要被声明。需要使用throws声明异常后的情况如下：调用一个抛出受查异常的方法：public int read() throws IOException方法中使用throw语句抛出了受查异常。抛出异常（throw）throw可以用于抛出异常对象，一般是受查异常对象。格式如下例：123public static void demo() throws Exception&#123; throw new Exception(&quot;出现异常&quot;);&#125;捕获异常直接处理异常需要使用try、catch、finally（非必需）关键字，代码格式如下：1234567try&#123; 有可能发生运行时异常的代码&#125;catch(XxxException e)&#123; 处理或者向外抛出&#125;finally&#123; 肯定被执行的代码，一般用于关闭资源&#125;return和finally的决斗一旦进入try … catch …的异常捕获结构，无论try和catch的语句块有没有return语句，finally一定会被执行，但是如果finally中还有return语句，return之后的不会被执行。同时后来的return值会覆盖之前的return值。但若未进入异常捕获结构则return后不允许有语句，因为即使有也一定不会被执行。多catch原则要求多个catch中的异常不能相同，并且若catch中的多个异常有继承实现关系，那么子类异常要求在上面的catch处理，父类异常在下面的catch处理。异常处理解耦就是让一个try对应一个catch。每一个可能的异常都对应一个try…catch…代码块。自定义异常若某类继承Throwable或其子类，则称此类为自定义的异常类。需要重写默认的构造函数和带有一个字符串参数的构造函数。非受查异常的特点非受查异常有两种可能，一是无法解决，即Error；二是必须被解决，即RuntimeException。也就是说如果发生了Error，则需要更换硬件或检查外部环境是否正确。如果发生了RuntimeException则必须修改程序，因为此时的程序健壮性不够。发生异常的代码的后续代码执行与否问题使用throw抛出异常：后续代码不会全部不会被执行。如下123456try&#123; throw new Exception("参数越界"); &#125;catch(Exception e) &#123; e.printStackTrace();&#125;System.out.println("异常后");//可以执行使用try … catch … 解决异常：try中发生异常代码的后续代码不会被执行，但catch和finally中的代码会被完全执行。如果未发生异常，catch中的代码完全不会被执行，try和finally中的代码会被完全执行。无论有没有发生异常，异常处理代码块之外的代码都会被执行。异常在方法重写中的要求父类中方法如果声明受查异常，子类可以声明异常也可以不声明异常，但子类如果选择声明，只能声明父类异常或者父类异常的子类。如果父类没有声明受查异常，则子类不能声明受查异常。设子类中方法能声明异常的集合为A，若此方法调用的方法抛出了集合A意外的异常，则只能捕获处理而不能向上抛出。抛出异常和捕获异常选择在被调方法中的异常如果能在被调方法中妥善的处理则建议在被调方法中处理。如果不能处理就向上抛出，上级不能处理就再向上抛出直至被处理。异常中的常用方法在Throwable中有三个方法用于显示异常的信息。String getMessage()：返回该异常的详细信息字符串，即异常提示信息；String toString()：返回该异常的名称与详细信息字符串；void printStackTrace()：在控制台输出该异常的名称与详细信息字符串、异常出现的代码位置。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[泛型]]></title>
    <url>%2F2019%2F%E6%B3%9B%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本文转至：https://blog.csdn.net/s10461/article/details/53941091概述泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。一个被举了无数次的例子：12345678List arrayList = new ArrayList();arrayList.add("aaaa");arrayList.add(100);for(int i = 0; i&lt; arrayList.size();i++)&#123; String item = (String)arrayList.get(i); Log.d("泛型测试","item = " + item);&#125;毫无疑问，程序的运行结果会以崩溃结束：1java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.StringArrayList可以存放任意类型，例子中添加了一个String类型，添加了一个Integer类型，再使用时都以String的方式使用，因此程序崩溃了。为了解决类似这样的问题（在编译阶段就可以解决），泛型应运而生。我们将第一行声明初始化list的代码更改一下，编译器会在编译阶段就能够帮我们发现类似这样的问题。123List&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();...//arrayList.add(100); 在编译阶段，编译器就会报错特性泛型只在编译阶段有效。看下面的代码：1234567891011121314151617181920package test;import java.util.ArrayList;import java.util.List;public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; stringArrayList = new ArrayList&lt;String&gt;(); List&lt;Integer&gt; integerArrayList = new ArrayList&lt;Integer&gt;(); Class classStringArrayList = stringArrayList.getClass(); Class classIntegerArrayList = integerArrayList.getClass(); if(classStringArrayList.equals(classIntegerArrayList))&#123; System.out.println("类型相同"); &#125; &#125;&#125;通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。对此总结成一句话：泛型类型在逻辑上可以看成是多个不同的类型，实际上都是相同的基本类型。泛型的使用泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。泛型类泛型类型用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是各种容器类，如：List、Set、Map。泛型类的最基本写法（这么看可能会有点晕，会在下面的例子中详解）：1234class 类名称 &lt;泛型标识：可以随便写任意标识号，标识指定的泛型的类型&gt;&#123; private 泛型标识 var; .....&#125;一个最普通的泛型类：1234567891011121314//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123; //key这个成员变量的类型为T,T的类型由外部指定 private T key; public Generic(T key) &#123; //泛型构造方法形参key的类型也为T，T的类型由外部指定 this.key = key; &#125; public T getKey()&#123; //泛型方法getKey的返回值类型为T，T的类型由外部指定 return key; &#125;&#125;12345678//泛型的类型参数只能是类类型（包括自定义类），不能是简单类型//传入的实参类型需与泛型的类型参数类型相同，即为Integer.Generic&lt;Integer&gt; genericInteger = new Generic&lt;Integer&gt;(123456);//传入的实参类型需与泛型的类型参数类型相同，即为String.Generic&lt;String&gt; genericString = new Generic&lt;String&gt;(&quot;key_vlaue&quot;);System.out.println(&quot;key is &quot; + genericInteger.getKey());System.out.println(&quot;key is &quot; + genericString.getKey());泛型接口的实现1234//定义一个泛型接口public interface Generator&lt;T&gt; &#123; public T next();&#125;当实现泛型接口的类，未传入泛型实参时：1234567891011/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; * 如果不声明泛型，如：class FruitGenerator implements Generator&lt;T&gt;，编译器会报错：&quot;Unknown class&quot; */class FruitGenerator&lt;T&gt; implements Generator&lt;T&gt;&#123; @Override public T next() &#123; return null; &#125;&#125;当实现泛型接口的类，传入泛型实参时：1234567891011121314151617/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator&lt;T&gt; * 但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：Generator&lt;T&gt;，public T next();中的的T都要替换成传入的String类型。 */public class FruitGenerator implements Generator&lt;String&gt; &#123; private String[] fruits = new String[]&#123;&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;&#125;; @Override public String next() &#123; Random rand = new Random(); return fruits[rand.nextInt(3)]; &#125;&#125;泛型通配符我们知道Ingeter是Number的一个子类，同时在特性章节中我们也验证过Generic&lt;Ingeter&gt;与Generic&lt;Number&gt;实际上是相同的一种基本类型。那么问题来了，在使用Generic&lt;Number&gt;作为形参的方法中，能否使用Generic&lt;Ingeter&gt;的实例传入呢？在逻辑上类似于Generic&lt;Number&gt;和Generic&lt;Ingeter&gt;是否可以看成具有父子关系的泛型类型呢？为了弄清楚这个问题，我们使用Generic&lt;T&gt;这个泛型类继续看下面的例子：123public void showKeyValue1(Generic&lt;Number&gt; obj)&#123; System.out.println(&quot;key value is &quot; + obj.getKey());&#125;12345678Generic&lt;Integer&gt; gInteger = new Generic&lt;Integer&gt;(123);Generic&lt;Number&gt; gNumber = new Generic&lt;Number&gt;(456);showKeyValue(gNumber);// showKeyValue这个方法编译器会为我们报错：Generic&lt;java.lang.Integer&gt; // cannot be applied to Generic&lt;java.lang.Number&gt;// showKeyValue(gInteger);通过提示信息我们可以看到Generic&lt;Integer&gt;不能被看作为Generic&lt;Number&gt;的子类。由此可以看出:同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。回到上面的例子，如何解决上面的问题？总不能为了定义一个新的方法来处理Generic&lt;Integer&gt;类型的类，这显然与java中的多台理念相违背。因此我们需要一个在逻辑上可以表示同时是Generic&lt;Integer&gt;和Generic&lt;Number&gt;父类的引用类型。由此类型通配符应运而生。我们可以将上面的方法改一下：123public void showKeyValue1(Generic&lt;?&gt; obj)&#123; System.out.println(&quot;key value is &quot; + obj.getKey());&#125;类型通配符一般是使用？代替具体的类型实参，注意了，此处？是类型实参，而不是类型形参 。再直白点的意思就是，此处的？和Number、String、Integer一样都是一种实际的类型，可以把？看成所有类型的父类。是一种真实的类型。可以解决当具体类型不确定的时候，这个通配符就是 ? ；当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用 ? 通配符来表未知类型。泛型方法在Java中，泛型类的定义非常简单，但是泛型方法就比较复杂了。尤其是我们见到的大多数泛型类中的成员方法也都使用了泛型，有的甚至泛型类中也包含着泛型方法，这样在初学者中非常容易将泛型方法理解错了。泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。123456789101112131415/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法。 * 2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 * 3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 * 4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException , IllegalAccessException&#123; T instance = tClass.newInstance(); return instance;&#125;1Object obj = genericMethod(Class.forName(&quot;com.test.test&quot;));泛型方法的详细举例光看上面的例子有的同学可能依然会非常迷糊，我们再通过一个例子，把我泛型方法再总结一下。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class GenericTest &#123; //这个类是个泛型类，在上面已经介绍过 public class Generic&lt;T&gt;&#123; private T key; public Generic(T key) &#123; this.key = key; &#125; //我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。 //这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。 //所以在这个方法中才可以继续使用 T 这个泛型。 public T getKey()&#123; return key; &#125; /** * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息&quot;cannot reslove symbol E&quot; * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。 public E setKey(E key)&#123; this.key = keu &#125; */ &#125; /** * 这才是一个真正的泛型方法。 * 首先在public与返回值之间的&lt;T&gt;必不可少，这表明这是一个泛型方法，并且声明了一个泛型T * 这个T可以出现在这个泛型方法的任意位置. * 泛型的数量也可以为任意多个 * 如：public &lt;T,K&gt; K showKeyName(Generic&lt;T&gt; container)&#123; * ... * &#125; */ public &lt;T&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println(&quot;container key :&quot; + container.getKey()); //当然这个例子举的不太合适，只是为了说明泛型方法的特性。 T test = container.getKey(); return test; &#125; //这也不是一个泛型方法，这就是一个普通的方法，只是使用了Generic&lt;Number&gt;这个泛型类做形参而已。 public void showKeyValue1(Generic&lt;Number&gt; obj)&#123; Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey()); &#125; //这也不是一个泛型方法，这也是一个普通的方法，只不过使用了泛型通配符? //同时这也印证了泛型通配符章节所描述的，?是一种类型实参，可以看做为Number等所有类的父类 public void showKeyValue2(Generic&lt;?&gt; obj)&#123; Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey()); &#125; /** * 这个方法是有问题的，编译器会为我们提示错误信息：&quot;UnKnown class &apos;E&apos; &quot; * 虽然我们声明了&lt;T&gt;,也表明了这是一个可以处理泛型的类型的泛型方法。 * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。 public &lt;T&gt; T showKeyName(Generic&lt;E&gt; container)&#123; ... &#125; */ /** * 这个方法也是有问题的，编译器会为我们提示错误信息：&quot;UnKnown class &apos;T&apos; &quot; * 对于编译器来说T这个类型并未项目中声明过，因此编译也不知道该如何编译这个类。 * 所以这也不是一个正确的泛型方法声明。 public void showkey(T genericObj)&#123; &#125; */&#125;类中的泛型方法当然这并不是泛型方法的全部，泛型方法可以出现杂任何地方和任何场景中使用。但是有一种情况是非常特殊的，即当泛型方法出现在泛型类中时：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package test;public class GenericFruit &#123; class Fruit&#123; @Override public String toString() &#123; return &quot;fruit&quot;; &#125; &#125; class Apple extends Fruit&#123; @Override public String toString() &#123; return &quot;apple&quot;; &#125; &#125; class Person&#123; @Override public String toString() &#123; return &quot;Person&quot;; &#125; &#125; class GenerateTest&lt;T&gt;&#123; //方法中的T和类上声明的T一致 public void show_1(T t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 //由于泛型方法在声明的时候会声明泛型&lt;E&gt;，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。 public &lt;E&gt; void show_3(E t)&#123; System.out.println(t.toString()); &#125; //在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。 public &lt;T&gt; void show_2(T t)&#123; System.out.println(t.toString()); &#125; &#125; public static void main(String[] args) &#123; Apple apple = new GenericFruit().new Apple(); Person person = new GenericFruit().new Person(); GenerateTest&lt;Fruit&gt; generateTest = new GenericFruit().new GenerateTest&lt;Fruit&gt;(); //apple是Fruit的子类，所以这里可以 generateTest.show_1(apple); //编译器会报错，因为泛型类型实参指定的是Fruit，而传入的实参类是Person //generateTest.show_1(person); //使用这两个方法都可以成功 generateTest.show_2(apple); generateTest.show_2(person); //使用这两个方法也都可以成功 generateTest.show_3(apple); generateTest.show_3(person); &#125;&#125;泛型方法与可变参数再看一个泛型方法和可变参数的例子：12345public &lt;T&gt; void printMsg( T... args)&#123; for(T t : args)&#123; Log.d(&quot;泛型测试&quot;,&quot;t is &quot; + t); &#125;&#125;1printMsg(&quot;111&quot;,222,&quot;aaaa&quot;,&quot;2323.4&quot;,55.55);静态方法与泛型静态方法有一种情况需要注意一下，那就是在类中的静态方法使用泛型：静态方法无法访问类上定义的泛型；如果静态方法操作的引用数据类型不确定的时候，必须要将泛型定义在方法上。即：如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法 。12345678910111213public class StaticGenerator&lt;T&gt; &#123; .... .... /** * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法） * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。 * 如：public static void show(T t)&#123;..&#125;,此时编译器会提示错误信息： &quot;StaticGenerator cannot be refrenced from static context&quot; */ public static &lt;T&gt; void show(T t)&#123; &#125;&#125;泛型上下边界在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。上边界为泛型添加上边界，即传入的类型实参必须是指定类型的子类型123public void showKeyValue1(Generic&lt;? extends Number&gt; obj)&#123; Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey());&#125;1234567891011Generic&lt;String&gt; generic1 = new Generic&lt;String&gt;(&quot;11111&quot;);Generic&lt;Integer&gt; generic2 = new Generic&lt;Integer&gt;(2222);Generic&lt;Float&gt; generic3 = new Generic&lt;Float&gt;(2.4f);Generic&lt;Double&gt; generic4 = new Generic&lt;Double&gt;(2.56);//这一行代码编译器会提示错误，因为String类型并不是Number类型的子类//showKeyValue1(generic1);showKeyValue1(generic2);showKeyValue1(generic3);showKeyValue1(generic4);如果我们把泛型类的定义也改一下：1234567891011public class Generic&lt;T extends Number&gt;&#123; private T key; public Generic(T key) &#123; this.key = key; &#125; public T getKey()&#123; return key; &#125;&#125;12//这一行代码也会报错，因为String不是Number的子类Generic&lt;String&gt; generic1 = new Generic&lt;String&gt;(&quot;11111&quot;);再来一个泛型方法的例子：1234567//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的&lt;T&gt;上添加上下边界，即在泛型声明的时候添加//public &lt;T&gt; T showKeyName(Generic&lt;T extends Number&gt; container)，编译器会报错：&quot;Unexpected bound&quot;public &lt;T extends Number&gt; T showKeyName(Generic&lt;T&gt; container)&#123; System.out.println(&quot;container key :&quot; + container.getKey()); T test = container.getKey(); return test;&#125;限制比如C类中有一个方法：void setC(T t)。在传入&lt;? extends Fruit&gt;之后就会变成：void setC(&lt;? extends Fruit&gt; t)。这时编译器就不知道你传过来的是什么类型，编译不会通过。但是类中的方法可以返回T，因为已经知道了它的上限是A，在调用之后用A来接收一下返回的对象就可以了。12GenerateTest&lt;? extends Fruit&gt; generateTest2 = new GenericFruit().new GenerateTest&lt;&gt;();generateTest2.setC(apple); //报错此时的通配符（?）有上限，故被称为上限限定的通配符。上限限定通配符的特点是：其中的方法可以返回泛型参数，但不能接收泛型参数。下边界&lt;? super A&gt;表示传入的只能是A的超类或超接口。此时，类中的方法void setC(T t)可以传入A或A的子类作为参数。但返回时只能返回Object对象。12GenerateTest&lt;? super Apple&gt; generateTest2 = new GenericFruit().new GenerateTest&lt;&gt;();Object object = generateTest2.get();关于泛型数组要提一下看到了很多文章中都会提起泛型数组，经过查看sun的说明文档，在java中是”不能创建一个确切的泛型类型的数组”的。也就是说下面的这个例子是不可以的：1List&lt;String&gt;[] ls = new ArrayList&lt;String&gt;[10];而使用通配符创建泛型数组是可以的，如下面这个例子：1List&lt;?&gt;[] ls = new ArrayList&lt;?&gt;[10];这样也是可以的：1List&lt;String&gt;[] ls = new ArrayList[10];下面使用Sun的一篇文档的一个例子来说明这个问题：1234567891011List&lt;String&gt;[] lsa = new List&lt;String&gt;[10]; // Not really allowed. Object o = lsa; Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Unsound, but passes run time store check String s = lsa[1].get(0); // Run-time error: ClassCastException./**这种情况下，由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的，所以可以给oa[1]赋上一个ArrayList而不会出现异常，但是在取出数据的时候却要做一次类型转换，所以就会出现ClassCastException，如果可以进行泛型数组的声明，上面说的这种情况在编译期将不会出现任何的警告和错误，只有在运行时才会出错。而对泛型数组的声明进行限制，对于这样的情况，可以在编译期提示代码有类型安全问题，比没有任何提示要强很多。*/下面采用通配符的方式是被允许的:数组的类型不可以是类型变量，除非是采用通配符的方式，因为对于通配符的方式，最后取出数据是要做显式的类型转换的。1234567List&lt;?&gt;[] lsa = new List&lt;?&gt;[10]; // OK, array of unbounded wildcard type. Object o = lsa; Object[] oa = (Object[]) o; List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;(); li.add(new Integer(3)); oa[1] = li; // Correct. Integer i = (Integer) lsa[1].get(0); // OK]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内部类]]></title>
    <url>%2F2019%2F%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[转至：https://www.cnblogs.com/dolphin0520/p/3811445.html内部类分类成员内部类成员内部类是最普通的内部类，它的定义为位于另一个类的内部，形如下面的形式：12345678910111213class Circle &#123; double radius = 0; public Circle(double radius) &#123; this.radius = radius; &#125; class Draw &#123; //内部类 public void drawSahpe() &#123; System.out.println("drawshape"); &#125; &#125;&#125;这样看起来，类Draw像是类Circle的一个成员，Circle称为外部类。成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）。1234567891011121314151617181920212223242526package test;public class Outer &#123; private double radius = 0; private int test = 1; public static int count =1; public Outer(double radius) &#123; this.radius = radius; &#125; class Draw &#123; //内部类 private int test = 2; public void drawSahpe() &#123; System.out.println(radius); //外部类的private成员 System.out.println(count); //外部类的静态成员 System.out.println(Outer.this.test); &#125; &#125; public static void main(String[] args) &#123; Draw draw = new Outer(20).new Draw(); draw.drawSahpe(); &#125; &#125;不过要注意的是，当成员内部类拥有和外部类同名的成员变量或者方法时，会发生隐藏现象，即默认情况下访问的是成员内部类的成员。如果要访问外部类的同名成员，需要以下面的形式进行访问：12外部类.this.成员变量外部类.this.成员方法虽然成员内部类可以无条件地访问外部类的成员，而外部类想访问成员内部类的成员却不是这么随心所欲了。在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问：123456789101112131415161718class Circle &#123; private double radius = 0; public Circle(double radius) &#123; this.radius = radius; getDrawInstance().drawSahpe(); //必须先创建成员内部类的对象，再进行访问 &#125; private Draw getDrawInstance() &#123; return new Draw(); &#125; class Draw &#123; //内部类 public void drawSahpe() &#123; System.out.println(radius); //外部类的private成员 &#125; &#125;&#125;成员内部类是依附外部类而存在的，也就是说，如果要创建成员内部类的对象，前提是必须存在一个外部类的对象。创建成员内部类对象的一般方式如下：1234567891011121314151617181920212223242526272829public class Test &#123; public static void main(String[] args) &#123; //第一种方式： Outter outter = new Outter(); Outter.Inner inner = outter.new Inner(); //必须通过Outter对象来创建 //第二种方式： Outter.Inner inner1 = outter.getInnerInstance(); &#125;&#125; class Outter &#123; private Inner inner = null; public Outter() &#123; &#125; public Inner getInnerInstance() &#123; if(inner == null) inner = new Inner(); return inner; &#125; class Inner &#123; public Inner() &#123; &#125; &#125;&#125;内部类可以拥有private访问权限、protected访问权限、public访问权限及包访问权限。如上面的例子：private：则只能在外部类的内部访问；public：则任何地方都能访问；protected：只能在同一个包下或者继承外部类的情况下访问；默认访问权限：则只能在同一个包下访问。这一点和外部类有一点不一样，外部类只能被public和包访问两种权限修饰。我个人是这么理解的，由于成员内部类看起来像是外部类的一个成员，所以可以像类的成员一样拥有多种权限修饰。局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。123456789101112131415161718class People&#123; public People() &#123; &#125;&#125; class Man&#123; public Man()&#123; &#125; public People getWoman()&#123; class Woman extends People&#123; //局部内部类 int age =0; &#125; return new Woman(); &#125;&#125;注意，局部内部类就像是方法里面的一个局部变量一样，是不能有public、protected、private以及static修饰符的。匿名内部类匿名内部类应该是平时我们编写代码时用得最多的，在编写事件监听的代码时使用匿名内部类不但方便，而且使代码更加容易维护。下面这段代码是一段Android事件监听代码：1234567891011121314151617scan_bt.setOnClickListener(new OnClickListener() &#123; @Override public void onClick(View v) &#123; // TODO Auto-generated method stub &#125;&#125;); history_bt.setOnClickListener(new OnClickListener() &#123; @Override public void onClick(View v) &#123; // TODO Auto-generated method stub &#125;&#125;);匿名内部类是唯一一种没有构造器的类。正因为其没有构造器，所以匿名内部类的使用范围非常有限，大部分匿名内部类用于接口回调。匿名内部类在编译的时候由系统自动起名为Outter$数字.class。一般来说，匿名内部类用于继承其他类或是实现接口，并不需要增加额外的方法，只是对继承方法的实现或是重写。静态内部类静态内部类也是定义在另一个类里面的类，只不过在类的前面多了一个关键字static。静态内部类是不需要依赖于外部类的，这点和类的静态成员属性有点类似，并且它不能使用外部类的非static成员变量或者方法，这点很好理解，因为在没有外部类的对象的情况下，可以创建静态内部类的对象，如果允许访问外部类的非static成员就会产生矛盾，因为外部类的非static成员必须依附于具体的对象。1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; Outter.Inner inner = new Outter.Inner(); &#125;&#125; class Outter &#123; public Outter() &#123; &#125; static class Inner &#123; public Inner() &#123; &#125; &#125;&#125;深入理解内部类为什么成员内部类可以无条件访问外部类的成员？在此之前，我们已经讨论过了成员内部类可以无条件访问外部类的成员，那具体究竟是如何实现的呢？下面通过反编译字节码文件看看究竟。事实上，编译器在进行编译的时候，会将成员内部类单独编译成一个字节码文件，下面是Outter.java的代码：123456789101112131415161718public class Outter &#123; private Inner inner = null; public Outter() &#123; &#125; public Inner getInnerInstance() &#123; if(inner == null) inner = new Inner(); return inner; &#125; protected class Inner &#123; public Inner() &#123; &#125; &#125;&#125;编译之后，出现了两个字节码文件：反编译Outter$Inner.class文件得到下面信息：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657E:\Workspace\Test\bin\com\cxh\test2&gt;javap -v Outter$InnerCompiled from &quot;Outter.java&quot;public class com.cxh.test2.Outter$Inner extends java.lang.Object SourceFile: &quot;Outter.java&quot; InnerClass: #24= #1 of #22; //Inner=class com/cxh/test2/Outter$Inner of class com/cxh/test2/Outter minor version: 0 major version: 50 Constant pool:const #1 = class #2; // com/cxh/test2/Outter$Innerconst #2 = Asciz com/cxh/test2/Outter$Inner;const #3 = class #4; // java/lang/Objectconst #4 = Asciz java/lang/Object;const #5 = Asciz this$0;const #6 = Asciz Lcom/cxh/test2/Outter;;const #7 = Asciz &lt;init&gt;;const #8 = Asciz (Lcom/cxh/test2/Outter;)V;const #9 = Asciz Code;const #10 = Field #1.#11; // com/cxh/test2/Outter$Inner.this$0:Lcom/cxh/test2/Outter;const #11 = NameAndType #5:#6;// this$0:Lcom/cxh/test2/Outter;const #12 = Method #3.#13; // java/lang/Object.&quot;&lt;init&gt;&quot;:()Vconst #13 = NameAndType #7:#14;// &quot;&lt;init&gt;&quot;:()Vconst #14 = Asciz ()V;const #15 = Asciz LineNumberTable;const #16 = Asciz LocalVariableTable;const #17 = Asciz this;const #18 = Asciz Lcom/cxh/test2/Outter$Inner;;const #19 = Asciz SourceFile;const #20 = Asciz Outter.java;const #21 = Asciz InnerClasses;const #22 = class #23; // com/cxh/test2/Outterconst #23 = Asciz com/cxh/test2/Outter;const #24 = Asciz Inner; &#123;final com.cxh.test2.Outter this$0; public com.cxh.test2.Outter$Inner(com.cxh.test2.Outter); Code: Stack=2, Locals=2, Args_size=2 0: aload_0 1: aload_1 2: putfield #10; //Field this$0:Lcom/cxh/test2/Outter; 5: aload_0 6: invokespecial #12; //Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 9: return LineNumberTable: line 16: 0 line 18: 9 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/cxh/test2/Outter$Inner; &#125;第11行到35行是常量池的内容，下面注意第38行的内容：1final com.cxh.test2.Outter this$0;这行是一个指向外部类对象的指针，看到这里想必大家豁然开朗了。也就是说编译器会默认为成员内部类添加了一个指向外部类对象的引用，那么这个引用是如何赋初值的呢？下面接着看内部类的构造器：1public com.cxh.test2.Outter$Inner(com.cxh.test2.Outter);从这里可以看出，虽然我们在定义的内部类的构造器是无参构造器，编译器还是会默认添加一个参数，该参数的类型为指向外部类对象的一个引用，所以成员内部类中的Outter this&amp;0 指针便指向了外部类对象，因此可以在成员内部类中随意访问外部类的成员。从这里也间接说明了成员内部类是依赖于外部类的，如果没有创建外部类的对象，则无法对Outter this&amp;0引用进行初始化赋值，也就无法创建成员内部类的对象了。为什么局部内部类和匿名内部类只能访问局部final变量？想必这个问题也曾经困扰过很多人，在讨论这个问题之前，先看下面这段代码：123456789101112131415public class Test &#123; public static void main(String[] args) &#123; &#125; public void test(final int b) &#123; final int a = 10; new Thread()&#123; public void run() &#123; System.out.println(a); System.out.println(b); &#125;; &#125;.start(); &#125;&#125;这段代码会被编译成两个class文件：Test.class和Test1.class。默认情况下，编译器会为匿名内部类和局部内部类起名为Outter1.class。默认情况下，编译器会为匿名内部类和局部内部类起名为Outter$x.class（x为正整数）。上段代码中，如果把变量a和b前面的任一个final去掉，这段代码都编译不过。我们先考虑这样一个问题：当test方法执行完毕之后，变量a的生命周期就结束了，而此时Thread对象的生命周期很可能还没有结束，那么在Thread的run方法中继续访问变量a就变成不可能了，但是又要实现这样的效果，怎么办呢？Java采用了复制的手段来解决这个问题。将这段代码的字节码反编译可以得到下面的内容：我们看到在run方法中有一条指令：bipush 10。这条指令表示将操作数10压栈，表示使用的是一个本地局部变量。这个过程是在编译期间由编译器默认进行，如果这个变量的值在编译期间可以确定，则编译器默认会在匿名内部类（局部内部类）的常量池中添加一个内容相等的字面量或直接将相应的字节码嵌入到执行字节码中。这样一来，匿名内部类使用的变量是另一个局部变量，只不过值和方法中局部变量的值相等，因此和方法中的局部变量完全独立开。下面再看一个例子：12345678910111213public class Test &#123; public static void main(String[] args) &#123; &#125; public void test(final int a) &#123; new Thread()&#123; public void run() &#123; System.out.println(a); &#125;; &#125;.start(); &#125;&#125;反编译得到：我们看到匿名内部类Test$1的构造器含有两个参数，一个是指向外部类对象的引用，一个是int型变量，很显然，这里是将变量test方法中的形参a以参数的形式传进来对匿名内部类中的拷贝（变量a的拷贝）进行赋值初始化。总结以上两次饭编译可得：如果局部变量的值在编译期间就可以确定，则直接在匿名内部里面创建一个拷贝。如果局部变量的值无法在编译期间确定，则通过构造器传参的方式来对拷贝进行初始化赋值。从上面可以看出，在run方法中访问的变量a根本就不是test方法中的局部变量a。这样一来就解决了前面所说的 生命周期不一致的问题。但是新的问题又来了，既然在run方法中访问的变量a和test方法中的变量a不是同一个变量，当在run方法中改变变量a的值的话，会出现什么情况？对，会造成数据不一致性，这样就达不到原本的意图和要求。为了解决这个问题，java编译器就限定必须将变量a限制为final变量，不允许对变量a进行更改（对于引用类型的变量，是不允许指向新的对象），这样数据不一致性的问题就得以解决了。到这里，想必大家应该清楚为何 方法中的局部变量和形参都必须用final进行限定了。静态内部类有特殊的地方吗？从前面可以知道，静态内部类是不依赖于外部类的，也就说可以在不创建外部类对象的情况下创建内部类的对象。另外，静态内部类是不持有指向外部类对象的引用的，这个读者可以自己尝试反编译class文件看一下就知道了，是没有Outter this&amp;0引用的。1234567891011public class Test&#123; public static void main(String[] args)&#123; // 初始化Bean2 Test.Bean2 b2 = new Test.Bean2(); bean2.J++; &#125; static class Bean2&#123; public int J = 0; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的AOP(注解方式)]]></title>
    <url>%2F2019%2FSpring%E7%9A%84AOP-%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[配置和注解IOC一样，也需要在配置文件中配置信息，让Spring知道AOP使用注解方式进行。12&lt;!-- 打开注解方式的AOP --&gt;&lt;aop:aspectj-autoproxy /&gt;入门使用@Aspect、@Before、@AfterReturning、@Around注解1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;&lt;!-- 打开注解方式的AOP --&gt;&lt;aop:aspectj-autoproxy /&gt;&lt;bean id="userDao" class="com.spring.annotation.UserDaoImpl"&gt;&lt;/bean&gt;&lt;bean id="myAspectJ" class="com.spring.annotation.MyAspectJ"&gt;&lt;/bean&gt;&lt;/beans&gt;12345678910111213141516public class UserDaoImpl implements UserDao &#123; public void delete() &#123; System.out.println("简简单单的删除"); &#125; public Integer delete(String userId, Double type) &#123; System.out.println("delete : " + userId); System.out.println("delete : " + type); return 100; &#125; public Boolean delete(Double type, String userId) &#123; System.out.println("delete : " + userId + " " + type); return true; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;/* 标识这个类是切面类 */@Aspectpublic class MyAspectJ &#123; /** * 前置增强，value表达式和xml方式一致 */ @Before(value="execution(void com.spring.annotation.UserDaoImpl.delete())") public void before() &#123; System.out.println("before"); &#125; /** * 后置增强，value表达式和xml方式一致 */ @AfterReturning(value="execution(Boolean com.spring.annotation.UserDaoImpl.delete(java.lang.Double, java.lang.String))", returning="ret") public void after(Boolean ret) &#123; System.out.println(ret); System.out.println("after"); &#125; @Around(value="execution(Integer com.spring.annotation.UserDaoImpl.delete(java.lang.String, java.lang.Double))") public Integer around(ProceedingJoinPoint pjp) throws Throwable &#123; Object[] args = pjp.getArgs(); for(Object o : args) System.out.println(o); //执行切点 Integer proceed = (Integer)pjp.proceed(); return proceed; &#125;&#125;1234567891011import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Test &#123; public static void main(String[] args) &#123; ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml"); UserDao ud = (UserDao)ac.getBean("userDao"); Integer delete = ud.delete("HelloWorld", 11.0); System.out.println(delete); &#125;&#125;切入点注解在上面的代码中，把注解加在通知的上面，类似于xml方式的123&lt;aop:aspect ref="myAspectJ"&gt; &lt;aop:around method="around" pointcut-ref="cut1" /&gt;&lt;/aop:aspect&gt;但是这样的话后期修改很麻烦，所以使用注解完成类似于下面，可以通过id添加通知的操作。1&lt;aop:pointcut expression="execution(Integer com.spring.aopxml.UserDaoImpl.delete(..))" id="cut1"/&gt;12345678910111213141516@Around(value="MyAspectJ.cut1")public Integer around(ProceedingJoinPoint pjp) throws Throwable &#123; Object[] args = pjp.getArgs(); for(Object o : args) System.out.println(o); //执行切点 Integer proceed = (Integer)pjp.proceed(); return proceed;&#125;/* * 不能使用属性 */@Pointcut(value="execution(Integer com.spring.annotation.UserDaoImpl.delete(java.lang.String, java.lang.Double))")private void cut1() &#123;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高校选课数据库范式分解]]></title>
    <url>%2F2019%2F%E9%AB%98%E6%A0%A1%E9%80%89%E8%AF%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[课程信息高校的课程一般都分为必须课和选修课，其中选修课又分为一定的类别，博主所在的中国民航大学课程信息如下：选修专业选修公共选修必修数据通过爬虫从选课系统爬下来的数据如下表所示：上课时间中每个分号分隔的是一个上课的时间段。比如2`7`8`3`12;3`9`10`3`12指的是有两个上课的时间段，其中第一个时间段是第3-12周中周2的7、8节，第二个时间段是第3-12周中周3的9、10节。有的课有不同的上课时间指的是这个课有多个教学班表设计]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的事务管理]]></title>
    <url>%2F2019%2FSpring%E7%9A%84%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring事务管理API结构PlatformTransactionManager、TransactionStatus和TransactionDefinition是Spring事务管理的三个顶层接口。PlatformTransactionManagerSpring事务管理器的接口是org.springframework.transaction.PlatformTransactionManager，如上图所示，Spring并不直接管理事务，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，也就是将事务管理的职责委托给Hibernate或者JDBC等持久化机制所提供的相关框架的事务来实现。我们进入到 PlatformTransactionManager 接口，查看源码：TransactionStatus这个接口描述的是一些处理事务提供简单的控制事务执行和查询事务状态的方法，在回滚或提交的时候需要应用对应的事务状态。获得方式就是PlatformTransactionManager的getTransaction(TransactionDefinition)。TransactionDefinition上面讲到的事务管理器接口PlatformTransactionManager通过getTransaction(TransactionDefinition definition)方法来得到事务，这个方法里面的参数是TransactionDefinition类，这个类就定义了一些基本的事务属性。 事务属性可以理解成事务的一些基本配置，描述了事务策略如何应用到方法上。事务属性包含了5个方面：隔离级别是否只读：由于只读事务不存在数据的修改，因此数据库将会为只读事务提供一些优化手段。事务超时传播行为：后续详解传播行为当具有事务的方法被另一个具有事务方法调用时，必须指定事务应该如何传播。PROPAGATION_REQUIRED ：required , 必须。默认值，A如果有事务，B将使用该事务；如果A没有事务，B将创建一个新的事务。PROPAGATION_SUPPORTS：supports ，支持。A如果有事务，B将使用该事务；如果A没有事务，B将以非事务执行。PROPAGATION_MANDATORY：mandatory ，强制。A如果有事务，B将使用该事务；如果A没有事务，B将抛异常。PROPAGATION_REQUIRES_NEW ：requires_new，必须新的。如果A有事务，将A的事务挂起，B创建一个新的事务；如果A没有事务，B创建一个新的事务。PROPAGATION_NOT_SUPPORTED ：not_supported ,不支持。如果A有事务，将A的事务挂起，B将以非事务执行；如果A没有事务，B将以非事务执行。PROPAGATION_NEVER ：never，从不。如果A有事务，B将抛异常；如果A没有事务，B将以非事务执行。PROPAGATION_NESTED ：nested ，嵌套。A和B底层采用保存点机制，形成嵌套事务。隔离级别ISOLATION_DEFAULT：使用后端数据库默认的隔离级别ISOLATION_READ_UNCOMMITTED：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读ISOLATION_READ_COMMITTED：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生ISOLATION_REPEATABLE_READ：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生ISOLATION_SERIALIZABLE：最高的隔离级别，完全服从ACID的隔离级别，确保阻止脏读、不可重复读以及幻读，也是最慢的事务隔离级别，因为它通常是通过完全锁定事务相关的数据库表来实现的编程式事务123456package com.tx.demo1;public interface AccountDao &#123; public void outMoney(String from ,Double money); public void inMoney(String to ,Double money);&#125;123456789101112131415161718package com.tx.demo1;import org.springframework.jdbc.core.support.JdbcDaoSupport;//JdbcDaoSupport是Spring为我们提供的简便Jdbc模板开发的类public class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; @Override public void outMoney(String from, Double money) &#123; this.getJdbcTemplate().update("update account set money = money - ? where name = ?", money,from); &#125; @Override public void inMoney(String to, Double money) &#123; this.getJdbcTemplate().update("update account set money = money + ? where name = ?", money ,to); &#125;&#125;1234567package com.tx.demo1;public interface AccountService &#123; public void transfer(String from,String to,Double money); &#125;12345678910111213141516171819202122232425262728293031323334353637package com.tx.demo1;import org.springframework.transaction.TransactionStatus;import org.springframework.transaction.support.TransactionCallbackWithoutResult;import org.springframework.transaction.support.TransactionTemplate;public class AccountServiceImpl implements AccountService &#123; // 注入DAO: private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; // 注入事务管理的模板：这个类应用于编程式事务 private TransactionTemplate trsactionTemplate; public void setTrsactionTemplate(TransactionTemplate trsactionTemplate) &#123; this.trsactionTemplate = trsactionTemplate; &#125; @Override public void transfer(final String from, final String to, final Double money) &#123; trsactionTemplate.execute(new TransactionCallbackWithoutResult() &#123; @Override protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) &#123; accountDao.outMoney(from, money); int d = 1/0; accountDao.inMoney(to, money); &#125; &#125;); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;!-- 配置Service============= --&gt; &lt;bean id="accountService" class="com.tx.demo1.AccountServiceImpl"&gt; &lt;property name="accountDao" ref="accountDao"/&gt; &lt;property name="trsactionTemplate" ref="transactionTemplate"/&gt; &lt;/bean&gt; &lt;!-- 配置DAO================= --&gt; &lt;bean id="accountDao" class="com.tx.demo1.AccountDaoImpl"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 配置连接池和JDBC的模板 --&gt; &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!-- 配置C3P0连接池=============================== --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;!-- 配置平台事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理的模板 --&gt; &lt;bean id="transactionTemplate" class="org.springframework.transaction.support.TransactionTemplate"&gt; &lt;property name="transactionManager" ref="transactionManager"/&gt; &lt;/bean&gt;&lt;/beans&gt;XML方式声明式事务修改AccountServiceImpl：1234567891011121314151617181920package com.tx.demo2;public class AccountServiceImpl implements AccountService &#123; private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void transfer( String from, String to, Double money) &#123; accountDao.outMoney(from, money); int d = 1/0; accountDao.inMoney(to, money); &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;!-- 配置Service============= --&gt; &lt;bean id="accountService" class="com.tx.demo2.AccountServiceImpl"&gt; &lt;property name="accountDao" ref="accountDao"/&gt; &lt;/bean&gt; &lt;!-- 配置DAO================= --&gt; &lt;bean id="accountDao" class="com.tx.demo2.AccountDaoImpl"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 配置连接池和JDBC的模板 --&gt; &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!-- 配置C3P0连接池=============================== --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器=============================== --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 配置事务的增强=============================== --&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;!-- * 表示所有方法 --&gt; &lt;tx:method name="*" propagation="REQUIRED" read-only="false" isolation="DEFAULT"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- aop的配置 --&gt; &lt;aop:config&gt; &lt;aop:pointcut expression="execution(* com.tx.demo2.AccountServiceImpl.*(..))" id="pointcut1"/&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="pointcut1"/&gt; &lt;/aop:config&gt;&lt;/beans&gt;注解方式声明式事务修改AccountServiceImpl：1234567891011121314151617181920212223242526package com.tx.demo3;import org.springframework.transaction.annotation.Isolation;import org.springframework.transaction.annotation.Propagation;import org.springframework.transaction.annotation.Transactional;@Transactional(isolation=Isolation.DEFAULT,propagation=Propagation.REQUIRED)public class AccountServiceImpl implements AccountService &#123; // 注入DAO: private AccountDao accountDao; public void setAccountDao(AccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public void transfer( String from, String to, Double money) &#123; accountDao.outMoney(from, money); int d = 1/0; accountDao.inMoney(to, money); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;!-- 配置Service============= --&gt; &lt;bean id="accountService" class="com.tx.demo3.AccountServiceImpl"&gt; &lt;property name="accountDao" ref="accountDao"/&gt; &lt;/bean&gt; &lt;!-- 配置DAO================= --&gt; &lt;bean id="accountDao" class="com.tx.demo3.AccountDaoImpl"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 配置连接池和JDBC的模板 --&gt; &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!-- 配置C3P0连接池=============================== --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;property name="driverClass" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理器=============================== --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt; &lt;!-- 开启注解事务================================ --&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;&lt;/beans&gt;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的AOP-xml方式]]></title>
    <url>%2F2019%2FSpring%E7%9A%84AOP-xml%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[AOP概念AOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。AOP的术语连接点（join point）可以被拦截到的点，或者说可以被增强的方法，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，其他语言或框架中的连接点还可以是字段或者构造器。切入点（point cut）真正被拦截到的连接点，比如我们可以对增删查改方法进行拦截来记录日志，但是实际开发中只需要知道对数据库进行了哪些update操作，而忽视查询操作，此时增删改方法就是切入点，而查询方法不是。通知（advice）指拦截到切入点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类。引介（Introduction）值类方面的增强，它描述的是一个过程，比如在类中动态的增加一个方法。目标（target）被增强的对象，也即被代理的对象，比如对对象userDao进行增强，则userDao就是目标。织入（Weaving）将advice应用到目标的过程。代理对象（Proxy）AOP的底层是使用动态技术的，所以代理对象就是Spring为我们提供的增强后的对象。切面（Aspect）类是对物体特征的抽象，切面就是对横切关注点的抽象使用Spring的AOP我们之前虽然一共介绍了八个术语，但是在借助Spring之后只有三个过程是我们编写的：编写目标类编写切面类织入编写目标类1234567891011package test.dao;public interface TestDao &#123; void save(); void update(); void delete(); void insert();&#125;123456789101112131415161718192021222324252627import org.springframework.stereotype.Service;import test.dao.TestDao;@Servicepublic class TestDaoImpl implements TestDao &#123; @Override public void save() &#123; System.out.println("save"); &#125; @Override public void update() &#123; System.out.println("update"); &#125; @Override public void delete() &#123; System.out.println("delete"); &#125; @Override public void insert() &#123; System.out.println("insert"); &#125;&#125;编写切面类1234567package test.aop;public class MyAspectXML &#123; public void checkPri() &#123; System.out.println("校验权限..."); &#125;&#125;织入123456789101112131415161718&lt;!-- 配置 扫描 @Service --&gt;&lt;context:component-scan base-package="test.dao" /&gt;&lt;!-- 配置切面类：将切面类交给Spring来管理 --&gt;&lt;bean id="myAspect" class="test.aop.MyAspectXML"&gt;&lt;/bean&gt;&lt;!-- 通过AOP的配置完成对目标类产生代理 --&gt;&lt;aop:config&gt; &lt;!-- 表达式配置哪些类的哪些方法需要进行增强 --&gt; &lt;aop:pointcut expression="execution(* test.dao.impl.TestDaoImpl.save(..))" id="pointcut1"/&gt; &lt;!-- 将切面类的方法应用在指定的pointcut上 --&gt; &lt;aop:aspect ref="myAspect"&gt; &lt;aop:before method="checkPri" pointcut-ref="pointcut1"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;测试12345678910111213141516171819202122232425262728293031package test;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import test.dao.TestDao;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:applicationContext-service.xml")public class Demo1 &#123; @Autowired private TestDao testDao; @Test public void test() &#123; testDao.insert(); testDao.save(); testDao.update(); testDao.delete(); &#125; &#125;通知的类型前置通知在目标方法之前进行操作。可以获得切入点信息。123public void checkPri(JoinPoint joinPoint) &#123; System.out.println(joinPoint);&#125;后置通知在目标方法之后进行操作。可以获得目标方法的返回值。123public void writeLog(Object str) &#123; System.out.println(str);&#125;12&lt;aop:pointcut expression="execution(* test.dao.impl.TestDaoImpl.delete(..))" id="pointcut2"/&gt;&lt;aop:after-returning method="writeLog" pointcut-ref="pointcut2" returning="str"/&gt;配置中的returning对应的属性值必须和切面类方法的参数名相同。环绕通知在目标方法执行之前和之后进行操作。123456789public Object around(ProceedingJoinPoint joinPoint) throws Throwable&#123; System.out.println(&quot;目标方法执行前...&quot;); //相当于执行目标程序 Object object = joinPoint.proceed(); System.out.println(&quot;目标方法执行后...&quot;); return object;&#125;12&lt;aop:pointcut expression="execution(* test.dao.impl.TestDaoImpl.update(..))" id="pointcut3"/&gt;&lt;aop:around method="around" pointcut-ref="pointcut3"/&gt;异常通知在程序出现异常的时候进行的操作。可以获得异常信息，throwing的属性值和参数名一致1&lt;aop:after-throwing method="" pointcut-ref="" throwing="ex"/&gt;123public void afterThrowing(Throwable ex) &#123; ex.printStackTrace();&#125;最终通知无论代码是否有异常总是会执行。1&lt;aop:after method="" pointcut-ref=""/&gt;表达式的书写由于Spring切面粒度最小是达到方法级别，而execution表达式可以用于明确指定方法返回类型，类名，方法名和参数名等与方法相关的部件，并且在Spring中，大部分需要使用AOP的业务场景也只需要达到方法级别即可，因而execution表达式的使用是最为广泛的。如下是execution表达式的语法：1execution([modifiers-pattern] ret-type-pattern declaring-type-pattern.name-pattern(param-pattern) throws-pattern?)modifiers-pattern：方法的可见性，如public，protected；ret-type-pattern：方法的返回值类型，如int，void等；declaring-type-pattern：方法所在类的全路径名，如com.spring.Aspect；name-pattern：方法名类型，如buisinessService()；param-pattern：方法的参数类型，如java.lang.String；throws-pattern：方法抛出的异常类型，如java.lang.Exception；例子12execution (public * com.spring.service.BusinessObject.businessService(java.lang.String,..))上述切点表达式将会匹配使用public修饰，返回值为任意类型，并且是com.spring.BusinessObject类中名称为businessService的方法，方法可以有多个参数，但是第一个参数必须是java.lang.String类型的方法。上述示例中我们使用了..通配符，关于通配符的类型，主要有两种：*通配符，该通配符主要用于匹配单个单词，或者是以某个词为前缀或后缀的单词。如下示例表示返回值为任意类型，在com.spring.service.BusinessObject类中，并且参数个数为零的方法：1execution(* com.spring.service.BusinessObject.*())下述示例表示返回值为任意类型，在com.spring.service包中，以Business为前缀的类，并且是类中参数个数为零方法：1execution(* com.spring.service.Business*.*())..通配符，该通配符表示0个或多个项，主要用于declaring-type-pattern和param-pattern中，如果用于declaring-type-pattern中，则表示匹配当前包及其子包，如果用于param-pattern中，则表示匹配0个或多个参数。如下示例表示匹配返回值为任意类型，并且是com.spring.service包及其子包下的任意类的名称为businessService的方法，而且该方法不能有任何参数：1execution(* com.spring.service..*.businessService())这里需要说明的是，包路径service...businessService()中的..应该理解为延续前面的service路径，表示到service路径为止，或者继续延续service路径，从而包括其子包路径；后面的.businessService()，这里的*表示匹配一个单词，因为是在方法名前，因而表示匹配任意的类。如下示例是使用..表示任意个数的参数的示例，需要注意，表示参数的时候可以在括号中事先指定某些类型的参数，而其余的参数则由..进行匹配：1execution(* com.spring.service.BusinessObject.businessService(java.lang.String,..))]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPC]]></title>
    <url>%2F2019%2FRPC%2F</url>
    <content type="text"><![CDATA[RPCRemote Procedure Call，远程过程调用。如下图将服务A想将计算的功能让服务B来实现，服务B计算完成后再把数据返回服务A，两个服务在两个不同的机子上。最简单的实现方法是服务B暴露一个借口，让A可以去访问。如使用http或者是直接使用TCP/UDP。那每次调用时，是不是都需要写一串发起http请求的代码呢？比如httpClient.sendRequest…之类的，能不能像本地调用一样，去发起远程调用，让使用者感知不到远程调用的过程呢，像这样：12345@Referenceprivate Calculator calculator;...calculator.add(1,2);...这就可以使用代理模式+IOC来做。通过Spring注入calculator对象，注入时，如果扫描到对象加了@Reference注解，那么就给它生成一个代理对象，将这个代理对象放进容器中。而这个代理对象的内部，就是通过httpClient来实现RPC远程过程调用的。完整的RPC过程，都可以用下面这张图来描述RPC要解决的两个问题：解决分布式系统中，服务之间的调用问题。远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。RMIRMI是Java提供的一种访问远程对象的协议，是已经实现好了的，可以直接用了。给一个小案例：1234567891011121314151617181920212223242526272829303132333435package pojo;import java.io.Serializable;public class User implements Serializable &#123; private static final long serialVersionUID = -8400949180923337013L; private String id; private String name; private int age; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;12345678910package service;import java.rmi.Remote;import java.rmi.RemoteException;import pojo.User;public interface UserService extends Remote &#123; public User getUserById(String id)throws RemoteException;&#125;1234567891011121314151617181920212223242526package service.impl;import java.rmi.RemoteException;import java.rmi.server.UnicastRemoteObject;import service.UserService;import pojo.User;public class UserServiceImpl extends UnicastRemoteObject implements UserService &#123; private static final long serialVersionUID = 6222175854495075991L; public UserServiceImpl() throws RemoteException &#123; super(); &#125; @Override public User getUserById(String id) &#123; User user=new User(); user.setId(id); user.setAge(100); user.setName("測试"); return user; &#125;&#125;1234567891011121314151617181920212223242526272829303132package test;import java.net.MalformedURLException;import java.nio.channels.AlreadyBoundException;import java.rmi.Naming;import java.rmi.RemoteException;import java.rmi.registry.LocateRegistry;import service.UserService;import service.impl.UserServiceImpl;public class Server &#123; public static void main(String[] args) &#123; try &#123; UserService userService = new UserServiceImpl(); // 注冊通讯端口 LocateRegistry.createRegistry(6600); // 注冊通讯路径 Naming.rebind("rmi://127.0.0.1:6600/userService", userService); System.out.println("Service Start!"); &#125; catch (RemoteException e) &#123; System.out.println("创建远程对象发生异常！"); e.printStackTrace(); &#125; catch (AlreadyBoundException e) &#123; System.out.println("发生反复绑定对象异常！"); e.printStackTrace(); &#125; catch (MalformedURLException e) &#123; System.out.println("发生URL畸形异常！"); e.printStackTrace(); &#125; &#125;&#125;12345678910111213141516171819package test;import java.rmi.Naming;import pojo.User;import service.UserService;public class Client &#123; public static void main(String[] args) &#123; try &#123; // 调用远程对象，注意RMI路径与接口必须与server配置一致 UserService userService = (UserService) Naming.lookup("rmi://127.0.0.1:6600/userService"); User user = userService.getUserById("1245"); System.out.println(user.getName()); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125;&#125;参考https://www.cnblogs.com/mfmdaoyou/p/6816797.html]]></content>
      <categories>
        <category>Java分布式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分布式系统开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO]]></title>
    <url>%2F2019%2FJava-NIO%2F</url>
    <content type="text"><![CDATA[概述服务器程序只需要一个线程就能同时负责接收客户的连接、接收各个客户发送的数据，以及向各个客户发送响应数据。服务器程序的处理流程如下：12345678while(一直等待，直到有接收连接就绪事件、读就绪事件或写就绪事件发生)&#123; //阻塞 if(有客户连接) 接收客户的连接; //非阻塞 if(某个Socket的输入流中有可读数据) 从输入流中读数据; //非阻塞 if(某个Socket的输出流可以写数据) 向输出流写数据; //非阻塞&#125;以上处理流程采用了轮询的工作方式，当某一种操作就绪，就执行该操作，否则就察看是否还有其他就绪的操作可以执行。线程不会因为某一个操作还没有就绪，就进入阻塞状态，一直傻傻的在那里等待这个操作就绪。SelectorSelector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。Selector的创建通过调用Selector.open()方法创建一个Selector，如下：1Selector selector = Selector.open();向Selector注册通道为了将Channel和Selector配合使用，必须将channel注册到selector上。通过SelectableChannel.register()方法来实现，如下：12channel.configureBlocking(false);SelectionKey key = channel.register(selector, Selectionkey.OP_READ);与Selector一起使用时，Channel必须处于非阻塞模式下。这意味着不能将FileChannel与Selector一起使用，因为FileChannel不能切换到非阻塞模式。而套接字通道都可以。注意register()方法的第二个参数。这是一个“interest集合”，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件：SelectionKey.OP_ACCEPT：接收连接就绪事件，表示服务器监听到了客户连接，服务器可以接收这个连接了。常量值为16SelectionKey.OP_CONNECT：连接就绪事件，表示客户与服务器的连接已经建立成功。常量值为8。SelectionKey.OP_READ：读就绪事件，表示通道中已经有了可读数据，可以执行读操作了。常量值为1。SelectionKey.OP_WRITE：写就绪事件，表示已经可以向通道写数据了。常量值为4。以上常量分别占居不同的二进制位，因此可以通过二进制的或运算“|”，来将它们进行任意组合。总结来说：通道触发了一个事件意思是该事件已经就绪。所以，某个channel成功连接到另一个服务器称为“连接就绪”。一个serverSocketChannel准备好接收新进入的连接称为“接收就绪”。一个有数据可读的通道可以说是“读就绪”。等待写数据的通道可以说是“写就绪”。SelectionKey在上一小节中，当向Selector注册Channel时，register()方法会返回一个SelectionKey对象。这个对象包含了一些你感兴趣的属性：interest集合ready集合ChannelSelector附加的对象（可选）interest集合就像向Selector注册通道一节中所描述的，interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合，像这样：1234int interestSet = selectionKey.interestOps();boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT；// 其他的也类似...ready集合ready 集合是通道已经准备就绪的操作的集合。在一次选择（Selection）之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合：intreadySet = selectionKey.readyOps();可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型：1234selectionKey.isAcceptable();selectionKey.isConnectable();selectionKey.isReadable();selectionKey.isWritable();Channel + Selector从SelectionKey访问Channel和Selector很简单。如下：12Channel channel = selectionKey.channel();Selector selector = selectionKey.selector();附加的对象可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下：12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment();还可以在用register()方法向Selector注册Channel的时候附加对象。如：1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);通过Selector选择通道一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。下面是select()方法：int select()：阻塞到至少有一个通道在你注册的事件上就绪了。int select(long timeout)：和select()一样，除了最长会阻塞timeout毫秒(参数)。int selectNow()：不会阻塞，不管什么通道就绪都立刻返回（此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。）。select()方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，因为有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。selectedKeys()一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示：1Set selectedKeys = selector.selectedKeys();当像Selector注册Channel时，Channel.register()方法会返回一个SelectionKey 对象。这个对象代表了注册到该Selector的通道。可以通过SelectionKey的selectedKeySet()方法访问这些对象。可以遍历这个已选择的键集合来访问就绪的通道。如下：123456789101112131415Set selectedKeys = selector.selectedKeys();Iterator keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // a connection was accepted by a ServerSocketChannel. &#125; else if (key.isConnectable()) &#123; // a connection was established with a remote server. &#125; else if (key.isReadable()) &#123; // a channel is ready for reading &#125; else if (key.isWritable()) &#123; // a channel is ready for writing &#125; keyIterator.remove();&#125;这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。SelectionKey.channel()方法返回的通道需要转型成你要处理的类型，如ServerSocketChannel或SocketChannel等。SocketChannel打开 SocketChannel下面是SocketChannel的打开方式：12SocketChannel socketChannel = SocketChannel.open();socketChannel.connect(new InetSocketAddress(&quot;127.0.0.1&quot;, 20000));关闭 SocketChannel1socketChannel.close();ServerSocketChannelJava NIO中的 ServerSocketChannel 是一个可以监听新进来的TCP连接的通道, 就像标准IO中的ServerSocket一样。ServerSocketChannel类在 java.nio.channels包中。打开 ServerSocketChannel通过调用 ServerSocketChannel.open() 方法来打开ServerSocketChannel，如：1ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();关闭 ServerSocketChannel通过调用ServerSocketChannel.close() 方法来关闭ServerSocketChannel，如：1serverSocketChannel.close();监听新进来的连接通过 ServerSocketChannel.accept() 方法监听新进来的连接。当 accept()方法返回的时候,它返回一个包含新进来的连接的 SocketChannel。因此, accept()方法会一直阻塞到有新连接到达。通常不会仅仅只监听一个连接,在while循环中调用 accept()方法，如下面的例子：123456while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel...&#125;当然，也可以在while循环中使用除了true以外的其它退出准则。非阻塞模式ServerSocketChannel可以设置成非阻塞模式。在非阻塞模式下，accept() 方法会立刻返回，如果还没有新进来的连接,返回的将是null。 因此，需要检查返回的SocketChannel是否是null，如：12345678910111213ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(9999));serverSocketChannel.configureBlocking(false);while(true)&#123; SocketChannel socketChannel = serverSocketChannel.accept(); if(socketChannel != null)&#123; //do something with socketChannel... &#125;&#125;服务器使用NIO向客户端Echo数据的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package com.core;import java.io.BufferedInputStream;import java.io.FileInputStream;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.ClosedChannelException;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.nio.charset.Charset;import java.util.ArrayList;import java.util.Date;import java.util.Iterator;import java.util.List;import java.util.Scanner;import java.util.Set;public class EchoSeverZJH &#123; private Selector selector; private ServerSocketChannel serverSocketChannel; private int port = 8000; private Charset charset = Charset.forName("utf-8"); private List&lt;String&gt; list = new ArrayList&lt;&gt;(); private int num; public EchoSeverZJH()&#123; try &#123; selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.socket().setReuseAddress(true); serverSocketChannel.socket().bind(new InetSocketAddress(port)); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; System.out.println("服务器开启成功... : " + new Date()); list.add("一共有18018条航班数据"); try (Scanner cin = new Scanner(new BufferedInputStream(new FileInputStream("copy")))) &#123; String line = null; while(cin.hasNext()) &#123; line = cin.nextLine(); list.add(line); &#125; list.add("no data"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; num = list.size(); System.out.println("数据已准备好... : " + new Date()); &#125; public void service()&#123; try &#123; serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); &#125; catch (ClosedChannelException e) &#123; e.printStackTrace(); &#125; while (true) &#123; //没有连接就会阻塞 int n = 0; try &#123; n = selector.select(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; if (n == 0) continue; Set&lt;SelectionKey&gt; readkeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = readkeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); if(!key.isValid()) &#123; iterator.remove(); continue; &#125; if (key.isAcceptable()) &#123; accept(key); &#125; if (key.isWritable()) &#123; send(key); &#125; iterator.remove(); &#125; &#125; &#125; // 处理接收连接就绪事件 private void accept(SelectionKey key)&#123; // 返回一个对象 SocketChannel socketChannel; try &#123; socketChannel = serverSocketChannel.accept(); System.out.println("收到了客户端连接，来自 ： " + socketChannel.getRemoteAddress()); socketChannel.configureBlocking(false); //注册到selector socketChannel.register(selector, SelectionKey.OP_WRITE, 0); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 处理写就绪事件 private void send(SelectionKey key)&#123; SocketChannel socketChannel = (SocketChannel) key.channel(); int index = (int)key.attachment(); key.attach((index + 1) % num); String line = list.get(index); ByteBuffer outputBuffer = charset.encode(line + "\r\n"); while (outputBuffer.hasRemaining()) &#123; try &#123; socketChannel.write(outputBuffer); &#125; catch (IOException e) &#123; key.cancel(); try &#123; System.out.println(socketChannel.getRemoteAddress() + " 断开连接----"); socketChannel.socket().close(); socketChannel.close(); outputBuffer.clear(); break; &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args)&#123; new EchoSeverZJH().service(); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435package com.core;import java.io.IOException;import java.net.InetAddress;import java.net.Socket;import java.util.Scanner;public class ReadFromSocket&#123; public static void main(String[] args) &#123; Socket socket = null; Scanner sc = null; try &#123; socket = new Socket(InetAddress.getByName("127.0.0.1"), 8000); String line = null; sc = new Scanner(socket.getInputStream()); line = sc.nextLine(); System.out.println(line); while (sc.hasNext()) &#123; Thread.sleep(1000); line = sc.nextLine(); System.out.println(line); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; sc.close(); &#125; &#125;&#125;Selector维护的集合对上面的代码有一个很大的疑问，即服务器端为什么要进行iterator.remove();。解答这个问题之前我们先来理一下思路：服务器端有一个ServerSocketChannel，它绑定了端口号，且设置为非阻塞模式，它先向Selector中注册：serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);。ServerSocketChannel在注册的时候指定的事件是：OP_ACCEPT`，表示接收连接就绪事件，即服务器在监听客户连接。每一个注册到selector上的channel都会被加入一个集合（key set），这个集合可以通过selector.keys()方法返回。然后判断已经准备好的连接n = selector.select();有几个，如果等于0则表示没有准备好的连接，此时需要continue。其中，已经准备好的连接可以按如下获得：Set&lt;SelectionKey&gt; readkeys = selector.selectedKeys();。即所有已经准备好channel都在一个集合（selected-key）中。但是selected-key本身并不是线程安全的，所以在处理的时候需要判断其是不是已经合法的，比如如果客户端中断了访问，则不能在传输数据，即其实不合法的。同时，每个都撤销的channel都在cancelled-key set中，但是所关联channel还没有被撤销登记。其不能够被直接返回，但也一定是key set的子集。所以我们移出的其实只是已准备好的channel的key。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-Channel和Buffer]]></title>
    <url>%2F2019%2FJava-Channel%E5%92%8CBuffer%2F</url>
    <content type="text"><![CDATA[ChannelJava NIO的通道类似流，但又有些不同：既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。通道可以异步地读写。通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。java.nio.channels.Channel接口只声明了两个方法：close()：关闭通道。isOpen()：判断通道是否打开。通道在创建时被打开，一旦关闭通道，就不能重新打开它。Channel的实现这些是Java NIO中最重要的通道的实现：FileChannel：从文件中读写数据。DatagramChannel：能通过UDP读写网络中的数据。SocketChannel：能通过TCP读写网络中的数据。ServerSocketChannel：可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。BufferJava NIO中的Buffer用于和NIO通道进行交互。如你所知，数据是从通道读入缓冲区，从缓冲区写入到通道中的。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。为了理解Buffer的工作原理，需要熟悉它的三个属性：capacity：作为一个内存块，Buffer有一个固定的大小值，叫“capacity”。你只能往对应的Buffer里写capacity个byte、long，char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。position：当你写数据到Buffer中时，position表示当前的位置。初始的position值为0，当一个byte、long等数据写到Buffer后， position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。当读取数据时，也是从某个特定位置读。当将Buffer从写模式切换到读模式，position会被重置为0. 当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。limit：写模式下，Buffer的limit表示你最多能往Buffer里写多少数据，此时limit等于Buffer的capacity。当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。换句话说，你能读到之前写入的所有数据（limit被设置成已写数据的数量，这个值在写模式下就是position）Buffer的实现Java NIO 有以下Buffer类型ByteBufferMappedByteBufferCharBufferDoubleBufferFloatBufferIntBufferLongBufferShortBufferBuffer详解在我们刚才的说明中提到了写模式和读模式，但是实际上这只是被强行赋予的，即JDK中并没有说法，这么说只是为了更方便的理解，所以下面我们来解读一下Buffer的API及怎么在两种模式之间进行切换。需要指出：写模式指的是想Buffer写入，读模式是从Buffer里读出。Buffer的分配要想获得一个Buffer对象首先要进行分配。 每一个Buffer类都有一个allocate方法。下面是一个分配48字节capacity的ByteBuffer的例子。ByteBuffer buf = ByteBuffer.allocate(48);这是分配一个可存储1024个字符的CharBuffer：CharBuffer buf = CharBuffer.allocate(1024);刚获得的Buffer默认是写模式。### 向Buffer中写数据写数据到Buffer有两种方式：- 从Channel写到Buffer：int bytesRead = inChannel.read(buf); //read into buffer- bytesRead指读出的数据大小。当bytesRead为-1时表示缓存区中不再有数据。- 通过Buffer的put()方法写到Buffer里：buf.put(127);- put()：相对写。向缓冲区的当前位置写入一个单元的数据，写完后把位置加1。- put(int index)：绝对写。向参数index指定的位置写入一个单元的数据。12345678910111213141516171819202122232425262728293031323334package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo1 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); FileChannel inChannel = fileIn.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf); while (bytesRead != -1) &#123; System.out.println("Read " + bytesRead); buf.flip(); //写模式切换为读模式 System.out.println(charset.decode(buf).toString()); buf.clear(); bytesRead = inChannel.read(buf); &#125; fileIn.close(); &#125;&#125;inChannel.read(buf);之后，buf.flip();之前Buffer的状态：向Channel中写数据12345678910111213141516171819202122232425262728293031323334353637package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo2 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 * test_out中没有数据，用于Java程序的写出 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel inChannel = fileIn.getChannel(); FileChannel outChannel = fileOut.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = -1; do &#123; bytesRead = inChannel.read(buf); System.out.println("Read " + bytesRead); buf.flip(); //写模式切换为读模式 outChannel.write(buf); buf.clear(); &#125;while(bytesRead != -1); fileIn.close(); fileOut.close(); &#125;&#125;buf.flip();之后，outChannel.write(buf);之前Buffer的状态。测试limit1234567891011121314151617181920212223242526272829303132333435363738package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo2 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; /** * test_in是有数据的文件，用于被读入至Java程序 * test_out中没有数据，用于Java程序的写出 */ RandomAccessFile fileIn = new RandomAccessFile("test_in", "rw"); RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel inChannel = fileIn.getChannel(); FileChannel outChannel = fileOut.getChannel(); ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = -1; do &#123; bytesRead = inChannel.read(buf); System.out.println("写模式下： " + buf.limit()); buf.flip(); //写模式切换为读模式 System.out.println("读模式下： " + buf.limit()); outChannel.write(buf); buf.clear(); &#125;while(bytesRead != -1); fileIn.close(); fileOut.close(); &#125;&#125;rewind()方法Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。clear()与compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。可以通过clear()或compact()方法来完成。如果调用的是clear()方法，position将被设回0，limit被设置成 capacity的值。换句话说，Buffer被清空了。Buffer中的数据并未清除。如果Buffer中有一些未读的数据，调用clear()方法，数据将“被遗忘”，意味着不再有任何标记会告诉你哪些数据被读过，哪些还没有。如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先先写些数据，那么使用compact()方法。compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。mark()与reset()方法通过调用Buffer.mark()方法，可以标记Buffer中的一个特定位置。之后可以通过调用Buffer.reset()方法将position置于这个位置。equals()与compareTo()方法equals()当满足下列条件时，表示两个Buffer相等：有相同的类型（byte、char、int等）。Buffer中剩余的byte、char等的个数相等。Buffer中所有剩余的byte、char等都相同。如你所见，equals只是比较Buffer的一部分，不是每一个在它里面的元素都比较。实际上，它只比较Buffer中的剩余元素。compareTo()方法compareTo()方法比较两个Buffer的剩余元素(byte、char等)， 如果满足下列条件，则认为一个Buffer“小于”另一个Buffer：第一个不相等的元素小于另一个Buffer中对应的元素 。所有元素都相等，但第一个Buffer比另一个先耗尽（第一个Buffer的元素个数比另一个少）。Scatter/Gatherscatter：分散，从Channel中读取是指在读操作时将读取的数据写入多个buffer中。因此，Channel将从Channel中读取的数据“分散（scatter）”到多个Buffer中。Scattering Reads是指数据从一个channel读取到多个buffer中。如下图描述：12345678910111213141516171819202122232425package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;import java.nio.charset.Charset;public class Demo3 &#123; private static Charset charset = Charset.forName("UTF-8"); public static void main(String[] args) throws Exception &#123; RandomAccessFile file = new RandomAccessFile("test_in", "rw"); FileChannel channel = file.getChannel(); ByteBuffer header = ByteBuffer.allocate(6); ByteBuffer body = ByteBuffer.allocate(64); ByteBuffer[] bufferArray = &#123; header, body &#125;; long read = channel.read(bufferArray); System.out.println(read); header.flip(); body.flip(); System.out.println(charset.decode(header).toString()); System.out.println(charset.decode(body).toString()); &#125;&#125;read()方法按照buffer在数组中的顺序将从channel中读取的数据写入到buffer，当一个buffer被写满后，channel紧接着向另一个buffer中写。Scattering Reads在移动下一个buffer前，必须填满当前的buffer，这也意味着它不适用于动态消息（消息大小不固定）。换句话说，如果存在消息头和消息体，消息头必须完成填充（例如 128byte），Scattering Reads才能正常工作。gather：聚集，写入Channel是指在写操作时将多个buffer的数据写入同一个Channel，因此，Channel 将多个Buffer中的数据“聚集（gather）”后发送到Channel。Gathering Writes是指数据从多个buffer写入到同一个channel。如下图描述：123456789101112131415161718192021222324252627package com.test;import java.io.RandomAccessFile;import java.nio.ByteBuffer;import java.nio.channels.FileChannel;public class Demo4 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fileOut = new RandomAccessFile("test_out", "rw"); FileChannel channelOut = fileOut.getChannel(); ByteBuffer header = ByteBuffer.allocate(6); ByteBuffer body = ByteBuffer.allocate(64); header.put("陈".getBytes()); body.put("钰琪是个大可爱".getBytes()); ByteBuffer[] bufferArray = &#123; header, body &#125;; header.flip(); body.flip(); channelOut.write(bufferArray); fileOut.close(); &#125;&#125;通道之间的数据传输在Java NIO中，如果两个通道中有一个是FileChannel，那你可以直接将数据从一个channel传输到另外一个channel。transferFrom()FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中（这个方法在JDK文档中的解释为将字节从给定的可读取字节通道传输到此通道的文件中）。下面是一个简单的例子：123456789101112131415161718192021222324package com.test;import java.io.RandomAccessFile;import java.nio.channels.FileChannel;public class Demo5 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fromFile = new RandomAccessFile("test_in", "rw"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile("test_out", "rw"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count); fromFile.close(); toFile.close(); &#125;&#125;transferTo()将数据从FileChannel传输到其他的channe中。下面是一个简单的例子：123456789101112131415161718192021222324package com.test;import java.io.RandomAccessFile;import java.nio.channels.FileChannel;public class Demo6 &#123; public static void main(String[] args) throws Exception &#123; RandomAccessFile fromFile = new RandomAccessFile("test_in", "rw"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile("test_out", "rw"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel); fromFile.close(); toFile.close(); &#125;&#125;参考http://ifeve.com/Java-Channel和Buffer-all/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-序列化]]></title>
    <url>%2F2019%2FJava-%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[概述把Java对象转换为字节序列的过程称为对象的序列化；把字节序列恢复为Java对象的过程称为对象的反序列化。对象的序列化主要有两种用途：把对象的字节序列永久的保存到硬盘上，通常存放在一个文件中。在网络上传送对象的字节序列。默认序列化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package cn.isjinhao.pojo;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;import java.nio.file.Path;import java.nio.file.Paths;public class Server &#123; public static void main(String[] args) throws Exception &#123; Path path = Paths.get("test"); Person temp = new Person("陈钰琪", 19, "411x2x19xx1x2x6x1x", 20000d); ObjectOutputStream out=new ObjectOutputStream(new FileOutputStream(path.toFile())); out.writeObject(temp); ObjectInputStream in=new ObjectInputStream(new FileInputStream(path.toFile())); Person readObject = (Person)in.readObject(); System.out.println(readObject); &#125;&#125;class Person implements Serializable&#123; private static final long serialVersionUID = -485348963313276072L; private String name; private Integer age; private String id; private Double money; public Person(String name, Integer age, String id, Double money) &#123; super(); this.name = name; this.age = age; this.id = id; this.money = money; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public Double getMoney() &#123; return money; &#125; public void setMoney(Double money) &#123; this.money = money; &#125; @Override public String toString() &#123; return "Person [name=" + name + ", age=" + age + ", id=" + id + ", money=" + money + "]"; &#125;&#125;版本号版本号是为了控制对象的版本而存在的，版本号一致才可认为可以进行对应的序列化和反序列化。比如我们使用上面的代码把一个Person写入temp文件了，然后修改serialVersionUID = 485348963313276072L;，会发现爆出java.io.InvalidClassException。12345678910111213import java.io.FileInputStream;import java.io.ObjectInputStream;import java.nio.file.Path;import java.nio.file.Paths;public class Client &#123; public static void main(String[] args) throws Exception &#123; Path path = Paths.get("test"); ObjectInputStream in=new ObjectInputStream(new FileInputStream(path.toFile())); Person readObject = (Person)in.readObject(); System.out.println(readObject); &#125;&#125;序列化图在默认方式下，对象输出流会对整个对象图进行序列化。控制序列化不会序列化对象的transient修饰的的变量。不会序列化静态变量。单例的处理12345678910public final class MySingleton implements Serializable&#123; private MySingleton() &#123; &#125; private static final MySingleton INSTANCE = new MySingleton(); public static MySingleton getInstance() &#123; return INSTANCE; &#125; private Object readResolve() throws ObjectStreamException &#123; // instead of the object we're on, // return the class variable INSTANCE return INSTANCE; &#125; &#125;反序列化”组装”一个新对象时，就会自动调用这个readResolve方法来返回我们指定好的对象了，单例规则也就得到了保证。ExternalizableExternalizable接口extends Serializable接口，而且在其基础上增加了两个方法：writeExternal()和readExternal()。这两个方法会在序列化和反序列化还原的过程中被自动调用，以便执行一些特殊的操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445package test.serializable;import java.io.Externalizable;import java.io.IOException;import java.io.ObjectInput;import java.io.ObjectOutput;public class Blip implements Externalizable &#123; private int i ; private String s;//没有初始化 public Blip() &#123; //默认构造函数必须有，而且必须是public System.out.println("Blip默认构造函数"); &#125; public Blip(String s ,int i) &#123; //s,i只是在带参数的构造函数中进行初始化。 System.out.println("Blip带参数构造函数"); this.s = s; this.i = i; &#125; public String toString() &#123; return s + i ; &#125; @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; System.out.println("调用readExternal（）方法"); s = (String)in.readObject();//在反序列化时，需要初始化s和i，否则只是调用默认构造函数，得不到s和i的值 i = in.readInt(); &#125; @Override public void writeExternal(ObjectOutput out) throws IOException &#123; System.out.println("调用writeExternal（）方法"); out.writeObject(s); //如果我们不将s和i的值写入的话，那么在反序列化的时候，就不会得到这些值。 out.writeInt(i); &#125;&#125;12345678910111213141516171819202122232425262728293031package test.serializable;import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;public class ExternalizableTest &#123; /** * @param args * @throws IOException * @throws ClassNotFoundException */ public static void main(String[] args) throws IOException, ClassNotFoundException &#123; System.out.println("序列化之前"); Blip b = new Blip("This String is " , 47); System.out.println(b); System.out.println("序列化操作，writeObject"); ByteArrayOutputStream out = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(out); oos.writeObject(b); System.out.println("反序列化之后,readObject"); ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray()); ObjectInputStream ois = new ObjectInputStream(in); Blip bb = (Blip)ois.readObject(); System.out.println(bb); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反射]]></title>
    <url>%2F2019%2F%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[概述通常能够分析类能力的程序称为反射（reflective）。程序员通过反射库（包括Class类，Constructor类等）完成业务功能，便是使用到了反射技术。反射的主要功能是在程序运行时分析类。一提到运行时分析类大家肯定第一个想到的是运行时多态。而反射也和运行时多态的功能一致，增强程序的可维护性和可拓展性。运用反射技术来实现功能一般分为四步：获得Class对象、获得构造器、获得类的实例、运行。反射技术甚至可以获得私有信息。获得Class对象Class对象是在类加载时由Java虚拟机创建的封装某类型信息的对象。有三种获得方式：123456789101112131415public class TestClazz &#123; @SuppressWarnings("rawtypes") public static void main(String[] args) throws ClassNotFoundException &#123; //1、通过Object类的getClass()方法 TestClazz tc = new TestClazz(); Class clazz1 = tc.getClass(); //2、通过类的静态class属性。 Class clazz2 = TestClazz.class; //3、通过Class类中的方法构造。这种可拓展性更强，根本不需要知道类型，通过字符串就能获得。 //但是也正是这个原因，可能发生ClassNotFoundException（main函数的此异常与前两者无关） Class clazz3 = Class.forName("com.first.TestClazz"); &#125;&#125;获得构造器获得所有公共权限的构造方法（包括继承的）：clazz.getConstructors();123456789101112131415161718import java.lang.reflect.Constructor;public class TestClazz &#123; public TestClazz(String msg) &#123; System.out.println(msg); &#125; public TestClazz() &#123; &#125; private TestClazz(int i) &#123; System.out.println(i); &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor[] constructors = clazz.getConstructors(); for(Constructor e:constructors) System.out.println(e); /*Console： public com.first.TestClazz(java.lang.String) public com.first.TestClazz() */ &#125;&#125;获得指定参数的公共构造器（可以获得继承的）：clazz.getConstructor((Class... parameterTypes);12345678910111213141516171819import java.lang.reflect.Constructor;public class TestClazz &#123; public TestClazz(String msg) &#123; System.out.println(msg); &#125; public TestClazz() &#123; &#125; private TestClazz(int i) &#123; System.out.println(i); &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor con1 = clazz.getConstructor(); Constructor con2 = clazz.getConstructor(String.class); System.out.println(con1); System.out.println(con2); /*Console: public com.first.TestClazz() public com.first.TestClazz(java.lang.String) */ &#125;&#125;获得所有的构造器（不包括继承的）：clazz.getDeclaredConstructors();12345678910111213141516171819import java.lang.reflect.Constructor;public class TestClazz &#123; private TestClazz(int i) &#123; System.out.println(i); &#125; public TestClazz(String msg) &#123; System.out.println(msg); &#125; public TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor []cons = clazz.getDeclaredConstructors(); for(Constructor e : cons) System.out.println(e); /*Console: public com.first.TestClazz() public com.first.TestClazz(java.lang.String) private com.first.TestClazz(int) */ &#125;&#125;获得指定的构造器（不包括继承的）：clazz.getDeclaredConstructor((Class... parameterTypes);12345678910111213141516import java.lang.reflect.Constructor;public class TestClazz &#123; private TestClazz(int i) &#123; System.out.println(i); &#125; public TestClazz(String msg) &#123; System.out.println(msg); &#125; public TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor con = clazz.getDeclaredConstructor(int.class); System.out.println(con); /*Console: private com.first.TestClazz(int) */ &#125;&#125;创建对象通过公共构造器创建对象：constructor.newInstance(Object... initargs)方法。传入的参数类型和构造器的参数类型一致。12345678910111213141516171819202122232425import java.lang.reflect.Constructor;public class TestClazz &#123; private TestClazz(int i) &#123; System.out.println(i); &#125; public TestClazz(String msg) &#123; System.out.println(msg); &#125; public TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor con1 = clazz.getConstructor(String.class); Object obj1 = con1.newInstance("HelloWorld!"); System.out.println(obj1); System.out.println("-----------------------"); Constructor con2 = clazz.getConstructor(); Object obj2 = con2.newInstance(); System.out.println(obj2); /*Console: HelloWorld! com.first.TestClazz@7852e922 ----------------------- com.first.TestClazz@4e25154f */ &#125;&#125;通过当前类不可访问的构造器创建对象：constructor.setAccessible(true);123456789101112131415161718192021import java.lang.reflect.Constructor;public class TestClazz &#123; private TestClazz(int i) &#123; System.out.println(i); &#125; public TestClazz(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Constructor constructor = clazz.getDeclaredConstructor(int.class); //在本例中不写这句也能执行，因为被反射的类和当前类是同一个类，private的构造方法是可以被访问的 //如果某个构造器是当前类不可访问的，此方法可以使其变成可访问的类型 constructor.setAccessible(true); Object object = constructor.newInstance(1); System.out.println(object); /*Console: 1 com.first.TestClazz@7852e922 */ &#125;&#125;快速获得对象如果被反射的类有被当前类可访问的无参构造函数，可以直接使用clazz.newInstance();12345678910111213141516import java.lang.reflect.Constructor;public class TestClazz &#123; private TestClazz(int i) &#123; System.out.println(i); &#125; public TestClazz(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Object object = clazz.newInstance(); System.out.println(object); /*Console: com.first.TestClazz@7852e922 */ &#125;&#125;获得成员变量获得所有公共类型的属性（包括继承的）：clazz.getFields();123456789101112131415import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Field[] fields = clazz.getFields(); for(Field f : fields) System.out.println(f); /*Console: public java.lang.String com.first.TestClazz.msg */ &#125;&#125;获得指定公共类型的属性（包括继承的）：clazz.getField(String name);1234567891011121314import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Field field = clazz.getField("msg"); System.out.println(field); /*Console: public java.lang.String com.first.TestClazz.msg */ &#125;&#125;获得所有的属性（不包括继承的）：clazz.getDeclaredFields();12345678910111213141516import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Field []fields = clazz.getDeclaredFields(); for(Field f : fields) System.out.println(f); /*Console: public java.lang.String com.first.TestClazz.msg private int com.first.TestClazz.i */ &#125;&#125;获得指定的属性（不包括继承的）：clazz.getDeclaredField(String name);1234567891011121314import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Field field = clazz.getDeclaredField("i"); System.out.println(field); /*Console: private int com.first.TestClazz.i */ &#125;&#125;设置成员变量的值设置可访问的变量的值：field.set(Object obj, Object value);1234567891011121314151617import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); TestClazz object = (TestClazz)clazz.newInstance(); Field field = clazz.getDeclaredField("msg"); field.set(object, "HelloWorld!"); System.out.println(object.msg); /*Console: HelloWorld! */ &#125;&#125;设置不可访问的变量的值：field.setAccessible(true);1234567891011121314151617181920import java.lang.reflect.Field;public class TestClazz &#123; public String msg; private int i; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); TestClazz object = (TestClazz)clazz.newInstance(); Field field = clazz.getDeclaredField("i"); //在本例中不写这句也能执行，因为被反射的类和当前类是同一个类，private的属性是可以被访问的 //如果某个属性是当前类不可访问的，此方法可以使其变成可访问的类型 field.setAccessible(true); field.set(object, 65535); System.out.println(object.i); /*Console: 65535 */ &#125;&#125;一个编译正则表达式的例子1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Regs &#123; //航班唯一标识 public static final String FLID = "((flid=)&#123;1&#125;)\\d&#123;7&#125;"; //航班标识 public static final String FFID = "((ffid=)&#123;1&#125;)\\w&#123;2&#125;-\\w&#123;3,6&#125;-\\d&#123;8&#125;-\\w"; //结束登机时间 public static final String POKT = "((pokt=)&#123;1&#125;)(\\d&#123;14&#125;|null)"; //预计起飞时间 public static final String FETT = "((fett=)&#123;1&#125;)(\\d&#123;14&#125;|null)"; //实际起飞时间 public static final String FRTT = "((frtt=)&#123;1&#125;)(\\d&#123;14&#125;|null)"; //值机柜台 public static final String CODE = "((code=)&#123;1&#125;)[A-Z]\\d&#123;2&#125;"; //航班号 public static final String FLNO = "((flno=)&#123;1&#125;)[A-Za-z0-9]&#123;3,6&#125;"; //出发地 public static final String ARNO1 = "((1, apcd=)&#123;1&#125;)(\\w&#123;3,4&#125;|null)"; //经停地 public static final String ARNO2 = "((2, apcd=)&#123;1&#125;)(\\w&#123;3,4&#125;|null)"; //目的地 public static final String ARNO3 = "((3, apcd=)&#123;1&#125;)(\\w&#123;3,4&#125;|null)"; //共享航班号 public static final String SFNO = "((sfno=)&#123;1&#125;)[A-Za-z0-9]&#123;3,6&#125;"; /** * &lt;p&gt;Title: get&lt;/p&gt; * &lt;p&gt;Description: 获得相应的Pattern&lt;/p&gt; * @param regName，正则表达式对应的属性名 * @return Pattern * @throws Exception */ public Pattern get(String regName) throws Exception &#123; Class clazz = Class.forName("com.core.Regs"); String reg = (String) clazz.getField(regName).get(regName); return changeToPattern(reg); &#125; //编译正则表达式 private static Pattern changeToPattern(String reg) &#123; return Pattern.compile(reg); &#125;&#125;获得成员方法获得所有公共的方法（包括继承的和构造器）：clazz.getMethods();12345678910111213141516171819202122232425import java.lang.reflect.Method;public class TestClazz &#123; private int getI() &#123; return i; &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Method[] methods = clazz.getMethods(); for(Method m : methods) System.out.println(m); /*Console: public static void com.first.TestClazz.main(java.lang.String[]) throws java.lang.Exception public final void java.lang.Object.wait() throws java.lang.InterruptedException public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedException public final native void java.lang.Object.wait(long) throws java.lang.InterruptedException public boolean java.lang.Object.equals(java.lang.Object) public java.lang.String java.lang.Object.toString() public native int java.lang.Object.hashCode() public final native java.lang.Class java.lang.Object.getClass() public final native void java.lang.Object.notify() public final native void java.lang.Object.notifyAll() */ &#125;&#125;获得指定的公共方法（包括继承的，不包括构造器）：clazz.getMethod(String name, Class&lt;?&gt;... parameterTypes);123456789101112131415import java.lang.reflect.Method;public class TestClazz&#123; public void show(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Method m = clazz.getMethod("show", String.class); System.out.println(m); /*Console: public void com.first.TestClazz.show(java.lang.String) */ &#125;&#125;获得所有的方法（不包括继承的，不包括构造器）：clazz.getDeclaredMethods();12345678910111213141516import java.lang.reflect.Method;public class TestClazz&#123; private int getI() &#123; return i; &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Method[] methods = clazz.getDeclaredMethods(); for(Method m : methods) System.out.println(m); /*Console: public static void com.first.TestClazz.main(java.lang.String[]) throws java.lang.Exception private int com.first.TestClazz.getI() */ &#125;&#125;获得指定的方法（不包括继承的，不包括构造器）：clazz.getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes);1234567891011121314import java.lang.reflect.Method;public class TestClazz&#123; private void show(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings("rawtypes") public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName("com.first.TestClazz"); Method m = clazz.getDeclaredMethod("show", String.class); System.out.println(m); /*Console: public void com.first.TestClazz.show(java.lang.String) */ &#125;&#125;执行方法执行公共方法：method.invoke(Object obj, Object... args);123456789101112131415import java.lang.reflect.Method;public class TestClazz&#123; public void show(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings(&quot;rawtypes&quot;) public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName(&quot;com.first.TestClazz&quot;); Object object = clazz.newInstance(); Method m = clazz.getDeclaredMethod(&quot;show&quot;, String.class); m.invoke(object, &quot;HelloWorld!&quot;); /*Console: HelloWorld */ &#125;&#125;执行私有方法：method.invoke(Object obj, Object... args);12345678910111213141516import java.lang.reflect.Method;public class TestClazz&#123; private void show(String msg) &#123; System.out.println(msg); &#125; TestClazz() &#123; &#125; @SuppressWarnings(&quot;rawtypes&quot;) public static void main(String[] args) throws Exception &#123; Class clazz = Class.forName(&quot;com.first.TestClazz&quot;); Object object = clazz.newInstance(); Method m = clazz.getDeclaredMethod(&quot;show&quot;, String.class); m.setAccessible(true); m.invoke(object, &quot;HelloWorld!&quot;); /*Console: HelloWorld */ &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[方法功能的增强]]></title>
    <url>%2F2019%2F%E6%96%B9%E6%B3%95%E5%8A%9F%E8%83%BD%E7%9A%84%E5%A2%9E%E5%BC%BA%2F</url>
    <content type="text"><![CDATA[引言方法功能的增强是开发时常做的事情，当官方或者第三方提供的API不能满足我们的需要时，可以在原有API的基础上加上我们自定义的功能来实现需求。常见的功能增强的方式有三种：继承、装饰者模式、动态代理。准备工作以最近看的某码农培训班的视频结合自己的理解给出个例子来理解。现在有一个很火的概念：无人驾驶。假设无人驾驶的标准是Oracle公司制定的，Google想使用Java语言来开发无人驾驶系统，那么首先它需要创建一个类实现Oracle公司提供的无人驾驶的接口（接口为AIDriving，类为GoogleAIDriving）。AIDriving1234public interface AIDriving &#123; public void start(); //无人驾驶汽车启动的方法 public void stop(); //无人驾驶汽车停止的方法&#125;GoogleAIDriving12345678public class GoogleAIDriving implements AIDriving &#123; public void start() &#123; System.out.println("Google汽车启动了..."); &#125; public void stop() &#123; System.out.println("Google汽车停止了..."); &#125;&#125;继承这个时候国内某汽车制造公司（设为A公司）想使用Google提供的无人驾驶系统。但是Google提供的系统不太适合我国国情，所以A公司的工程师就想在Google系统的基础上进行定制。他们选择的方式是继承GoogleAIDriving，创建一个自己的类：A1GoogleAIDriving。12345678910public class A1GoogleAIDriving extends GoogleAIDriving&#123; public void start() &#123; System.out.println("在中国启动汽车"); super.start(); &#125; public void stop() &#123; System.out.println("在中国停止汽车"); super.stop(); &#125;&#125;装饰者模式但理想很美好，现实很残忍。GoogleAIDriving被定义为一个final类（不能被继承），这个是可以理解的，因为如果GoogleAIDriving不是一个final类，任何继承GoogleAIDriving的类都可以对其start()、stop()方法进行覆盖，如果覆盖时出现bug就可能会出现大问题。所以像启动、停止这种核心功能是不允许汽车制造商随意修改的。A公司的工程师就想到了使用装饰者模式来增强功能（设类为A2GoogleAIDriving）。装饰者模式该怎么做呢？首先，装饰类得和被装饰类实现相同的接口，即AIDriving；第二，在装饰类中定义一个AIDriving类型的属性，即AIDriving car；第三，有一个参数为AIDriving类型的构造函数，即A2GoogleAIDriving(AIDriving car)；第四，装饰类的每个方法都要调用被装饰类相应的方法；第五，使用第三步中的构造函数创建装饰类；第六，在装饰类的方法中自定义功能。创建装饰类123456789101112131415public class A2GoogleAIDriving implements AIDriving &#123; private AIDriving car; public A2GoogleAIDriving(AIDriving car) &#123; this.car = car; &#125; public void start() &#123; System.out.println("在中国启动汽车..."); car.start(); &#125; public void stop() &#123; System.out.println("在中国停止汽车..."); car.stop(); &#125;&#125;调用装饰类12345678910public class Test &#123; public static void main(String[] args) &#123; GoogleAIDriving car = new GoogleAIDriving(); A2GoogleAIDriving aCar = new A2GoogleAIDriving(car); aCar.start(); /* Console : 在中国启动汽车... Google汽车启动了... */ &#125;&#125;动态代理A公司工程师正沉浸在胜利到来前的喜悦中，突然他们发现AIDriving接口有1000个方法，所以在装饰类中其他不需要加入自定义动能的998个方法我们也要调用。这一看就不是一个好的解决方案，A公司的某大佬就想起来动态代理。动态代理的详细讲解请见这里。动态代理中可以使用反射技术得到方法的信息，如果是start()或者stop()方法就加上自定义的功能，其他方法直接执行。A3GoogleAIDriving123456789101112131415161718192021222324252627public class A3GoogleAIDriving&#123; private AIDriving car; public A3GoogleAIDriving(AIDriving car) &#123; this.car = car; &#125; public AIDriving getIns() &#123; AIDriving a3GoogleAIDriving = (AIDriving)Proxy.newProxyInstance( GoogleAIDriving.class.getClassLoader(), GoogleAIDriving.class.getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if(method.getName().equals("start") &amp;&amp;method.getParameterTypes().length == 0) &#123; System.out.println("在中国启动汽车..."); return method.invoke(car, args); &#125;else if (method.getName().equals("stop") &amp;&amp;method.getParameterTypes().length == 0) &#123; System.out.println("在中国停止汽车..."); return method.invoke(car, args); &#125; return method.invoke(car, args); &#125; &#125;); return a3GoogleAIDriving; &#125;&#125;执行A3GoogleAIDriving123456789101112public static void main(String[] args) throws Exception &#123; GoogleAIDriving car = new GoogleAIDriving(); A3GoogleAIDriving a3GoogleAIDriving = new A3GoogleAIDriving(car); AIDriving ins = a3GoogleAIDriving.getIns(); ins.start(); ins.stop(); /* Console : 在中国启动汽车... Google汽车启动了... 在中国停止汽车... Google汽车停止了... */&#125;三种方式总结分析了三种方式的功能增强，各位大腿是不是被小码农带入了一个误区：后者比前者更好？按照存在即合理的解释，肯定不是这样的。相反，三种方法中继承却是最常见的增强方式，因为它结构简单、易于理解。而后两种都是设计模式，一般在大型软件开发时才会用到。而且对于装饰者模式和动态代理的区别是：装饰者模式一般用于增强功能，动态代理一般用于拦截对方法的请求。装饰者模式解决Web开发乱码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import java.io.UnsupportedEncodingException;import java.util.Map;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletRequestWrapper;/** * @ClassName: RequestEncodingUtils * @Description: TODO(解决request乱码的工具类) * @author 詹金浩 * @date 2018年3月11日 下午2:27:04 */public class RequestEncodingUtils extends HttpServletRequestWrapper &#123; private HttpServletRequest request; private Boolean isEncoded = false; public RequestEncodingUtils(HttpServletRequest request) &#123; super(request); this.request = request; &#125; @Override public Map&lt;String, String[]&gt; getParameterMap() &#123; String method = request.getMethod(); Map&lt;String, String[]&gt; parameterMap = request.getParameterMap(); //处理Post请求 if(method.equalsIgnoreCase("post")) &#123; try &#123; request.setCharacterEncoding("utf-8"); parameterMap = request.getParameterMap(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;else if (method.equalsIgnoreCase("get")) &#123; //处理Get请求 //保证编码只被执行一次 if(!isEncoded) &#123; for(String key : parameterMap.keySet()) &#123; String []values = parameterMap.get(key); if(values != null) &#123; for(int i = 0; i &lt; values.length; i++) &#123; try &#123; values[i] = new String(values[i].getBytes("ISO-8859-1"),"utf-8"); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125; isEncoded = true; &#125; return parameterMap; &#125; @Override public String[] getParameterValues(String name) &#123; Map&lt;String, String[]&gt; parameterMap = this.getParameterMap(); String []values = parameterMap.get(name); return values; &#125; @Override public String getParameter(String name) &#123; String []values = getParameterValues(name); return values!=null?values[0]:null; &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.io.IOException;import javax.servlet.Filter;import javax.servlet.FilterChain;import javax.servlet.FilterConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.annotation.WebFilter;import javax.servlet.http.HttpServletRequest;import com.sys.utils.RequestEncodingUtils;/** * @ClassName: GlobalEncoding * @Description: TODO(解决全局编码的filter) * @author 詹金浩 * @date 2018年3月10日 下午10:26:09 */@WebFilter("/*")public class GlobalEncoding implements Filter &#123; /** * Default constructor. */ public GlobalEncoding() &#123; // TODO Auto-generated constructor stub &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; response.setContentType("text/html;charset=UTF-8"); RequestEncodingUtils myRequest = new RequestEncodingUtils((HttpServletRequest)request); chain.doFilter(myRequest, response); &#125; /** * @see Filter#destroy() */ public void destroy() &#123; // TODO Auto-generated method stub &#125; /** * @see Filter#doFilter(ServletRequest, ServletResponse, FilterChain) */ /** * @see Filter#init(FilterConfig) */ public void init(FilterConfig fConfig) throws ServletException &#123; // TODO Auto-generated method stub &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态代理]]></title>
    <url>%2F2019%2F%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[理解代理代理这个词对于广告满天飞的现代社会应该是很常见了，和它具有相同意义还有中介、经纪人等词。我们就以找影视明星拍片为例来理解代理。假如你有一个很好的剧本，现在想找A明星来做主角，可以两种方式：第一种是直接找A明星本人，第二种是找A明星的经纪人。但是明星的主要功能是拍戏，如果诸如报酬、档期、宣传等工作也让A明星来负责，势必会减少他/她的拍戏时间，所以更好的方式是去寻求他/她的经纪人，让经纪人来做这些拍戏以外的工作。但同时经济人也得有和明星A一样的功能，比如A会演戏、唱歌、跳舞，那么经纪人也得有这些功能，只不过经纪人的功能是让明星A去完成的，经纪人本身只提供这种服务的接口。而我们所说的明星A便是目标对象，经纪人便是代理对象。对于Java中的代理，假如有一个方法（设为M1）的功能是把UTF-8编码下的字符转化成GBK编码下的字符。那么这个方法的功能就是进行转化、对于判断传入的是不是UTF-8编码下的字符这种事情应该传入之前就处理完成，所以这时候就要有一个代理方法（设为M2）在M1执行之前做个处理。当然M1执行完毕之后也可能存在M3进行一些处理。代理对象的要点代理对象存在的价值主要用于拦截对目标对象的访问。代理对象应该具有和目标对象相同的方法。动态代理在我们刚才的解释中，每个目标对象都要有一个实在的代理对象，这在实际开发中是很耗费精力的一件事，但如果说能在程序运行期间给我们动态生成一个代理对象可以大大减小编写的代码的压力。所以动态代理的概念就是：不用手动编写一个代理对象，不需要编写与目标对象相同的方法，运行时在内存中动态生成代理对象（字节码对象级别的代理对象）。JDK提供的动态代理JDK1.5之后为我们提供了用于专用于动态生成代理对象的类：java.lang.reflect.Proxy。有一个很重要的静态方法：12static Object newProxyInstance (ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHander h)在解释参数之前，我们先看一个接口InvocationHander，JDK对它的解释是：Each proxy instance has an associated invocation handler. When a method is invoked on a proxy instance, the method invocation is encoded and dispatched to the method of its invocation handler.（每个代理实例都有一个关联的调用处理程序。当在代理实例上调用方法时，将方法调用编码并调度到其调用处理程序的方法。） 它只有一个invoke()方法。我们之后执行时真正起作用的也是这个方法。public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;对newProxyInstance()方法参数的解释在下面的例子中。明星接口12345public interface BrightStar &#123; public void sing(); public String dancing(); public String ShootFilm(String filmName);&#125;A明星类1234567891011121314public class StarA implements BrightStar&#123; @Override public void sing() &#123; System.out.println("A is singing..."); &#125; @Override public String dancing() &#123; return "Hai cao wu"; &#125; @Override public String ShootFilm(String filmName) &#123; return filmName; &#125;&#125;测试动态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Test &#123; public static void main(String[] args) &#123; StarA starA = new StarA(); BrightStar newProxyInstance = (BrightStar)Proxy.newProxyInstance( //代理类的类加载器，获取目标类加载器即可 StarA.class.getClassLoader(), //代理类应该实现的接口，由于代理类和目标类需要继承相同的接口，使用目标类的接口即可 StarA.class.getInterfaces(), //使用匿名内部类传入InvocationHandler的实例 new InvocationHandler() &#123; /* * proxy：传入代理对象。 * method：被执行的方法。 * args：传入的参数。 * 例子： newProxyInstance.ShootFilm("我不是药神"); * proxy：newProxyInstance； method：ShootFilm； args："我不是药神" */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //执行前的操作 System.out.println("before"); Object invoke = method.invoke(starA, args); //执行后的操作 System.out.println("after"); return invoke; &#125; &#125;); //调用方法 newProxyInstance.sing(); System.out.println("------------------------------------"); String dancing = newProxyInstance.dancing(); System.out.println(dancing); System.out.println("------------------------------------"); String film = newProxyInstance.ShootFilm("我不是药神"); System.out.println(film); /* Console : before A is singing... after ------------------------------------ before after Hai cao wu ------------------------------------ before after 我不是药神 */ &#125;&#125;下面介绍一个经典案例，使用动态代理解决Web工程的全局编码问题。前端代码1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;title&gt;Insert_Title_Here&lt;/title&gt; &lt;/head&gt; &lt;style&gt; &lt;/style&gt; &lt;body&gt; &lt;!--主体部分--&gt; &lt;h2&gt;get方式&lt;/h2&gt; &lt;form action="/ProxySolveCoding/test" method="get"&gt; &lt;input name="name" type="text"/&gt; &lt;input type="submit" value="提交"/&gt; &lt;/form&gt; &lt;h2&gt;post方式&lt;/h2&gt; &lt;form action="/ProxySolveCoding/test" method="post"&gt; &lt;input name="name" type="text"/&gt; &lt;input type="submit" value="提交"/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt;Servlet1234567891011121314@WebServlet("/test")public class Test extends HttpServlet &#123; private static final long serialVersionUID = 1L; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; String name = request.getParameter("name"); System.out.println(name); &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125;&#125;filter12345678910111213141516171819202122232425262728293031@WebFilter(urlPatterns="/*")public class FilterCoding implements Filter &#123; public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; final HttpServletRequest req = (HttpServletRequest)request; HttpServletRequest proReq = (HttpServletRequest)Proxy.newProxyInstance( req.getClass().getClassLoader(), req.getClass().getInterfaces(), new InvocationHandler() &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if(method.getName().equalsIgnoreCase("getParameter")) &#123; String gm = req.getMethod(); if(gm.equalsIgnoreCase("get")) &#123; //处理get方式的请求 String before = (String) method.invoke(req, args); System.out.println(before); String after = new String(before.getBytes("iso-8859-1"), "utf-8"); return after; &#125;else &#123; //处理post形式的请求 req.setCharacterEncoding("utf-8"); &#125; &#125; return method.invoke(req, args); &#125; &#125;); chain.doFilter(proReq, response); &#125;&#125;JDK动态代理的特点能被代理的对象必须存在接口，否则会报错。且被增强的方法一定是在接口中有相同的方法签名。因为它生成代理对象的方式是拿到类的所有接口，然后根据这些接口和我们实现的InvocationHandler中的invoke()动态创建一个对象。Cglib概述是一个强大的，高性能，高质量的Code生成类库，它可以在运行期扩展Java类与实现Java接口。它是第三方实现的，所以需要导入jar包。特点和JDK提供的动态代理相比，Cglib更加灵活，不需要类上存在接口，因为它生成代理对象是通过现有的类派生出一个子类，在子类中加入我们新的条件。所以被代理的类不能使用final修饰。使用的例子123public interface UserDao &#123; void save();&#125;1234567891011121314import org.springframework.beans.factory.annotation.Value;public class UserDaoImpl implements UserDao &#123; @Value("HelloWorld") private String name; public void save() &#123; System.out.println("保存..."); &#125; public void talk() &#123; System.out.println("接口中没有我"); &#125; public String toString() &#123; return "UserDaoImpl [name=" + name + "]"; &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041import java.lang.reflect.Method;import com.spring.secondday.UserDao;import com.spring.secondday.UserDaoImpl;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;public class CglibProxy &#123; private UserDao ud; public CglibProxy(UserDao ud) &#123; this.ud = ud; &#125; public UserDaoImpl getProxy()&#123; Enhancer en = new Enhancer(); en.setSuperclass(ud.getClass()); en.setCallback(new MethodInterceptor() &#123; //proxy：被代理的对象 m：被增强的方法 args：方法所需的参数 methodProxy：增强后的方法 public Object intercept(Object proxy, Method m, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println("before"); Object super1 = methodProxy.invokeSuper(proxy, args); System.out.println("after"); return super1; &#125; &#125;); UserDaoImpl proxy = (UserDaoImpl)en.create(); return proxy; &#125; public static void main(String[] args) &#123; UserDaoImpl ud = new UserDaoImpl(); UserDaoImpl proxy = new CglibProxy(ud).getProxy(); /*Console: before 接口中没有我 after */ proxy.talk(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2019%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[本文转至：https://blog.csdn.net/u011240877/article/details/52346671作者基于网络小说的套路，讲解了用代码如何实现“如何用固定套路写小说”先定义一个故事梗概接口 Synopsis ，里面设定了主要情节不幸的开始突然有天遇到神人/捡到神器以弱胜强，暂露光芒开挂似的升级超快组团刷怪九死一生（主角怎么也死不了）功成名就 + 妻妾成群1234567891011121314151617181920212223242526272829303132333435363738394041/** * 网络玄幻小说的故事梗概接口 * 固定的一些套路 * Created by zhangshixin on 8/27/2016. */public interface Synopsis &#123; /** * 穷困潦倒的开始 */ void badStart(); /** * 突然有天遇到神人/捡到神器，实力大涨 */ void adventure(); /** * 在一场战斗中以弱胜强 */ void winABattle(); /** * 从此飞速成长 */ void growFast(); /** * 组团刷怪,经历九死一生（主角怎么也死不了） */ void manyFights(); /** * 最终功成名就，妻妾成群 */ void succeed(); /** * 组合起来就是小说内容 */ void getContent();&#125;有了梗概剩下的就是填内容了，我们分别创建两个具体小说类 StoryA 、 StoryB故事 A ，跳舞的恶魔法则123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 故事 A ，恶魔法则 * Created by zhangshixin on 8/27/2016. */public class StoryA implements Synopsis &#123; private String mName; public StoryA(String name) &#123; mName = name; &#125; @Override public void badStart() &#123; System.out.println(mName + " 无故穿越，因为没有魔法能力，成为将军家的废物，不受待见。"); &#125; @Override public void adventure() &#123; System.out.println(mName + " 因为意外来到恶魔岛，在恶魔岛上遇见了恶魔的仆人，获得了一直想要的使用魔法的能力"); &#125; @Override public void winABattle() &#123; System.out.println(mName + " 协助辰皇子夺得了帝国的权力，成为郁金香公爵"); &#125; @Override public void growFast() &#123; System.out.println(mName + " 先后在曾曾曾祖母、恶魔仆人、圣骑士、魔导师的帮助下飞速成长"); &#125; @Override public void manyFights() &#123; System.out.println(mName + " 建立魔法学院和魔法学会，与魔法工会分庭抗礼。坐拥西北十万雄兵，歼灭西北军团，打退草原人，带领人类全族击退北方的异族军队。"); &#125; @Override public void succeed() &#123; System.out.println(mName + " 娶了女皇为妻子，成为罗兰帝国的英雄。"); &#125; @Override public void getContent() &#123; badStart(); adventure(); winABattle(); growFast(); manyFights(); succeed(); &#125;&#125;故事 B ，萧鼎的诛仙1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 故事 B ,诛仙 * Created by zhangshixin on 8/27/2016. */public class StoryB implements Synopsis &#123; private String mName; public StoryB(String name) &#123; mName = name; &#125; @Override public void badStart() &#123; System.out.println(mName + " 全村被屠，投入青云七脉中人数最少的大竹峰。"); &#125; @Override public void adventure() &#123; System.out.println(mName + " 在一次伐竹过程中，为追一只三眼灵猴，入青云山深处得到了烧火棍。"); &#125; @Override public void winABattle() &#123; System.out.println(mName + " 在七脉会武中侥幸进了前 4，和陆雪琪等人一起万蝠古窟历练。"); &#125; @Override public void growFast() &#123; System.out.println(mName + " 在魔教十年，深得鬼王器重和真传。"); &#125; @Override public void manyFights() &#123; System.out.println(mName + " 经历无数战斗，先是为鬼王卖命，后来与鬼王大战。"); &#125; @Override public void succeed() &#123; System.out.println("天地不仁，以万物为刍狗。 " + mName +" 最后成为最有资格拥有天书的人。"); &#125; @Override public void getContent() &#123; badStart(); adventure(); winABattle(); growFast(); manyFights(); succeed(); &#125;&#125;故事梗概、具体内容都有了，剩下的就是量产了123456789101112131415161718192021222324252627282930313233/** * 写小说 * Created by zhangshixin on 8/28/2016. */public class WriteNovel &#123; private Synopsis mSynopsis; //故事梗概 private String mMainActorName; //主角名称 /** * 梗概、内容都差不多确定后，换个名称就是另一部小说 * @param mainName */ public WriteNovel(String mainName)&#123; switch (mainName)&#123; case "张小凡": mSynopsis = new StoryB(mainName); break; case "杜维": mSynopsis = new StoryA(mainName); break; default: mSynopsis = new StoryB(mainName); break; &#125; &#125; /** * 获取小说内容 */ public void getNovelDetail()&#123; mSynopsis.getContent(); &#125;&#125;客户端只要输入主角名称，就可以得到一部小说，比如写一部类似诛仙的小说，主角名称为张拭心12345@Testpublic void testGetNovelDetail() throws Exception &#123; WriteNovel writeNovel = new WriteNovel("张拭心"); writeNovel.getNovelDetail();&#125;我们可以把 WriteNovel 类中的 default 设置为 StoryB ，即 诛仙：12345678public WriteNovel(String mainName)&#123; switch (mainName)&#123; //...省略掉不关键的内容 default: mSynopsis = new StoryB(mainName); break; &#125;&#125;假如现在需求变了，要写一部穿越的小说，主角还是 张拭心，这时只需修改 WriteNovel 中的 default 设置为 StoryA ，即 恶魔法则 即可，客户端不需要修改1234567891011121314151617/** * 梗概、内容都差不多确定后，换个名称就是另一部小说 * @param mainName */public WriteNovel(String mainName)&#123; switch (mainName)&#123; case &quot;张小凡&quot;: mSynopsis = new StoryB(mainName); break; case &quot;杜维&quot;: mSynopsis = new StoryA(mainName); break; default: mSynopsis = new StoryA(mainName); break; &#125;&#125;我们将公共的情节提取到梗概接口 Synopsis 中，然后创建不同的故事类，写小说时WriteNovel 中有一个接口的引用，根据客户端传入主角名称创建不同的实现类。其实这就是传说中的 策略模式。只要遇到很多 if-else 或者有很多 case 的 switch，就可以考虑使用策略模式了，将这些行为独立的封装起来，可以在公共类中消除条件语句。在实践中，只要听到需要在不同情况下应用不同的业务，就可以考虑使用策略模式来封装这种变化的可能性。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Comparable和Comparator]]></title>
    <url>%2F2019%2FComparable%E5%92%8CComparator%2F</url>
    <content type="text"><![CDATA[这俩都是Java集合框架的一部分，而且都是和集合排序有关。ComparableComparable 在 java.lang 包下，是一个接口，内部只有一个方法 compareTo()：123public interface Comparable&lt;T&gt; &#123; public int compareTo(T o);&#125;compareTo 方法的返回值有三种情况：e1.compareTo(e2) &gt; 0 即 e1 &gt; e2e1.compareTo(e2) = 0 即 e1 = e2e1.compareTo(e2) &lt; 0 即 e1 &lt; e2This interface imposes a total ordering on the objects of each class that implements it. This ordering is referred to as the class’s natural ordering, and the class’s compareTo method is referred to as its natural comparison method.Lists (and arrays) of objects that implement this interface can be sorted automatically by Collections.sort (and Arrays.sort). Objects that implement this interface can be used as keys in a sorted map or as elements in a sorted set, without the need to specify a comparator.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package test;import java.io.IOException;import java.util.HashSet;import java.util.Iterator;import java.util.Set;public class Test &#123; public static void main(String[] args) throws IOException &#123; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(); set.add(new Person(50)); set.add(new Person(30)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person implements Comparable&lt;Person&gt;&#123; private Integer age; public Person(Integer age) &#123; super(); this.age = age; &#125; @Override public int compareTo(Person o) &#123; if(age &gt; o.age) return 1; else if(age &lt; o.age) return -1; return 0; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; &#125;Note that null is not an instance of any class, and e.compareTo(null) should throw a NullPointerException even though e.equals(null)returns false.The natural ordering for a class C is said to be consistent with equals if and only if e1.compareTo(e2) == 0 has the same boolean value as e1.equals(e2) for every e1 and e2 of class C. It is strongly recommended (though not required) that natural orderings be consistent with equals. This is so because sorted sets (and sorted maps)without explicit comparators behave “strangely” when they are used with elements (or keys) whose natural ordering is inconsistent with equals. In particular, such a sorted set (or sorted map) violates the general contract for set (or map), which is defined in terms of the equals method.For example, if one adds two keys a and b such that (!a.equals(b) &amp;&amp; a.compareTo(b) == 0) to a sorted set that does not use an explicit comparator, the second add operation returns false (and the size of the sorted set does not increase) because a and b are equivalent from the sorted set’s perspective.这段话的意思是如果compareTo规则和equals规则不同就会发生奇怪的问题，即在!a.equals(b) &amp;&amp; a.compareTo(b) == 0这种情况下，不能插入集合中，但是从排序集合的角度来看它们是不同的。（排序集合通过equals规则判断是否一致）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package test;import java.io.IOException;import java.util.Iterator;import java.util.Set;import java.util.TreeSet;public class Test &#123; public static void main(String[] args) throws IOException &#123; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(); set.add(new Person(50)); set.add(new Person(50)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person implements Comparable&lt;Person&gt;&#123; private Integer age; public Person(Integer age) &#123; super(); this.age = age; &#125; @Override public int compareTo(Person o) &#123; if(age &gt; o.age) return 1; else if(age &lt; o.age) return -1; return 0; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; @Override public boolean equals(Object obj) &#123; Person p = (Person)obj; if(p.age == age + 1) return true; return false; &#125; &#125;Comparator核心方法如下：12345public interface Comparator&lt;T&gt; &#123; public int compare(T lhs, T rhs); public boolean equals(Object object);&#125;使用自然排序需要类实现 Comparable，并且在内部重写 comparaTo 方法。而 Comparator 则是在外部制定排序规则，然后作为排序策略参数传递给某些类，比如 Collections.sort(), Arrays.sort(), 或者一些内部有序的集合（比如 SortedSet，SortedMap 等）。使用方式主要分三步：创建一个 Comparator 接口的实现类，并赋值给一个对象。在 compare 方法中针对自定义类写排序规则。将 Comparator 对象作为参数传递给 排序类的某个方法向排序类中添加 compare 方法中使用的自定义类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package test;import java.io.IOException;import java.util.Comparator;import java.util.Iterator;import java.util.Set;import java.util.TreeSet;public class Test &#123; public static void main(String[] args) throws IOException &#123; Comparator&lt;Person&gt; com = new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; if(o1.getAge() &gt; o2.getAge()) return -1; else if(o1.getAge() &lt; o2.getAge()) return 1; return 0; &#125; &#125;; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(com); set.add(new Person(50)); set.add(new Person(20)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person&#123; private Integer age; public Person(Integer age) &#123; super(); this.age = age; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125;总结Java 中的两种排序方式：Comparable 自然排序。（实体类实现）Comparator 是定制排序。（无法修改实体类时，直接在调用方创建）同时存在时采用 Comparator（定制排序）的规则进行比较。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package test;import java.io.IOException;import java.util.Comparator;import java.util.Iterator;import java.util.Set;import java.util.TreeSet;public class Test &#123; public static void main(String[] args) throws IOException &#123; Comparator&lt;Person&gt; com = new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; if(o1.getAge() &gt; o2.getAge()) return -1; else if(o1.getAge() &lt; o2.getAge()) return 1; return 0; &#125; &#125;; Set&lt;Person&gt; set = new TreeSet&lt;&gt;(com); set.add(new Person(50)); set.add(new Person(20)); set.add(new Person(90)); Iterator&lt;Person&gt; iterator = set.iterator(); while(iterator.hasNext()) System.out.println(iterator.next()); &#125; &#125;class Person implements Comparable&lt;Person&gt;&#123; private Integer age; public Person(Integer age) &#123; super(); this.age = age; &#125; @Override public String toString() &#123; return "Person [age=" + age + "]"; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public int compareTo(Person o) &#123; if(age &gt; o.age) return 1; else if(age &lt; o.age) return -1; return 0; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requset的get开头无参方法测试]]></title>
    <url>%2F2019%2Frequset%E7%9A%84get%E5%BC%80%E5%A4%B4%E6%97%A0%E5%8F%82%E6%96%B9%E6%B3%95%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[笔者一直都对request.get*()方法觉得迷惑，分不清返回的到底是什么东西。所以做个测试：12345678910111213141516171819202122232425262728293031323334353637383940414243444546package test;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet("/test")public class Test extends HttpServlet &#123; private static final long serialVersionUID = 1L; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; System.out.println(request.getRequestURL().toString()); System.out.println(request.getRequestURI().toString()); System.out.println(request.getServletPath()); System.out.println(request.getServerPort()); System.out.println(request.getScheme()); System.out.println(request.getRemoteUser()); System.out.println(request.getRemotePort()); System.out.println(request.getRemoteHost()); System.out.println(request.getRemoteAddr()); System.out.println(request.getQueryString()); System.out.println(request.getProtocol()); System.out.println(request.getPathTranslated()); System.out.println(request.getAuthType()); System.out.println(request.getCharacterEncoding()); System.out.println(request.getContentLength()); System.out.println(request.getContentLengthLong()); System.out.println(request.getContentType()); System.out.println(request.getContextPath()); System.out.println(request.getLocalAddr()); System.out.println(request.getLocalName()); System.out.println(request.getLocalPort()); System.out.println(request.getMethod()); System.out.println(request.getPathInfo()); &#125; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; // TODO Auto-generated method stub doGet(request, response); &#125;&#125;客户端IP：10.5.70.87服务器IP：10.5.69.2041234567891011121314151617181920212223242526getAuthType : nullgetCharacterEncoding : nullgetContentLength : -1getContentLengthLong : -1getContentType : nullgetContextPath : /Test-URI //webapps下的项目文件夹名称getLocalAddr : 10.5.69.204 //相对Web应用来说是Local，对B/S结构来说是SgetLocalName : DESKTOP-OI1K2LH //S的名称getLocalPort : 80 //S的端口号getMethod : GETgetPathInfo : nullgetPathTranslated : nullgetProtocol : HTTP/1.1getQueryString : id=10getRemoteAddr : 10.5.70.87 //B/S的B的地址getRemoteHost : 10.5.70.87getRemotePort : 52897 //B的端口号getRemoteUser : nullgetRequestedSessionId : nullgetRequestURI : /Test-URI/test //相对于项目的地址getScheme : http //协议类型getServerName : 10.5.69.204getServerPort : 80getServletPath : /test //Servlet映射的地址getAttributeNames : java.util.Collections$3@1994a730getRequestURL : http://10.5.69.204/Test-URI/test //浏览器中输入地址]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[File和Path和Files]]></title>
    <url>%2F2019%2FFile%E5%92%8CPath%E5%92%8CFiles%2F</url>
    <content type="text"><![CDATA[File构造123456789public File(String filepath);绝对路径:以盘符开头的路径相对路径:相对当前项目的根目录public File(String parent, String child);public File(File parent,String child);public File(URI uri);123456789101112public class Demo1 &#123; public static void main(String[] args) &#123; File aFile; try &#123; aFile = new File(new URI("file:///https://isjinhao.github.io/2019/Maven%E5%9F%BA%E7%A1%80/%E4%BC%A0%E7%BB%9F%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91.png")); System.out.println(aFile.getName());// false &#125; catch (URISyntaxException e) &#123; e.printStackTrace(); &#125; &#125;&#125;获取方法123456789public String getAbsolutePath();//获取绝对路径public String getName();//获取当前File对象的名字public String getPath();//获取创建File对象时 传递的路径public long length();//获取表示文件的File对象的占用的字节数//如果是文件夹的File对象,返回目录本身的大小,不是目录及其所有孩子的大小创建和删除创建方法创建文件1public boolean createNewFile();//创建一个新的文件(只能是文件,不能是文件夹),返回是否创建成功创建文件夹1public boolean mkdir();//创建一个新的文件夹,返回是否创建成功判断方法判断File对象所表示的文件在OS中是否存在1public boolean exists(); //返回该File 对象是否存在判断是否是文件1public boolean isFile();//返回是否是文件判断是否是文件夹1public boolean isDirectory();//返回是否是文件夹删除方法1public boolean delete();//删除文件或者文件夹。可以删除的是单个文件,或者空文件夹File类的list和listFiles方法123public String[] list();public File[] listFiles();//只能列出当前文件夹下的一级子文件或者子文件夹文件过滤123456789101112131415161718192021222324252627package file;import java.io.File;import java.io.FileFilter;public class Demo2 &#123; public static void main(String[] args) &#123; File fileDir = new File("D:\\blog\\isjinhao\\source\\_posts\\04-进程管理"); //列出file下所有file对象 MyFileFilter ff = new MyFileFilter(); File[] files = fileDir.listFiles(ff); for (File file : files) &#123; System.out.println(file); &#125; &#125;&#125;class MyFileFilter implements FileFilter&#123; @Override public boolean accept(File pathname) &#123; String name = pathname.getName(); if(name.endsWith(".png") || name.endsWith(".PNG")) return true; return false; &#125;&#125;PathPath是JDK7中表达路径的一个新方式，在Path中，它把文件的路径看做几个部件组成的，比如/usr/develop/tomcat可以被看出两个部件组成：/usr和/develop/tomcat，当然也可以看做三个部件/usr、/develop和/tomcat组成的。以根部件开始的是绝对路径，在类Unix系统中是\，在Windows系统中是C:\等。API获得Path通过Paths的静态方法：static Path get(String first, String ... more);public static Path get(URI uri);通过连接给定的字符串创建一个路径。按当前路径解析路径Path resolve(Path other);Path resolve(String other);如果other是绝对路径，那么返回other；否则，返回通过连接this和other获得路径。12345678910111213public class PathTest &#123; public static void main(String[] args) &#123; Path path1 = Paths.get("D:\\", "data.csv"); Path path2 = Paths.get("test\\test", "选修课数据修改.csv"); Path path3 = path1.resolve(path2); Path path4 = path2.resolve(path1); System.out.println(path3); //D:\data.csv\test\test\选修课数据修改.csv System.out.println(path4); //D:\data.csv &#125;&#125;按当前路径解析路径Path resolveSibling(Path other);Path resolveSibling(String other);如果other是绝对路径，那么返回other；否则，返回通过连接this的父路径和other获得路径。按相对路径进行解析12345678910111213import java.nio.file.Path;import java.nio.file.Paths;public class PathTest &#123; public static void main(String[] args) &#123; Path path1 = Paths.get("D:\\", "data.csv"); Path path2 = Paths.get("D:\\test\\test", "选修课数据修改.csv"); Path path3 = path2.relativize(path1); System.out.println(path3); //返回相对于path2的path1的绝对路径 &#125;&#125;其他API移除诸如.和..等的冗余元素：Path normalize();返回和当前路径相等价的绝对路径：Path toAbsolutePath();返回父路径（没有时返回null）：Path getParent();返回该路径的最后一个部件：Path getFileName();返回该路径的根部件（没有时返回null）：Path getRoot();由Path创建一个File对象：File toFile();Files处理小型文本文件public static byte[] readAllBytes(Path path) throws IOException12345678910public static void main(String[] args) &#123; try &#123; byte[] bytes = Files.readAllBytes(Paths.get("filestest")); String string = new String(bytes, "UTF-8"); System.out.println(string); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125;&#125;public static List&lt;String&gt; readAllLines(Path path) throws IOException123456public static void main(String[] args) throws Exception &#123; List&lt;String&gt; lines = Files.readAllLines(Paths.get("filestest")); Iterator&lt;String&gt; iterator = lines.iterator(); while(iterator.hasNext()) System.out.println(iterator.next());&#125;public static Path write(Path path, byte[] bytes, OpenOption... options) throws IOException123public static void main(String[] args) throws Exception &#123; Files.write(Paths.get("filestest"), "深陷琪中，钰罢不能".getBytes(), StandardOpenOption.APPEND);&#125;获得IO流public static InputStream newInputStream(Path path, OpenOption... options)public static OutputStream newOutputStream(Path path, OpenOption... options)public static BufferedReader newBufferedReader(Path path, Charset cs)public static BufferedReader newBufferedReader(Path path)替换FileFiles.exists()Files.exists()方法检查给定的Path在文件系统中是否存在。可以创建在文件系统中不存在的Path实例。例如，如果您计划创建一个新目录，您首先要创建相应的Path实例，然后创建目录。由于Path实例可能指向，也可能没有指向文件系统中存在的路径，你可以使用Files.exists()方法来确定它们是否存在(如果需要检查的话)。这里是一个Java Files.exists()的例子：1234Path path = Paths.get(&quot;data/logging.properties&quot;);boolean pathExists = Files.exists(path, new LinkOption[]&#123; LinkOption.NOFOLLOW_LINKS &#125;);这个例子首先创建一个Path实例指向一个路径，我们想要检查这个路径是否存在。然后，这个例子调用Files.exists()方法，然后将Path实例作为第一个参数。注意Files.exists()方法的第二个参数。这个参数是一个选项数组，它影响Files.exists()如何确定路径是否存在。在上面的例子中的数组包含LinkOption.NOFOLLOW_LINKS，这意味着Files.exists()方法不应该在文件系统中跟踪符号链接，以确定文件是否存在。Files.createDirectory()Files.createDirectory()方法，用于根据Path实例创建一个新目录：123456789Path path = Paths.get(&quot;data/subdir&quot;);try &#123; Path newDir = Files.createDirectory(path);&#125; catch(FileAlreadyExistsException e)&#123; // 目录已经存在&#125; catch (IOException e) &#123; // 其他发生的异常 e.printStackTrace();&#125;第一行创建表示要创建的目录的Path实例。在try-catch块中，用路径作为参数调用Files.createDirectory()方法。如果创建目录成功，将返回一个Path实例，该实例指向新创建的路径。如果该目录已经存在，则是抛出一个java.nio.file.FileAlreadyExistsException。如果出现其他错误，可能会抛出IOException。例如，如果想要的新目录的父目录不存在，则可能会抛出IOException。父目录是您想要创建新目录的目录。因此，它表示新目录的父目录。Files.copy()Files.copy()方法从一个路径拷贝一个文件到另外一个目录，这里是一个Java Files.copy()例子：1234567891011Path sourcePath = Paths.get(&quot;data/logging.properties&quot;);Path destinationPath = Paths.get(&quot;data/logging-copy.properties&quot;);try &#123; Files.copy(sourcePath, destinationPath);&#125; catch(FileAlreadyExistsException e) &#123; // 目录已经存在&#125; catch (IOException e) &#123; // 其他发生的异常 e.printStackTrace();&#125;首先，该示例创建一个源和目标Path实例。然后，这个例子调用Files.copy()，将两个Path实例作为参数传递。这可以让源路径引用的文件被复制到目标路径引用的文件中。如果目标文件已经存在，则抛出一个java.nio.file.FileAlreadyExistsException异常。如果有其他错误，则会抛出一个IOException。例如，如果将该文件复制到不存在的目录，则会抛出IOException。重写已存在的文件可以强制Files.copy()覆盖现有的文件。这里有一个示例，演示如何使用Files.copy()覆盖现有文件。1234567891011Path sourcePath = Paths.get(&quot;data/logging.properties&quot;);Path destinationPath = Paths.get(&quot;data/logging-copy.properties&quot;);try &#123; Files.copy(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING);&#125; catch(FileAlreadyExistsException e) &#123; // 目标文件已存在&#125; catch (IOException e) &#123; // 其他发生的异常 e.printStackTrace();&#125;请注意Files.copy()方法的第三个参数。如果目标文件已经存在，这个参数指示copy()方法覆盖现有的文件。Files.move()Java NIO Files还包含一个函数，用于将文件从一个路径移动到另一个路径。移动文件与重命名相同，但是移动文件既可以移动到不同的目录，也可以在相同的操作中更改它的名称。是的,java.io.File类也可以使用它的renameTo()方法来完成这个操作，但是现在已经在java.nio.file.Files中有了文件移动功能。这里有一个Java Files.move()例子：123456789Path sourcePath = Paths.get(&quot;data/logging-copy.properties&quot;);Path destinationPath = Paths.get(&quot;data/subdir/logging-moved.properties&quot;);try &#123; Files.move(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING);&#125; catch (IOException e) &#123; //移动文件失败 e.printStackTrace();&#125;首先创建源路径和目标路径。源路径指向要移动的文件，而目标路径指向文件应该移动到的位置。然后调用Files.move()方法。这会导致文件被移动。请注意传递给Files.move()的第三个参数。这个参数告诉Files.move()方法来覆盖目标路径上的任何现有文件。这个参数实际上是可选的。如果移动文件失败，Files.move()方法可能抛出一个IOException。例如，如果一个文件已经存在于目标路径中，并且您已经排除了StandardCopyOption.REPLACE_EXISTING选项，或者被移动的文件不存在等等。Files.delete()Files.delete()方法可以删除一个文件或者目录。下面是一个Java Files.delete()例子：12345678Path path = Paths.get(&quot;data/subdir/logging-moved.properties&quot;);try &#123; Files.delete(path);&#125; catch (IOException e) &#123; // 删除文件失败 e.printStackTrace();&#125;首先，创建指向要删除的文件的Path。然后调用Files.delete()方法。如果Files.delete()由于某种原因不能删除文件(例如，文件或目录不存在)，会抛出一个IOException。文件搜索Files.walkFileTree()Files.walkFileTree()方法包含递归遍历目录树的功能。walkFileTree()方法将Path实例和FileVisitor作为参数。Path实例指向您想要遍历的目录。FileVisitor在遍历期间被调用。在我解释遍历是如何工作之前，这里我们先了解FileVisitor接口:12345678910111213public interface FileVisitor &#123; public FileVisitResult preVisitDirectory( Path dir, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFile( Path file, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFileFailed( Path file, IOException exc) throws IOException; public FileVisitResult postVisitDirectory( Path dir, IOException exc) throws IOException &#123;&#125;您必须自己实现FileVisitor接口，并将实现的实例传递给walkFileTree()方法。在目录遍历过程中，您的FileVisitor实现的每个方法都将被调用。如果不需要实现所有这些方法，那么可以扩展SimpleFileVisitor类，它包含FileVisitor接口中所有方法的默认实现。这里是一个walkFileTree()的例子：12345678910111213141516171819202122232425Files.walkFileTree(path, new FileVisitor&lt;Path&gt;() &#123; @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; System.out.println(&quot;pre visit dir:&quot; + dir); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; System.out.println(&quot;visit file: &quot; + file); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException &#123; System.out.println(&quot;visit file failed: &quot; + file); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; System.out.println(&quot;post visit directory: &quot; + dir); return FileVisitResult.CONTINUE; &#125;&#125;);FileVisitor实现中的每个方法在遍历过程中的不同时间都被调用:在访问任何目录之前调用preVisitDirectory()方法。在访问一个目录之后调用postVisitDirectory()方法。调用visitFile()在文件遍历过程中访问的每一个文件。它不会访问目录-只会访问文件。在访问文件失败时调用visitFileFailed()方法。例如，如果您没有正确的权限，或者其他什么地方出错了。这四个方法中的每个都返回一个FileVisitResult枚举实例。FileVisitResult枚举包含以下四个选项:CONTINUE 继续TERMINATE 终止SKIP_SIBLING 跳过同级SKIP_SUBTREE 跳过子级通过返回其中一个值，调用方法可以决定如何继续执行文件。CONTINUE继续意味着文件的执行应该像正常一样继续。TERMINATE终止意味着文件遍历现在应该终止。SKIP_SIBLINGS跳过同级意味着文件遍历应该继续，但不需要访问该文件或目录的任何同级。SKIP_SUBTREE跳过子级意味着文件遍历应该继续，但是不需要访问这个目录中的子目录。这个值只有从preVisitDirectory()返回时才是一个函数。如果从任何其他方法返回，它将被解释为一个CONTINUE继续。文件搜索这里是一个用于扩展SimpleFileVisitor的walkFileTree()，以查找一个名为README.txt的文件:123456789101112131415161718192021Path rootPath = Paths.get(&quot;data&quot;);String fileToFind = File.separator + &quot;README.txt&quot;;try &#123; Files.walkFileTree(rootPath, new SimpleFileVisitor&lt;Path&gt;() &#123; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; String fileString = file.toAbsolutePath().toString(); //System.out.println(&quot;pathString = &quot; + fileString); if(fileString.endsWith(fileToFind))&#123; System.out.println(&quot;file found at path: &quot; + file.toAbsolutePath()); return FileVisitResult.TERMINATE; &#125; return FileVisitResult.CONTINUE; &#125; &#125;);&#125; catch(IOException e)&#123; e.printStackTrace();&#125;递归删除目录Files.walkFileTree()也可以用来删除包含所有文件和子目录的目录。Files.delete()方法只会删除一个目录，如果它是空的。通过遍历所有目录并删除每个目录中的所有文件(在visitFile())中，然后删除目录本身(在postVisitDirectory()中)，您可以删除包含所有子目录和文件的目录。下面是一个递归目录删除示例:123456789101112131415161718192021Path rootPath = Paths.get(&quot;data/to-delete&quot;);try &#123; Files.walkFileTree(rootPath, new SimpleFileVisitor&lt;Path&gt;() &#123; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; System.out.println(&quot;delete file: &quot; + file.toString()); Files.delete(file); return FileVisitResult.CONTINUE; &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; Files.delete(dir); System.out.println(&quot;delete dir: &quot; + dir.toString()); return FileVisitResult.CONTINUE; &#125; &#125;);&#125; catch(IOException e)&#123; e.printStackTrace();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java-文件处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-正则表达式]]></title>
    <url>%2F2019%2FJava-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述正则表达式(regular expression)描述了一种字符串匹配的模式（pattern），可以用来检查一个串是否含有某种子串、将匹配的子串替换或者从某个串中取出符合某个条件的子串等。但是上面的叙述，对于之前没有接触过正则表达式的人还是很迷，我们打个比方，有一串字符：123xyz234和一个模式：*^*，我们假设*表示任意长度的由数字组成的字符串，^表示任意长度的由英文字符表示的字符串，那么我们就可以说这个字符串能匹配上这个模式。因为123可以匹配上*，xyz可以匹配上^，234可以匹配上*。同样的，假如我们再有一个模式：*^，我们用这个模式在字符串中提取，可以提取出来：123、123x、123xyz、234 等等，但是不能提取出来z234、123xyz234。因为我们能提取出来的都是符合这个模式的，这个模式就是正则表达式。语法不同的语言在正则表达式上的语法是有差距的，但是相同点远远大于不同点。我们在这使用Java语言中正则表达式。不过正则表达式的语法非常难记，在这也是举例出一些常用的语法，具体使用还是得查文档。最简单的正则表达式在我们刚才的举例中可以看出正则表达式其实就是一种匹配规则，那么每个字符串也都是一种匹配规则（这种规则只能匹配其自身）。比如下面的split()方法是按照正则表达式把字符串分割，我们传入的一个字符串就是一个正则表达式。123456789101112public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "1234567890"; /** * Splits this string around matches of the given regular expression. */ String[] split = testStr.split("67"); //testStr中只有67能匹配split()方法中传入的67，所以按67进行分隔，同时67被删除 System.out.println(Arrays.deepToString(split)); &#125;&#125;和正则表达式有关的类虽然上个例子我们并没有使用到正则表达式相关的类，但这并不表明正则表达式就是一个字符串这么简单，在split()方法的内部还是调用了正则表达式相关的方法。123public String[] split(String regex) &#123; return split(regex, 0);&#125;Pattern类：一个Pattern表示一个正则表达式。Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。该方法接受一个正则表达式字符串作为它的第一个参数。Matcher类：Matcher 对象是对输入字符串进行解释和匹配操作的引擎。与Pattern 类一样，Matcher 也没有公共构造方法。你需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。PatternSyntaxException：PatternSyntaxException 是一个非强制异常类，它表示一个正则表达式模式中的语法错误。现在我们使用正则表达式有关的类来完成上面的例子：12345678910public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "1234567890"; Pattern pattern = Pattern.compile("67"); String[] split = pattern.split(testStr); System.out.println(Arrays.deepToString(split)); &#125;&#125;PatternSyntaxException 式一个异常类，但是不强制处理正则表达式的异常，所以这里可加可不加。Matcher的用法请继续看下去。匹配在上面我们测试的是正则表达式的分割作用，但是这并不是一个很好的学习正则表达式的例子。所以下面我们将采用匹配方法来学习正则表达式，先给一个小例子。123456789public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "1234567890"; boolean matches = Pattern.matches("67", testStr); System.out.println(matches); &#125;&#125;这里的输出结果肯定是false了，因为这是两个不同的字符串，自然无法被匹配。字符类[abc] ：a、b 或 c（简单类）[^abc] ：任何字符，除了 a、b 或 c（否定）[a-zA-Z] ：a 到 z 或 A 到 Z，两头的字母包括在内（范围）[a-d[m-p]] ：a 到 d 或 m 到 p：[a-dm-p]（并集）[a-z&amp;&amp;[def]] ：d、e 或 f（交集）[a-z&amp;&amp;[^bc]] ：a 到 z，除了 b 和 c：[ad-z]（减去）[a-z&amp;&amp;[^m-p]] ：a 到 z，而非 m 到 p：[a-lq-z]（减去）123456789public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "123"; Pattern.matches("[123][123][123]", testStr); //true Pattern.matches("[^123][123][123]", testStr); //false &#125;&#125;预定义字符类. ：任何字符（与行结束符可能匹配也可能不匹配）\d ：数字：[0-9]\D ：非数字： [^0-9]\s ：空白字符：[ \t\n\x0B\f\r]\S ：非空白字符：[^\s]\w ：单词字符：[a-zA-Z_0-9]\W ：非单词字符：[^\w]12345678public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "123"; System.out.println(Pattern.matches("\\d\\d\\d", testStr)); //true System.out.println(Pattern.matches("\\w\\w\\w", testStr)); //true &#125;&#125;数量词X?： X存在一次或一次也没有X* ：X存在零次或多次X+ ：X存在一次或多次X{n} ：X存在恰好 n 次X{n,} ：X存在至少 n 次X{n,m} ：X存在至少 n 次，但是不超过 m 次123456789public class RegTest &#123; public static void main(String[] args) &#123; String testStr = "123"; boolean matches = Pattern.matches("[123]&#123;3&#125;", testStr); //true System.out.println(matches); &#125;&#125;查找子串查找子串需要使用到Pattern和Mather[flid=1415279, ffid=BK-2898-20180922-A, frtt=20180922210700, frlt=20180923000300][flid=1417032, ffid=OD-689-20180923-D, fatt=2401, stat=BOR, ista=BOR]123456789101112131415public class RegTest &#123; public static final String FFID = "((ffid=)&#123;1&#125;)\\w&#123;2&#125;-\\w&#123;3,6&#125;-\\d&#123;8&#125;-\\w"; public static void main(String[] args) &#123; String str = "[flid=1415279, ffid=BK-2898-20180922-A, frtt=20180922210700, frlt=20180923000300][flid=1417032, ffid=OD-689-20180923-D, fatt=2401, stat=BOR, ista=BOR]"; Pattern pattern = Pattern.compile(FFID); Matcher matcher = pattern.matcher(str); //循环找出全部的匹配子串 while(matcher.find()) &#123; System.out.println(matcher.group(0)); &#125; &#125;&#125;//ffid=BK-2898-20180922-A//ffid=OD-689-20180923-Dmarcher.group()必须和find()方法配合使用，也就是说find()是真正在字符串中搜索模式的方法（搜索到返回真，否则返回假），但是marcher.group()是将其输出的方法。组在正则表达式中，每个小括号()括起来的一个子模式是一个组，如(&quot;W(or)(ld!)&quot;中，有两个组or和ld!。在我们方才的例子中，matcher.group(0)的0指的就是matcher关联的模式，但是如果是matcher.group(1)指的就是(ffid=)。12345678910111213141516public class Demo1 &#123; public static final String FFID = "((ffid=)&#123;1&#125;)\\w&#123;2&#125;-\\w&#123;3,6&#125;-\\d&#123;8&#125;-\\w"; public static void main(String[] args) &#123; String str = "[flid=1415279, ffid=BK-2898-20180922-A, frtt=20180922210700, frlt=20180923000300][flid=1417032, ffid=OD-689-20180923-D, fatt=2401, stat=BOR, ista=BOR]"; Pattern pattern = Pattern.compile(FFID); Matcher matcher = pattern.matcher(str); //循环找出全部的匹配子串 System.out.println(matcher.groupCount()); while(matcher.find()) &#123; System.out.println(matcher.group(1)); &#125; &#125;&#125;//flid=//flid=正在表达式实例https://www.cnblogs.com/fozero/p/7868687.html。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven配置SSM环境详解]]></title>
    <url>%2F2019%2FMaven%E9%85%8D%E7%BD%AESSM%E7%8E%AF%E5%A2%83%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[配置web.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" version="2.5"&gt; &lt;display-name&gt;ssm-maven-template&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;session-config&gt; &lt;!-- 单位分钟 --&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt; &lt;/session-config&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 解决post乱码 --&gt; &lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt;web.xml没有什么好说的，就是将SSM的配置文件加载进去。21行的&lt;servlet&gt;&lt;/servlet&gt;是加载进入SpringMVC的配置文件，可以理解成controller层的配置文件。34行的&lt;context-param&gt;是加载进去service层和dao层的配置文件。配置springmvc.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.2.xsd"&gt; &lt;mvc:default-servlet-handler /&gt; &lt;!-- 配置扫描 器 --&gt; &lt;context:component-scan base-package="cn.template.controller"/&gt; &lt;!-- 配置处理器映射器 适配器 --&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults="true"&gt; &lt;!-- 配置Fastjson支持 --&gt; &lt;bean class="com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter"&gt; &lt;property name="supportedMediaTypes"&gt; &lt;list&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;value&gt;application/json&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="features"&gt; &lt;list&gt; &lt;value&gt;WriteMapNullValue&lt;/value&gt; &lt;value&gt;QuoteFieldNames&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!-- 配置视图解释器 jsp --&gt; &lt;bean id="jspViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!-- 设置上传文件的最大尺寸为5MB --&gt; &lt;property name="maxUploadSize"&gt; &lt;value&gt;5242880&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 拦截器 --&gt;&lt;!-- &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**" /&gt; &lt;bean class="cn.template.Interceptor.AutoLoginInterceptor" /&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; --&gt; &lt;/beans&gt;在springmvc.xml中主要配置的是controller层的扫描器，视图解析器，文件上传插件，拦截器等和用户交互相关的配置。SpringMVC默认使用Jackson包来处理json，但是个人一般喜欢使用阿里巴巴的fastjson，所以在此配置文件中将fastjson配置进去。配置applicationContext-*.xmlapplicationContext-dao.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.2.xsd"&gt; &lt;!-- 配置 读取properties文件 jdbc.properties --&gt; &lt;context:property-placeholder location="classpath:jdbc.properties" /&gt; &lt;!-- 配置 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置 Mybatis --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;!-- 配置pojo别名 --&gt; &lt;property name="typeAliasesPackage" value="cn.template.pojo"&gt;&lt;/property&gt; &lt;!-- 加载mybatis的全局配置文件 --&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;bean class="com.github.pagehelper.PageInterceptor"&gt; &lt;property name="properties"&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt; &lt;value&gt;helperDialect=mysql&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 扫描mapper--&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="cn.template.mapper" /&gt; &lt;/bean&gt;&lt;/beans&gt;dao层配置文件配置和数据库相关的信息。本人在写项目的时候只使用过mysql，所以这一部分的配置仅可以保证针对mysql生效。数据库连接池：阿里巴巴的druid配置mybatis及其分页插件配置自动扫描接口applicationContext-service.xml1234567891011121314151617181920212223242526&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:task="http://www.springframework.org/schema/task" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.2.xsd"&gt; &lt;!-- 配置 扫描 @Service --&gt; &lt;context:component-scan base-package="cn.template.service" /&gt; &lt;/beans&gt;applicationContext-transaction.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:task="http://www.springframework.org/schema/task" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.2.xsd"&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 配置通知 --&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;!-- 增删改加入事物控制 --&gt; &lt;tx:method name="save*" propagation="REQUIRED"/&gt; &lt;tx:method name="insert*" propagation="REQUIRED"/&gt; &lt;tx:method name="delete*" propagation="REQUIRED"/&gt; &lt;tx:method name="update*" propagation="REQUIRED"/&gt; &lt;!-- 查询方法(只读)不用事物控制 --&gt; &lt;tx:method name="find*" propagation="SUPPORTS" read-only="true"/&gt; &lt;tx:method name="get*" propagation="SUPPORTS" read-only="true"/&gt; &lt;tx:method name="select*" propagation="SUPPORTS" read-only="true"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置aop切面 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* cn.template.service.impl.*.*(..))"/&gt; &lt;/aop:config&gt;&lt;/beans&gt;配置pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;ssm-maven-template&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.2.7&lt;/mybatis.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 配置支持事物的事务管理器applicationContext-transaction.xml中 org.springframework.jdbc.datasource.DataSourceTransactionManager --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis依赖包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis-Spring整合包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 通用Mapper依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;3.3.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis_PageHelper分页依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSTL --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql-connector --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.18&lt;/version&gt; &lt;/dependency&gt; &lt;!-- servlet-api和jsp-api --&gt; &lt;dependency&gt; &lt;groupId&gt;servletapi&lt;/groupId&gt; &lt;artifactId&gt;servletapi&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;!-- 指明只在编译中有效(因为发布过程中Tomcat等容器已经包含了该jar包，导致冲突) --&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- slf4j到log4j的转接包,才能看到sql语句打印(依赖了log4j，不用单独配置上述log4j) --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/template&lt;/path&gt; &lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 资源文件拷贝插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt;坐标没有什么好说的，主要是不产生依赖问题就行。但是插件必须要解释一下：tomcat7-maven-plugin：可以将tomcat内嵌到web项目中，直接运行webapp项目。有了这个插件才可以使用tomcat7:run命令。maven-resources-plugin：这是资源拷贝插件。在原始的maven项目中，我们使用tomcat7:run运行项目之后会如上图所示，将src/main/java目录下的java文件编译至target目录下的classes目录下。但是我们的mapper.xml文件虽然和mapper.java文件放在同一目录下，但是仍然不会被拷贝至classes目录下。所以我们需要加入此插件将src/main/java下的mapper.xml文件拷贝至classer目录下。不过加入这个插件后，此插件替代了默认的拷贝方式，及src/main/resources不会再被拷贝至classes目录下，所以我们需要指定src/main/resources下的配置文件拷贝过去。参考源码：https://github.com/isjinhao/ssm-maven-template]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>SSM</tag>
        <tag>Maven</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven基础]]></title>
    <url>%2F2019%2FMaven%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[概述Maven是Apache下的一个纯Java开发的开源项目，它是一个项目管理工具，使用Maven对项目进行构建和依赖管理等。所以下面就会介绍什么是项目构建，什么是依赖管理，以及使用Maven来做的好处。项目构建项目构建是指一个项目从编写源代码到编译、测试、运行、打包、部署、运行的过程。在传统的项目构建中流程图如下：但是上面的开发适应于小型项目开发，对于大型项目开发，使用Maven给我们提供的规范可以更好更快的开发。依赖管理如果一个项目，需要使用第三方jar包才能运行，我们就说这个项目依赖了这些第三方jar包。比如：使用SSM框架开发OA系统，则此OA依赖SSM框架。在原始开发的过程中，我们是手动添加jar包进去，这样太过麻烦，使用Maven，可以通过配置的方式自动获取jar包并且添加进去。安装官网下载地址：http://maven.apache.org/download.cgi下载之后解压到不含中文字符和特殊符号的路径下。再配置环境变量：然后把%MAVEN_HOME%\bin\配置进Path中。再CMD中输入 mvn -v测试是否安装成功。Maven仓库Maven能通过配置的方式添加第三方jar包，是因为它可以自动把指定位置的jar包导入仓库中，这些指定位置就是Maven的仓库。在Maven中有三种仓库：本地仓库，私服和中央仓库。中央仓库是Maven团队维护的市面上常用的jar包的集合，平时所用的jar包都能在这个中央仓库中找到。私服指的是在团队开发或公司中，维护一个内网下的中央仓库，所有人使用的jar包都从这个仓库中获取，保证所有人用的开发版本是一致的。本地仓库就是在我们自己的计算机中维护一个仓库，自己在开发的时候都使用这个仓库中的jar包。Maven项目在查找jar包的顺序：本地 -&gt; 私服 -&gt; 中央仓库。但是无论的jar包的来源是什么，项目最终都是在本地仓库中寻找jar包。如果本地仓库找不到jar包的时候可以去这个网站寻找，然后贴在pom.xml的&lt;dependencies&gt;&lt;dependencies&gt;中，再update project就可以了。Maven仓库的配置建一个保存jar包的文件夹。在%MAVEN_HOME%\conf\settings.xml中配置图片中最后一行，位置是自己的本地仓库。修改JDK版本在%MAVEN_HOME%\conf\settings.xml中的&lt;/profiles&gt;便签里配置：123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;Eclipse配置Maven安装Maven更换配置文件更新索引更换镜像Maven默认的镜像是国外站点的镜像。换成阿里云的镜像访问较快。修改setting.xml文件。12345678 &lt;mirrors&gt;&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;重建索引Window -&gt; Show View -&gt; Other -&gt; Maven Repositories。Maven项目开发Maven项目的目录规范就像Java项目有它的目录规范，Dynamic Web项目有它的项目规范，Maven项目自然也有他自己的项目规范。Eclipse开发Maven项目new的时候选择Maven Project。勾选create a simple project…。这步一定要做，否则构建出来的Maven不完整。选择Next后必填项是Group Id 和 Artifact Id，前者一般写域名的后置，如：com.xxx，后者是项目名。需要注意的是Packaging，这里有三种选择，jar、pom和war，jar指的是Java Project，pom用于工程的继承，父工程一般打成pom包，war包指的是Java Web项目。本次测试使用war包。创建项目后，右击项目 -&gt; Java EE Tools -&gt; Generate Deployment Descriptor Stub新建项目后。我们在Java Resource/src/main/java中写Java代码。在src/main/webapp中写jsp代码。Hello.java1234567891011121314151617181920import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet(urlPatterns="/hello")public class Hello extends HttpServlet &#123; public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.getWriter().write("hello haohao..."); request.getRequestDispatcher("/NewFile.jsp").forward(request, response); &#125; public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; doGet(request, response); &#125; &#125;NewFile.jsp123456789101112&lt;%@ page language="java" contentType="text/html; charset=ISO-8859-1" pageEncoding="ISO-8859-1"%&gt;&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; hello&lt;/body&gt;&lt;/html&gt;pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.isjinhao&lt;/groupId&gt; &lt;artifactId&gt;course-selection-help&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;4.0.1&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;jsp-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/helloworld2&lt;/path&gt; &lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt;使用tomcat7:run运行运行时如果报：No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK?，请参考这篇文章：https://blog.csdn.net/lslk9898/article/details/73836745启动后发现访问时会报错此时需要注意Maven的依赖范围，所以我们需要继续看下去。Maven依赖范围什么是依赖范围?maven 项目不同的阶段引入到classpath中的依赖是不同的，例如，编译时，maven 会将与编译相关的依赖引入classpath中，测试时，maven会将测试相关的的依赖引入到classpath中，运行时，maven会将与运行相关的依赖引入classpath中，而依赖范围就是用来控制依赖于这三种classpath的关系。依赖范围在pom.xml中如何体现？pom文件如下配置：123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.7&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;其scope标签就是依赖范围的配置，默认是compile，可选配置有test、provided、runtime、system、import。6个中最常用的是前四个。编译依赖范围（compile）该范围就是默认依赖范围，此依赖范围对 于编译、测试、运行三种classpath都有效，举个简单的例子，假如项目中有spring-core的依赖，那么spring-core不管是在编译，测试，还是运行都会被用到，因此spring-core必须是编译范围（构件默认的是编译范围，所以依赖范围是编译范围的无须显示指定）测试依赖范围（test）顾名思义就是针对于测试的，使用此依赖范围的依赖，只对测试classpath有效，在编译主代码和项目运行时，都将无法使用该依赖，最典型的例子就是 Junit, 构件在测试时才需要，所以它的依赖范围是测试，因此它的依赖范围需要显示指定为&lt;scope&gt;test&lt;/scope&gt;，当然不显示指定依赖范围也不会报错，但是该依赖会被加入到编译和运行的classpath中,造成不必要的浪费 。已提供依赖范围（provided）使用该依赖范围的maven依赖，只对编译和测试的classpath有效，对运行的classpath无效，典型的例子就是servlet-api， 编译和测试该项目的时候需要该依赖，但是在运行时，web容器已经提供的该依赖，所以运行时就不再需要此依赖，如果不显示指定该依赖范围，并且容器依赖的版本和maven依赖的版本不一致的话，可能会引起版本冲突，造成不良影响。运行时依赖范围（runtime）使用该依赖范围的maven依赖，只对测试和运行的classpath有效，对编译的classpath无效，典型例子就是JDBC的驱动实现，项目主代码编译的时候只需要JDK提供的JDBC接口，只有在测试和运行的时候才需要实现上述接口的具体JDBC驱动。之前问题的解决把pom.xml文件中的runtime修改为provided。Maven命令右击项目在Run As中可以看到build、clean、generate-sources、install、和test命令，但是build一个就可以完成整个Maven项目的发布，其他的只是把常用的Maven项目发布的重甲过程提取出来。但是eclipse中命令不是很完整，所以我们进入maven工程的根目录执行命令。compile把src/main/java下的文件编译成class文件，并输出到target目录下。test执行src/test/java下的单元测试类。在src/test/java下创建类：12345678package cn.isjinhao.test;public class Test &#123; @org.junit.Test public void demo() &#123; System.out.println("demo1"); &#125; &#125;这时需要注意两点。一个是要配置pom.xml文件：scope一定不能写test。123456&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;第二个是需要配置更新工程：右击项目 -&gt; Maven -&gt; Update Project。clean删除target目录中我们生成的文件。packageweb工程打成jar包，java工程打成war包。install执行install将使用maven打包发布到本地仓库。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaWeb</tag>
        <tag>项目构建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-网络编程]]></title>
    <url>%2F2019%2FJava-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[InetAddressThis class represents an Internet Protocol (IP) address.获得本机IP地址获得本地IP地址InetAddress iaddress = InetAddress.getLocalHost();但是这个函数有问题，因为这个函数的原理是通过获取本机的hostname，然后对此hostname做解析，从而获取IP地址的。那么问题来了，如果在本机的/etc/hosts文件里对这个主机名指向了一个错误的IP地址，那么InetAddress.getLocalHost就会返回这个错误的IP地址。当然如果你的hostname是到DNS去解析的，碰巧DNS上的信息也是错的，也同样是悲惨结局。InetAddress是由两部分组成的，一部分是getHostName()，一部分是getHostAddress()。获得本机所有的IP地址1234567891011121314151617181920212223242526272829/** * 获取机器所有网卡的IP（ipv4） */public static List&lt;String&gt; getLocalIP() &#123; List&lt;String&gt; ipList = new ArrayList&lt;String&gt;(); InetAddress ip = null; try &#123; Enumeration&lt;NetworkInterface&gt; netInterfaces = (Enumeration&lt;NetworkInterface&gt;) NetworkInterface.getNetworkInterfaces(); while (netInterfaces.hasMoreElements()) &#123; NetworkInterface ni = (NetworkInterface) netInterfaces.nextElement(); // 遍历所有ip Enumeration&lt;InetAddress&gt; ips = ni.getInetAddresses(); while (ips.hasMoreElements()) &#123; ip = (InetAddress) ips.nextElement(); if (null == ip || "".equals(ip)) &#123; continue; &#125; String sIP = ip.getHostAddress(); if(sIP == null || sIP.indexOf(":") &gt; -1) &#123; continue; &#125; ipList.add(sIP); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ipList;&#125;获取其他主机的IP地址对象InetAddress otherInetAddress = InetAddress.getByName(&quot;www.baidu.com&quot;);123456789101112131415public static void main(String[] args) throws UnknownHostException &#123; //1.获取本地主机 InetAddress iaddress = InetAddress.getLocalHost(); System.out.println(iaddress); //打印 InetAddress对象 默认格式: 用户名/IP地址 //2.获取主机名 String hostName = iaddress.getHostName(); //3.获取主机IP地址 String ip = iaddress.getHostAddress(); System.out.println(hostName); System.out.println(ip); //3.获取其他主机的IP地址对象 InetAddress otherInetAddress = InetAddress.getByName("www.baidu.com"); System.out.println(otherInetAddress);&#125;UDPUDP通信需要两个类的支持：数据的发送接收器：DatagramSocket数据包类：DatagramPacket123456789101112131415161718192021222324252627282930313233343536import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.net.SocketException;public class UDPReceiver &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub //1.创建DatagramSocket对象, //强调:接收端必须指定一个端口号 DatagramSocket ds = new DatagramSocket(12345); while(true)&#123; //2.直接创建一个DatagramPacket对象 byte[] bs = new byte[1024]; DatagramPacket dp = new DatagramPacket(bs, bs.length); //3.接收 System.out.println("等待发送端发送数据...."); ds.receive(dp);//这个方法具有等待功能,等待发送端发送过来的数据 System.out.println("接收数据成功!!"); //获取发送端的地址 InetAddress sendAddress = dp.getAddress(); System.out.println("发送端是:"+sendAddress.getHostAddress()); //获取真正的数据 byte[] data = dp.getData(); //获取发送端 发来了多少字节 int len = dp.getLength(); //打印数据 String receiveMsg = new String(data, 0, len); System.out.println("发送端说:"+receiveMsg); &#125; //4.关闭资源（程序运行结束之后是需要关闭资源的，但是我们的程序是一个死循环，此句永不会执行，所以不能加关闭） //ds.close(); &#125;&#125;1234567891011121314151617181920212223242526import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetAddress;import java.util.Scanner;public class UDPSender &#123; public static void main(String[] args) throws Exception &#123; Scanner sc = new Scanner(System.in); //1.创建DatagramSocket对象 DatagramSocket ds = new DatagramSocket(); while(true)&#123; //2.创建DatagramPacket对象 //存储 发送的数据,对方的IP,端口号 System.out.println("请输入您要发送的数据:"); String sendMsg = sc.nextLine(); byte[] bs = sendMsg.getBytes(); //IP地址:127.0.0.1 代表本机,本地回环地址 DatagramPacket dp = new DatagramPacket(bs,bs.length,InetAddress.getByName("127.0.0.1"),12345); //3.发送 ds.send(dp); System.out.println("发送数据成功!!!");//192.168.146.72 &#125; //4.关闭资源（程序运行结束之后是需要关闭资源的，但是我们的程序是一个死循环，此句永不会执行，所以不能加关闭） //ds.close(); &#125;&#125;TCP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;/** * TCP服务器:(ServerSocket) 步骤: * * 1.创建一个ServerSocket对象,必须绑定一个端口,这个端口必须和客户端连接的端口一致 * * 2.调用server的accept()方法,获取到底哪一个客户端连接的服务器 * * 3.通过刚刚获取到的客户端对象 调用getInputStream()方法 * * 4.通过输入流调用read方法,读取客户端写过来的数据 * * 5.关闭资源 * */public class ServerDemo &#123; public static void main(String[] args) throws IOException &#123; // 1.创建一个ServerSocket对象,必须绑定一个端口,这个端口必须和客户端连接的端口一致 ServerSocket server = new ServerSocket(12345); // 2.获取到 哪一个 客户端连接的我 System.out.println("等待客户端连接..."); Socket client = server.accept();// 此方法也具有等待功能,等待某一个客户端连接 // 打印一些和客户端有关信息 String ip = client.getInetAddress().getHostAddress(); System.out.println("小样,抓到你了:" + ip); // 3.获取输入流,实际上是客户端写数据时的输出流 InputStream in = client.getInputStream(); // 4.读取数据 byte[] bs = new byte[1024]; int len = in.read(bs); // 打印 System.out.println("客户端说:" + new String(bs, 0, len)); // 5.要向客户端 回写数据,告诉客户端您的信息我已经收到了 OutputStream out = client.getOutputStream(); out.write("您的消息已经收到...".getBytes()); System.out.println("给客户端反馈的信息发送成功!!!"); // 关闭资源 server.close(); client.close(); in.close(); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738import java.io.IOException;import java.io.InputStream;import java.net.Socket;/** * * 使用TCP协议的客户端(Socket类) 步骤: 1.创建一个客户端对象(注意:指定这个Socket要连接的服务器的IP和端口) * * 2.从客户端对象中获取 输出流:getOutputStream() * * 3.调用输出流的Write方法写数据到服务器即可 * * 4.关闭资源 * */public class ClientDemo &#123; public static void main(String[] args) throws IOException &#123; // 1.创建一个客户端对象(注意:指定这个Socket要连接的服务器的IP和端口) /* * 这个构造方法干了很多事情: a.自动去连接服务器 b.自动进行三次握手,建立连接 c.自动为连接中创建两个流 */ Socket client = new Socket("127.0.0.1", 12345); // 2.从客户端对象中获取 输出流:getOutputStream() // OutputStream out = client.getOutputStream(); // 3.调用输出流的Write方法写数据到服务器即可 // out.write("How are you".getBytes()); client.getOutputStream().write("How are you".getBytes()); System.out.println("给服务器发送数据成功!!"); // 4.读取服务器 发送过来的反馈信息 InputStream in = client.getInputStream(); byte[] bs = new byte[1024]; int len = in.read(bs); System.out.println("服务器响应:" + new String(bs, 0, len)); // 关闭资源 client.close(); &#125;&#125;文件传输案例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;public class FileUploadServer &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub //1.创建ServerSocket对象,绑定一个端口 ServerSocket server = new ServerSocket(12345); while(true)&#123; //2.获取哪一个客户端连接的服务器 System.out.println("等待客户端连接..."); final Socket client = server.accept(); //开启一个线程,和clinet进行交互 new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; // TODO Auto-generated method stub System.out.println("小样:"+client.getInetAddress().getHostAddress()); //3.获取输入流,读取客户端发来数据 InputStream in = client.getInputStream(); //4.创建文件的输出流,把数据写到文件中 String picName = "D:\\"+System.currentTimeMillis()+".png"; FileOutputStream fos = new FileOutputStream(picName); //5.循环 从输入流读取客户端数据, 写入到文件中 byte[] bs = new byte[1024]; int len = 0; while((len=in.read(bs))!=-1)&#123; fos.write(bs, 0, len); &#125;//1小时 System.out.println("客户端的文件已经保存完毕,可以查看了"+picName); //6.告知客户端,文件真的真的真的上传成功 try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; OutputStream out = client.getOutputStream(); out.write("您的文件真的真的真的上传成功".getBytes()); client.close(); in.close(); out.close(); fos.close(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; //6.关闭 // server.close(); &#125;&#125;12345678910111213141516171819202122232425262728293031323334import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;public class FileUploadClient &#123; public static void main(String[] args)throws IOException &#123; //1.创建Socket对象,连接服务器 Socket client = new Socket("127.0.0.1", 12345); System.out.println("连接服务器成功.."); //2.获取输出流,把数据写向服务器 OutputStream out = client.getOutputStream(); //3.创建文件的输入流,读取本地的文件数据 FileInputStream fis = new FileInputStream("C:\\Users\\ISJINHAO\\Desktop\\我.jpg"); //4.循环,读取本地文件,写到服务器 byte[] bs = new byte[1024]; int len = 0; while((len=fis.read(bs))!=-1)&#123; out.write(bs, 0, len); &#125; //关闭输出流 client.shutdownOutput(); //5.获取服务器反馈的信息 InputStream in = client.getInputStream(); byte[] bs1 = new byte[1024]; int len1 = in.read(bs1); System.out.println("服务器说:"+new String(bs1,0,len1)); //6关闭 client.close(); out.close(); fis.close(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-IO流]]></title>
    <url>%2F2019%2FJava-IO%E6%B5%81%2F</url>
    <content type="text"><![CDATA[输入流概述InputStream是字节输入流的根类，Reader是字符输入流的根类。我们所说的输入输出都是相对Java程序而言的，所以输入是把外存中的数据读取到内存中。而分成两个根类的原因是在流的基本单位是字节，但是Java字符使用UTF-16编码，在UTF-16编码中，绝大部分字符是双字节的，所以单独划分一个类别来表示字符输入流。InputStream概述InputStream是字节输入流，常用的直接实现类有ByteArrayInputStream和FileInputStream，前者是把某byte数组指定为数据源，后者是把文件作为数据源。API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.io.ByteArrayInputStream;import java.io.FileInputStream;import java.io.InputStream;public class Test &#123; public String test; public static void main(String[] args) throws Exception &#123; byte []bs = new byte[100]; for(int i = 0; i &lt; 100; i++) bs[i] = (byte)i; //以字节数组为数据源 InputStream isb = new ByteArrayInputStream(bs); //以文件为数据源 InputStream isf = new FileInputStream("E:\\video\\10 IO流-基础\\视频\\avi\\10.01_IO流的概述和分类.avi"); /** * 两个的演示API相同，但是字节数组更直观，所以使用字节数组作为数据源演示 */ /** * 读取当前数据源的下一个字节数据并返回： * Console: * 0 * 1 */ System.out.println(isb.read()); System.out.println(isb.read()); /** * 跳过指定字节的数据 * Console: * 4 */ isb.skip(2); System.out.println(isb.read()); /** * 还可以读取的字节数 * Console: * 95 */ System.out.println(isb.available()); /** * 尽可能把数据读入temps中，即如果数据字节数大于数组容量，数组会被读满， * 小于数据源数据会全部读进去， 返回真正读取的字节数 * Console: * 5 6 7 8 9 10 11 12 13 14 * 10 */ byte []temps = new byte[10]; int read = isb.read(temps); for(byte e : temps) System.out.print(e + " "); System.out.println("\n" + read); /** * read(byte[] b, int off, int len) * 从off位置开始开始读入len个字节的数据到b中，返回真正读取的字节数 * Console: * 5 6 7 8 9 10 11 12 13 14 * 10 */ int read2 = isb.read(temps, 3, 2); for(byte e : temps) System.out.print(e + " "); System.out.println("\n" + read2); /** * mark(int readlimit) &amp; reset() * 再调用reset()之后，会返回最近的一次被mark的位置， * 传入的参数：readLimit是说系统会保证在readLimit * 个字节之内不会使mark失效，超过这个字节之后就不再保证了 * Console: * 17 */ isb.mark(isb.available()); isb.read(); isb.reset(); System.out.println(isb.read()); /** * 查看当前流是否支持mark和reset。 * Console: * true */ System.out.println(isb.markSupported()); /** * 关闭此流并且释放系统资源 */ isb.close(); &#125;&#125;FilterInputStream这个类直译是过滤输入流，但是在Java中过滤的目的是为了增强某些功能，所以我更喜欢叫他增强输入流。虽然它不是抽象类，但是它却不能直接使用，因为它所有的属性和方法都是protected的，它有一个常用的实现类：BufferedInputStream。这个类的增强的功能就是采用开辟缓存区的方式使输入流读取数据能更快。123456789101112131415161718192021222324252627import java.io.BufferedInputStream;import java.io.FileInputStream;import java.io.InputStream;public class Test2 &#123; public static void main(String[] args) throws Exception &#123; InputStream is = new FileInputStream("E:\\video\\10 IO流-基础\\视频\\avi\\10.01_IO流的概述和分类.avi"); long begin1 = System.currentTimeMillis(); while(is.read() != -1) &#123;&#125; long end1 = System.currentTimeMillis(); System.out.println(end1 - begin1); InputStream bis = new BufferedInputStream(new FileInputStream("E:\\video\\10 IO流-基础\\视频\\avi\\10.01_IO流的概述和分类.avi")); long begin2= System.currentTimeMillis(); while(bis.read() != -1) &#123;&#125; long end2 = System.currentTimeMillis(); System.out.println(end2 - begin2); /** * Console: * 23175 * 53 */ is.close(); bis.close(); &#125;&#125;Reader概述这个类是处理字符文件的根类。它的常用实现类有FileReader和CharArrayReader。同样的，如果要加快读取速度，使用带缓冲区的BufferedReader类。API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.io.CharArrayReader;import java.io.FileReader;import java.io.Reader;public class Test2 &#123; public static void main(String[] args) throws Exception &#123; char []strs = new char[26]; for(int i = 0; i &lt; 26; i++) strs[i] = (char)(i + 97); //以文件作为数据源 Reader fr = new FileReader("D:\\a.txt"); //以字符数组作为数据源 Reader car = new CharArrayReader(strs); /** * 为了方便，数据源使用字符数组 */ /** * 读取单个字符，并返回相应的int值 * Console: * a */ int read = car.read(); System.out.println((char)read); /** * 尽可能读取到字符数组，并返回真实读取的字符数。如果数组容量小于数据源字符个数 * 数组会被全部读满，否则读至数据源结尾。 * Console: * b c d e f g h i j k * 10 */ char []temps = new char[10]; int read2 = car.read(temps); for(char e : temps) System.out.print(e + " "); System.out.println("\n" + read2); /** * read(char[] cbuf, int off, int len) * 从字符数组的off位置开始，读入长度为len的数据进入，返回真正读取的字符数、 * Console: * b c d l m g h i j k * 2 */ int read3 = car.read(temps, 3, 2); for(char e : temps) System.out.print(e + " "); System.out.println("\n" + read3); /** * skip(long n) * mark(int readAheadLimit) * reset() * markSupported() * * 和InputStream一致 */ &#125;&#125;InputStreamReaderInputStreamReader是 a bridge from byte streams to character streams: It reads bytes and decodes them into characters using a specified charset。它有且只有FileReader这个子类，所以FileReader实现从文件中读取的方法是从把文件按字节读入后按照指定编码规则进行解码，默认是平台解码集。输出流概述OutputStream是字节输出流的根类，Writer是字符输出流的根类。我们所说的输入输出都是相对Java程序而言的，所以输出是把内存中的数据读取到外存中。而分成两个根类的原因是在流的基本单位是字节，但是Java字符使用UTF-16编码，在UTF-16编码中，绝大部分字符是双字节的，所以单独划分一个类别来表示字符输出流。OutputStream概述OutputStream是字节输出流，常用的直接实现类是FileOutputStream，它把文件作为数据输出位置。如果想加快输出效率，使用BufferedOutputStream。API1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.FileOutputStream;import java.io.OutputStream;public class Test3 &#123; public static void main(String[] args) throws Exception &#123; //如果不存在这个文件，会自动创建 OutputStream fos = new FileOutputStream("D:\\aa.txt"); /** * write(int b)：将指定的字节写入此输出流。 */ fos.write(97); /** * flush()：刷新缓冲区，让write的数据真正写入磁盘文件 */ fos.flush(); /** * write(byte[] b)：将 b.length 个字节从指定的 byte 数组写入此输出流。 */ byte []bs = new byte[5]; for(int i = 0; i &lt; 5; i++) bs[i] = (byte) ((i % 26) + 97); fos.write(bs); fos.flush(); /** * void write(byte[] b, int off, int len) * 将指定 byte数组中从off开始的 len个字节写入此输出流。 */ fos.write(bs, 2, 2); fos.flush(); /** * close()：释放资源 */ fos.close(); &#125;&#125;Writer概述这个类是写入字符文件的根类。它的常用实现类是FileWriter。同样的，如果要加快读取速度，使用带缓冲区的BufferedWriter类。API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.io.FileWriter;import java.io.Writer;public class Test4 &#123; public static void main(String[] args) throws Exception &#123; //指定一个输出位置，如果不存在会自动创建 Writer w = new FileWriter("d:\\bbb.txt"); //写入单个字符 w.write(97); //写入字符串 w.write("bcd"); //写入字符串的某一部分 w.write("defgf", 1, 2); //写入字符数组 char []temps = &#123;'g', 'h'&#125;; w.write(temps); //写入字符数组的某一部分 w.write(temps, 1, 1); w.flush(); w.close(); /** * File: * abcdefghh */ //流被关闭之后是不能再被打开的，重新开启输出一个流，向其中写入数据会覆盖原有 //数据，如果我们想继续之前的写，可以使用追加方法，不过append方法虽然翻译过来叫住追加 //但是它不是追加，它的作用和write()差不多。 w = new FileWriter("d:\\bbb.txt"); //写入一个字符 w.append('|'); //写入一个字符串 w.append("abc"); //写入字符串的某一部分 w.append("def", 1, 2); w.flush(); w.close(); /** * File: * |abce */ //字符流追加数据可以在构造方法中指定写入数据为追加数据 w = new FileWriter("d:\\bbb.txt", true); w.write("aaa"); w.flush(); w.close(); /** * File: * |abceaaa */ &#125;&#125;InputStreamReaderOutputStreamReader是a bridge from character streams to byte streams:Characters written to it are encoded into bytes using a specified charset。它有且只有FileWriter这个子类，所以FileWriter实现从写入文件的方法是从把字符按编码规则编码成字节数据后写入文件，默认是平台编码集。打印流PrintStream和PrintReader是为了方便输出而产生的两个流，前者是java.io.FilterOutputStream的子类，后者是java.io.Writer的子类。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.io.BufferedWriter;import java.io.FileOutputStream;import java.io.IOException;import java.io.OutputStream;import java.io.OutputStreamWriter;import java.io.PrintStream;import java.io.PrintWriter;import java.io.Writer;import java.nio.file.Files;import java.nio.file.Paths;import java.nio.file.StandardOpenOption;public class TestPrintStream &#123; public static void main(String[] args) throws IOException &#123; OutputStream stream = Files.newOutputStream(Paths.get("test"), StandardOpenOption.WRITE); /** * 设置true之后，当输出字节数组、println方法或写入换行符或字节（'\n'）后，将自动调用flush方法 */ /** * PrintStream打印的所有字符都使用平台的默认字符编码转换为字节 */ PrintStream printStream = new PrintStream(stream, true); /** * 指定转化为字节数组的编码集后使用指定的编码集 */ printStream.write("陈钰琪 ".getBytes("GBK")); /** * ture表示是追加 */ /** * GBK指定输出时按GBK编码集转化成字节数组 */ Writer writer = new OutputStreamWriter(new FileOutputStream("test", true), "GBK"); /** * true表示自动刷新，但只有println, printf, or format方法才能触发自动刷新 */ PrintWriter printWriter = new PrintWriter(writer, true); printWriter.write("钰琪是个小可爱"); printWriter.flush(); printWriter.close(); /** * BufferedWriter writer = Files.newBufferedWriter(Paths.get("test"), StandardOpenOption.WRITE, StandardOpenOption.APPEND); PrintWriter printWriter = new PrintWriter("test", "GBK"); printWriter.write("钰琪是个小可爱"); printWriter.close(); writer.close(); 这段代码无法进行追加...讲道理应该是可以追加的... */ &#125;&#125;RandomAccessFileRandomAccessFile是Java的IO流体系中功能最丰富的文件内容访问类，既可以读取文件内容，也可以向文件输出数据。与普通的输入/输出流不同的是，RandomAccessFile支持跳到文件任意位置读写数据，RandomAccessFile对象包含一个记录指针，用以标识当前读写处的位置，当程序创建一个新的RandomAccessFile对象时，该对象的文件记录指针对于文件头（也就是0处），当读写n个字节后，文件记录指针将会向后移动n个字节。除此之外，RandomAccessFile可以自由移动该记录指针。RandomAccessFile包含两个方法来操作文件记录指针：long getFilePointer()：返回文件记录指针的当前位置void seek(long pos)：将文件记录指针定位到pos位置RandomAccessFile类在创建对象时，除了指定文件本身，还需要指定一个mode参数，该参数指定RandomAccessFile的访问模式，该参数有如下四个值：r：以只读方式打开指定文件。如果试图对该RandomAccessFile指定的文件执行写入方法则会抛出IOExceptionrw：以读取、写入方式打开指定文件。如果该文件不存在，则尝试创建文件rws：以读取、写入方式打开指定文件。相对于rw模式，还要求对文件的内容或元数据的每个更新都同步写入到底层存储设备，默认情形下（rw模式下）,是使用buffer的，只有cache满的或者使用RandomAccessFile.close()关闭流的时候儿才真正的写到文件（其没有flush方法）rwd：与rws类似，只是仅对文件的内容同步更新到磁盘，而不修改文件的元数据文件系统中的数据分为数据和元数据。数据是指普通文件中的实际数据，而元数据指用来描述一个文件的特征的系统数据，诸如访问权限、文件拥有者以及文件数据块的分布信息(inode…)等等。读文件1234567891011121314151617181920212223242526272829303132333435import java.io.IOException;import java.io.RandomAccessFile; public class Test &#123; public static void main(String[] args) &#123; String fileName = "test"; //文件内容：陈钰琪好可爱 RandomAccessFile raf = null; try &#123; raf = new RandomAccessFile(fileName, "r"); System.out.println("RandomAccessFile的文件指针初始位置:" + raf.getFilePointer()); raf.seek("陈钰琪".getBytes().length); byte[] bbuf = new byte[1024]; int hasRead = 0; while ((hasRead = raf.read(bbuf)) &gt; 0) &#123; System.out.print(new String(bbuf, 0, hasRead)); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; try &#123; if (raf != null) &#123; raf.close(); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125;追加文件RandomAccessFile先获取文件的长度，再将指针移到文件的末尾，再将要插入的内容插入到文件。12345678910111213141516171819202122232425262728293031323334import java.io.IOException;import java.io.RandomAccessFile; public class Test &#123; public static void main(String[] args) &#123; String filename = "test"; //文件内容：陈钰琪好可爱 RandomAccessFile raf = null; try &#123; String[] arrays = new String[] &#123; "Hello Hadoop", "Hello Spark", "Hello Hive" &#125;; raf = new RandomAccessFile(filename, "rw"); raf.seek(raf.length()); raf.write("追加内容:\n".getBytes()); for (String arr : arrays) &#123; raf.write((arr + "\n").getBytes()); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; try &#123; if (raf != null) &#123; raf.close(); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125;文件中间插入RandomAccessFile如果向文件的指定的位置插入内容，则新输出的内容会覆盖文件中原有的内容。如果需要向指定位置插入内容，程序需要先把插入点后面的内容读入缓冲区，等把需要的插入数据写入文件后，再将缓冲区的内容追加到文件后面。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.cauc.chat;import java.io.File;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.io.RandomAccessFile; public class Test &#123; public static void main(String[] args) &#123; String fileName = "test"; Long pos = (long) "陈钰琪".getBytes().length; String insertContent = "可爱可爱可爱啊"; FileInputStream fis = null; FileOutputStream fos = null; RandomAccessFile raf = null; try &#123; raf = new RandomAccessFile(fileName, "rw"); File tmp = File.createTempFile("tmp", null); tmp.deleteOnExit(); fis = new FileInputStream(tmp); fos = new FileOutputStream(tmp); raf.seek(pos); byte[] bbuf = new byte[64]; int hasRead = 0; while ((hasRead = raf.read(bbuf)) &gt; 0) &#123; fos.write(bbuf, 0, hasRead); &#125; raf.seek(pos); raf.write("\n插入内容:\n".getBytes()); raf.write((insertContent + "\n").getBytes()); while ((hasRead = fis.read(bbuf)) &gt; 0) &#123; raf.write(bbuf, 0, hasRead); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; finally &#123; try &#123; if (fis != null) &#123; fis.close(); &#125; if (fos != null) &#123; fos.close(); &#125; if (raf != null) &#123; raf.close(); &#125; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java网络编程</tag>
        <tag>JavaIO流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thread和synchronized]]></title>
    <url>%2F2019%2Fthread%E5%92%8Csynchronized%2F</url>
    <content type="text"><![CDATA[按照时间发展呢的顺序，Java中是先出现了synchronized（since 1.0），再出现了Lock（since 5.0）。这是由于synchronized有一定的不足，所以才出现了Lock来更好的完成同步操作。synchronized在Java中，每一个对象都拥有一个锁标记（monitor），也称为监视器，我们可以使用synchronized关键字来标记一个方法或者代码块，当某个线程调用该对象的synchronized方法或者访问synchronized代码块时，这个线程便获得了该对象的锁，其他线程暂时无法访问这个方法，只有等待这个方法执行完毕或者代码块执行完毕，这个线程才会释放该对象的锁，其他线程才能执行这个方法或者代码块。synchronized方法：123public synchronized void insert()&#123; &#125;普通方法获得当前对象的锁，即this的锁。静态方法获得类的字节码对象的锁。synchronized代码块123synchronized(synObject) &#123; &#125;对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。条件对象当一个线程进入临界区后却发现某一条件被满足之后它才能执行，比如在银行转账时，A向B账户转账，但是当A账户获得锁后，发现账户中没有钱，需要等待C账户给其转账之后其才能给B账户转账，这时它就需要释放锁，进入等待状态，并且当其的账户余额能保证向B转完账后不为负数这个条件时才能转账，同时当此条件被满足时其他线程需要通知等待的线程让其进入运行状态。方法如下：synchronized方法123456public synchronized void test()&#123; if(条件x不满足) wait(); if(条件x被满足) notify() or notifyAll() //唤醒等待在条件x上的线程&#125;synchronized代码块123456synchronized(synObject) &#123; if(条件x不满足) wait(); if(条件x被满足) notify() or notifyAll() //唤醒等待在条件x上的线程&#125;但是如果还有一个条件可以迫使线程进入等待状态，在编程时只能将其也等待在条件x上，这就是其不足之一。需要注意：对于synchronized方法或者synchronized代码块，当出现异常时，JVM会自动释放当前线程占用的锁，因此不会由于异常导致出现死锁现象。LockLock接口定义的方法如下：12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125;tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。Lock接口的典型使用方法如下：123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125;ReentrantLock翻译为是“可重入锁”，意思是如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。按不同的分类，还有一类锁是中断锁，顾名思义，就是可以相应中断的锁。在Java中，synchronized就不是可中断锁，而Lock是可中断锁。如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread0 = new MyThread(test); MyThread thread1 = new MyThread(test); thread0.start(); thread1.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread1.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+"得到了锁"); long startTime = System.currentTimeMillis(); for(;;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; /* * 插入数据 */ &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+"执行finally"); lock.unlock(); System.out.println(thread.getName()+"释放了锁"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+"被中断"); &#125; &#125;&#125;在这段代码中，如果线程1首先获得锁，其会一直运行下去，此时线程0得不到锁就会永远等待下去。但是如果线程0首先获得锁，其会一直运行下去，所以此时线程1得不到锁，但是在主线程中线程1启用了interrupt()方法，而lockInterruptibly()可以响应中断。thread的状态yield()12// JDK原型public static native void yield();A hint to the scheduler that the current thread is willing to yield its current use of a processor. The scheduler is free to ignore this hint.当yield()成功的时候会自动放弃时间片，转入就绪状态，然后和其它线程进行CPU的争夺。join()join方法有三个重载版本：123join()join(long millis) //参数为毫秒join(long millis,int nanoseconds) //第一参数为毫秒，第二个参数为纳秒假如在main线程中，调用thread.join方法，则main方法会等待thread线程执行完毕或者等待一定的时间。如果调用的是无参join方法，则等待thread执行完毕，如果调用的是指定了时间参数的join方法，则等待一定的时间。join的实现123456789101112131415161718192021222324public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125;join是使用wait来实现的，如果线程仍然活着，则等待对应的时间。当调用线程（设为A）执行到其他线程（设为B）的join()方法时，A阻塞在线程B的this对象（线程B本身），如第12行或第20行所示。从代码上我们看不出来什么时候notify线程A，但是JDK注释上描述：As a thread terminates the this.notifyAll method is invoked.笔者也是在此知道，当一个线程结束时会通知所有在其上等待的线程。interrupt() 和 isInterrupted()interrupt()是一个线程中断的方法，本人只在Java网络编程这门课的实验里用过一次。其可以使得处于阻塞状态的线程抛出一个异常，也就说，它可以用来中断一个正处于阻塞状态的线程。1234567891011121314151617181920212223242526272829303132package test;import java.io.IOException;public class Test &#123; public static void main(String[] args) throws IOException &#123; Test test = new Test(); MyThread thread = test.new MyThread(); thread.start(); try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; thread.interrupt(); &#125; class MyThread extends Thread&#123; @Override public void run() &#123; try &#123; System.out.println("进入睡眠状态"); Thread.currentThread().sleep(10000); System.out.println("睡眠完毕"); &#125; catch (InterruptedException e) &#123; System.out.println("得到中断异常"); &#125; System.out.println("run方法执行完毕"); &#125; &#125;&#125;配合isInterrupted()能够中断正在运行的线程，因为调用interrupt方法相当于将中断标志位置为true，那么可以通过调用isInterrupted()判断中断标志是否被置位来中断线程的执行。比如下面这段代码：12345678910111213141516171819202122232425public class Test &#123; public static void main(String[] args) throws IOException &#123; Test test = new Test(); MyThread thread = test.new MyThread(); thread.start(); try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; thread.interrupt(); &#125; class MyThread extends Thread&#123; @Override public void run() &#123; int i = 0; while(!isInterrupted() &amp;&amp; i &lt; Integer.MAX_VALUE)&#123; System.out.println(i+" while循环"); i++; &#125; &#125; &#125;&#125;但是以上的暂停程序运行的方法可以被替换为如下代码：1234567891011121314class MyThread extends Thread&#123; private volatile boolean isStop = false; @Override public void run() &#123; int i = 0; while(!isStop)&#123; i++; &#125; &#125; public void setStop(boolean stop)&#123; this.isStop = stop; &#125;&#125;volatile的目的是禁止指令重排。参见：https://isjinhao.github.io/2019/volatile/#moreinterrupted()Tests whether the current thread has been interrupted. The interrupted status of the thread is cleared by this method. In other words, if this method were to be called twice in succession, the second call would return false (unless the current thread were interrupted again, after the first call had cleared its interrupted status and before the second call had examined it).A thread interruption ignored because a thread was not alive at the time of the interrupt will be reflected by this method returning false.每个线程都有一个中断状态位：isInterrupted(boolean ClearInterrupted)：传入true重置状态位，传入false不重置状态位。返回此方法执行完成前线程中断状态位的状态。interrupt()：将中断状态位设置为true。isInterrupted()：查看当前状态位但是不影响状态位，内部实现原理isInterrupted(false)。interrupted()：重置当前线程状态位（即如果状态位是true，则设置为false），内部实现原理isInterrupted(true)。参考：https://blog.csdn.net/zhuyong7/article/details/80852884参考https://www.cnblogs.com/dolphin0520/p/3920357.htmlJava核心技术卷1]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Java并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7软件安装和JavaWeb环境搭建]]></title>
    <url>%2F2019%2Fcentos7%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E5%92%8CJavaWeb%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[由于Linux各发行版对软件安装工具的不同支持，导致Linux软件安装是相对很麻烦的事情，由于本人目前只使用过Centos7，所以借着搭建JavaWeb开发环境把Centos7的软件安装总结一下。不过在这之前需要先了解一下wget。wget下载单个文件wget url。如wget www.baidu.com，得到百度站点的首页html文件。下载并改变文件名选项：-O。后台下载选项：-b。应用于下载文件非常大的时候。断点续传选项：-c。对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。限速下载选项：--limit。如wget --limit-rate=30k www.baidu.com。下载多个文件选项：-i。首先，保存一份下载链接文件。但是在文件中需要完整的路径名，比如不能直接使用www.baidu.com，需要使用https://www.baidu.com。如以下是文件urls中的两个url。下载时使用wget -i urls即可。更多参考https://www.cnblogs.com/semonxv/p/3816366.html源码包解压即用源码包解压即用是最简单的一种方式。如安装tomcat的时候，我们先获得压缩包：wget https://www-us.apache.org/dist/tomcat/tomcat-8/v8.5.39/bin/apache-tomcat-8.5.39.tar.gz解压：tar -zxvf apache-tomcat-8.5.39.tar.gz然后进入apache-tomcat-8.5.39\bin\运行startup.sh就可以使用。源码包解压配置环境变量刚才不需要配置环境变量是因为，我们在运行war包的时候可以将包放入webapps中，在运行bin目录下的startup.sh。如果我们想一个软件在任何位置都能运行就需要配置环境变量，比如jdk。获得jdk的安装包不能再使用官网上的url并执行wget url来获取，因为oracle的官方网站有限制。所以我们需要先下载jdk，再上传到服务器上。上传服务器之后解压即可。Linux配置环境变量时就是修改/etc/profile文件。JAVA_HOME指向解压的JDK目录。12export JAVA_HOME=/usr/jdk1.8.0_201export PATH=$JAVA_HOME/bin:$ANT_HOME/bin:$PATH修改完配置文件后使用命令刷新：source /etc/profilerpmrpm是由红帽公司开发的软件包管理方式，使用rpm我们可以方便的进行软件的安装、查询、卸载、升级等工作。但是rpm软件包之间的依赖性问题往往会很繁琐，尤其是软件由多个rpm包组成时。一般过程：找到相应的软件包，比如soft.version.rpm，下载到本机某个目录；打开一个终端，su 成root用户；cd soft.version.rpm所在的目录；输入rpm -ivh soft.version.rpmYumYum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。安装Mysql在centos7中一般默认安装了MariaDB。这是mysql的一个开源分支。为了避免这个分支对我们安装mariadb产生影响，我们先卸载这个东西：yum remove maria*。获得mysql5.7的Repository的rpm安装包：wget http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm安装下载的rpm：yum -y install mysql57-community-release-el7-10.noarch.rpm。安装mysql：yum install mysql-server配置Mysql启动：systemctl start mysqld然后在/var/log/mysqld.log文件中会自动生成一个随机的密码，我们需要先取得这个随机密码，以用于登录 MySQL 服务端：cat /var/log/mysqld.log | grep password登录：mysql -u root -p修改密码：alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;hilX0U!9i3_6&#39;;设置密码永不过期：ALTER USER &#39;root&#39;@&#39;localhost&#39; PASSWORD EXPIRE NEVER;设置root可以在远程访问：grant all privileges on *.* to root@&quot;%&quot; identified by &quot;new password&quot;;设置root可以在本地访问：grant all privileges on *.* to root@&quot;localhost&quot; identified by &quot;new password&quot;;刷新配置：flush privileges;退出：exit解封阿里云3306端口。密码策略：https://blog.csdn.net/hello_world_qwp/article/details/79551789Mysql相关命令启动：systemctl start mysqld查看状态：service mysqld status停止：service mysqld stop重启：service mysqld restartmake安装解压执行“./configure”命令为编译做好准备；执行“make”命令进行软件编译；执行“make install”完成安装；执行“make clean”删除安装时产生的临时文件。Cmake安装CMake是一种跨平台编译工具，比make更为高级，使用起来要方便得多。CMake主要是编写CMakeLists.txt文件，然后用cmake命令将CMakeLists.txt文件转化为make所需要的makefile文件，最后用make命令编译源码生成可执行程序或共享库（so，shared object）。因此CMake的编译基本就两个步骤：cmakemakecmake 指向CMakeLists.txt所在的目录，例如cmake .. 表示CMakeLists.txt在当前目录的上一级目录。cmake后会生成很多编译的中间文件以及makefile文件，所以一般建议新建一个新的目录，专门用来编译，例如12345mkdir buildcd buildcmake ..//等cmake结束makemake根据生成的makefile文件，编译程序。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>JavaWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树基础]]></title>
    <url>%2F2019%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[定义对任何节点$x$，其左子树中的关键字最大不超过$x.key$，其右子树中的关键字最小不低于$x.key$。性质中序遍历得到的结点是非降序排序。递归根节点的左子树得到树中最小元素，递归根节点的右子树得到树中最大元素。数据结构定义对于结点$x$，$x$存在指向左孩子、右孩子及父节点的指针。有且仅有根节点中的指向父节点的指针为空。算法查找$x$是根节点，$k$是待查找关键字，查找的到则返回相应节点，查找不到返回空。### 后继$x$是待查找结点，右子树不为空，右子树的最小值所在的节点是后继。解释第3-7行代码需要证明一个定理：&gt; 对于一棵二叉搜索树T，其关键字各不相同，如果T中一个节点$x$的右子树为空，且$x$有一个后继$y$，那么$y$一定是$x$的最底层祖先，并且其左孩子也是$x$的祖先。（每个结点都是其自身的祖先）#### 证明对于给定结点$x$，若其后继$y$存在，则$y &gt; x$。1. 考虑结点$x$，对于$x$的左子树，显然其中任意结点值都小于$x$，所以$y$必定不在其左子树中。2. $x$的右子树，其中任意结点值都大于$x$,但是根据题设，其右子树为空。所以，$y$必定为$x$的祖先或其祖先的右子树。又因为$y$是其中大于$x$且最小的一个，则$y$不可能是其祖先的右子树，那么我们可以将范围缩小至$y$必定为$x$的某一祖先，又根据$y&gt;x$，则$x$必定在$y$的左子树中，即$y$的左孩子也是$x$的祖先（$x$也是$x$的祖先）对于所有满足条件的，假设有$p_0,p_1 \dots p_n$共$n+1$个，且$p_0 &lt; p_1 &lt; p_2 &lt; \dots &lt; p_n$。显然，$x$的前驱结点$y$必定是其中的最小一个，即$y=p_0$。又因为$y$是$x$的祖先，则$y$必然是$x$的最底层祖先。#### 结论这个定理实际的意义是，对于二叉搜索树中的一个节点（$x$），如果其不存在右子树且还有后继（$y$），则$y$是$x$祖先节点中有左子树的最底层祖先。如下图中的13。前驱前驱的代码和后继对应。12345678TREE-PREDECESSOR(x)if x.left != null return TREE-MAXNUM(x.left);y = x.pwhile y != null and x == y.left x = y y = y.preturn y3-7行代码的意思是，对于二叉搜索树中的一个节点（$x$），如果其不存在左子树且还有前驱（$y$），则$y$是$x$祖先节点中有右子树的最底层祖先。如图中的17。插入$z$是待插入节点，3-7行$y$下降到叶子结点。下降之后插入。### 删除讨论删除之前需要证明一个定理：&gt; 如果一个二叉搜索树中的一个节点有两个孩子，那么它的后继没有左孩子，它的前驱没有右孩子。#### 证明如果一棵二叉搜索树中的一个结点有两个孩子，那么它的后继为它的右子树中的最小值，所以它的后继没有左孩子，它的前驱为它的左子树中的最大值，所以它的前驱没有右孩子。#### 删除过程删除时有三种情况：1. 如果被删除节点（$z$）没有孩子节点，直接删除，修改父节点相应指针指向空。2. 如果$z$只有一个孩子，把孩子提到树中$z$所在的位置，并修改$z$的父节点，用$z$的孩子来替换。3. 如果$z$有两个孩子，那么找$z$的后继$y$（一定在$z$的右子树中）。1. 如果$y$是$z$的右孩子，用$y$替换$z$，同时留下$y$的右孩子。2. 如果$y$不是$z$的右孩子，有之上定理可知，$y$是没有左孩子的，此时用$y$的右孩子替换$y$，用$y$替换$z$，不留下$y$的右孩子。#### 伪码实现##### TRANSPLANTTRANSPLANT的功能是在树$T$中用一棵以$v$为根的子树来替换一棵以$u$为根的子树。- 1-2行：当$u$是树根的时候，直接让$T$的根指向$v$。- 3-4行：当$u$是一个左孩子的时候，将$v$放在$u$的左孩子的位置。- 5行：当$u$是一个右孩子的时候，将$v$放在$u$的右孩子的位置。- 6-7行：更新$v$的父节点。##### TREE-DELETETREE-DELETE的功能：1. 1-4行：如果$z$没有左孩子，那么用其右孩子替换$z$。如果$z$没有右孩子，那么用其左孩子替换$z$。（此时等同于上诉删除过程中的1和2）2. 6-9行：如果如果$z$有两个孩子，且$y$不是$z$的右孩子，用$y$的右孩子替换$y$，用$y$替换$z$。3. 10-12行：如果$y$是$z$的右孩子，用$y$替换$z$，同时留下$y$的右孩子。]]></content>
      <categories>
        <category>DSA</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>DSA</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo上传图片]]></title>
    <url>%2F2019%2FHexo%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[步骤找到Hexo下的_config.yml里的post_asset_folder，把这个选项从false改成true。在博客根目录下执行一个下载上传图片插件的命令npm install hexo-asset-image --save。插件地址：https://github.com/dangxuandev/hexo-asset-image之后再使用hexo new xxx就会在_post目录下生成xxx.md文件和xxx目录。在xxx.md文件中要插入图片时，先要把所要插入的图片放在生成的同名文件夹下。利用markdown的语法将文件引入文章中。提交到github上时就可以有图片了。Bug修复插件有一个bug，使用时可能会出现如下问题：12345678910111213141516171819202122TypeError: Cannot read property &apos;replace&apos; of undefinedat Object. (D:\blog\isjinhao\node_modules\hexo-asset-image\index.js:31:38)at initialize.exports.each (D:\blog\isjinhao\node_modules\hexo-asset-image\node_modules\cheerio\lib\api\traversing.js:293:24)at Hexo. (D:\blog\isjinhao\node_modules\hexo-asset-image\index.js:29:16)at Hexo.tryCatcher (D:\blog\isjinhao\node_modules\bluebird\js\release\util.js:16:23)at Hexo. (D:\blog\isjinhao\node_modules\bluebird\js\release\method.js:15:34)at Promise.each.filter (D:\blog\isjinhao\node_modules\hexo\lib\extend\filter.js:63:65)at tryCatcher (D:\blog\isjinhao\node_modules\bluebird\js\release\util.js:16:23)at Object.gotValue (D:\blog\isjinhao\node_modules\bluebird\js\release\reduce.js:155:18)at Object.gotAccum (D:\blog\isjinhao\node_modules\bluebird\js\release\reduce.js:144:25)at Object.tryCatcher (D:\blog\isjinhao\node_modules\bluebird\js\release\util.js:16:23)at Promise._settlePromiseFromHandler (D:\blog\isjinhao\node_modules\bluebird\js\release\promise.js:512:31)at Promise._settlePromise (D:\blog\isjinhao\node_modules\bluebird\js\release\promise.js:569:18)at Promise._settlePromise0 (D:\blog\isjinhao\node_modules\bluebird\js\release\promise.js:614:10)at Promise._settlePromises (D:\blog\isjinhao\node_modules\bluebird\js\release\promise.js:694:18)at _drainQueueStep (D:\blog\isjinhao\node_modules\bluebird\js\release\async.js:138:12)at _drainQueue (D:\blog\isjinhao\node_modules\bluebird\js\release\async.js:131:9)at Async._drainQueues (D:\blog\isjinhao\node_modules\bluebird\js\release\async.js:147:5)at Immediate.Async.drainQueues [as _onImmediate] (D:\blog\isjinhao\node_modules\bluebird\js\release\async.js:17:14)at runCallback (timers.js:705:18)at tryOnImmediate (timers.js:676:5)at processImmediate (timers.js:658:5)这是插件的index.js文件中存在bug，把node_modules/hexo-asset-image/index.js的内容修改为：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061'use strict';var cheerio = require('cheerio');// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) &#123; return str.split(m, i).join(m).length;&#125;var version = String(hexo.version).split('.');hexo.extend.filter.register('after_post_render', function(data)&#123; var config = hexo.config; if(config.post_asset_folder)&#123; var link = data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 1) + 1; else var beginPos = getPosition(link, '/', 3) + 1; // In hexo 3.1.1, the permalink of "about" page is like ".../about/index.html". var endPos = link.lastIndexOf('/') + 1; link = link.substring(beginPos, endPos); var toprocess = ['excerpt', 'more', 'content']; for(var i = 0; i &lt; toprocess.length; i++)&#123; var key = toprocess[i]; var $ = cheerio.load(data[key], &#123; ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false &#125;); $('img').each(function()&#123; if ($(this).attr('src'))&#123; // For windows style path, we replace '\' to '/'. var src = $(this).attr('src').replace('\\', '/'); if(!/http[s]*.*|\/\/.*/.test(src) &amp;&amp; !/^\s*\//.test(src)) &#123; // For "about" page, the first part of "src" can't be removed. // In addition, to support multi-level local directory. var linkArray = link.split('/').filter(function(elem)&#123; return elem != ''; &#125;); var srcArray = src.split('/').filter(function(elem)&#123; return elem != '' &amp;&amp; elem != '.'; &#125;); if(srcArray.length &gt; 1) srcArray.shift(); src = srcArray.join('/'); $(this).attr('src', config.root + link + src); console.info&amp;&amp;console.info("update link as:--&gt;"+config.root + link + src); &#125; &#125;else&#123; console.info&amp;&amp;console.info("no src attr, skipped..."); console.info&amp;&amp;console.info($(this)); &#125; &#125;); data[key] = $.html(); &#125; &#125;&#125;);]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[canvas把摄像头拍摄到的视频保存为图片]]></title>
    <url>%2F2019%2Fcanvas%E6%8A%8A%E6%91%84%E5%83%8F%E5%A4%B4%E6%8B%8D%E6%91%84%E5%88%B0%E7%9A%84%E8%A7%86%E9%A2%91%E4%BF%9D%E5%AD%98%E4%B8%BA%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[截图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="bootstrap/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" href="bootstrap/css/bootstrap.min.css"&gt;&lt;/script&gt; &lt;script src="bootstrap/holder.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type="application/javascript"&gt; window.onload=function() &#123; let video = document.getElementById("video"); /** * constraints：打开摄像头时约束，下面的约束对video没有约束，它选择设备的默认摄像头，但是禁止了音频 */ let constraints = &#123; video: &#123;&#125;, audio : false &#125;; let promise; if(navigator.mediaDevices.getUserMedia)&#123; //最新标准API promise = navigator.mediaDevices.getUserMedia(constraints); &#125; else if (navigator.webkitGetUserMedia)&#123; //webkit内核浏览器 promise = navigator.webkitGetUserMedia(constraints); &#125; else if (navigator.mozGetUserMedia)&#123; //Firefox浏览器 promise = navagator.mozGetUserMedia(constraints); &#125; else if (navigator.getUserMedia)&#123; //旧版API promise = navigator.getUserMedia(constraints); &#125; promise.then(function (MediaStream) &#123; video.srcObject = MediaStream; video.play(); &#125;); &#125; &lt;/script&gt; &lt;body&gt; &lt;video class="myvideo" style="border-radius: 10%;" id="video" autoplay="autoplay" &gt;&lt;/video&gt; &lt;button id="b"&gt;画图&lt;/button&gt; &lt;canvas id="myCanvas"&gt;&lt;/canvas&gt; &lt;/body&gt; &lt;script type="text/javascript"&gt; var btn = document.getElementById("b"); btn.onclick =function()&#123; var c=document.getElementById("myCanvas"); ctx=c.getContext('2d'); ctx.drawImage(video, 0, 0, 270, 135); &#125; &lt;/script&gt;&lt;/html&gt;转化为file此标题中说的file是表单中&lt;input type=&quot;file&quot; name=&quot;&quot; id=&quot;&quot; value=&quot;&quot; /&gt;。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="bootstrap/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" href="bootstrap/css/bootstrap.min.css"&gt;&lt;/script&gt; &lt;script src="bootstrap/holder.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type="application/javascript"&gt; window.onload=function() &#123; let video = document.getElementById("video"); /** * constraints：打开摄像头时约束，下面的约束对video没有约束，它选择设备的默认摄像头，但是禁止了音频 */ let constraints = &#123; video: &#123;&#125;, audio : false &#125;; let promise; if(navigator.mediaDevices.getUserMedia)&#123; //最新标准API promise = navigator.mediaDevices.getUserMedia(constraints); &#125; else if (navigator.webkitGetUserMedia)&#123; //webkit内核浏览器 promise = navigator.webkitGetUserMedia(constraints); &#125; else if (navigator.mozGetUserMedia)&#123; //Firefox浏览器 promise = navagator.mozGetUserMedia(constraints); &#125; else if (navigator.getUserMedia)&#123; //旧版API promise = navigator.getUserMedia(constraints); &#125; promise.then(function (MediaStream) &#123; video.srcObject = MediaStream; video.play(); &#125;); &#125; function getBase64() &#123; //获得Canvas对象 var cas = document.getElementById("myCanvas"); var ctx = cas.getContext("2d"); let video = document.getElementById("video"); ctx.drawImage(video, 0, 0, 500, 400); var data = cas.toDataURL('image/png', 0.1); //1表示质量(无损压缩) return data; &#125; //'file' 等价于 浏览本地文件上传时本地文件的名字 function dataURLtoFile(dataurl, filename = 'file')&#123; dataurl = dataurl + ""; var arr = dataurl.split(','), mime = arr[0].match(/:(.*?);/)[1], bstr = atob(arr[1]), n = bstr.length, u8arr = new Uint8Array(n); while(n--)&#123; u8arr[n] = bstr.charCodeAt(n); &#125; return new File([u8arr], filename, &#123;type:mime&#125;); &#125; &lt;/script&gt; &lt;body&gt; &lt;video id="video" autoplay="autoplay" &gt;&lt;/video&gt; &lt;button id="b"&gt;画图&lt;/button&gt; &lt;canvas id="myCanvas" width="500px" height="500px"&gt;&lt;/canvas&gt; &lt;/body&gt; &lt;script type="text/javascript"&gt; var btn = document.getElementById("b"); btn.onclick =function()&#123; console.log(dataURLtoFile(getBase64())); &#125; &lt;/script&gt;&lt;/html&gt;源码https://github.com/isjinhao/html5-handle-img]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[html5启用摄像头]]></title>
    <url>%2F2019%2Fhtml5%E5%90%AF%E7%94%A8%E6%91%84%E5%83%8F%E5%A4%B4%2F</url>
    <content type="text"><![CDATA[h5启用默认摄像头123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="bootstrap/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" href="bootstrap/css/bootstrap.min.css"&gt;&lt;/script&gt; &lt;script src="bootstrap/holder.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type="application/javascript"&gt; window.onload=function() &#123; let video = document.getElementById("video"); /** * constraints：打开摄像头时约束，下面的约束对video没有约束，它选择设备的默认摄像头，但是禁止了音频 */ let constraints = &#123; video: &#123;&#125;, audio : false &#125;; let promise; if(navigator.mediaDevices.getUserMedia)&#123; //最新标准API promise = navigator.mediaDevices.getUserMedia(constraints); &#125; else if (navigator.webkitGetUserMedia)&#123; //webkit内核浏览器 promise = navigator.webkitGetUserMedia(constraints); &#125; else if (navigator.mozGetUserMedia)&#123; //Firefox浏览器 promise = navagator.mozGetUserMedia(constraints); &#125; else if (navigator.getUserMedia)&#123; //旧版API promise = navigator.getUserMedia(constraints); &#125; promise.then(function (MediaStream) &#123; video.srcObject = MediaStream; video.play(); &#125;); &#125; &lt;/script&gt; &lt;body&gt; &lt;video class="myvideo" style="border-radius: 10%;" id="video" autoplay="autoplay" &gt;&lt;/video&gt; &lt;/body&gt;&lt;/html&gt;分析上面的代码只能打开设备默认摄像头，在手机上会是前置摄像头。此博文代码测试时间为2019.4.7。在开启摄像头这一块，不同的浏览器兼容性很差，而且标准今年来改动过大，很多的API都被弃用，所以不能使用时请勿喷。h5启用手机后置摄像头12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="bootstrap/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" href="bootstrap/css/bootstrap.min.css"&gt;&lt;/script&gt; &lt;script src="bootstrap/holder.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type="application/javascript"&gt; window.onload=function() &#123; let video = document.getElementById("video"); // 此API请求可用媒体输入和输出设备的列表，例如麦克风，摄像头，耳机等。 let promoseDevs = navigator.mediaDevices.enumerateDevices(); var exArray = []; promoseDevs.then(function(devices) &#123; devices.forEach(function (dv) &#123; var kind = dv.kind; //我们需要的是摄像头，所以匹配video if (kind.match(/^video.*/)) &#123; exArray.push(dv.deviceId); console.log(dv); &#125; &#125;); &#125;).then(function()&#123; alert("摄像头个数：" + exArray.length); //设置启用摄像头时的约束，在手机端约束摄像头为后置 let constraints = &#123; video: &#123; deviceId: exArray[exArray.length - 1] &#125;, audio : false &#125;; let promise; if (navigator.mediaDevices.getUserMedia) &#123; //最新的标准API promise = navigator.mediaDevices.getUserMedia(constraints); &#125; else if (navigator.webkitGetUserMedia) &#123; //webkit核心浏览器 promise = navigator.webkitGetUserMedia(constraints, success, error) &#125; else if (navigator.mozGetUserMedia) &#123; //firfox浏览器 promise = navigator.mozGetUserMedia(constraints, success, error); &#125; else if (navigator.getUserMedia) &#123; //旧版API promise = navigator.getUserMedia(constraints, success, error); &#125; promise.then(function (MediaStream) &#123; video.srcObject = MediaStream; video.play(); &#125;) &#125;) &#125; &lt;/script&gt; &lt;body&gt; &lt;video class="myvideo" style="border-radius: 10%;" id="video" autoplay="autoplay" &gt;&lt;/video&gt; &lt;/body&gt;&lt;/html&gt;参考源码：https://github.com/isjinhao/html5-handle-imghttps://www.jianshu.com/p/e03bd23b6b5c]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[html5实现图片预览]]></title>
    <url>%2F2019%2Fhtml5%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E9%A2%84%E8%A7%88%2F</url>
    <content type="text"><![CDATA[实例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;&lt;/title&gt; &lt;script src="bootstrap/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" href="bootstrap/css/bootstrap.min.css"&gt;&lt;/script&gt; &lt;script src="bootstrap/holder.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;script type="application/javascript"&gt; function select_file(fileid)&#123; document.getElementById(fileid).click(); &#125; //预览图片并获得图片的base64编码 function imgPreview(fileDom)&#123; //判断是否支持FileReader /** * FileReader 对象允许Web应用程序异步读取存储在用户计算机上的文件 */ if (window.FileReader) &#123; var reader = new FileReader(); &#125; else &#123; alert("请更新您的浏览器！"); return; &#125; //获取文件 var file = fileDom.files[0]; var imageType = /^image\//; //是否是图片 if (!imageType.test(file.type)) &#123; alert("请选择图片文件！"); return; &#125; /* * readAsDataURL 方法会读取指定的 Blob 或 File 对象。返回文件的base64编码 */ reader.readAsDataURL(file); /** * 当文件读取完成的时候会回调此函数，e就是获取的文件 */ reader.onload = function(e) &#123; //获取图片dom var img = document.getElementById("img"); //e是获取的文件，reader.readAsDataURL(file);读取的Base64编码存放在target.result中 img.src = e.target.result; &#125;; &#125; &lt;/script&gt; &lt;body&gt; &lt;div class="row"&gt; &lt;div class="panel-title" style="text-align: center;"&gt; &lt;input type="file" class="hidden" id="image" onchange="imgPreview(this)"&gt; &lt;img style="height: 200px; border-radius: 50%;" src="holder.js/300x300" onclick="select_file('image');" id="img" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt;参考https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader源码：https://github.com/isjinhao/html5-handle-img]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dbutils]]></title>
    <url>%2F2019%2FDbutils%2F</url>
    <content type="text"><![CDATA[介绍Commons DbUtils是Apache组织提供的一个对JDBC进行简单封装的开源工具类库，使用它能够简化JDBC应用程序的开发，同时也不会影响程序的性能。最大的好处是它能帮我们自动封装结果集。下面使用C3P0作为数据库连接池。增删改1234567891011121314151617181920212223import org.apache.commons.dbutils.QueryRunner;import com.mchange.v2.c3p0.ComboPooledDataSource;public class Test &#123; public static void main(String[] args) throws Exception &#123; //1、指定数据库连接池 ComboPooledDataSource dataSource = new ComboPooledDataSource(); //2、增删改都使用update方法 QueryRunner qr = new QueryRunner(dataSource); String insert = &quot;insert into students(id, name, clazz) values(?, ?, ?)&quot;; qr.update(insert, &quot;123&quot;, &quot;123&quot;, &quot;123&quot;); String update = &quot;update students set name = ? where id = ?&quot;; qr.update(update, &quot;789&quot;, &quot;123&quot;); String delete = &quot;delete from students where id = ?&quot;; qr.update(delete, &quot;123&quot;); &#125;&#125;查询自定义封装-返回值类型是单个对象123456789101112131415161718String query = "select * from students where id = ?";Student student = qr.query(query, new ResultSetHandler&lt;Student&gt;() &#123; public Student handle(ResultSet rs) throws SQLException &#123; Student s = new Student(); while(rs.next()) &#123; String id = rs.getString("id"); String name = rs.getString("name"); String clazz = rs.getString("clazz"); s.setId(id); s.setName(name); s.setClazz(clazz); &#125; return s; &#125;&#125;, "helloworld");System.out.println(student);自定义封装-返回值类型是集合123456789101112131415String query = "select * from students";List&lt;Student&gt; list = qr.query(query, new ResultSetHandler&lt;List&lt;Student&gt;&gt;() &#123; public List&lt;Student&gt; handle(ResultSet rs) throws SQLException &#123; List&lt;Student&gt; l = new ArrayList&lt;&gt;(); Student s = new Student(); while(rs.next()) &#123; s.setId(rs.getString("id")); s.setName(rs.getString("name")); s.setClazz(rs.getString("clazz")); l.add(s); &#125; return l; &#125;&#125;);System.out.println(list);快速封装-返回值类型是单个对象123456String query = "select * from students where id = ?";Student q = qr.query(query, new BeanHandler&lt;&gt;(Student.class), "helloworld");System.out.println(q);/**Console:* Student [id=helloworld, name=qwe, clazz=160341B]*/快速封装-返回值类型是多个对象123456789String query = "select * from students";List&lt;Student&gt; l = qr.query(query, new BeanListHandler&lt;&gt;(Student.class));System.out.println(l);/** * [Student [id=160341240, name=qwe, clazz=160341B], * Student [id=160341244, name=qwe, clazz=160341B], * Student [id=aaa, name=詹金浩, clazz=160341B], * Student [id=helloworld, name=qwe, clazz=160341B]] */]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Java</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库连接池]]></title>
    <url>%2F2019%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[楔子之前的不足程序和数据库之间建立连接的过程是比较耗时的，而且每次建立连接之后还需要释放资源，频繁的建立和释放是会造成很大的时间消耗。解决方法在程序中始终维护多个和数据库的的连接，这些连接在程序启动的时候就建立，直到程序结束才释放。每次需要和数据库建立连接时，之际从连接池中获取连接即可。如图：自定义数据库连接池入门数据库连接池的概念本来就是sun公司提出来的额，所以sun公司针对数据库连接池也提供了一套规范，一个简单的数据库连接池如下，只有获取连接和归还连接的方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class MyDataSource implements DataSource &#123; List &lt;Connection&gt; list = new ArrayList&lt;Connection&gt;(); public MyDataSource() &#123; for (int i = 0; i &lt; 10; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125;// 该连接池对外公布的获取连接的方法 @Override public Connection getConnection() throws SQLException &#123; //来拿连接的时候，先看看，池子里面还有没有。 if(list.size() == 0 )&#123; for (int i = 0; i &lt; 5; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; //remove(0) ---&gt; 移除第一个。 移除的是集合中的第一个。 移除的是开始的那个元素 Connection conn = list.remove(0); return conn; &#125; /** * 用完之后，记得归还。 * @param conn */ public void addBack(Connection conn)&#123; list.add(conn); &#125; //---------------------------- @Override public PrintWriter getLogWriter() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setLogWriter(PrintWriter out) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void setLoginTimeout(int seconds) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public int getLoginTimeout() throws SQLException &#123; // TODO Auto-generated method stub return 0; &#125; @Override public Logger getParentLogger() throws SQLFeatureNotSupportedException &#123; // TODO Auto-generated method stub return null; &#125; @Override public &lt;T&gt; T unwrap(Class&lt;T&gt; iface) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public boolean isWrapperFor(Class&lt;?&gt; iface) throws SQLException &#123; // TODO Auto-generated method stub return false; &#125; @Override public Connection getConnection(String username, String password) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125;&#125;问题 &amp; 解决问题AddBack()：这个方法不是接口中的方法，不能使用面向接口的编程。连接池不是单例：在一个程序中，连接池应该只存在一个，每new一个都会产生一个连接池和n个连接。扩容：当连接数大于我们设置的数量时需要对连接池中的连接扩容，否则就会产生问题。解决使用装饰者模式；把连接池设为单例；连接池空时自动增加机制。改进的数据库连接池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class MyDataSource implements DataSource &#123; private MyDataSource() &#123;&#125; private static MyDataSource mds = new MyDataSource(); static List &lt;Connection&gt; list = new ArrayList&lt;Connection&gt;(); static&#123; for (int i = 0; i &lt; 10; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; public static MyDataSource getMyDataSource() &#123; return mds; &#125;// 该连接池对外公布的获取连接的方法，扩容 @Override public Connection getConnection() throws SQLException &#123; //来拿连接的时候，先看看，池子里面还有没有。 if(list.size() == 0 )&#123; for (int i = 0; i &lt; 5; i++) &#123; Connection conn = JDBCUtil.getConn(); list.add(conn); &#125; &#125; Connection conn = list.remove(0); Connection connection = new ConnectionWrap(conn, list); return connection; &#125; /** * 用完之后，记得归还。 * @param conn */ public void addBack(Connection conn)&#123; list.add(conn); &#125; //---------------------------- @Override public PrintWriter getLogWriter() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setLogWriter(PrintWriter out) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void setLoginTimeout(int seconds) throws SQLException &#123; &#125; @Override public int getLoginTimeout() throws SQLException &#123; return 0; &#125; @Override public Logger getParentLogger() throws SQLFeatureNotSupportedException &#123; return null; &#125; @Override public &lt;T&gt; T unwrap(Class&lt;T&gt; iface) throws SQLException &#123; return null; &#125; @Override public boolean isWrapperFor(Class&lt;?&gt; iface) throws SQLException &#123; return false; &#125; @Override public Connection getConnection(String username, String password) throws SQLException &#123; return null; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324public class ConnectionWrap implements Connection&#123; private Connection connection = null; private List &lt;Connection&gt; list ; public ConnectionWrap(Connection connection , List &lt;Connection&gt; list) &#123; super(); this.connection = connection; this.list = list; &#125; @Override public void close() throws SQLException &#123; list.add(connection); &#125; @Override public PreparedStatement prepareStatement(String sql) throws SQLException &#123; return connection.prepareStatement(sql); &#125; //==================================================================== //之后的方法没有被装饰，需要使用时再装饰 @Override public &lt;T&gt; T unwrap(Class&lt;T&gt; iface) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public boolean isWrapperFor(Class&lt;?&gt; iface) throws SQLException &#123; return false; &#125; @Override public Statement createStatement() throws SQLException &#123; return null; &#125; @Override public CallableStatement prepareCall(String sql) throws SQLException &#123; return null; &#125; @Override public String nativeSQL(String sql) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setAutoCommit(boolean autoCommit) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public boolean getAutoCommit() throws SQLException &#123; // TODO Auto-generated method stub return false; &#125; @Override public void commit() throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void rollback() throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public boolean isClosed() throws SQLException &#123; // TODO Auto-generated method stub return false; &#125; @Override public DatabaseMetaData getMetaData() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setReadOnly(boolean readOnly) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public boolean isReadOnly() throws SQLException &#123; // TODO Auto-generated method stub return false; &#125; @Override public void setCatalog(String catalog) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public String getCatalog() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setTransactionIsolation(int level) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public int getTransactionIsolation() throws SQLException &#123; // TODO Auto-generated method stub return 0; &#125; @Override public SQLWarning getWarnings() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void clearWarnings() throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public Statement createStatement(int resultSetType, int resultSetConcurrency) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Map&lt;String, Class&lt;?&gt;&gt; getTypeMap() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setTypeMap(Map&lt;String, Class&lt;?&gt;&gt; map) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void setHoldability(int holdability) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public int getHoldability() throws SQLException &#123; // TODO Auto-generated method stub return 0; &#125; @Override public Savepoint setSavepoint() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Savepoint setSavepoint(String name) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void rollback(Savepoint savepoint) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void releaseSavepoint(Savepoint savepoint) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public Statement createStatement(int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public PreparedStatement prepareStatement(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public CallableStatement prepareCall(String sql, int resultSetType, int resultSetConcurrency, int resultSetHoldability) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public PreparedStatement prepareStatement(String sql, int autoGeneratedKeys) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public PreparedStatement prepareStatement(String sql, int[] columnIndexes) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public PreparedStatement prepareStatement(String sql, String[] columnNames) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Clob createClob() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Blob createBlob() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public NClob createNClob() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public SQLXML createSQLXML() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public boolean isValid(int timeout) throws SQLException &#123; // TODO Auto-generated method stub return false; &#125; @Override public void setClientInfo(String name, String value) throws SQLClientInfoException &#123; // TODO Auto-generated method stub &#125; @Override public void setClientInfo(Properties properties) throws SQLClientInfoException &#123; // TODO Auto-generated method stub &#125; @Override public String getClientInfo(String name) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Properties getClientInfo() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Array createArrayOf(String typeName, Object[] elements) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public Struct createStruct(String typeName, Object[] attributes) throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void setSchema(String schema) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public String getSchema() throws SQLException &#123; // TODO Auto-generated method stub return null; &#125; @Override public void abort(Executor executor) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public void setNetworkTimeout(Executor executor, int milliseconds) throws SQLException &#123; // TODO Auto-generated method stub &#125; @Override public int getNetworkTimeout() throws SQLException &#123; // TODO Auto-generated method stub return 0; &#125;&#125;开源数据库连接池DBCP12345678910111213141516171819202122232425262728293031#连接设置driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/jdbc-studyusername=rootpassword=root#&lt;!-- 初始化连接 --&gt;initialSize=10#最大连接数量maxActive=50#&lt;!-- 最大空闲连接 --&gt;maxIdle=20#&lt;!-- 最小空闲连接 --&gt;minIdle=5#&lt;!-- 超时等待时间以毫秒为单位 6000毫秒/1000等于60秒 --&gt;maxWait=60000#JDBC驱动建立连接时附带的连接属性属性的格式必须为这样：[属性名=property;] #注意：&quot;user&quot; 与 &quot;password&quot; 两个属性会被明确地传递，因此这里不需要包含他们。connectionProperties=useUnicode=true;characterEncoding=gbk#指定由连接池所创建的连接的自动提交（auto-commit）状态。defaultAutoCommit=true#driver default 指定由连接池所创建的连接的事务级别（TransactionIsolation）。#可用值为下列之一：（详情可见javadoc。）NONE,READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ, SERIALIZABLEdefaultTransactionIsolation=READ_UNCOMMITTED123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.io.FileInputStream;import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.util.Properties;import javax.sql.DataSource;import org.apache.commons.dbcp.BasicDataSourceFactory;public class Test &#123; public static void main(String[] args) throws Exception &#123; Connection connection = null; PreparedStatement ps = null; try &#123; //1、构建数据源 BasicDataSourceFactory bdsf = new BasicDataSourceFactory(); Properties pro = new Properties(); pro.load(new FileInputStream("src/dbcpconfig.properties")); DataSource ds = bdsf.createDataSource(pro); //2、得到连接对象 connection = ds.getConnection(); //3、执行sql语句 String sql = "select * from students"; ps = connection.prepareStatement(sql); //4、获得结果、处理结果 ResultSet query = ps.executeQuery(); while(query.next()) &#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; //直接关闭就行，dbcp帮我们包装好了 ps.close(); connection.close(); &#125; &#125;&#125;C3P0123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;c3p0-config&gt; &lt;!-- default-config 默认的配置， --&gt; &lt;default-config&gt; &lt;property name="driverClass"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="jdbcUrl"&gt;jdbc:mysql://localhost/jdbc-study&lt;/property&gt; &lt;property name="user"&gt;root&lt;/property&gt; &lt;property name="password"&gt;root&lt;/property&gt; &lt;property name="initialPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxIdleTime"&gt;30&lt;/property&gt; &lt;property name="maxPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;10&lt;/property&gt; &lt;property name="maxStatements"&gt;200&lt;/property&gt; &lt;/default-config&gt; &lt;!-- This app is massive! --&gt; &lt;named-config name="oracle"&gt; &lt;property name="acquireIncrement"&gt;50&lt;/property&gt; &lt;property name="initialPoolSize"&gt;100&lt;/property&gt; &lt;property name="minPoolSize"&gt;50&lt;/property&gt; &lt;property name="maxPoolSize"&gt;1000&lt;/property&gt; &lt;!-- intergalactoApp adopts a different approach to configuring statement caching --&gt; &lt;property name="maxStatements"&gt;0&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;5&lt;/property&gt; &lt;!-- he's important, but there's only one of him --&gt; &lt;user-overrides user="master-of-the-universe"&gt; &lt;property name="acquireIncrement"&gt;1&lt;/property&gt; &lt;property name="initialPoolSize"&gt;1&lt;/property&gt; &lt;property name="minPoolSize"&gt;1&lt;/property&gt; &lt;property name="maxPoolSize"&gt;5&lt;/property&gt; &lt;property name="maxStatementsPerConnection"&gt;50&lt;/property&gt; &lt;/user-overrides&gt; &lt;/named-config&gt;&lt;/c3p0-config&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import com.mchange.v2.c3p0.ComboPooledDataSource;public class Test &#123; public static void main(String[] args) &#123; Connection connection = null; PreparedStatement ps = null; try &#123; //1、构建数据源 ComboPooledDataSource cpds = new ComboPooledDataSource(); //2、得到连接对象 connection = cpds.getConnection(); //3、执行sql语句 String sql = "select * from students"; ps = connection.prepareStatement(sql); //4、获得结果、处理结果 ResultSet query = ps.executeQuery(); while(query.next()) &#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; ps.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;DBCP和C3P0的区别http://www.cnblogs.com/JavaSubin/p/5294721.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Java</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC入门]]></title>
    <url>%2F2019%2FJDBC%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[JDBC - 入门概述Java Database Connectivity，Java数据库连接。是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。JDBC提供了一种基准，据此可以构建更高级的工具和接口，使数据库开发人员能够编写数据库应用程序，所以说，JDBC对Java程序员而言是API，对实现与数据库连接的服务提供商而言是接口模型。作为API，JDBC为程序开发提供标准的接口，并为数据库厂商及第三方中间件厂商实现与数据库的连接提供了标准方法。配置环境数据库并不是Java提供的，所以在Java中如果想连接数据库，肯定需要使用第三方jar包，这些jar包是数据库厂商根据JDBC接口模型开发的自己数据库的连接包。文章里使用的数据库是mysql，所以使用mysql-connector。基础操作使用JDBC需要六步：注册驱动、建立连接、创建Statement、执行查询、获得结果集、处理结果集、释放资源。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.Statement;public class Test &#123; public static void main(String[] args) throws Exception &#123; Connection con = null; Statement statement = null; ResultSet query = null; try &#123; /** * 1、注册驱动：在使用JDBC连接连接数据库的时候，Java程序并不知道自己是否连接上了相应的 * 数据库，所以在第一步需要注册驱动，如果连接正常则可以进行接下来的操作。也 * 就是说注册驱动这一步是通过我们导入的jar包测试能否正常连接数据库。 */ DriverManager.registerDriver(new com.mysql.jdbc.Driver()); /** * 2、获得连接：数据库服务器中可能存在多个数据库，我们需要连接上我们即将使用的数据库。 */ con = DriverManager.getConnection("jdbc:mysql://localhost/jdbc-study", "root", "root"); /** * 3、创建Statement：如果想和数据库进行交互，一定需要使用这个类。JDK对他的解释是： * The object used for executing a static SQL statementand returning the results it produces. */ statement = con.createStatement(); /** * 4、执行查询，获得结果集：想数据库中注入SQL语句，是我们能够进行操作 */ String sql = "select * from students"; /** * 5、处理结果集：query是数据库中的元组集合，可以通过循环获得每个元组 */ query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; /** * 6、释放资源：操作结束后进行操作 */ if(query != null) query.close(); if(statement != null) statement.close(); if(con != null) con.close(); &#125; &#125;&#125;封装工具类JDBCUtils.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152import java.io.FileInputStream;import java.io.InputStream;import java.sql.Connection;import java.sql.DriverManager;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.Properties;public class JDBCUtil &#123; static String driverClass = null; static String url = null; static String name = null; static String password= null; static&#123; try &#123; //1. 创建一个属性配置对象 Properties properties = new Properties(); InputStream is = new FileInputStream("jdbc.properties"); //使用类加载器，去读取src底下的资源文件。 后面在servlet// InputStream is = JDBCUtil.class.getClassLoader().getResourceAsStream("jdbc.properties"); //导入输入流。 properties.load(is); //读取属性 driverClass = properties.getProperty("driverClass"); url = properties.getProperty("url"); name = properties.getProperty("name"); password = properties.getProperty("password"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; Connection conn = null; public Connection initialValue() &#123; try &#123; conn = DriverManager.getConnection(url, name, password); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125; &#125;; /** * 获取连接对象 * @return */ public static Connection getConn()&#123; Connection conn = null; try &#123; Class.forName(driverClass); //静态代码块 ---&gt; 类加载了，就执行。 java.sql.DriverManager.registerDriver(new Driver()); //DriverManager.registerDriver(new com.mysql.jdbc.Driver()); //DriverManager.getConnection("jdbc:mysql://localhost/test?user=monty&amp;password=greatsqldb"); //2. 建立连接 参数一： 协议 + 访问的数据库 ， 参数二： 用户名 ， 参数三： 密码。 conn = connectionHolder.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return conn; &#125; /** * 释放资源 * @param conn * @param st * @param rs */ public static void release(Connection conn , Statement st , ResultSet rs)&#123; closeRs(rs); closeSt(st); closeConn(conn); &#125; //开启事务 public static void startTransaction()&#123; try&#123; Connection conn = connectionHolder.get(); conn.setAutoCommit(false); &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //回滚事务 public static void rollback()&#123; try&#123; Connection conn = connectionHolder.get(); if(conn != null)&#123; conn.rollback(); &#125; &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; //提交事务 public static void commit()&#123; try&#123; Connection conn = connectionHolder.get(); if(conn!=null)&#123; conn.commit(); &#125; &#125;catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; private static void closeRs(ResultSet rs)&#123; try &#123; if(rs != null)&#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; rs = null; &#125; &#125; private static void closeSt(Statement st)&#123; try &#123; if(st != null)&#123; st.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; st = null; &#125; &#125; private static void closeConn(Connection conn)&#123; try &#123; if(conn != null)&#123; conn.close(); &#125; &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125;finally&#123; conn = null; &#125; &#125;&#125;jdbc.properties1234driverClass=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost/jdbc-studyname=rootpassword=rootTest123456789101112131415161718192021import java.sql.Connection;import java.sql.ResultSet;import java.sql.Statement;import com.utils.JDBCUtil;public class TestUtils &#123; public static void main(String[] args) throws Exception &#123; Connection conn = JDBCUtil.getConn(); Statement sta = conn.createStatement(); String sql = "select * from students"; ResultSet query = sta.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; JDBCUtil.release(null, sta, query); &#125;&#125;注册驱动的细节其实在JDBC4.0之后不再需要写Class.forName(...);因为JDBC4.0之后，驱动包必须在指定位置包含java.sql.Driver文件，这样就可以自动加载驱动。原话如下：123JDBC 4.0 Drivers mustinclude the file META-INF/services/java.sql.Driver. This file contains the name of the JDBC driversimplementation of java.sql.Driver. For example, to load the my.sql.Driver class,the META-INF/services/java.sql.Driver file would contain the entry: my.sql.DriverApplications no longer need to explicitly load JDBC drivers using Class.forName(). Existing programswhich currently load JDBC drivers using Class.forName() will continue to work withoutmodification.CURD1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.sql.Connection;import java.sql.ResultSet;import java.sql.Statement;import org.junit.Test;import com.utils.JDBCUtil;public class CRUD &#123; static Connection con; static &#123; con = JDBCUtil.getConn(); &#125; @Test public void query() throws Exception &#123; Statement statement = con.createStatement(); String sql = "select * from students"; ResultSet query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125; @Test public void insert() throws Exception &#123; Statement statement = con.createStatement(); String sql = "insert into students(id, name, clazz) values ('160341238', '赵承阳', '160341B')"; int row = statement.executeUpdate(sql); &#125; @Test public void update() throws Exception &#123; Statement statement = con.createStatement(); String sql = "update students set id = 'helloworld' where id = '160341237'"; int row = statement.executeUpdate(sql); &#125; @Test public void delete() throws Exception &#123; Statement statement = con.createStatement(); String sql = "delete from students where id = '160341238'"; //返回处理的行数 int row = statement.executeUpdate(sql); &#125;&#125;PrepareStatementStatement的问题123456789101112131415public static void main(String[] args) throws Exception &#123; Statement statement = con.createStatement(); String qid = "160341238 or 1 = 1"; String sql = "select * from students where id = " + qid; ResultSet query = statement.executeQuery(sql); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz);&#125; /**Console: * 160341238 赵承阳 160341B aaa 詹金浩 160341B */&#125;在上面这段代码中，查询的qid后面添加上了or 1 = 1就可以把表中所有信息都查询出来，因为or 1 = 1这句话是一定为真，而我们刚才使用的Statement又使用的是拼接字符串的方式，在字符串中or会被认为是关键字，所以sql语句的条件永远为真。可以采用PrepareStatement类来解决这个问题。PrepareStatement12345678910111213141516public static void main(String[] args) throws Exception &#123; String sql = "select * from students where id=?"; PreparedStatement ps = con.prepareStatement(sql); /** * 从1开始，把字符串填到匹配的?里。关键字也被认为是是字符串 */ ps.setString(1, "160341238 or 1 = 1"); ResultSet query = ps.executeQuery(); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz);&#125; //无结果&#125;改进的CURD123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class AdvancedCURD &#123; static Connection con; static &#123; con = JDBCUtil.getConn(); &#125; @Test public void query() throws Exception &#123; String sql = "select * from students where id=?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341238"); ResultSet query = ps.executeQuery(); while(query.next())&#123; String id = query.getString("id"); String name = query.getString("name"); String clazz = query.getString("clazz"); System.out.println(id + " " + name + " " + clazz); &#125; &#125; @Test public void insert() throws Exception &#123; String sql = "insert into students(id, name, clazz) values (?, ?, ?)"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341244"); ps.setString(2, "qwe"); ps.setString(3, "160341B"); int row = ps.executeUpdate(); System.out.println(row); &#125; @Test public void update() throws Exception &#123; String sql = "update students set id = ? where id = ?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "helloworld"); ps.setString(2, "160341243"); int row = ps.executeUpdate(); &#125; @Test public void delete() throws Exception &#123; String sql = "delete from students where id = ?"; PreparedStatement ps = con.prepareStatement(sql); ps.setString(1, "160341238"); int row = ps.executeUpdate(); //返回处理的行数 System.out.println(row); &#125;&#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Java</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal分析]]></title>
    <url>%2F2019%2FThreadLocal%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ThreadLocal使用ThreadLocal是一个线程局部变量，我们都知道全局变量和局部变量的区别，拿Java举例就是定义在类中的是全局的变量，各个方法中都能访问得到，而局部变量定义在方法中，只能在方法内访问。那线程局部变量（ThreadLocal）就是每个线程都会有一个局部变量，独立于变量的初始化副本，而各个副本是通过线程唯一标识相关联的。方法摘要作用域类型方法描述publicTget()返回此线程局部变量的当前线程副本中的值protectedTinitialValue()返回此线程局部变量的当前线程的“初始值”publicvoidremove()移除此线程局部变量当前线程的值publicvoidset(T value)将此线程局部变量的当前线程副本中的值设置为指定值案例线程1234567891011121314151617181920212223242526package threadlocal;import java.lang.reflect.Method;public class TaskThread&lt;T&gt; extends Thread &#123; private T t; public TaskThread(String threadName, T t) &#123; this.setName(threadName); this.t = t; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 4; i++) &#123; try &#123; Class[] argsClass = new Class[0]; Method method = t.getClass().getMethod("getUniqueId", argsClass); int value = (int) method.invoke(t); System.out.println("thread[" + Thread.currentThread().getName() + "] --&gt; uniqueId[" + value + "]"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;ThreadLocal12345678910111213141516171819package threadlocal;public class UniqueThreadIdGenerator &#123; // 线程局部整型变量 private static final ThreadLocal &lt;Integer&gt; uniqueNum = new ThreadLocal &lt;Integer&gt; () &#123; @Override protected Integer initialValue() &#123; return 0; &#125; &#125;; //变量值 public static int getUniqueId() &#123; uniqueNum.set(uniqueNum.get() + 1); return uniqueNum.get(); &#125;&#125;测试1234567891011121314package threadlocal;public class Test &#123; public static void main(String[] args) &#123; UniqueThreadIdGenerator uniqueThreadId = new UniqueThreadIdGenerator(); // 为每个线程生成一个唯一的局部标识 TaskThread&lt;UniqueThreadIdGenerator&gt; t1 = new TaskThread&lt;&gt;("custom-thread-1", uniqueThreadId); TaskThread&lt;UniqueThreadIdGenerator&gt; t2 = new TaskThread&lt;&gt;("custom-thread-2", uniqueThreadId); TaskThread&lt;UniqueThreadIdGenerator&gt; t3 = new TaskThread&lt;&gt;("custom-thread-3", uniqueThreadId); t1.start(); t2.start(); t3.start(); &#125;&#125;结果1234567891011121314thread[custom-thread-3] --&gt; uniqueId[1]thread[custom-thread-3] --&gt; uniqueId[2]thread[custom-thread-3] --&gt; uniqueId[3]thread[custom-thread-3] --&gt; uniqueId[4]thread[custom-thread-2] --&gt; uniqueId[1]thread[custom-thread-2] --&gt; uniqueId[2]thread[custom-thread-1] --&gt; uniqueId[1]thread[custom-thread-1] --&gt; uniqueId[2]thread[custom-thread-1] --&gt; uniqueId[3]thread[custom-thread-1] --&gt; uniqueId[4]thread[custom-thread-2] --&gt; uniqueId[3]thread[custom-thread-2] --&gt; uniqueId[4]//每个线程之间的uniqueId是互不干扰的ThreadLocal源码分析get()123456789101112131415161718192021//ThreadLocal.javapublic T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;//ThreadThreadLocal.ThreadLocalMap threadLocals = null;每个线程都有一个ThreadLocalMap，get()的时候就是获得当前线程的ThreadLocalMap，并且将当前对象的ThreadLocal对象传入map.getEntry(this);。初始化123456789101112131415161718private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;protected T initialValue() &#123; return null;&#125;如果get()时ThreadLocalMap不存在，则使用initialValue()初始化，如果initialValue()没被覆盖，默认用null初始化。set()12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;remove()12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125;内存泄漏12345678910111213141516171819202122static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;public WeakReference(T referent) &#123; super(referent);&#125; Reference(T referent) &#123; this(referent, null);&#125;Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue;&#125;注：被WeakReference的对象只能存活到下一次垃圾回收。可知k被传递到了WeakReference的构造函数里面，也就是说ThreadLocalMap里面的key为ThreadLocal对象的弱引用，具体是referent变量引用了ThreadLocal对象，value为具体调用ThreadLocal的set方法传递的值。当一个线程调用ThreadLocal的set方法设置变量时候，当前线程的ThreadLocalMap里面就会存放一个记录，这个记录的key为ThreadLocal的引用，value则为设置的值。如果当前线程一直存在而没有调用ThreadLocal的remove方法，并且这时候其它地方还是有对ThreadLocal的引用，则当前线程的ThreadLocalMap变量里面会存在ThreadLocal变量的引用和value对象的引用是不会被释放的，这就会造成内存泄露的。但是考虑如果这个ThreadLocal变量没有了其他强依赖，而当前线程还存在的情况下，由于线程的ThreadLocalMap里面的key是弱依赖，则当前线程的ThreadLocalMap里面的ThreadLocal变量的弱引用会被在gc的时候回收，但是对应value还是会造成内存泄露，这时候ThreadLocalMap里面就会存在key为null但是value不为null的entry项。所以在ThreadLocal使用完毕后即使调用remove方法才是解决内存泄露的王道。ThreadLocalMap其实在ThreadLocalMap的set和getEntry和remove方法里面有一些时机是会对这些key为null的entry进行清理的，但是这些清理不是必须发生的，下面简单分析这三个方法的源码：set()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; //快速定位，index生成规则：threadLocalHashCode &amp; (len-1) int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //如果e和k相等，替换为新的value if (k == key) &#123; e.value = value; return; &#125; //由于e不空，所以如果k为空，则替换这个entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; //原Entry[]中没有找到键为key的entry，且遍历到e为空的值创建一个entry tab[i] = new Entry(key, value); int sz = ++size; //创建新的entry之后，清除一些e不空但key为空的元素 // if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; n = len; removed = true; i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0); return removed;&#125;private void rehash() &#123; expungeStaleEntries(); // 超过阈值的3/4就会扩容，所以Entry[]中一定有为null的元素 if (size &gt;= threshold - threshold / 4) resize();&#125;getEntry()123456789101112131415161718192021222324252627private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; //能快速定位到则直接使用 if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125;private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; //遍历的时候遇到e不空但k为空的时候清除此e if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); e = tab[i]; &#125; return null;&#125;remove()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private void remove(ThreadLocal&lt;?&gt; key) &#123; //(1)计算当前ThreadLocal变量所在table数组位置，尝试使用快速定位方法 Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); //(2)这里使用循环是防止快速定位失效后，变量table数组 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; //(3)找到 if (e.get() == key) &#123; //(4)找到则调用WeakReference的clear方法清除对ThreadLocal的弱引用 e.clear(); //(5)清理key为null的元素 expungeStaleEntry(i); return; &#125; &#125;&#125;private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; //（6）去掉去value的引用 tab[staleSlot].value = null; tab[staleSlot] = null; size--; Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len))&#123; ThreadLocal&lt;?&gt; k = e.get(); //(7)如果key为null,则去掉对value的引用。 if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125;步骤（4）调用了Entry的clear方法，实际调用的是父类WeakReference的clear方法，作用是去掉对ThreadLocal的弱引用。步骤（6）是去掉对value的引用，到这里当前线程里面的当前ThreadLocal对象的信息被清理完毕了。代码（7）从当前元素的下标开始看table数组里面的其他元素是否有key为null的，有则清理。循环退出的条件是遇到table里面有null的元素。所以这里知道null元素后面的Entry里面key为null的元素不会被清理。参考https://segmentfault.com/a/1190000011264294http://www.cnblogs.com/dolphin0520/p/3920407.htmlhttp://ifeve.com/%E4%BD%BF%E7%94%A8threadlocal%E4%B8%8D%E5%BD%93%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非阻塞同步]]></title>
    <url>%2F2019%2F%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[非阻塞同步互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步（Blocking Synchronization）。 从处理问题的方式上说，互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、 用户态核心态转换、 维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。为什么使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为我们需要操作和冲突检测这两个步骤具备原子性，靠什么来保证呢？如果这里再使用互斥同步来保证就失去意义了，所以我们只能靠硬件来完成这件事情，硬件保证一个从语义上看起来需要多次操作的行为只通过一条处理器指令就能完成，这类指令常用的有：测试并设置（Test-and-Set）获取并增加（Fetch-and-Increment）交换（Swap）比较并交换（Compare-and-Swap，下文称CAS）加载链接/条件存储（Load-Linked/Store-Conditional，下文称LL/SC）。其中，前面的3条是20世纪就已经存在于大多数指令集之中的处理器指令，后面的两条是现代处理器新增的，而且这两条指令的目的和功能是类似的。 在IA64、 x86指令集中有cmpxchg指令完成CAS功能，在sparc-TSO也有casa指令实现，而在ARM和PowerPC架构下，则需要使用一对ldrex/strex指令来完成LL/SC的功能。CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地址，用V表示）、 旧的预期值（用A表示）和新值（用B表示）。 CAS指令执行时，当且仅当V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供，虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程。由于Unsafe类不是提供给用户程序调用的类（Unsafe.getUnsafe()的代码中限制了只有启动类加载器（Bootstrap ClassLoader）加载的Class才能访问它），因此，如果不采用反射手段，我们只能通过其他的Java API来间接使用它，如J.U.C包（java.util.concurrent）里面的整数原子类，其中的compareAndSet()和getAndIncrement()等方法都使用了Unsafe类的CAS操作。我们不妨拿一段使用volatile关键字没有解决的问题代码来看看如何使用CAS操作来避免阻塞同步，代码如下面所示。 我们曾经通过这段20个线程自增10000次的代码来证明volatile变量不具备原子性，那么如何才能让它具备原子性呢？把“race++”操作或increase()方法用同步块包裹起来当然是一个办法，但是如果改成如下所示的代码，那效率将会提高许多。12345678910111213141516171819202122232425262728293031import java.util.concurrent.atomic.AtomicInteger;public class AtomicTest &#123; public static AtomicInteger race = new AtomicInteger(0); public static void increase() &#123; race.incrementAndGet(); &#125; private static final int THREADS_COUNT = 20; public static void main(String[] args) throws Exception &#123; Thread[] threads = new Thread[THREADS_COUNT]; for (int i = 0; i &lt; THREADS_COUNT; i++) &#123; threads[i] = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; increase(); &#125; &#125; &#125;); threads[i].start(); &#125; while (Thread.activeCount() &gt; 1) Thread.yield(); System.out.println(race); //200000 &#125;&#125;使用AtomicInteger代替int后，程序输出了正确的结果，一切都要归功于incrementAndGet()方法的原子性。它的实现其实非常简单，如下代码所示：1234567891011/** * Atomically increment by one the current value. */public final int incrementAndGet()&#123; for(;;)&#123; int current=get(); int next=current+1; if(compareAndSet(current,next)) return next; &#125;&#125;incrementAndGet()方法在一个无限循环中，不断尝试将一个比当前值大1的新值赋给自己。 如果失败了，那说明在执行“获取-设置”操作的时候值已经有了修改，于是再次循环进行下一次操作，直到设置成功为止。尽管CAS看起来很美，但显然这种操作无法涵盖互斥同步的所有使用场景，并且CAS从语义上来说并不是完美的，存在这样的一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。 J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。 不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。无同步方案要保证线程安全，并不是一定就要进行同步，两者没有因果关系。 同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的，这里简单地介绍其中的两类：可重入代码和线程本地存储。可重入代码(Reentrant Code)这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。 相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、 用到的状态量都由参数中传入、 不调用非可重入的方法等。 我们可以通过一个简单的原则来判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。线程本地存储(Thread Local Storage)如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”；如果一个变量要被某个线程独享，可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。ThreadLocal用法APIThreadLocal.get: 获取ThreadLocal中当前线程共享变量的值。ThreadLocal.set: 设置ThreadLocal中当前线程共享变量的值。ThreadLocal.remove: 移除ThreadLocal中当前线程共享变量的值。ThreadLocal.initialValue: ThreadLocal没有被当前线程赋值时或当前线程刚调用remove方法后调用get方法，返回此方法值获得ThreadLocal变量123456789ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;();ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;() &#123; @Override protected String initialValue() &#123; System.out.println("调用get方法时，当前线程共享变量没有设置，调用initialValue获取默认值！"); return "initialValue: "; &#125;&#125;;参考深入理解JVM第二版（周志明）https://blog.csdn.net/djokermax/article/details/81296644http://www.cnblogs.com/dolphin0520/p/3920407.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile]]></title>
    <url>%2F2019%2Fvolatile%2F</url>
    <content type="text"><![CDATA[提升计算机工作能力在许多情况下，让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计算机的运算速度与它的存储和通信子系统速度的差距太大， 大量的时间都花费在磁盘I/O、网络通信或者数据库访问上。 如果不希望处理器在大部分时间里都处于等待其他资源的状态，就必须使用一些手段去把处理器的运算能力” 压榨” 出来， 否则就会造成很大的浪费，而计算机同时处理几项任务则是最容易想到、也被证明是非常有效的 “压榨” 手段。除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一个更具体的并发应用场景。衡量一个服务性能的高低好坏，每秒事务处理数（Transactions Per Second，TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序的并发能力。服务端是Java语言最擅长的领域之一，这个领域的应用占了Java应用中最大的一块份额，不过如何写好并发应用程序却又是服务端程序开发的难点之一，处理好并发方面的问题通常需要更多的编码经验来支持。幸好Java语言和虚拟机提供了许多工具，把并发编程的门槛降低了不少。并且各种中间件服务器、各类框架都努力地替程序员处理尽可能多的线程并发细节，使得程序员在编码时能更关注业务逻辑，而不是花费大部分时间去关注此服务会同时被多少人调用、如何协调硬件资源。无论语言、中间件和框架如何先进，开发人员都不能期望它们能独立完成所有并发处理的事情，了解并发的内幕也是成为一个高级程序员不可缺少的课程。真机的内存结构在正式讲解 Java 虚拟机并发相关的知识之前，我们先花费一点时间去了解一下物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。“让计算机并发执行若干个运算任务” 与 “更充分地利用计算机处理器的效能” 之间的因果关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的复杂性来源是绝大多数的运算任务都不可能只靠处理器 “计算” 就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个 I/O 操作是很难消除的（无法仅靠寄存器来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。基于高速缓存的存储交互很好地理解了处理器与内存的速度矛盾，但是也为计算机系统带来了更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），如图所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有 MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly 及 Dragon Protocol 等。其中最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。在本章中将会多次提到的 “内存模型” 一词，可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型，而 Java 虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件的缓存访问操作具有很高的可比性。除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序执行的结果充足，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类型，Java 虚拟机的即时编译器中有有类似的指令重排序（Instruction Reorder）优化。## JVM的内存结构Java 虚拟机规范中试图定义一种 Java 内存模型（Java Memory Model，JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。Java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量（Variables）与 Java 编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。为了获得较好的执行效能，Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。Java 内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。内存间交互操作关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步会主内存之类的实现细节，Java 内存模型中定义了以下 8 种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于 double 和 long 类型的变量来说，load、store、read 和 write 操作在某些平台上允许有例外）。lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。load（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。write（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。如果要把一个变量从主内存复制到工作内存，那就要顺序地执行 read 和 load 操作，如果要把变量从工作内存同步回主内存，就要顺序地执行 store 和 write 操作。注意，Java 内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read 与 load 之间、store 与 write 之间是可插入其他指令的，如对主内存中的变量 a、b 进行访问时，一种可能出现顺序是 read a、read b、load b、load a。除此之外，Java 内存模型还规定了在执行上述 8 种基本操作时必须满足如下规则：不允许 read 和 load、store 和 write 操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。如果一个变量事先没有被 lock 操作锁定，那就不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定住的变量。一个变量在同一个时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中（执行 store、write 操作）。如果对一个变量执行 lock 操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操纵初始化变量的值。不允许一个线程丢弃它的最近的 assign 操作，即变量在工作内存中改变了之后该变化必然会同步至主内存。不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从线程的工作内存同步回主内存中。一个新的变量只能在主内存中 “诞生”，不允许在工作内存中直接使用一个未被初始化（load 或 assign）的变量。换句话说，就是对一个变量实施 use、store 操作之前，必须先执行过了 assign 和 load 操作。对于 long 和 double 型变量的特殊规则Java 内存模型要求 lock、unlock、read、assign、use、store、write 这 8 个操作都具有原子性，但是对于 64 位的数据类型（long 和 double），在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，即允许虚拟机实现选择可以不保证 64 位数据类型的 load、store、read 和 write 这 4 个操作的原子性，这点就是所谓的 long 和 double 的非原子性协定（Nonatomic Treatment of double and long Variables）。如果有多个线程共享一个并未声明为 volatile 的 long 或 double 类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改的值的代表了 “半个变量” 的数值。不过这种读取到 “半个变量” 的情况非常罕见（在目前商用 Java 虚拟机中不会出现），因为 Java 内存模型虽然允许虚拟机不把 long 和 double 变量的读写实现成原子操作，但允许虚拟机选择把这些操作实现为具有原子性的操作，而且还 “强烈建议” 虚拟机这样实现。在实际开发中，目前各种平台下的商用虚拟机几乎都选择把 64 位的数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要把用到的 long 和 double 变量专门声明为 volatile。​volatile关键字 volatile 可以说是 Java 虚拟机提供的最轻量级的同步机制。当一个变量定义为 volatile 之后，它将具备两种特性：保证此变量对所有线程的可见性这里的 “可见性” 是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成，例如，线程 A 修改一个普通变量的值，然后向主内存进行回写，另外一条线程 B 在线程 A 回写完成了之后再从主内存进行读取操作，新变量值才会对线程 B 可见。关于 volatile 变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile 变量对所有线程是立即可见的，对 volatile 变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile 变量在各个线程中是一致的，所以基于 volatile 变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出 “基于 volatile 变量的运算在并发下是安全的” 这个结论。比如以下代码：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125;运行它会发现每次运行结果都不一致，都是一个小于10000的数字。这便是由于volatile 不能保证原子性。同时自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：假如某个时刻变量inc的值为10。线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。那么两个线程分别进行了一次自增操作后，inc只增加了1。禁止指令重排序优化普通的变量仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这也就是 Java 内存模型中描述的所谓的 “线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。volatile关键字禁止指令重排序有两层意思：当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。可能上面说的比较绕，举个简单的例子：1234567//x、y为非volatile变量//flag为volatile变量x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5`由于 flag 变量为 volatile 变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。并且 volatile 关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。那么我们看一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep();&#125;doSomethingwithconfig(context);前在这个例子中，有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。并发编程的三个概念并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。原子性（Atomicity）在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子，请分析以下哪些操作是原子性操作：1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4乍一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。所以上面4个语句只有语句1的操作具备原子性。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。可见性（Visibility）当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。有序性（Ordering）在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 先行发生原则（happens-before原则）。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。先行发生原则程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。下面我们来解释一下前4条规则：对于程序次序规则：一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。锁定规则：也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。volatile变量规则：如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。传递规则：实际上就是体现happens-before原则具备传递性。volatile关键字的场景所以总结来说，volatile 变量在各个线程的工作内存中不存在一致性问题（在各个线程的工作内存中，volatile 变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在不一致性问题），但是 Java 里面的运算并非原子操作，导致 volatile 变量的运算在并发下一样是不安全的。由于 volatile 变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然需要通过加锁（使用 synchronized 或 java.util.concurrent 中的原子类）来保证原子性。通常来说，使用volatile必须具备以下2个条件：对变量的写操作不依赖于当前值该变量没有包含在具有其他变量的不变式中实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。下面列举几个Java中使用volatile的几个场景。状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125;12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context);double check123456789101112131415class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125;参考：https://www.cnblogs.com/NaLanZiYi-LinEr/p/7492571.html参考https://blog.51cto.com/13981400/2320809深入理解JVM第二版https://www.cnblogs.com/dolphin0520/p/3920373.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程安全分类]]></title>
    <url>%2F2019%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[线程安全定义当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那这个对象是线程安全的。这个定义其实很严格，我们通常所说的线程安全都达不到这个要求。Java中各种操作共享的数据分为以下5类：不可变， 绝对线程安全， 相对线程安全，线程兼容，线程对立。不可变可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再采取任何的线程安全保障措施，只要一个不可变的对象被正确地构建出来（没有发生this引用逃逸的情况），那其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。例：被final修饰的变量，java.lang.String类的对象。绝对线程安全绝对线程安全就是满足定义中的线程安全要求。但是实际上Java API中标注自己是线程安全的类大多数都没做到绝对线程安全。比如Vector。12345678910111213141516171819202122232425262728293031// 对线程安全的容器 Vector的测试public class VectorTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while(true) &#123; for (int i = 0; i &lt; 100; i++) &#123; vector.add(i); &#125; Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125;); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致os 假死 while(Thread.activeCount() &gt; 20); &#125; &#125;&#125;因为如果另一个线程恰好在错误的时间里删除了一个元素，导致序号i 已经不再可用的话，再用i访问数组就会抛出一个ArrayIndexOutOfBoundsException。但是并发问题是有偶然性的，所以需要多测几次才能获得结果。如果要保证这段代码能够正确执行下去，修改后的代码为：12345678910111213141516171819202122232425262728293031323334353637383940// 对线程安全的容器 Vector的测试(修改后的代码)public class ModifiedVectorTest &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while(true) &#123; for (int i = 0; i &lt; 100; i++) &#123; vector.add(i); &#125; Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (vector) &#123; // 添加同步块，this line for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (vector) &#123; // 添加同步块，this line for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125; &#125;); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致os 假死 while(Thread.activeCount() &gt; 20); &#125; &#125;&#125;相对线程安全上述 VectorTest.java 和 ModifiedVectorTest.java 就是相对线程安全的案例。实际上Java API标注的线程安全基本都指相对线程安全。线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。线程对立定义指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于Java语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常是有害的，应当尽量避免。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新生代内存为什么使用两个Survivor]]></title>
    <url>%2F2019%2F%E6%96%B0%E7%94%9F%E4%BB%A3%E5%86%85%E5%AD%98%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E4%B8%A4%E4%B8%AASurvivor%2F</url>
    <content type="text"><![CDATA[为什么要有Survivor区先不去想为什么有两个Survivor区，第一个问题是，设置Survivor区的意义在哪里？如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满，触发Major GC（因为Major GC一般伴随着Minor GC，也可以看做触发了Full GC）。老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多。你也许会问，执行时间长有什么坏处？频发的Full GC消耗的时间是非常可观的，这一点会影响大型程序的执行和响应速度，更不要说某些连接会因为超时发生连接错误了。Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。为什么要设置两个Survivor区设置两个Survivor区最大的好处就是解决了碎片化。stackoverflow上有一个个人推荐的回答：The reason for the HotSpot JVM’s two survivor spaces is to reduce the need to deal with fragmentation. New objects are allocated in eden space. All well and good. When that’s full, you need a GC, so kill stale objects and move live ones to a survivor space, where they can mature for a while before being promoted to the old generation. Still good so far. The next time we run out of eden space, though, we have a conundrum. The next GC comes along and clears out some space in both eden and our survivor space, but the spaces aren’t contiguous. So is it better to Try to fit the survivors from eden into the holes in the survivor space that were cleared by the GC?Shift all the objects in the survivor space down to eliminate the fragmentation, and then move the survivors into it?Just say “screw it, we’re moving everything around anyway,” and copy all of the survivors from both spaces into a completely separate space–the second survivor space–thus leaving you with a clean eden and survivor space where you can repeat the sequence on the next GC?参考https://blog.csdn.net/antony9118/article/details/51425581https://stackoverflow.com/questions/10695298/java-gc-why-two-survivor-regions]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM中的锁优化]]></title>
    <url>%2F2019%2FJVM%E4%B8%AD%E7%9A%84%E9%94%81%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Java线程的实现方式OS中线程的实现方式参考：https://isjinhao.github.io/2019/02-%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6/计算机操作系统（汤子瀛）Java线程的实现Java线程的实现机制和操作系统本身有关，限于笔者水平，我们下面介绍的Java线程都是基于Linux平台的实现。在Linux平台上，一条Java线程会映射到一个轻量级进程（LWP）之中，而LWP的本质是供程序使用内核线程的接口，每个LWP都会对应一个内核支持线程（KLT），KLT的调度是内核通过操纵调度器（Thread Scheduler）完成，TS的功能就是将KLT的任务映射到各个处理器上。从这可以看出Java线程的创建、撤销、同步等操作都需要进行用户态和内核态的转换，是一种消耗较大的操作。Java线程的状态自旋锁和自适应自旋最常控制同步的手段是互斥，也即synchronized，但是从上面的分析我们可以知道互斥操作对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态进行。不过虚拟机的开发团队意识到，共享数据的锁定时间在大多数情况下只会持续很短一段时间，所以对于多处理机的机器来说，我们可以让后请求锁的线程执行一个忙循环而不放弃处理器的执行时间。这就是自旋锁。从上面的分析可知，自旋锁在多处理机的机器上可以减少内核态与用户态之间切换的消耗，但自旋本身是要占用处理机时间的，如果自旋等待的时间太多就会白白消耗处理机资源。所以在JDK6中引入了自适应的自旋锁，自旋的时间由上次在同一个锁上的自旋时间以及锁的拥有者决定。。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋有很大几率成功，允许自旋较长的时间。如果对于某个锁很少自旋成功过，则以后可能会省略掉自旋过程。锁消除锁消除指的是虚拟机即时编译器在运行时，检测到对不可能发生共享的数据进行加锁就会进行锁消除。锁消除的判定依赖来源于逃逸分析的数据支持。这里会有一个问题就是：对象会不会发生逃逸其实是程序员可以感知到的，如果对于一段代码不可能存在竞争自然不会加锁。但是实际上Java中很多的同步不是程序员可以控制的。比如：123public String concatString(String s1, String s2, String s3)&#123; return s1 + s2 + s3;&#125;我们都知道String是一个不可变的对象，对于字符串的连接总是通过生成新的String对象来进行的，比如上面代码的实际操作是：1234567public String concatString(String s1, String s2, String s3)&#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125;而StringBuffer.append()方法中有一个同步块，锁的就是sb：123456@Overridepublic synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125;虽然这种锁程序员无法控制，但是JVM可以进行锁消除来优化代码。锁粗化原则上，我们在编写并发代码的时候希望同步快范围越小越好，这样是为了使需要同步的操作数量尽可能变小。这种原则在大多数情况下都是合理的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁和解锁的操作出现在循环体中，会增加很多不必要的消耗，此时虚拟机会把锁的范围扩大来减少加锁解锁的操作。比如上面代码的append()操作就是如此。轻量级锁对象头HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。HotSpot虚拟机的对象头(Object Header)包括两部分信息，第一部分用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等，这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别为32个和64个Bits，官方称它为“Mark Word”。但是对象需要存储的运行时数据很多，其实已经超出了32、64位Bitmap结构所能记录的限度，但是对象头信息是与对象自身定义的数据无关的额 外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码（HashCode），4Bits用于存储对象分代年龄，2Bits用于存储锁标志 位，1Bit固定为0，在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示。epoch：偏向时间戳对象头的另外一部分是类型指针，即是对象指向它的类的元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说查找对象的元数据信息并不一定要经过对象本身（比如通过句柄访问对象时就可以不通过对象本身获得类型）。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中无法确定数组的大小。轻量级锁轻量级锁的本质是减少传统的重量级锁使用操作系统互斥量产生的性能消耗。具体过程如下：在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁标志为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。拷贝对象头中的Mark Word复制到锁记录中。拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态。如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。这里我们需要注意两个问题，第一：CAS是对Mark Word进行的CAS。第二就是要考虑一个问题，为什么更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧？在代码进入同步块的时候，同步对象锁状态为无锁状态，把对象头中的Mark Word复制到锁记录中后如果发生了线程调度，可能再调度回来的时候别的线程CAS成功，所以本线程会CAS失败，此时对象的Mark Word指向别的线程的栈帧。但是在这个过程中怎么既能CAS失败，又指向本线程的栈帧呢？笔者没有弄懂。我们可以看到在有竞争的条件下，轻量级锁会膨胀为重量级锁，此时不仅使用到信号量，还会增加多余的CAS操作，所以在有竞争的条件下，轻量级锁的引入会增加线程同步消耗。不过事实证明：“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是轻量级锁存在的必要。偏向锁轻量级锁的目的是在无竞争的情况下使用CAS操作去除同步使用的互斥量。而偏向锁就是在无竞争的情况下把整个同步都去掉，连CAS都不用做了。具体过程：访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）（在这个时间点上没有字节码正在执行）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）执行同步代码。撤销操作：偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。锁膨胀一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是可偏向的，意味着，它现在认为只可能有一个线程来访问它，当到来第一个线程时，这个线程在修改对象头成为偏向锁的时候使用CAS操作，这时候的CAS是对对象头中的偏向线程ID做，会将偏向线程ID该为本线程的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。一旦有第二个线程访问这个对象（个人理解，即使第一个线程运行结束，它持有的偏向锁不会主动释放，即对象头不会被修改），所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的线程依然存活，则检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（偏向锁就是这个时候升级为轻量级锁的）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。轻量级锁认为竞争存在，但是竞争的程度很轻，一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。 但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。掘金上的巨佬，提出了一些意见：按照图中流程，如果发现锁已经膨胀为重量级锁，就直接使用互斥量mutex阻塞当前线程。然而，自旋锁的一大好处就是减少线程切换的开销。在这里没有必要直接阻塞当前线程，大可以像轻量级锁一样，自旋一会，失败了再阻塞。参考https://blog.csdn.net/choukekai/article/details/63688332https://blog.dreamtobe.cn/2015/11/13/java_synchronized/https://juejin.im/post/5a5c09d051882573282164ae深入理解JVM第二版（周志明）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JIT和逃逸分析]]></title>
    <url>%2F2019%2FJIT%E5%92%8C%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[JIT全称：Just-In-Time Compilation。在部分商用虚拟机中（如HotSpot），Java程序最初是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为“热点代码”。为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（Just In Time Compiler，下文统称JIT编译器）。引入JIT编译器的Java程序运行过程如下图：即时编译器并不是虚拟机必须的部分，Java虚拟机规范并没有规定Java虚拟机内必须要有即时编译器存在，更没有限定或指导即时编译器应该如何去实现。但是，即时编译器编译性能的好坏、代码优化程度的高低却是衡量一款商用虚拟机优秀与否的最关键的指标之一，它也是虚拟机中最核心且最能体现虚拟机技术水平的部分。由于Java虚拟机规范并没有具体的约束规则去限制即使编译器应该如何实现，所以这部分功能完全是与虚拟机具体实现相关的内容，如无特殊说明，我们提到的编译器、即时编译器都是指Hotspot虚拟机内的即时编译器，虚拟机也是特指HotSpot虚拟机。HotSpot虚拟机在JDK8中默认开启了JIT。上图中的mixed mode便是指在硬件上跑程序时，使用解释和JIT编译的混合模式。设定HotSpot工作模式解释模式：-Xint编译模式：-Xcomp混合模式：-Xmixed热点探测如何判断方法或一段代码或是不是热点代码呢？要知道方法或一段代码是不是热点代码，是不是需要触发即时编译，需要进行Hot Spot Detection（热点探测）。目前主要的热点探测方式有以下两种：基于采样的热点探测采用这种方法的虚拟机会周期性地检查各个线程的栈顶，如果发现某些方法经常出现在栈顶，那这个方法就是“热点方法”。这种探测方法的好处是实现简单高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。基于计数器的热点探测采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阀值，就认为它是“热点方法”。这种统计方法实现复杂一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系，但是它的统计结果相对更加精确严谨。HotSpot的热点检测方式？在HotSpot虚拟机中使用的是第二种——基于计数器的热点探测方法，因此它为每个方法准备了两个计数器：方法调用计数器和回边计数器。在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发JIT编译。方法调用计数器顾名思义，这个计数器用于统计方法被调用的次数。当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本，如果存在，则优先使用编译后的本地代码来执行。如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。如果超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。如果不做任何设置，执行引擎并不会同步等待编译请求完成，而是继续进行解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译工作完成之后，这个方法的调用入口地址就会系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。回边计数器它的作用就是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”。逃逸分析在《深入理解Java虚拟机中》关于Java堆内存有这样一段描述：但是，随着JIT编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。这里只是简单提了一句，并没有深入分析，笔者在刚到这里由于对JIT、逃逸分析等技术不了解，无法真正理解上面这段话的含义，但现在略有理解。JIT刚才已经介绍过，逃逸分析这部分摘取周志明老师的深入理解JVM第二版。逃逸逃逸分析的基本行为就是分析对象动态作用域：方法逃逸当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。123456public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;&#125;上诉代码中返回了sb，这样这个StringBuffer有可能被其他方法所改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，称其逃逸到了方法外部。如果想要StringBuffer sb不逃出方法，可以这样写：123456public static String createStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString();&#125;线程逃逸同理，如果一个对象可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，则称为线程逃逸。逃逸分析如果能证明一个对象不会逃逸到方法或线程以外，也就是别的方法或线程无法通过任何途径访问这个对象，则可能为这个变量进行一些高效的优化。如何优化栈上分配Java虚拟机中，在Java堆上分配创建对象的内存空间几乎是Java程序员都清楚的常识了，Java堆中的对象对于各个线程都是共享可见的，只要持有这个对象的引用，就可以访问堆中存储的对象数据。虚拟机的垃圾收集系统可以回收堆中不再使用的对象，但回收动作无论是筛选可回收对象还是回收和整理内存都需要耗费时间。如果确定一个对象不会逃逸出方法之外，那让这个对象在栈上分配内存将会是一个很不错的主意，对象所占用的内存空间就可以随着栈帧的出栈而销毁。在一般应用中，不会逃逸的局部对象所占的比例很大，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，垃圾收集系统的压力会小很多。同步消除线程同步本身是一个很耗时的过程，如果逃逸分析能够确定一个变量不会逃逸出线程，无法被其他线程访问，那这个变量的读写肯定就不会有竞争，对这个变量实施的同步措施也就可以消除掉。标量替换标量是指一个数据已经无法再分解成更小的数据来显示了，Java虚拟机中的原始数据类型（ing、long等数值类型以及引用类型）都不能再进一步分解，他们就可以称为标量。相应的，如果一个数据可以继续分解，那么就把它叫做聚合量。对象就是常见的聚合量。如果把一个Java对象拆散，根据程序访问的情况，将其使用到的成员变量恢复原始类型来访问就叫做标量替换。如果逃逸分析证明一个对象不会被外部访问，并且这个对象可以被拆散的话，程序运行的时候就可以不创建这个对象，而改为直接创建若干个标量来代替。逃逸分析开启JDK8中JIT和逃逸分析都是默认开启的， JVM参数如下：-XX:+DoEscapeAnalysis ： 表示开启逃逸分析-XX:-DoEscapeAnalysis ： 表示关闭逃逸分析逃逸分析测试12345678910111213141516171819202122public class Test &#123; public static void main(String[] args) &#123; long a1 = System.currentTimeMillis(); for (int i = 0; i &lt; 1000000; i++) &#123; alloc(); &#125; long a2 = System.currentTimeMillis(); System.out.println("cost " + (a2 - a1) + " ms"); // 为了方便查看堆内存中对象个数，线程sleep try &#123; Thread.sleep(100000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; &#125; private static void alloc() &#123; User user = new User(); &#125; static class User &#123; &#125;&#125;关闭逃逸分析DOS窗口执行命令1java -Xmx4G -Xms4G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError Test新开一个DOS窗口，输入jps，找到Test进程，使用jmap -histo PID查看。开启逃逸分析DOS窗口执行命令1java -Xmx4G -Xms4G -XX:+DoEscapeAnalysis -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError Test新开一个DOS窗口，输入jps，找到Test进程，使用jmap -histo PID查看。可以发现开启逃逸分析之后，堆中只创建了11万个对象。不开启就会创建100万个对象。逃逸分析并不成熟关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。虽然这项技术并不十分成熟，但是他也是即时编译器优化技术中一个十分重要的手段。JIT和逃逸分析的联系最开始的时候笔者一直以为，逃逸分析是JIT中的优化技术，为什么呢？因为逃逸分析的代价较大，而JIT是对热点代码进行优化，如果对诸如循环等代码进行逃逸分析，只需要分析一次就可以得到循环中的代码是否满足逃逸的条件，可以淡化逃逸分析的代价。但事实上是笔者的一个错误理解。测试中即使关闭JIT也可以开启逃逸分析。如java -Xint -XX:+DoEscapeAnalysis Test。this引用逃逸提到逃逸，必须引出另外一个名字类似，但意义完全不同的概念，this引用逃逸：在构造器构造还未彻底完成前（即实例初始化阶段还未完成），将自身this引用向外抛出并被其他线程复制（访问）了该引用，可能会问到该还未被初始化的变量，甚至可能会造成更大严重的问题。this引用逃逸是一种错误，而逃逸分析是优化策略。详见：https://www.cnblogs.com/straybirds/p/8640748.html参考https://blog.csdn.net/sunxianghuang/article/details/52094859深入理解JVM第二版，周志明http://ju.outofmemory.cn/entry/354837]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于比较的三种简单排序]]></title>
    <url>%2F2019%2F%E5%9F%BA%E4%BA%8E%E6%AF%94%E8%BE%83%E7%9A%84%E4%B8%89%E7%A7%8D%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include&lt;bits/stdc++.h&gt;using namespace std;/* 简单排序： 平均时间复杂度都是O(N方)级别。包括：冒泡排序、插入排序、选择排序 说明： 实现的算法都是升序排序。 */void swap(int &amp;e1, int &amp;e2)&#123; int temp = e1; e1 = e2; e2 = temp;&#125;/* 冒泡排序（稳定）： 重复地走访过要排序的元素列，一次比较两个相邻的元素，如果他们的顺序（如从大到小、首字母从 A到Z）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说 该元素已经排序完成。这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端 （升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。*/ void bubbleSort(int *arr, int len)&#123; for(int i = 0; i &lt; len - 1; i++) //len - 1 趟就行 &#123; int flag = 0; for(int j = 0; j &lt; len - i - 1; j++) &#123; if(arr[j] &gt; arr[j + 1]) &#123; swap(arr[j], arr[j + 1]); flag = 1; &#125; &#125; if(flag == 0) //某趟排序没有进行交换时，排序结束 break; &#125;&#125;/* 插入排序（稳定）： 从索引为1的元素（设为temp）开始开始，每次把之前的元素调整成有序序列。由于之前的元素都是有序序列， 从后向前若temp小于当前遍历到的元素（arr[j]），此元素后移。否则退出此次遍历。退出后把temp插入当前的arr[j]。 */ void insertSort(int *arr, int len)&#123; for(int i = 1; i &lt; len; i++) &#123; int temp = arr[i], j; for(j = i - 1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--) arr[j + 1] = arr[j]; arr[j + 1] = temp; &#125;&#125;/* 选择排序（不稳定）： 每次从待排序的数据元素中选出最小的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。*/void selectSort(int *arr, int len)&#123; for(int i = 0; i &lt; len; i++) &#123; int min = i; for(int j = i; j &lt; len; j++) if(arr[j] &lt; arr[min]) min = j; swap(arr[min], arr[i]); &#125;&#125;int main()&#123; int arr[10]; srand((unsigned)time(NULL)); for(int i = 0; i &lt; 10; i++) arr[i] = rand() % 10; for(int i = 0; i &lt; 10; i++) cout &lt;&lt; arr[i] &lt;&lt; " "; cout &lt;&lt; endl; selectSort(arr, 10); for(int i = 0; i &lt; 10; i++) cout &lt;&lt; arr[i] &lt;&lt; " "; return 0;&#125;]]></content>
      <categories>
        <category>DS</category>
      </categories>
      <tags>
        <tag>DSA</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML基础]]></title>
    <url>%2F2019%2FHTML%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[超链接1&lt;a href="http://www.baidu.com" target="_self"&gt;百度&lt;/a&gt;target的属性值_self：在本窗口中打开目标页面。默认属性值。_blank：在新的浏览器窗口打开目标页面。_parent：这个目标使得文档载入父窗口或者包含来超链接引用的框架的框架集。如果这个引用是在窗口或者在顶级框架中，那么它与目标_self等效，即如果不使用frameset，就和_self等效。_top：这个目标使得文档载入包含这个超链接的窗口，用_top目标将会清除所有被包含的框架并将文档载入整个浏览器窗口。其他值：给一堆超链接以相同的target值，这种方式可以使得一组超链接在同一窗口打开，即通过单击一个窗口中的不同链接控制另一窗口内容变化。首先，浏览器会找与target值相符的框架或者窗口中的文档，有则在其中显示文档。如果不存在，浏览器打开一个新窗口，给其指定一个标识为target值，之后只要该窗口不关闭，其它超链接就可以指向这个新窗口。123456&lt;ul&gt; &lt;li&gt;&lt;a href="http://www.google.com.hk" target="HelloWorld"&gt;google&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://cn.bing.com" target="HelloWorld"&gt;必应&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.baidu.com" target="HelloWorld"&gt;百度&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://www.soso.com" target="HelloWorld"&gt;搜搜&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;锚链接跳转至网页的指定部分。123&lt;a name="tar"&gt;&lt;!-- 1000行 --&gt;&lt;a href="#tar"&gt;锚链接&lt;/a&gt;链接邮件1&lt;a href="mailto:xxx@yyy.zzz"&gt;发送邮件&lt;/a&gt;水平线标签&lt;hr /&gt;图片1&lt;img src="..." border="xxx" alt="yyy" title="zzz" /&gt;图片分类bmp：windows系统下的标准位图（像素点构成的图）格式。文件较大，不建议大量使用。gif：动图。但是只支持256种色彩，不适合保存图片。jpeg：又称jpg，有损压缩的图片。有损压缩：只对图像或声波中的某些频率成分不敏感的特性，允许压缩过程中损失一定的信息；虽然不能完全恢复原始数据，但是所损失的部分对理解原始图像的影响缩小，却换来了大得多的压缩比。png：无损压缩图片。alt图片无法加载时，用于替换图片内容的文字。title鼠标悬停时显示的文字。图片热点1234567&lt;img src ="planets.gif" alt="Planets" usemap ="#planetmap" /&gt;&lt;map name="planetmap"&gt; &lt;area shape="rect" coords="0,0,110,260" href="sun.htm" alt="Sun" /&gt; &lt;area shape="circle" coords="129,161,10" href="mercur.htm" alt="Mercury" /&gt; &lt;area shape="circle" coords="180,139,14" href="venus.htm" alt="Venus" /&gt;&lt;/map&gt;参考：http://www.w3school.com.cn/tags/att_area_coords.asp文本格式化标签滚动字幕12345678910111213141516171819&lt;marquee&gt;默认的滚动字幕（左←右）&lt;/marquee&gt;&lt;marquee direction="right"&gt; &lt;img src="02_11 (1).jpg" width="128" /&gt; &lt;img src="02_11 (2).jpg" width="128" /&gt; &lt;img src="02_11 (3).jpg" width="128" /&gt; &lt;img src="02_11 (4).jpg" width="128" /&gt; &lt;img src="02_11 (5).jpg" width="128" /&gt; &lt;img src="02_11 (6).jpg" width="128" /&gt; &lt;img src="02_11 (7).jpg" width="128" /&gt; &lt;img src="02_11 (8).jpg" width="128" /&gt; &lt;img src="02_11 (9).jpg" width="128" /&gt;&lt;/marquee&gt;&lt;marquee height="150" bgcolor="#eeeeee" direction="up" scrollamount="220"&gt; &lt;p&gt;1111111111111111&lt;/p&gt; &lt;p&gt;2222222222222222&lt;/p&gt; &lt;p&gt;3333333333333333&lt;/p&gt; &lt;p&gt;4444444444444444&lt;/p&gt; &lt;p&gt;5555555555555555&lt;/p&gt;&lt;/marquee&gt;表格cellpadding：规定单元边沿与其内容之间的空白cellspacing：规定的是单元之间的空间。colspan：合并列1234567891011121314151617181920&lt;table border="1" width="400"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th width="30%"&gt;姓名&lt;/th&gt; &lt;th colspan="2" width="70%"&gt;考试成绩&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;张三&lt;/td&gt; &lt;td width="35%"&gt;理论：79分&lt;/td&gt; &lt;td width="35%"&gt;上机：88分&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李四&lt;/td&gt; &lt;td&gt;理论：87分&lt;/td&gt; &lt;td&gt;上机：74分&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;rowspan：合并列123456789101112131415161718192021222324252627282930313233&lt;table border="1" width="90%" align="center"&gt; &lt;thead&gt; &lt;tr bgcolor="#eeeeee"&gt; &lt;th width="30%"&gt;日期&lt;/th&gt; &lt;th width="30%"&gt;时间&lt;/th&gt; &lt;th width="40%"&gt;上映电影&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td rowspan="3"&gt;8月1日&lt;/td&gt; &lt;td&gt;8:00-11:00&lt;/td&gt; &lt;td&gt;哈利珀特7&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;11:00-13:00&lt;/td&gt; &lt;td&gt;哈利珀特7&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;13:00-15:00&lt;/td&gt; &lt;td&gt;阿凡达2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;8月2日&lt;/td&gt; &lt;td&gt;8:00-11:00&lt;/td&gt; &lt;td&gt;哈利珀特7&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;13:00-15:00&lt;/td&gt; &lt;td&gt;阿凡达2&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的GC]]></title>
    <url>%2F2019%2FJava%E7%9A%84GC%2F</url>
    <content type="text"><![CDATA[概述程序计数器、虚拟机栈、本地方法栈这些区域不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟着回收了。垃圾收集器关注的是堆和方法区中的垃圾。对象已死吗对象判死算法引用计数器给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。但这种计数法无法解决循环引用的问题，即若A对象中有属性B，B对象中有属性A，则A、B永远都有计数。可达性分析算法通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。在Java语言中，可作为GC Roots的对象包括下面几种：虚拟机栈（栈帧中的本地变量表）中引用的对象。方法区中类静态属性引用的对象。方法区中常量引用的对象。本地方法栈中JNI（即一般说的Native方法）引用的对象再谈引用在Java1.2之前，引用的定义是这样的：如果reference类型的数据中存储的数值代表的是另外一块内存中的起始地址，就称这块内存代表着一个引用。我们可以看到，这个引用的定义是非常狭隘的，因为他不能描述一些“鸡肋”对象，即我们最希望的是能描述这样一类对象：当内存空间还足够时，则能保存在内中，如果内存空间在回收后仍然很紧张则可以抛弃这些对象。所以，在Java1.2以后提出了新的引用定义：强引用：在代码中普遍存在的，类似Object obj = new Object();。只要强引用还存在，垃圾回收期就永远不会回收被引用的对象软引用：用来描述一些还有用，但并非必须的对象。这样当系统要发生内存溢出异常之前，就会把软引用列进第二次垃圾回收的计划中。弱引用：比软引用还弱的引用，被弱引用的对象只能存活到下一次垃圾回收之前。虚引用：最弱的一种引用关系了。使用虚引用的唯一目的就是在这个对象回收前收到一个系统回收通知。生存还是死亡即使是不可达对象，也并非是非死不可的，这时候它们暂时处于”缓刑“阶段，真正宣告一个对象死亡，至少要经过两次标记过程：如果对象在进行根搜索后发现跟root不同根，就被标记一次，同时进行筛选，筛选的条件是此对象是否有必要执行finalize()方法，”没有必要执行”的原因如下：当对象没有覆盖finalize()方法，或者finalize()已经被JVM调用过（说明一个对象的finalize()方法只能执行一次）。如果这个对象有必要执行finalize()方法，JVM就会把它放在F-Queue中，稍后JVM会触发一个低优先级的线程去执行。但是去执行并不承诺会等待它运行结束，因为如果一个对象在finalize()方法中执行缓慢，甚至发生了死循环，就会导致F-Queue其他对象永久处于等待状态，更严重的话可能会拖垮整个内存回收系统。finalize()是对象逃脱死亡命运的最后一次机会，稍后GC将会对F-Queue进行第二次小规模的标记，如果在finalize()中将自己和root挂在一个根上（比如把自己赋值给某个类变量或者对象的成员变量），那么在这第二次标记将会被移除出“即将回收的集合”：如果对象还没有逃脱，那么就基本上真的被回收了。不过非常不推荐使用finalize()方法自救对象，因为这是Java刚诞生为了使C/C++程序员更容易接受它作的一个妥协。它的运行带价高昂，不确定性大，无法保证各个对象的调用顺序。有些教材中提到它使用“关闭外部资源”之类的工作，这完全是对这种方法的用途的一种自我安慰。finalize()能做的所有工作，使用try-finally或其他方法都可以做的更好、更及时，Java程序员完全可以忘掉Java有finalize()。finalize()测试：1234567891011121314151617181920212223242526272829303132333435363738public class FinalizeEscapeGC &#123; public static FinalizeEscapeGC SAVE_HOOK = null; public void isAlive() &#123; System.out.println("haha, i'm still alive!"); &#125; @Override protected void finalize() throws Throwable &#123; super.finalize(); System.out.println("finalize method executed!"); FinalizeEscapeGC.SAVE_HOOK = this; &#125; public static void main(String[] args) throws Throwable &#123; SAVE_HOOK = new FinalizeEscapeGC(); //对象第一次拯救自己 SAVE_HOOK = null; System.gc(); Thread.sleep(500); if(SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("5555, i'm dead!"); &#125; //对象第二次拯救自己，但是却跪了。因为finalize只能执行一次呀，亲！！ SAVE_HOOK = null; System.gc(); Thread.sleep(500); if(SAVE_HOOK != null) &#123; SAVE_HOOK.isAlive(); &#125; else &#123; System.out.println("5555, i'm dead!"); &#125; &#125;&#125;/*output: finalize method executed! haha, i'm still alive! 5555, i'm dead!*/回收方法区永久代的垃圾收集主要回收两部分内容：废弃常量：以常量池中字面量的回收为例，假如一个字符串“abc”已经进入了常量池中，但是当前系统没有任何一个String对象是叫做“abc”的，换句话说，就是没有任何String对象引用常量池中的“abc”常量，也没有其他地方引用了这个字面量，如果这时发生内存回收，而且必要的话，这个“abc”常量就会被系统清理出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。无用的类：判断一个类是无用的类的条件比废弃变量要苛刻的多，要同时满足3个条件才能算是“无用的类”：该类所有的实例都已经被回收，意思是堆上没有该对象的实例了加载该类的ClassLoader已经被回收。该类对象的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法（因为通过反射，就一定要加载该类）在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。垃圾收集算法标记-清除算法首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。有两个问题：一是效率不高，因为当对象数量比较多的时候一一进行标记和清除较复杂；二是会产生内存碎片，当需要大的连续内存空间时，即使碎片内存总和远大于需求，也会触发垃圾回收操作。复制算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。实现简单，运行高效，但是空间缩小为原来的一半了。现在的商业JVM采用这种算法来回收新生代，IBM经过调研发现，新生代的对象98%都是朝生夕死的，所有并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor还存活着的对象一次性拷贝到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor的空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8：1，也就是每次新生代中可用内存空间为整个内存空间的9/10，只有10%的内存是用来浪费的。当然了，我们无法保证每次回收只有少于10%的对象存活，当存活对象大于10%，就会借用其他内存（这里指老年代）进行分配担保。分配担保的详细介绍在后面。标记整理算法标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。（老年代一般采用这个方法）分代收集算法当前商业虚拟机的垃圾回收都采用分代收集算法，这种算法没有啥特别的，就是根据对象的存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代，这样就可以根据每个代不同的特点采用最适当的回收算法。比如新生代存活对象少，就采用复制算法；老年代存活对象少，复制的话代价太大，就可以采用标记-整理算法。HotSpot 的算法实现枚举根节点可达性分析在逐个检查引用链和GC停顿（保证分析工作的一致性）上浪费时间较多。主流Java虚拟机使用的都是准确式GC，即虚拟机应当有办法直接得知哪些地方存放着对象的引用。HotSpot是通过一个OopMap的数据结构来达到这个目的的。在类加载完成的时候，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。安全点HotSpot没有为每条指令都生成OopMap，那样占用空间太多，前面已经提到，只是在“特定的位置”记录了这些信息，这些位置称为安全点（Safepoint），即程序执行时并非在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。Safepoint的选定既不能太少以致于让GC等待时间太长，也不能过于频繁以致于过分增大运行时的负荷。所以，安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的，“长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。另一个问题是如何让所有线程都跑到最近的安全点停顿。这里有两种方案可供选择：抢先式中断（Preemptive Suspension）和主动式中断（Voluntary Suspension），其中抢先式中断不需要线程的执行代码主动去配合，在GC发生时，首先把所有线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复线程，让它“跑”到安全点上。现在几乎没有虚拟机实现采用抢先式中断来暂停线程从而响应GC事件。而主动式中断的思想是当GC需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。安全区域如果线程没有在执行呢，比如线程处于Sleep状态或者Blocked状态，就需要安全区域解决了。安全区域是指在一段代码片段之中，引用关系不会发生变化。在这个区域中的任意地方开始GC都是安全的。在线程执行到Safe Region中的代码时，首先标识自己已经进入了Safe Region，那样，当在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程了。在线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举（或者是整个GC过程），如果完成了，那线程就继续执行，否则它就必须等待直到收到可以安全离开Safe Region的信号为止。OopMap和安全点辨析OopMap 记录了栈上本地变量到堆上对象的引用关系。其作用是：垃圾收集时，收集线程会对栈上的内存进行扫描，看看哪些位置存储了 Reference 类型。如果发现某个位置确实存的是 Reference 类型，就意味着它所引用的对象这一次不能被回收。但问题是，栈上的本地变量表里面只有一部分数据是 Reference 类型的（它们是我们所需要的），那些非 Reference 类型的数据对我们而言毫无用处，但我们还是不得不对整个栈全部扫描一遍，这是对时间和资源的一种浪费。一个很自然的想法是，能不能用空间换时间，在某个时候把栈上代表引用的位置全部记录下来，这样到真正 gc 的时候就可以直接读取，而不用再一点一点的扫描了。事实上，大部分主流的虚拟机也正是这么做的，比如 HotSpot ，它使用一种叫做 OopMap 的数据结构来记录这类信息。我们知道，一个线程意味着一个栈，一个栈由多个栈帧组成，一个栈帧对应着一个方法，一个方法里面可能有多个安全点。 gc 发生时，程序首先运行到最近的一个安全点停下来，然后更新自己的OopMap，记下栈上哪些位置代表着引用。枚举根节点时，递归遍历每个栈帧的OopMap，通过栈中记录的被引用对象的内存地址，即可找到这些对象（ GC Roots ）。参考：https://dsxwjhf.iteye.com/blog/2201685垃圾收集器Serial收集器最基本，历史最悠久。新生代的，“单线程的”，只会用一个CPU或一个线程工作，并且收集时，必须暂停所有的工作线程，直到收集结束。它依然是虚拟机运行在Client端的默认新生代收集器。简单而高效，因为它不需要考虑线程切换，只专注一次把收集工作搞定，而且在Client端，新生代的内存一般只有几十M或者一两百M的样子，完成一次收集工作完全可以控制在几十毫秒或者一百毫秒左右，不会有很大的停顿感。ParNew收集器这个本质上就是Serial收集器的多线程版本。许多运行在Server模式下的虚拟机中首选的新生代收集器，其中还有一个与性能无关但很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。（原因是Parallel Scavenge收集器和后面的G1收集器都没有使用传统的GC收集器代码框架，而是另外独立实现的，其余几种收集器则共用了框架代码）。ParNew收集器也是使用-XX:+UseConcMarkSweepGC选项后的默认新生代收集器，当然也可以使用-XX:+UseParNewGC选项来显式指定使用单CPU的话一般会考虑用Serial，多CPU的话一般考虑用ParNew，它默认开启的收集器线程数和CPU核数相同，当你想控制的时候，可以使用-XX:ParallelGCThreads参数来限制收集器的线程数。然后提前解释一下并行和并发的概念，因为后面会有几个并发和并行的收集器：并行(Parallel)：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。所以，遇到 Parallel 关键字的话，都是并行。所以当它们工作的时候，用户线程是阻塞的。所以也是 stop the world并发(Concurrent)：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会根据时间片轮转交替进行），用户程序继续运行，而垃圾收集程序运行在另外一个CPU上。所以遇到 concurrent 关键字就是 GC 线程和用户线程在一段时间内交叉运行，不会将用户线程阻塞，不是 stop the worldParallel Scavenge收集器Parallel Scavenge也是一个新生代收集器，它也是使用复制算法的收集器，同时也是并行的多线程收集器。它的目标是达到可控制的CPU吞吐量。所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾回收时间）。比如虚拟机运行了100分钟，垃圾回收使用了1分钟，那么吞吐量就是99%。这就说说一下应用场景了。停顿时间（垃圾回收时间）： 停顿时间越短越适合于用户交互的程序，良好的响应速度能提升用户体验高吞吐量： 可以最高效率的利用CPU时间，尽快的完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务为了这两个目的，Parallel Scavenge收集器提供了2个参数：-XX:MaxGCPauseMillis：大于0的毫秒数，收集器将尽力保证内存回收时间不超过这个值。不过不要异想天开认为把这个值设的特别小，就能使系统垃圾收集速度更快，GC停顿时间缩短肯定是有代价的，它会牺牲吞吐量和新生代空间来实现。-XX:GCTimeRatio：大于0小于100的整数.假如设为N，那么垃圾收集时间占总时间的比率就是1/(1+N),比如设置为19,占比就是1/(1+19)=5%，默认值是99，即1%。-XX:+UseAdaptiveSizePolicy：这也是一个有用的参数，放在这里说一下。它是一个开关参数，当这个参数打开之后，就不需要手工指定新生代的大小（-Xmn）、Eden、Survivor区的比例（-XX:SurvivorRatio）、晋升老年代对象年龄（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以一同最合适的停顿时间或最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。自适应调节策略也是Parallel Scavenge收集器和ParNew收集器的一个重要区别Serial Old 收集器Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用”标记-整理“算法。这个收集器的主要意义就是被Client模式下的虚拟机使用。如果在Server模式下，它还有两大用途：在JDK1.5及之前的版本中与Parallel Scavenge收集器搭配使用；另外一个就是CMS的后备预案，在并发收集发生Concurrent Mode Failure的时候使用。Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法。是在JDK 1.6之后才提供的。前面说过，Parallel Scavenge收集器采用了独立的架构，无法和CMS配合使用。那么，在JDK 1.6以前，Parallel Scavenge只能和Serial Old配合使用。因为Serial Old是单线程的，所以在多CPU情况下无法发挥性能，所以根本实现不了高吞吐量的需求，直到JDK 1.6推出了Parallel Old之后，Parallel Scavenge收集器和Parallel Old搭配，才真正实现了对吞吐量优先的控制。所以，在注重吞吐量及CPU资源敏感的场合，都可以考虑Parallel Scavenge和Parallel Old组合。CMS（Comcurrent Mark Sweep）收集器CMS收集器是以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用都集中在互联网站或者B/S系统上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，给用户最佳的用户体验。而CMS收集器就非常符合这类应用的需求从名字上可以看出，”Mark Sweep“是基于标记-清除算法实现的，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为4个步骤：初始标记：初始标记仅仅只是标记一下GC roots能直接关联到的对象，速度很快，需要stop the world。并发标记：并发标记就是进行GC Roots Tracing（可达性算法）的过程。重新标记：重新标记则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变化的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍微长一些，但远比并发标记的时间短，需要stop the world。并发清除：垃圾清除由于整个过程中，并发标记和并发清除时间最长，收集器线程可以和用户线程一起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。CMS收集器的优点在于并发收集、低停顿，但是也不是完美的，主要有3个显著的缺点：CMS收集器对CPU资源非常敏感。默认情况下，CMS的收集线程数=(CPU数目+3)/4，当CPU个数大于4的时候，CMS的收集线程不会超过整个CPU占用率的25%。但是在CPU个数比较小的情况下，CPU占用就会突然增大，这样对于初始标记和并发标记这样”Stop The World”的过程来说，用户就会明显感觉到停顿。CMS收集器无法处理浮动垃圾，可能出现”Concurrent Mode Failure”失败而导致另一次Full GC的产生。由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，它需要预留一部分空间提供并发收集时的线程使用。在JDK1.5默认设置下，CMS收集器在老年代使用了68%的空间会被激活，这是一个偏保守的设置。如果在应用中，老年代增长不是太快，可以适当调高这个参数-XX:CMSInitiatingOccupancyFraction。要是CMS运行期间预留的内存无法满足程序的需要，就会出现”Concurrent Mode Failure”失败，这时候JVM会启动后备方案：临时启动Serial Old收集器来重新进行老年代的垃圾收集，因为是单线程，停顿时间就会更长了。所以如果大量出现”Concurrent Mode Failure”，就可以将这个值调低CMS是基于标记-清除算法实现的收集器，所以会产生内存碎片。空间碎片过多时，将会给大对象分配带来很大的麻烦：老年代还有空间但是没有连续的足够大的空间，于是不得不触发一次Full GC。为了解决这个问题，有一个开关叫做-XX:+UseCMSCompactAtFullCollection，用于在Full GC时开启内存碎片的合并整理过程。当然，这个内存整理没法并发，只有”Stop The World”了。另外，虚拟机还设计了一个参数-XX:CMSFullGCsBeforeCompaction,用于指定在多少次不压缩的Full GC后，跟着来一次带压缩的。G1收集器G1是一款面向服务端应用的垃圾收集器。与其他GC收集器相比，G1具备如下特点。并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。分代收集：与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。空间整合：与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。可预测的停顿：这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。G1收集器的运作大致可划分为以下几个步骤：初始标记（Initial Marking）并发标记（Concurrent Marking）最终标记（Final Marking）筛选回收（Live Data Counting and Evacuation）理解GC日志1233.125: [GC [DefNew: 3324K-&gt;152K(3712K), 0.0025925 secs] 3324K-&gt;152K(11904K), 0.0031680 secs]100.667: [Full GC [Tenured: 0K-&gt;210K(10240K), 0.0149142 secs] 4603K-&gt;210K(19456K), [Perm : 2999K-&gt;2999K(21248K)], 0.0150007 secs] [Times: user=0.01 sys=0.00, real=0.02 secs]最前面的数字“33.125：”和“100.667：”代表了GC发生的时间，这个数字的含义是从Java虚拟机启动以来经过的秒数。GC日志开头的“[GC”和“[Full GC”说明了这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC的。如果有“Full”，说明这次GC是发生了Stop-The-World的，例如下面这段新生代收集器ParNew的日志也会出现“[Full GC”（这一般是因为出现了分配担保失败之类的问题，所以才导致STW）。如果是调用System.gc()方法所触发的收集，那么在这里将显示“[Full GC（System）”。1[Full GC 283.736: [ParNew: 261599k-&gt;261599k(261592k), 0.0000288sec]]接下来的“[DefNew”、“[Tenured”、“[Perm”表示GC发生的区域，这里显示的区域名称与使用的GC收集器是密切相关的。后面方括号内部的“3324K-&gt;152K（3712K）”含义是“GC前该内存区域已使用容量-&gt;GC后该内存区域已使用容量（该内存区域总容量）”。而在方括号之外的“3324K-&gt;152K（11904K）”表示“GC前Java堆已使用容量-&gt;GC后Java堆已使用容量（Java堆总容量）”。再往后，“0.0025925 secs”表示该内存区域GC所占用的时间，单位是秒。有的收集器会给出更具体的时间数据，如“[Times：user=0.01 sys=0.00，real=0.02 secs]”，这里面的user、sys和real与Linux的time命令所输出的时间含义一致。参数总结参数描述UseSerialGC虚拟机运行在Client模式下的默认值，打开此开关后，使用Serial+Serial Old的收集器组合进行内存回收UseParNewGC打开此开关后，使用ParNew+Serial Old的收集器组合进行内存回收UseConcMarkSweepGC打开此开关后，使用ParNew+CMS+Serial Old的收集器组合进行内存回收。Serial Old收集器将作为CMS收集器出现Concurrent Mode Failure失败后的后壁收集器使用UseParallelGC虚拟机运行在Server模式下的默认值，打开此开关后，使用Parallel Scavenge+Serial Old（PS MarkSweep）的收集器组合进行内存回收UseParallelOldGC打开此开关后，使用Parallel Scavenge+Parallel Old的收集器组合进行内存回收SurvivorRatio新生代中Eden区域与Survivor区域的容量比值，默认为8，代表Eden:Survivor=8:1PretenureSizeThreshold直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配MaxTenuringThreshold晋升到老年代的对象年龄。每个对象在坚持过一次Minor GC之后，年龄加1，当超过这个参数值时就进入老年代UseAdaptiveSizePolicy动态调整Java堆中各个区域的大小以及进入老年代的年龄HandlePromotionFailure是否允许分配担保失败，即老年代的剩余空间不足以应对新生代的整个Eden和Survivor区的所有对象都存活的极端情况ParallelGCThreads设置并行GC时进行内存回收的线程数GCTimeRatioGC时间占总时间的比率，默认值为99，即允许1%的GC时间。仅在使用Parallel Scavenge收集器时生效MaxGCPauseMillis设置GC的最大停顿时间。仅在使用Parallel Scavenge收集器时生效CMSinitiatingOccupancyFraction设置CMS收集器在老年代空间被使用多少后出发垃圾收集。默认值为68%，仅在使用CMS收集器时生效UseCMSCompactAtFullCollection设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理。仅在使用CMS收集器时生效CMSFullGCsBeforeCompaction设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理。仅在使用CMS收集器时生效内存分配与回收策略Minor GC和Full GCMinor GC：发生在新生代的GC。C触发条件：当Eden区满时。Full GC（也叫Major GC）：发生在老年代的GC，通常会触发MinorGC。Major GC的速度一般会比Minor GC慢10倍以上。触发条件：调用System.gc时，系统建议执行Full GC，但是不必然执行老年代空间不足方法区空间不足通过Minor GC后进入老年代的平均大小大于老年代的可用内存由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小但是这种定义不是很规范，详细参考：http://www.importnew.com/15820.html对象优先在Eden分配大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。大对象直接进入老年代所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组（笔者列出的例子中的byte[]数组就是典型的大对象）。大对象对虚拟机的内存分配来说就是一个坏消息，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们。虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区及两个Sur-vivor区之间发生大量的内存复制。注意PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效。长期存活的对象将进入老年代虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在Eden出生并经过第一次MinorGC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并且对象年龄设为1。对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置。动态对象年龄判定虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。空间分配担保在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么Minor GC可以确保是安全的。如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于就尝试进程一次Minor GC（尽管此次GC是有风险的），如果小于或者不允许冒险，需要进行一次Full GC。在JDK 6 Update 24之后，HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行Full GC。参考深入理解JVM第二版（周志明）http://howiefh.github.io/2015/04/08/jvm-note-2/https://blog.csdn.net/yhyr_ycy/article/details/52566105]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接引用和符号引用]]></title>
    <url>%2F2019%2F%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%E5%92%8C%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在JVM中，类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载7个阶段。而解析阶段即是虚拟机将常量池内的符号引用替换为直接引用的过程。符号引用符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。例如，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现。符号引用与虚拟机的内存布局无关，引用的目标并不一定加载到内存中。在Java中，一个Java类将会编译成一个class文件。在编译时，Java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。直接引用直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。参考https://blog.csdn.net/u014656992/article/details/51107127深入理解Java虚拟机第七章]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常量池和String]]></title>
    <url>%2F2019%2F%E5%B8%B8%E9%87%8F%E6%B1%A0%E5%92%8CString%2F</url>
    <content type="text"><![CDATA[声明常量池及String在JDK6、JDK7、JDK8中的实现以及在不同虚拟机中的实现有很大区别，限于笔者水平无法兼顾到太多版本之间的差异，所以下文章中的解释和测试都仅仅针对于HotSpot虚拟机的JDK8。常量池和运行时常量池在刚开始学习Java内存模型的时候笔者掉进入过一个大坑，即认为常量池是运行时常量池的简称。但是实际上这两者是不一样池子，运行时常量池的英文：Runtime Constant Pool，常量池的英文：Constant Pool Table，运行时常量池是方法区的一部分。常量池是Class文件中的一部分，用于存放编译期生成的各种字面量和符号引用。符号引用和直接引用请参考：https://isjinhao.github.io/2019/%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%E5%92%8C%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8/#more常量池的内容常量池到运行时常量池静态常量池存储的是当class文件被java虚拟机加载进来后存放在方法区的一些字面量和符号引用，字面量包括字符串，基本类型的常量，符号引用其实引用的就是常量池里面的字符串，但符号引用不是直接存储字符串，而是存储字符串在常量池里的索引。动态常量池是当class文件被加载完成后，java虚拟机会将静态常量池里的内容转移到动态常量池里，在静态常量池的符号引用有一部分是会被转变为直接引用的，比如说类的静态方法或私有方法，实例构造方法，父类方法，这是因为这些方法不能被重写其他版本，所以能在加载的时候就可以将符号引用转变为直接引用，而其他的一些方法是在这个方法被第一次调用的时候才会将符号引用转变为直接引用的。8种基本类型的包装类和常量池Java中基本类型的包装类的大部分都实现了常量池技术，即Byte、Short、Integer、Long、Character、Boolean。他么默认创建了数值[-128，127]的相应类型的缓存数据，但是超出此范围仍然会去创建新的对象。1234567//Integer 缓存代码 ：public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125;1234567Integer i1 = 40;Integer i2 = 40;System.out.println(i1==i2);//输出TRUEInteger i1 = 400;Integer i2 = 400;System.out.println(i1==i2);//输出falseInteger比较更丰富的一个例子12345678910111213141516171819202122Integer i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println("i1=i2 " + (i1 == i2));System.out.println("i1=i2+i3 " + (i1 == i2 + i3));System.out.println("i1=i4 " + (i1 == i4));System.out.println("i4=i5 " + (i4 == i5));System.out.println("i4=i5+i6 " + (i4 == i5 + i6)); System.out.println("40=i5+i6 " + (40 == i5 + i6));/* i1=i2 true i1=i2+i3 true i1=i4 false i4=i5 false i4=i5+i6 true 40=i5+i6 true*/解释：语句i4 == i5 + i6，因为+这个操作符不适用于Integer对象，首先i5和i6进行自动拆箱操作，进行数值相加，即i4 == 40。然后Integer对象无法与数值进行直接比较，所以i4自动拆箱转为int值40，最终这条语句转为40 == 40进行数值比较。String类和常量池字符串常量池英文名字：String Pool，字符串常量池的本质是一个StringTable类（它是一个HashSet）。这个StringTable在每个HotSpot VM的实例只有一份，被所有的类共享。但它只存储运行时常量池里String对象的引用，而不存储String对象的内容，根据这个引用可以得到具体的String对象。注意，字符串常量池是字符串类维护的。字符串常量池只是为了加快String类型常量的检索。intern()String.intern() 是一个 Native 方法，JDK对它的解释是（水平有限，不再翻译）：A pool of strings, initially empty, is maintained privately by the class String. When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned.It follows that for any two strings s and t, s.intern() == t.intern() is true if and only if s.equals(t) is true.All literal strings and string-valued constant expressions are interned.大致意思是：如果字符串常量池中已经有了这个字符串，那么直接返回字符串常量池中的它的引用，如果没有，那就将它的引用保存一份到字符串常量池，然后直接返回这个引用。判断字符串是否相等使用equals方法。字面量进入字符串常量池的时机就HotSpot VM的实现来说，在加载类的时候，字符串字面量会进入当前类的运行时常量池，不会进入String Pool。加载类的时候，没有解析字符串字面量，等到执行ldc指令的时候就会触发这个解析的动作。解析指符号引用替换为直接引用的过程，参见：https://isjinhao.github.io/2019/%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%E5%92%8C%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8/#moreldc指令的语义是：到当前类的运行时常量池（Runtime Constant Pool）去查找该index对应的项，如果该项尚未resolve则resolve之，并返回resolve后的内容。 在遇到String类型常量时，resolve的过程如果发现StringTable已经有了内容匹配的java.lang.String的引用，则直接返回这个引用，反之，如果StringTable里尚未有内容匹配的String实例的引用，则会在Java堆里创建一个对应内容的String对象，然后在StringTable记录下这个引用，并返回这个引用出去。可见，ldc指令是否需要创建新的String实例，全看在第一次执行这一条ldc指令时，StringTable是否已经记录了一个对应内容的String的引用。字符串常量池中有哪些字符串的引用由字面量创建的String在字符串常量池中都有一份引用被new出来的对象调用intern()方法后再字符串常量池中才有一份引用获得String对象123String str1 = "abcd";String str2 = new String("abcd");System.out.println(str1==str2); //false直接使用双引号声明出来的 String 对象会直接存储在常量池中。使用双引号声明时会调用ldc命令，所以其检查的是字符串常量池。对于new String()则会在堆中创建一个String对象，并返回该对象的引用。Initializes a newly created String object so that it represents the same sequence of characters as the argument; in other words, the newly created string is a copy of the argument string. Unless an explicit copy of original is needed, use of this constructor is unnecessary since Strings are immutable.例题1Q：String s = new String(&quot;123&quot;);定义了几个对象。A：若常量池中已经存在”123”，则直接引用，也就是此时只会创建一个对象，如果常量池中不存”123”，则先创建后将在堆中创建”123”的一份拷贝，并把这个拷贝的引用返回。此时字符串常量池中有”123“的引用。2Q：123456String s1 = "Hollis";String s2 = new String("Hollis");String s3 = new String("Hollis").intern();System.out.println(s1 == s2); //falseSystem.out.println(s1 == s3); //trueA：3Q：12345678String s = new String("1");String s2 = "1";s.intern();System.out.println(s == s2); //falseString s3 = new String("1") + new String("2");s3.intern();String s4 = "12";System.out.println(s3 == s4); //trueA：123451：常量池中有&quot;1&quot;，堆中有字符串&quot;1&quot;，字符串常量池中是常量池中&quot;1&quot;的引用，s是堆中的引用2：在字符串常量池中检索，有&quot;1&quot;，则得到常量池中&quot;1&quot;的引用5：常量池中有&quot;1&quot;，&quot;2&quot;。new String(&quot;1&quot;) + new String(&quot;2&quot;);的底层是使用StringBuffer的append方法将&quot;2&quot;和&quot;2&quot;拼接在一块，然后调用toString方法new出“22”；所以此时的“22”字符串是创建在堆区的；6：在字符串常量池中检索，没有&quot;22&quot;，把堆中该对象的引用放在字符串常量池中7：检查字符串常量池，有&quot;2&quot;的引用，指向堆4Q：1234String s1=new String("xy") + "z"; String s2=s1.intern(); System.out.println(s1==s1.intern()); //true System.out.println(s2==s1.intern());A：12341：堆中有&quot;xyz&quot;，常量池中有&quot;xy&quot;，&quot;z&quot;2：把堆中的&quot;xyz&quot;的引用存在字符串常量池中。3：都指向堆中4：都指向堆中5Q：1234String s1=new String("xyz") ; String s2=s1.intern(); System.out.println(s1==s1.intern()); //falseSystem.out.println(s2==s1.intern()); //trueA：12341：常量池中有&quot;xyz&quot;，堆中有&quot;xyz&quot;2：s2指向常量池中的&quot;xyz&quot;3：s1.intern()指向常量池，s1指向堆4：s2指向堆6Q：1234String s1 = "xy" + "z";String s2 = s1.intern();System.out.println( s1==s1.intern() ); //trueSystem.out.println( s2==s1.intern() ); //trueA：12341：编译期可以确定s1是&quot;xyz&quot;，所以编译器会优化。在常量池中有&quot;xyz&quot;2：s2指向常量池中的&quot;xyz&quot;3：都指向常量池中的&quot;xyz&quot;4：都指向常量池中的&quot;xyz&quot;7Q：12345678String s1=new String("xy") + "z"; String s3 = "xyz";String s2=s1.intern(); System.out.println(s1 == s3); //falseSystem.out.println(s1 == s2); //falseSystem.out.println(s2 == s3); //trueSystem.out.println(s1==s1.intern()); //falseSystem.out.println(s2==s1.intern()); //trueA：123456781：堆中有&quot;xyz&quot;，常量池中有&quot;xy&quot;和&quot;z&quot;，s1指向堆中的&quot;xyz&quot;2：检索字符串常量池，没有&quot;xyz&quot;，在常量池中创建&quot;xyz&quot;，s3指向常量池中的&quot;xyz&quot;3：字符串常量池有&quot;xyz&quot;的引用，且指向常量池，s2指向常量池中&quot;xyz&quot;4：s1指向堆中的&quot;xyz&quot;，s2指向常量池中&quot;xyz&quot;5：s1指向堆中的&quot;xyz&quot;，s3指向常量池中的&quot;xyz&quot;6：都指向常量池中&quot;xyz&quot;7：s1指向堆中的&quot;xyz&quot;，s1==s1.intern指向常量池中的&quot;xyz&quot;8：s2指向常量池中&quot;xyz&quot;，s1==s1.intern指向常量池中的&quot;xyz&quot;参考https://blog.csdn.net/wangbiao007/article/details/78545189https://blog.csdn.net/Mypromise_TFS/article/details/81504137https://www.zhihu.com/question/55994121深入理解JVM第二版]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2019%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[JVMJVM则是JRE中的核心组成部分，承担分析和执行Java字节码的工作。在Java历史上有很多发行的Java虚拟机，但目前一般都是HotSpot。查看本机JVM：java -version运行时数据区Java虚拟机在执行Java程序的时候会把它所管理的内存区域划分为若干个不同的数据区域。根据JVM规范，JVM 内存共分为虚拟机栈、堆、方法区、程序计数器、本地方法栈五个部分。运行时数据区划分JDK6JDK8线程私有程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完。另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。从上面的介绍中我们知道程序计数器主要有两个作用：字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。注意：程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。Java虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。Java 内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack)，其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 （实际上，Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息）局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向一条字节码指令的地址）。Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。StackOverFlowError： 若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。Java 虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。扩展：那么方法/函数如何调用？Java 栈可用类比数据结构中栈，Java 栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入Java栈，每一个函数调用结束后，都会有一个栈帧被弹出。Java方法有两种返回方式：return 语句。抛出异常。不管哪种返回方式都会导致栈帧被弹出。本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。线程共享Java堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。Java 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代。再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。上图所示的eden区、s0区、s1区都属于新生代，tentired区属于老年代。大部分情况，对象都会首先在Eden区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入s0或者s1，并且对象的年龄还会加 1（Eden区-&gt;Survivor 区后对象的初始年龄变为1），当它的年龄增加到一定程度（默认为15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。HotSpot 虚拟机中方法区也常被称为 “永久代”，本质上两者并不等价。仅仅是因为 HotSpot 虚拟机设计团队用永久代来实现方法区而已，这样 HotSpot 虚拟机的垃圾收集器就可以像管理 Java 堆一样管理这部分内存了。但是这并不是一个好主意，因为这样更容易遇到内存溢出问题。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。JDK 1.8 的时候，方法区被彻底移除了（JDK1.7就已经开始了），取而代之是元空间，元空间使用的是直接内存。我们可以使用参数： -XX:MetaspaceSize 来指定元数据区的大小。与永久区很大的不同就是，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。运行时常量池运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）字面量就是指这个量本身，比如字面量3。也就是指3. 再比如 string类型的字面量”ABC”, 这个”ABC” 通过字来描述。 可以理解成一眼就能知道的量。既然运行时常量池时方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。JDK1.8及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。元空间为什么永久代向元空间的转换字符串存在永久代中，容易出现性能问题和内存溢出。类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。类的各个部分分别在哪个位置字节码：方法区字节码对象：堆普通对象：大部分存在于堆。更多参考：https://blog.csdn.net/rickiyeat/article/details/76802085对象的属性：大部分存在于堆static属性：常量池方法：方法区方法中的局部变量：Java虚拟机栈String对象：堆或常量池final属性：常量池对象的创建- 类加载检查： 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。- 分配内存： 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配方式由 Java 堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。### 内存分配的两种方式选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。详细可参考：深入理解Java虚拟机第二版第三章。- 指针碰撞：假设JAVA堆中的内存时绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式成为“指针碰撞”。- 空闲链表：如果JAVA堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式成为“空闲列表”。- 初始化零值： 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。- 设置对象头： 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。- 执行 init 方法： 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。### 内存分配并发问题在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，否则比如当虚拟机正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存就会引发严重的问题。通常来讲，虚拟机采用两种方式来保证线程安全：- CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。- TLAB： 为每一个线程预先在Eden区分配一块儿内存，称为本地线程分配缓存（Thread Local Allocation Buffer，TLAB），JVM在给线程中的对象分配内存时，首先在TLAB分配，当对象大于TLAB中的剩余内存或TLAB的内存已用尽时，再采用上述的CAS进行内存分配。## 对象的内存布局在 Hotspot 虚拟机中，对象在内存中的布局可以分为3块区域：对象头、实例数据和对齐填充。Hotspot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的自身运行时数据（哈希码、GC分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。 因为Hotspot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（1倍或2倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。## 对象的访问定位建立对象就是为了使用对象，我们的Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式有虚拟机实现而定，目前主流的访问方式有使用句柄和直接指针两种：- 句柄： 如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息；直接指针：如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference 中存储的直接就是对象的地址。这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。参考JavaGuide深入理解Java虚拟机]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于winpcap的cpp控制台网络协议分析]]></title>
    <url>%2F2019%2F%E5%9F%BA%E4%BA%8Ewinpcap%E7%9A%84cpp%E6%8E%A7%E5%88%B6%E5%8F%B0%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[环境搭建软件版本winpcap4.1.3vs2015创建项目新建项目-&gt;Visual C++项目-&gt;Win32控制台项目，在Win32应用程序向导窗口中的应用程序设置-&gt;附加选项选中空项目。将WinPcap开发包中的Include和Lib两个文件夹复制到新建项目所在文件夹下。点击项目，右击，然后点击属性C/C++-&gt;常规-&gt;附加包含目录：如 ..\include链接器-&gt;常规-&gt;附加库目录：如 ..\lib链接器-&gt;输入-&gt;附加依赖项：wpcap.lib（winpcap的包），ws2_32.lib（windows的socket）数据结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#ifdef _MSC_VER#define _CRT_SECURE_NO_WARNINGS#endif#include "pcap.h"typedef struct eth_address&#123; u_char byte1; u_char byte2; u_char byte3; u_char byte4; u_char byte5; u_char byte6;&#125;eth_address;/* 4 bytes IP address */typedef struct ip_address&#123; u_char byte1; u_char byte2; u_char byte3; u_char byte4;&#125;ip_address;/* IPv4 header */typedef struct ip_header&#123; u_char ver_ihl; // Version (4 bits) + Internet header length (4 bits) u_char tos; // Type of service u_short tlen; // Total length u_short identification; // Identification u_short flags_fo; // Flags (3 bits) + Fragment offset (13 bits) u_char ttl; // Time to live u_char proto; // Protocol u_short crc; // Header checksum ip_address saddr; // Source address ip_address daddr; // Destination address u_int op_pad; // Option + Padding&#125;ip_header;/* UDP header*/typedef struct udp_header&#123; u_short sport; // Source port u_short dport; // Destination port u_short len; // Datagram length u_short crc; // Checksum&#125;udp_header;/* MAC header*/typedef struct eth_header&#123; eth_address daddr; eth_address saddr; u_short type;&#125;eth_header;typedef struct arp_header&#123; u_short hardtype; //硬件类型字段 u_short prototype; //协议类型字段 u_char htlen; //硬件地址的长度,以字节为单位.对于以太网上IP地址的ARP请求或应答来说,它们的值为6 u_char ptlen; //协议地址的长度,以字节为单位.对于以太网上IP地址的ARP请求或应答来说,它们的值为4 u_short op; //操作字段 eth_address arp_esa; //发送端MAC地址 ip_address arp_isa; //发送端IP地址 eth_address arp_eda; //目的端MAC地址 ip_address arp_ida; //目的端IP地址&#125;arp_header;typedef struct icmp_header&#123; u_char type; //ICMP报文类型 u_char code; //代码 u_short checksum; //校验和 u_short identifier; //标识符 u_short sequence_number; //序列号&#125;icmp_header;/* TCP header */typedef struct tcp_header&#123; u_short sport; //源端口 u_short dport; //目的端口 u_long sequence_number; //序号（4字节ntohl） u_long acknowlegement_number; //确认号 u_short hlen_bl_flags; //数据偏移+保留+控制位 u_short window_size; //窗口（发送方自己的接收窗口） u_short checksum; //检验和（首部+数据） u_short urg; //紧急指针 u_long option; //可选+填充&#125;tcp_header;typedef struct dns_packet //报文head+data&#123; u_short id; //每一个占2个字节，共12个字节 u_short flags; //标志第一个为0代表查询报文 u_short ques; u_short answer; u_short author; u_short addition; u_char dns_data; //查询问题部分&#125;dns_packet;运行代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506#ifdef _MSC_VER#define _CRT_SECURE_NO_WARNINGS#endif#include "pcap.h"#include "headers.c"#define DNSPORT 53//输出基本信息void myPrintBaseInfo(const struct pcap_pkthdr *header)&#123; struct tm *ltime; char timestr[16]; time_t local_tv_sec; local_tv_sec = header-&gt;ts.tv_sec; ltime=localtime(&amp;local_tv_sec); strftime(timestr, sizeof timestr, "%H:%M:%S", ltime); printf("\n\n\n\n监听到Mac帧的时间：%s MAC帧长度:%d Byte(s)\n", timestr, header-&gt;len * 4); /* 以四字节为单位 */&#125;//输出硬件地址void myPrintEthAddress(eth_address eth)&#123; printf("%02X:%02X:%02X:%02X:%02X:%02X", eth.byte1, eth.byte2, eth.byte3, eth.byte4, eth.byte5, eth.byte6 );&#125;//输出IP地址void myPrintIPAddress(ip_address ia)&#123; printf("%d.%d.%d.%d", ia.byte1, ia.byte2, ia.byte3, ia.byte4 );&#125;//输出网络层协议类型void myPrintNetType(u_short type)&#123; printf("网络层协议： "); if(type==0x0800) printf("IP协议"); else if(type==0x0806) printf("ARP协议"); else if(type==0x8035) printf("RARP协议"); else printf("接收到非本程序能处理的网络层协议类型！"); printf("\n");&#125;/* 分析Mac帧： 输出： 网络层协议类型：源MAC -&gt; 目的MAC 返回： 网络层协议类型*/u_short handleMac(eth_header *eth)&#123; u_short type=ntohs(eth-&gt;type); printf("Mac地址： "); myPrintEthAddress(eth-&gt;saddr); printf("-&gt;"); myPrintEthAddress(eth-&gt;daddr); printf("\n\n"); return type;&#125;void handleARPAndRARP(arp_header *ah)&#123; u_short arp_ht; //硬件地址的类型.它的值为1即表示以太网地址 u_short arp_pt; //要映射的协议地址类型.它的值为0x0800，即表示IP地址 u_short arp_op; //四种操作类型,它们是ARP请求(值为1)、ARP应答(值为2)、RARP请求(值为3)和RARP应答(值为4) arp_ht=ntohs(ah-&gt;hardtype); //硬件地址的类型.它的值为1即表示以太网地址 arp_pt=ntohs(ah-&gt;prototype); //要映射的协议地址类型.它的值为0x0800，即表示IP地址 arp_op=ntohs(ah-&gt;op); printf("硬件地址类型为：%d\t\t\t",arp_ht); printf("协议地址类型为：0x%04X\n",arp_pt); printf("硬件地址长度为：%d\t\t\t",ah-&gt;htlen); printf("协议地址长度为：%d\n",ah-&gt;ptlen); if (arp_op == 1)&#123; printf("操作类型为：ARP请求报文。\n本机Mac地址："); myPrintEthAddress(ah-&gt;arp_esa); printf("\t正在请求"); myPrintIPAddress(ah-&gt;arp_ida); printf("的Mac地址\n"); &#125; if (arp_op == 2)&#123; printf("操作类型为：ARP应答报文。\n应答方的Mac地址："); myPrintEthAddress(ah-&gt;arp_eda); printf("\t应答方的IP地址"); myPrintIPAddress(ah-&gt;arp_ida); printf("\n"); &#125; if (arp_op == 3) printf("操作类型为：RARP请求报文\n"); if (arp_op == 4) printf("操作类型为：RARP应答报文\n");&#125;int all_ip_len = 20;u_short handleIP(ip_header *ih)&#123; u_int ip_ver; //版本 u_int ip_len; //首部长度 u_short ip_tlen; //总长度 u_short ip_ident; //标识 u_short ip_flag_fo; //标志和片偏移 u_int ip_flag; //标志（3位，值为2还有分片且允许分片,1不能分片,0没有分片且允许分片） u_int ip_fo; //片偏移 u_short ip_type; //协议 u_short ip_crc; //首部检验和 u_long ip_op_pad; //可选项 /* retireve the position of the ip header *///检索IP首部的位置 ip_ver = (ih-&gt;ver_ihl &gt;&gt; 4); //版本 ip_len = (ih-&gt;ver_ihl &amp; 0xf) * 4; //首部长度，与运算，可以只取ip头部的版本长度字段的后4位 ip_tlen=ntohs(ih-&gt;tlen); //总长度 ip_ident=ntohs(ih-&gt;identification); //标识 ip_flag_fo = ntohs(ih-&gt;flags_fo); //2字节存放，会有字节序问题 ip_flag = (ip_flag_fo &gt;&gt; 13); //标志 ip_fo = (ip_flag_fo &amp; 0x1fff); //片偏移 ip_type = ih-&gt;proto; //上层协议类型 ip_crc = ntohs(ih-&gt;crc); //首部校验和 /*打印IP数据报首部*/ printf("版本：%d\t\t\t",ip_ver); printf("首部长度：%d\n",ip_len); printf("区分服务：%d\t\t", ih-&gt;tos); printf("总长度：%d\n", ip_tlen); printf("标识：%d\t\t", ip_ident); if (ip_flag == 2) printf("标志：DF=1（不能分片），MF=0（没有后续分片）\n"); if (ip_flag == 1) printf("标志：DF=0（允许分片），MF=1（还有后续分片）\n"); if (ip_flag == 0) printf("标志：DF=0（允许分片），MF=0（没有后续分片）\n"); printf("片偏移：%d\t\t",ip_fo*8);//片偏移以8字节为单位 printf("生存时间：%d\n",ih-&gt;ttl); printf("协议：%d\t\t\t",ih-&gt;proto); printf("首部校验和：%d\n",ip_crc); printf("IP地址： "); myPrintIPAddress(ih-&gt;saddr); printf(" -&gt; "); myPrintIPAddress(ih-&gt;daddr); printf("\n"); if (ip_len == 20)//IP首部长度&gt;20时才有 printf("首部长度为20，IP报文首部没有可选字段。\n"); else&#123; ip_op_pad = ntohl(ih-&gt;op_pad); printf("可选自段内容为：%u\n", ip_op_pad); &#125; all_ip_len = ip_len; return ip_type;&#125;void handleICMP(icmp_header *ich)&#123; u_short icmp_checksum; //校验和 u_short icmp_ident; //标识符 u_short icmp_seqnum; //序列号 icmp_checksum = ntohs(ich-&gt;checksum); //校验和 icmp_ident = ntohs(ich-&gt;identifier); //标识符 icmp_seqnum = ntohs(ich-&gt;sequence_number); printf("\n运输层协议： ICMP协议\n"); /*打印ICMP报文首部*/ if (ich-&gt;type == 0) printf("ICMP类型：回显应答\n"); else if (ich-&gt;type == 8) printf("ICMP类型：回显请求\n"); else printf("ICMP类型：其他\n"); printf("代码：%d\t\t",ich-&gt;code); printf("校验和：%d\n",icmp_checksum); printf("标识符：%d\t\t",icmp_ident); printf("序列号：%d\n",icmp_seqnum);&#125;u_int udp_len;bool handleUDP(udp_header *uh)&#123; u_short sport, dport;//端口 u_short uh_len; //长度 u_short uh_crc; //校验和 sport = ntohs( uh-&gt;sport );//源端口 dport = ntohs( uh-&gt;dport );//目的端口 uh_len = ntohs(uh-&gt;len); //长度 uh_crc = ntohs(uh-&gt;crc); //校验和 printf("\n运输层协议： UDP协议\n"); printf("端口号：%d -&gt; %d\n", sport, dport); printf("长度：%d\t\t", uh_len); printf("校验和：%d\n", uh_crc); udp_len = uh_len; if(sport == DNSPORT || dport == DNSPORT) return true; return false;&#125;void handleTCP(tcp_header *th)&#123; u_short tcp_sport; //源端口 u_short tcp_dport; //目的端口 u_long tcp_seqnum; //序号（4字节ntohl） u_long tcp_acknum; //确认号 u_short tcp_hlen_bl_flags; //数据偏移+保留+控制位 u_short tcp_hlen; u_short tcp_bl; u_short tcp_flags_urg; //紧急1有效 u_short tcp_flags_ack; //确认=1时，确认号有效 u_short tcp_flags_psh; //推送1有效，可以不用填满缓存就发报 u_short tcp_flags_rst; //复位1有效，重新建立连接 u_short tcp_flags_syn; //同步syn=1,ack=0时，表明这是一个连接请求报文；syn=1,ack=1,接受连接请求 u_short tcp_flags_fin; //释放连接=1时，表示数据报 u_short tcp_window_size; //窗口（发送方自己的接收窗口） u_short tcp_checksum; //检验和（首部+数据） u_short tcp_urg; //紧急指针 u_long tcp_option; tcp_sport=ntohs(th-&gt;sport); //源端口 tcp_dport=ntohs(th-&gt;dport); //目的端口 tcp_seqnum=ntohl(th-&gt;sequence_number); //序号（4字节ntohl） tcp_acknum=ntohl(th-&gt;acknowlegement_number);//确认号 tcp_hlen_bl_flags=ntohs(th-&gt;hlen_bl_flags); //数据偏移4+保留6+控制位6 tcp_hlen=(tcp_hlen_bl_flags &gt;&gt; 12)*4; //以4字节为单位 tcp_bl=(tcp_hlen_bl_flags &amp; 0x0fc0); //保留 tcp_flags_urg=(tcp_hlen_bl_flags &amp; 0x0020); //紧急1有效 ----- tcp_flags_ack=(tcp_hlen_bl_flags &amp; 0x0010); //确认=1时，确认号有效 tcp_flags_psh=(tcp_hlen_bl_flags &amp; 0x0008); //推送1有效，可以不用填满缓存就发报 tcp_flags_rst=(tcp_hlen_bl_flags &amp; 0x0004); //复位1有效，重新建立连接 tcp_flags_syn=(tcp_hlen_bl_flags &amp; 0x0002); //同步syn=1,ack=0时，表明这是一个连接请求报文；syn=1,ack=1,接受连接请求 tcp_flags_fin=(tcp_hlen_bl_flags &amp; 0x0001); //释放连接=1时，表示数据报 tcp_window_size=ntohs(th-&gt;window_size); //窗口（发送方自己的接收窗口） tcp_checksum=ntohs(th-&gt;checksum); //检验和（首部+数据） tcp_urg=ntohs(th-&gt;urg); printf("\n运输层协议： TCP协议\n"); /*打印TCP数据报首部*/ printf("端口号：%d -&gt; %d\n",tcp_sport,tcp_dport); printf("序号：%u\t",tcp_seqnum); printf("确认号：%u\n",tcp_acknum); printf("数据偏移：%d\t\t",tcp_hlen);//首部长度// printf("保留：%d\n",tcp_bl); /*控制字段,标志位*/ if (tcp_flags_urg == 1) printf("标志：URG\n"); if (tcp_flags_ack == 1) printf("标志：ACK\n"); if (tcp_flags_psh == 1) printf("标志：PSH\n"); if (tcp_flags_rst == 1) printf("标志：RST\n"); if (tcp_flags_syn == 1) printf("标志：SYN\n"); if (tcp_flags_fin == 1) printf("标志：FIN\n"); printf("窗口：%d\t\t",tcp_window_size); printf("检验和：%d\n",tcp_checksum); printf("紧急指针：%d\t\t",tcp_urg);//URG=1时才有用，窗口大小为0也能发送 if(tcp_hlen == 20)//数据偏移(TCP首部长度)&gt;20时才有 printf("首部长度为20字节，没有填充字段。\n"); else &#123; tcp_option = ntohl(th-&gt;option); printf("填充字段:%u\n", tcp_option); &#125;&#125;/* Callback function invoked by libpcap for every incoming packet */void packet_handler(u_char *param, const struct pcap_pkthdr *header, const u_char *pkt_data) //param 无用&#123; eth_header *eth; u_short macType; myPrintBaseInfo(header); eth=(eth_header *) (pkt_data); //过滤以太网头部 pkt_data += 14; //HandleMac macType=handleMac(eth); myPrintNetType(macType); // 处理ARP 和 RARP if(macType==0x0806 || macType==0x8035) &#123; arp_header *ap; ap = (arp_header *)(pkt_data); handleARPAndRARP(ap); &#125; // 处理IP if(macType==0x0800) &#123; u_short ip_type; ip_header *ih; ih = (ip_header *) (pkt_data); ip_type = handleIP(ih); if (ip_type == 1) &#123; icmp_header *ich; ich = (icmp_header *)((u_char*)ih + all_ip_len); handleICMP(ich); &#125;else if(ip_type == 17)&#123; udp_header *uh; uh = (udp_header *) ((u_char*)ih + all_ip_len); if(handleUDP(uh)) &#123; /* struct dns_packet *pdns; pdns = (struct dns_packet *)(pkt_data + all_ip_len + udp_len); // sport+dport+length+checksum,DNS头指针 u_char *query=&amp;(pdns-&gt;dns_data);//定位到查询部分头部 printf("QueryDomain="); u_char domainname[100]=&#123;0&#125;; u_int i=0; //query++;//把点去了 while(*query) &#123; printf("%d", *query); if(*query &lt; 0x10)//48以后出现数字和英文字母 printf("."); else printf("%c", *query); query++; i++; &#125; printf("\n"); */ &#125; &#125;else if(ip_type == 6)&#123; tcp_header *th; th=(tcp_header *) ((u_char*)ih + all_ip_len); handleTCP(th); &#125; &#125;&#125;int main()&#123; pcap_if_t *alldevs; pcap_if_t *d; int inum; int i=0; pcap_t *adhandle; char errbuf[PCAP_ERRBUF_SIZE]; u_int netmask; char packet_filter[100]; int i; scanf("%d", &amp;i); printf("分析IP数据报输入：\t1\n"); printf("分析ARP数据报输入：\t2\n"); printf("分析TCP数据报输入：\t3\n"); printf("分析UDP数据报输入：\t4\n"); printf("分析ICMP数据报输入：\t5\n"); printf("分析MAC、IP、ARP、TCP、UDP、IMCP输入\t6\n"); if(i == 1) packet_filter = "ip"; else if(i == 2) packet_filter = "arp"; else if(i == 3) packet_filter = "ip and tcp"; else if(i == 4) packet_filter = "ip and udp"; else if(i == 5) packet_filter = "ip and icmp"; else if(i == 6) packet_filter = ""; else&#123; printf("InputError : check the number you input! exit(1)"); exit(1); &#125; struct bpf_program fcode; if(pcap_findalldevs(&amp;alldevs, errbuf) == -1) &#123; fprintf(stderr,"Error in pcap_findalldevs: %s\n", errbuf); exit(1); &#125; for(d=alldevs; d; d=d-&gt;next) &#123; printf("%d. %s", ++i, d-&gt;name); if (d-&gt;description) printf(" (%s)\n", d-&gt;description); else printf(" (No description available)\n"); &#125; if(i==0) &#123; printf("\nNo interfaces found! Make sure WinPcap is installed.\n"); return -1; &#125; printf("Enter the interface number (1-%d):",i); scanf("%d", &amp;inum); /* Check if the user specified a valid adapter */ if(inum &lt; 1 || inum &gt; i) &#123; printf("\nAdapter number out of range.\n"); pcap_freealldevs(alldevs); return -1; &#125; /* Jump to the selected adapter */ for(d=alldevs, i=0; i&lt; inum-1 ;d=d-&gt;next, i++); /* Open the adapter */ if ((adhandle= pcap_open_live(d-&gt;name, // name of the device 65536, // portion of the packet to capture. // 65536 grants that the whole packet will be captured on all the MACs. 1, // promiscuous mode (nonzero means promiscuous) 1000, // read timeout errbuf // error buffer )) == NULL) &#123; fprintf(stderr,"\nUnable to open the adapter. %s is not supported by WinPcap\n"); pcap_freealldevs(alldevs); return -1; &#125; /* Check the link layer. We support only Ethernet for simplicity. */ if(pcap_datalink(adhandle) != DLT_EN10MB) &#123; fprintf(stderr,"\nThis program works only on Ethernet networks.\n"); pcap_freealldevs(alldevs); return -1; &#125; if(d-&gt;addresses != NULL) /* Retrieve the mask of the first address of the interface */ netmask=((struct sockaddr_in *)(d-&gt;addresses-&gt;netmask))-&gt;sin_addr.S_un.S_addr; else /* If the interface is without addresses we suppose to be in a C class network */ netmask=0xffffff; //compile the filter if (pcap_compile(adhandle, &amp;fcode, packet_filter, 1, netmask) &lt;0 ) &#123; fprintf(stderr,"\nUnable to compile the packet filter. Check the syntax.\n"); pcap_freealldevs(alldevs); return -1; &#125; //set the filter if (pcap_setfilter(adhandle, &amp;fcode)&lt;0) &#123; fprintf(stderr,"\nError setting the filter.\n"); pcap_freealldevs(alldevs); return -1; &#125; printf("\nlistening on %s...\n", d-&gt;description); /* At this point, we don't need any more the device list. Free it */ pcap_freealldevs(alldevs); /* start the capture */ pcap_loop(adhandle, 0, packet_handler, NULL); return 0;&#125;分析听到网卡上Mac帧时的回调函数12void packet_handler(u_char *param, const struct pcap_pkthdr *header, const u_char *pkt_data);输出基本信息：包括监听到帧的时间，帧的长度1void myPrintBaseInfo(const struct pcap_pkthdr *header);输出硬件地址，格式：xx:xx:xx:xx:xx:xx1void myPrintEthAddress(eth_address eth);输出IP地址，格式：xx.xx.xx.xx1void myPrintIPAddress(ip_address ia);输出网络层协议类型，格式：网络层协议：xxxx1void myPrintNetType(u_short type);分析Mac帧：1u_short handleMac(eth_header *eth);分析ARP和RARP帧1void handleARPAndRARP(arp_header *ah);分析IP数据报1u_short handleIP(ip_header *ih);分析ICMP数据报1void handleICMP(icmp_header *ich);分析UDP数据报1bool handleUDP(udp_header *uh);分析TCP数据报1void handleTCP(tcp_header *th);]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>winpcap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11-关系数据库理论]]></title>
    <url>%2F2019%2F11-%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[关系 &amp; 关系模式关系模式相当于一张二维表的框架，在这个框架下填入数据，称为关系模式的一个实例，或者叫关系R。关系模式的形式化定义是：$R(U,D,DOM,F)$R：关系名U：组成该关系的属性名集合D：U中属性所来自的域域：一组具有相同数据类型的值的集合DOM：属性向域的映像集合F：属性间数据的依赖关系集合由于D和DOM域与关系模式的设计无关，因此在讨论关系数据库理论时可以把关系模式看做：$R(U,F)$关系的形式化定义：当且仅当$U$上的一个关系$r$满足$F$时，r称为关系模式$R(U,F)$上的一个关系。范式关系模式的设计直接影响着后续增删查改等的操作。如果设计的不合理就会发生各种各样的问题：数据冗余太大更新异常插入异常删除异常比如对于一个描述学校在校生信息数据库：$Student&lt;U,F&gt;$，$U=\lbrace Sno,Sdept,Mname,Cname,Grade\rbrace$会发生的问题：冗余问题：每个系的系主任姓名重复出现，重复次数与该系所有学生的所有课程成绩次数相同更新问题：如果某系的系主任更换后，该数据库该系中所有的元组都要更新插入异常：如果一个系刚成立，尚无学生，则无法把该系的系主任存入数据库删除异常：如果某个系的学生都毕业了，在删除该系学生的同时，该系系主任的信息也会被删除一个好的模式不能发生插入异常、删除异常和更新异常，数据冗余应该尽可能少。定义范式指的是规范化的关系模式，而规范也就是条件，满足不同的条件可以分别解除上述所说的不同问题。问题发生的原因之所以会发生上诉的问题其实就是由于数据依赖。而数据依赖可以分为两种：函数依赖和多值依赖。但这两种依赖关系不是平级，而是递进的关系，所以我们先介绍函数依赖。函数依赖设$R(U)$是一个属性集$U$上的关系模式，$X$和$Y$是$U$的子集。若对于$R(U)$的任意两个可能的关系$r_1$、$r_2$，若$r_1[x]=r_2[x]$，则$r_1[y]=r_2[y]$，则称$X$决定$Y$，或者$Y$依赖$X$。记作$X \rightarrow Y$。对于$X$、$Y$范围的不同，可以再次分为：非平凡函数依赖：如果$X \rightarrow Y$但$Y \nsubseteq X$，则称$X \rightarrow Y$是非平凡函数依赖平凡函数依赖：如果$X \rightarrow Y$但$Y \subseteq X$，则称$X \rightarrow Y$是非平凡函数依赖。例：$(Sno,Sname) \rightarrow Sname$所以，在关系模式中，平凡函数依赖是一定是可以被满足的，所以我们在以后的讨论中不再关注平凡函数依赖，只关注非平凡函数依赖。而我们对于非平凡函数依赖又可以分为以下几类：完全函数依赖：如果$X \rightarrow Y$，并且对于任意的真子集$X_i$，都无法做到$X_i \rightarrow Y$，则称$Y$对$X$是完全函数依赖。部分函数依赖：如果$X \rightarrow Y$，存在真子集$X_i$，可以做到$X_i \rightarrow Y$，则称$Y$对$X$是部分函数依赖。传递函数依赖：如果$X \rightarrow Y$，$Y \rightarrow Z$且$Y \nrightarrow X$，则称$X$对$X$有传递函数依赖。第一范式在关系模型中的每一个具体关系$R$中，如果每个属性都是不可再分的，则称$R$属于第一范式，记作$R \in 1NF$。第二范式$R \in 1NF$且每一个非主属性完全函数依赖于码，则$R \in 2NF$。依赖有直接依赖和传递依赖。第三范式$R \in 2NF$且$R$中的每个非主属性不传递依赖于主码，则关系$R$是第三范式，$R \in 3NF$。模式分解从低级范式到高级范式的方法是模式分解。举例：对于一个关系$R(SNO,SNA,CNO,GRADE,CNA,TNA,TAGE)$（学号、姓名、课号、成绩、课程名称、教师姓名、教师年龄）。现实语义：如果假设一个教师可以交多门课且一门课仅由一个教师讲授，可得R的函数依赖集：$SNO \rightarrow SNM$$(SNO,CNO) \rightarrow GRADE$$CNO \rightarrow CNA$$CNO \rightarrow TNA$$TNA \rightarrow TAGE$函数依赖图如下：分解为第二范式：- $R1&lt;(SNO,SNA),SNO \rightarrow SNA&gt;$- $R2&lt;(SNO,CNO,GRADE), (SNO,CNO) \rightarrow GRADE&gt;$- $R3&lt;(CNO,CNA,TNA,TAGE),CNO \rightarrow CNA, CNO \rightarrow TNA, TNA \rightarrow TAGE&gt;$分解为第三范式：- $R1&lt;(SNO,SNA),SNO \rightarrow SNA&gt;$- $R2&lt;(SNO,CNO,GRADE), (SNO,CNO) \rightarrow GRADE&gt;$- $R3&lt;(CNO,CNA,TNA),CNO \rightarrow CNA, CNO \rightarrow TNA&gt;$- $R3&lt;(CNO,TAGE),CNO \rightarrow TAGE&gt;$### 第三范式的问题仓库保管$WPE(W#,P#,E#,QNT)$，（ 仓库号，器件号，职工号，数量）。一个职工只能管理一个仓库的某类型器件，一个仓库的某类型器件数量是确定的，一个员工管理的某类型器件数量是一定的。函数依赖：1. $(W#, P#) \rightarrow QNT$2. $(E#,P#) \rightarrow QNT$3. $(W#,P#) \rightarrow E#$4. $E# \rightarrow W#$函数依赖图：此时关系模式$WPE$有两个侯选码，$(W#,P#)$ ，$(E#,P#)$，假设确定$(E#,P#)$为主码，那么某新职工分配来仓库，处于学习阶段，但没有独立承但任务，即有$E#$但无$P#$，缺少码的组成部分，无法插入到该关系，即插入异常。这是由于主属性$W#$对另一个侯选码$(E#,P#)$的部分函数依赖。### BC范式BC范式的定义：每个决定因素都包含码，则$R \in BCNF$。而既然每个决定因素都要包含码，则此时意味着必须放弃某些函数依赖，即失去某些现实语义。如例子中若选择$(E#,P#)$，则只能保存函数依赖中的2和4。### 多值依赖设$R(U)$是属性集U上的一个关系模式。$X$，$Y$，$Z$是的$U$的子集，并且$Z=U-X-Y$。关系模式$R(U)$中多值依赖（记做，$X \rightarrow \rightarrow Y$）成立，当且仅当对$R(U)$的任一关系$r$，给定的一对$(x,z)$值有一组$Y$的值，这组值仅仅决定于$x$值而与$z$值无关。若$X \rightarrow \rightarrow Y$，$Z$为空，则称$X \rightarrow \rightarrow Y$为平凡的多值依赖。 所以我们以下只讨论非平凡的函数依赖。#### 例比如对于关系模型$Teaching(C,T,B)$便是存在多值依赖（码为全属性）：第四范式如果对于$R$的每个非平凡多值依赖$X \rightarrow \rightarrow Y$，$X$都含有码，则$R$都含有码。多值依赖的解决依然是分解。如上例中分解为：$R(C,T)$$R(C,B)$]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPP中的字节序]]></title>
    <url>%2F2019%2FCPP%E4%B8%AD%E7%9A%84%E5%AD%97%E8%8A%82%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[字节序计算机硬件有两种储存数据的方式：大端字节序（big endian）和小端字节序（little endian）。大端字节序：高位字节在前，低位字节在后。小端字节序：低位字节在前，高位字节在后。假如我们要存储0x01234567，大端法和小端法如下：为什么会有小端字节序人类能接受的字节序肯定是大端存储，所以很多人会不理解为什么还要有小端字节序呢？其实计算机处理字节序的时候，不知道什么是高位字节，什么是低位字节。它只知道按顺序读取字节，先读第一个字节，再读第二个字节。如果是大端字节序，先读到的就是高位字节，后读到的就是低位字节。小端字节序正好相反。个人觉得之所以会存在小端字节序是由于计算机电路在计算时先处理低位字节，存储单元里的数据按小端字节序存储方便计算。字节序的处理其实只有读取的时候，才必须区分字节序，其他情况都不用考虑。数据长度大于1字节（8bits）时才需要区分字节序。虽然在计算机中存储和具体的平台相关，但是规定在网络中传输的数据采用大端传输，即如果有一串网络流为：010101000100110101010，实际发送时越左边的越先发送到网络中。C语言中处理字节序1234567891011// 参数为16位主机字节序的值，返回值是16位网络字节序的值uing16_t htons(uint16_t host16bitvalue);// 参数为32位主机字节序的值，返回值是32位网络字节序的值uint32_t htonl(uint32_t host32bitvalue);// 参数为16位网络字节序的值，返回值是16位主机字节序的值uint16_t ntohs(uint16_t net16bitvalue);// 参数为16位网络字节序的值，返回值是16位主机字节序的值uint32_t ntohl(uint32_t net32bitvalue);]]></content>
      <categories>
        <category>计算机组成原理</category>
      </categories>
      <tags>
        <tag>字节序</tag>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理层]]></title>
    <url>%2F2019%2F%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[码元官方解释数字通信中对数字信号的计量单位。在使用时间域（或简称为时域）的波形表示数字信号时，代表不同离散数值的基本波形。理解假如基带信号是101011000110111010...，如果直接发送，则每个码元携带一个比特的信息（每个码元只有2种状态），但是如果将信号中的三个比特编为一组，即101，011，000，110，111，010…，三个比特共有8种不同的排列，我们可以用不同的调制方法来表示这种信，如8种不同的振幅，频率，相位等，如果采用相位调制，相位$\phi_0$表示000，$\phi_1$表示001，以此类推，那么接收端如果收到相位是$\phi_0$的信号就知道表示的是000，以此类推，这样一个码元就不知不觉的传输了三个比特位的信号，此时每个码元有8种状态。一个码元可表示的比特数越多，则在接收端进行解调时要正确识别每一种状态就越困难。编码级别如果把n个比特编码成一个码元，则此时编码状态$M=2^n$，其表示当前传输时有多少不同的状态，如8级编码，会有：000、001、010 …奈斯准则码间串扰码元的传输速率是有限制的，超过某上限就会出现码间串扰问题。这是由于在真正传输中，信号在传输时都不是理想化的，如下图就是理想化的高低电平和真实传输时的高低电平。假如此时速度太快，就可能把低电平和高电平弄混。而最高的码元传输速率被奈斯准则限制。奈斯准则内容理想低通信道（能通过信号频率在某值之下）的最高码元传输速率为：$2W Baud$。理想带通信道（能通过信号频率在某范围之内）的最高码元传输速率为：$1W Baud$。W是理想低通信道的带宽，单位为赫(Hz)。Baud 是波特，是码元传输速率的单位，1 波特为每秒传送 1 个码元。波特率单位时间内数据通信系统所传输的码元个数（信号个数），单位是波特（Baud）。比特率表示单位时间内数据通信系统传输的比特数，单位是比特/秒（b/s或bps）。$比特率 = 波特率 * log_2M$香农公式编码级数限制虽然码元传输速率有限制，但是如果我们能尽可能提高编码级数不就能提升信息传输速率了吗？但事实上信号传输速率不受限于调制技术，而是受限于信噪比。举个例子，如果我们是在天气晴朗的一天出门，我们穿任意颜色衣服都能被分辨出来，但是如果我们在沙尘暴天气出门，穿橘黄和橙黄两种颜色的衣服别人自然就认不出来了。在这个比喻中衣服的颜色代表码元，确定衣服的颜色代表信息，沙尘暴就是噪声。香农公式内容带宽受限且有高斯白噪声干扰的信道的极限信息传输速率$C=W \ast log_2(1+PS/PN)（b/s）​$。其中$W$是信道的带宽。$PS$是信号的能量。$PN$是噪声的能量。信噪比：$S/N=10lg{PS/PN}$。举例设带宽是1MHz，信噪比是24dB，则信道的最高信息传输速率为：$C=1M \ast log_2{(1+(10^{2.4}))}=7.98Mbps$。奈氏准则vs香农公式多路复用电路交换中独占电路资源，并不是指用户线和中继线都被此次交换所独占，而是说在两个用户建立连接之后，除非连接中断，否则他们当前所拥有的资源不会被释放，即使他们之间不传输信息。而如何在中继线上实现多组用户通信就是多路复用技术。产生多路复用的物理基础是：传输媒体的带宽或容量往往会大于传输单一信号的需求，使用多路复用，为了有效地利用通信线路，希望一个信道同时传输多路信号。这种技术会将链路/网络资源（如带宽）划分为“资源片”，将资源片分配给各路“呼叫”（calls），每路呼叫独占分配到的资源片进行通信，资源片可能“闲置”常见的复用技术有：频分多路复用、时分多路复用、波分多路复用、码分多路复用。频分多路复用FMD：Frequency-division multiplexing，是指载波带宽被划分为多种不同频带的子信道，每个子信道可以并行传送一路信号的一种多路复用技术。也就是说信道的可用频带被分成若干个互不交叠的频段，每路信号用其中一个频段传输，因而可以用滤波器将它们分别滤出来，然后分别解调接收。时分多路复用TDM：time division multiplexing，它使不同的信号在不同的时间内传送，将整个传输时间分为许多时间间隔（Time Slot，TS，又称为时隙），每个时间片被一路信号占用。TDM就是通过在时间上交叉发送每一路信号的一部分来实现一条电路传送多路信号的。电路上的每一短暂时刻只有一路信号存在。因数字信号是有限个离散值，所以TDM多应用于数字通信系统。波分多路复用将两种或多种不同波长的光载波信号（携带各种信息）在发送端经复用器（亦称合波器，Multiplexer）汇合在一起，并耦合到光线路的同一根光纤中进行传输的技术；在接收端，经解复用器（亦称分波器或称去复用器，Demultiplexer）将各种波长的光载波分离，然后由光接收机作进一步处理以恢复原信号。码分多路复用为每个用户分配一个唯一的mbit的码片序列（chipping sequence），二进制下的0用-1表示，二进制下的1用+1表示。在信道上传输的信号 = 原始数据 码片序列，比如码片序列是：(-1, 1, 1)，需要传一个0，应该是 -1 (-1, 1, 1)，所以传输的就是(1, -1, -1)。同时为了保证数据之间不相互影响，被共享的用户所占有的码片应该相互正交的。即：$\frac{1}{m}S_i \cdot S_j = 0 (i \neq j)​$。而信道上真正传输的数据是各用户发送数据的叠加值。数字信号在模拟信道传输数字信号需要编码后才能传输。常见的三种编码：NRZ编码：进制数字0、1分别用两种电平来表示。常用-5V表示1，+5V表示0。曼切斯特编码：用电压的变化表示0和1：高→低 &lt;=&gt; 0，低→高 &lt;=&gt; 1。差分曼切斯特编码：在码元开始处有无跳变来表示0和1：有 &lt;=&gt; 0，无 &lt;=&gt; 1。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络基础]]></title>
    <url>%2F2019%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[本人是非通信专业学生，加上本身水平有限，对于物理层和计算机网络基础错误会较多，敬请指出。信道信道是数据交换的载体。狭义上说人和人之间交流所承载信息的空气就是信道。广义上说它还可以包括有关的变换装置，这样的话信道往往被分成信道编码器、信道本身和信道译码器。简易通信系统模型如下：计算机网络计算机网络就是互联的、自治的计算机集合。自治指的是所有的计算机直接没有主从关系；互联指的是互联互通，能进行数据交换。计算机网络的本质是一种通信网络，只不过信源和信宿都是主机。它是计算机技术和通信技术的结合。主机（host）诸如手机、电脑、服务器等端系统（end systems）。交换机如果想实现多个计算机之间的互联，按照之前的想法是每两台计算机进行连接，但这样太麻烦，一个好的做法是把这个计算机连接在某一中心上，这个中心把所有连接上来的计算机进行互联，在链路层这个中心叫做交换机。分组分组是带有地址信息的信息小片，可以理解成是计算机把一个文件切片后打成的包裹，由两部分构成：地址信息和真正传输的东西。路由器是计算机网络的一种专用计算机，它只有一个功能，就是转发分组。可以简单的理解为路由器是电子化的邮局，全国所有的邮局之间互联，是包裹能够传递，路由器之间互联，是分组能够正确转发。路由器和交换机的区别是：交换机将计算机连在一起，构成局域网；路由器将局域网连在一起，形成互联网。计算机网络基本原理分组交换技术，也就是拆分分组、传输分组、合并分组的技术。这个技术的优点就是便宜，因为把数据打包成分组和分组拆分都在计算机中进行，网络上只进行分组的转发，就使得网络的结构很简单，路由器设计也很简单。这一中原则被叫做“端到端的原则”，即能在端系统做的事情不在网络上实现。分组交换技术一个主机至少连接一个路由器：数据最终是通过路由器进行转发的，所以一个主机至少得连接一个路由器。分组存储转发：分组完全进入路由器后，路由器按照地址信息检索转发表。注意不是第一个bit或Byte进入时就开始转发，是全部进入才转发。分组独立选择路径：一个文件被分成多个分组，但这些分组之间是独立的，路由器给他们看成相互独立的数据。分组的组装是通过接收方进行的，和网络无关。Internet组成细节角度ISP网络互联形成的网络之网络。由运行各种网路应用的计算设备，光纤、铜缆、无线电等通信链路、路由器和交换机等组成的分组交换设备组成。服务角度是为网络应用提供通信服务的通信基础设施和为网络应用提供的应用编程接口。ISPISP，全称为Internet Service Provider，因特网服务提供商，即指提供互联网服务的公司。能提供拨号上网服务、网上浏览、下载文件、收发电子邮件等服务。网络的结构网络边缘：位于“网络边缘”运行网络应用程序的端系统。接入网络、物理介质：有线或无线的通信链路。网络核心：互联的路由器（或分组转发设备）。构成“网络之网络”的关键。网络应用模型客户/服务器应用模型：依赖于专用服务器，如Web应用。对等应用模型：不依赖专用服务器，通信在对等实体之间进行，如P2P应用。接入网络接入网络是一种用户网络，它连接用户到特定的服务提供商并通过承载网络到达其他网络。两个被用户关心的特征：带宽（数据传输速率，bps）、独占/共享（独占是带宽为某用户独用，共享是多个用户分用同一带宽）。数字用户线路：DSL是以电话线为传输介质的传输技术组合。DSL技术在传递公用电话网络的用户环路上支持对称和非对称传输ADSL：上行速度较慢，下行速度较快）模式。用DSL接入Internet时用户一方会有DSL调制解调器，被接入方会有DSL接入多路复用器与多个用户进行接入。电缆网络又被称为混合光纤同轴电缆网络。也是一种非对称式的接入网络。但它是共享网络，多个用户共同接入一个解调器。常见网络接入家庭接入家庭接入机构（企业）接入无线局域网广域局域网网络核心网络核心的功能是：路由（routing）：确定分组从源到目的传输路径；转发（forwarding）：将分组从路由器的输入端口交换至正确的输出端口。Internet结构一级ISP包含：网通、电信等商业ISP，还包含谷歌、微软等内容提供商网络。IXP：全称：Internet eXchange Point，即互联网交换中心。互联网Internet是由众多的网络互相连接而形成的全球性网络，互联网交换中心负责这些不同的网络之间互相通信的交换点，是互联网的关键基础设施。数据交换方式电路交换包含三个阶段：建立连接、通信、释放连接。最显著的特点是独占电路资源。最典型的是电话网络。（下图的中继线上可以存在多组用户通信，详见复用技术）报文交换报文交换是指把信息整个打包，然后经过存储转发送到目的地。分组交换分组交换是把信息拆分成不同的分组，然后把所有的分组相继发送给路由器，路由器通过路由&amp;转发把数据传输到目的地。和报文交换的区别是：报文交换不拆分信息。和电路交换的区别是：如果把每个分组看成原子单位，区别就是各分组走不同的路径，不需要独占资源。图解三种交换分组交换的优势和报文交换相比：速度快，因为在报文交换时，同一时间只有一个路由器在工作，其他路由器在等待。路由器的存储空间小，最低存储空间和分组大小差不多。和电路交换相比：分组交换允许更多用户同时使用网络，让网络资源充分共享。分组交换的劣势可能产生拥塞（congestion）：分组延迟和丢失。需要协议处理可靠数据传输和拥塞控制。RFC文档Request For Comments（RFC），是一系列以编号排定的文件。文件收集了有关互联网相关信息，以及UNIX和互联网社区的软件文件。目前RFC文件是由Internet Society（ISOC）赞助发行。基本的互联网通信协议都有在RFC文件内详细说明。RFC文件还额外加入许多的论题在标准内，例如对于互联网新开发的协议及发展中所有的记录。因此几乎所有的互联网标准都有收录在RFC文件之中。IETF全称：The Internet Engineering Task Force，国际互联网工程任务组。全球互联网最具权威的技术标准化组织，主要任务是负责互联网相关技术规范的研发和制定，是一个由为互联网技术工程及发展做出贡献的专家自发参与和管理的国际民间机构。主要任务是负责互联网相关技术标准的研发和制定，是国际互联网业界具有一定权威的网络相关技术研究团体。绝大多数国际互联网技术标准出自IETF。时延和网络利用率若令D0表示网络空闲时的时延，D表示网络当前的时延，则在适当的假定条件下，可以用下面的简单公式表示D和D0之间的关系：$D=\frac{D_0}{1-U}$。网络协议network protocol。为进行网络中的数据交换而建立的规则、标准或约定。其中规定了通信实体之间所交换的消息的格式、意义、顺序以及针对收到的消息或发生的事件而产生的动作。也可以说网络协议规定了网络中所有信息的发送和接受过程。协议三要素语义：语义是解释控制信息每个部分的意义。它规定了需要发出何种控制信息，以及完成的动作与做出什么样的响应。语法：语法是用户数据与控制信息的结构与格式，以及数据出现的顺序。时序：时序是对事件发生顺序的详细说明。（也可称为“同步”）。总结：语义表示要做什么，语法表示要怎么做，时序表示做的顺序。速率 &amp; 带宽速率：又称数据率，数据传输速率或比特率。单位bps、kbps、Mbps、Gbps。带宽：数字信道所能传输的最大数据率。单位bps等。丢包如果路由器的缓存满了，再到达的分组会被路由器丢弃，即造成丢包现象。丢包率 = 丢包数 / 已发分组数。分组延迟结点处理延迟：差错检测、确定输出链路；排队延迟：等待输出链路可用、取决于路由器拥塞程度；传输延迟：分组长度/链路带宽；传播延迟：物理链路长度/信号传输速度。流量强度设链路带宽为R(bps)，分组长度为L(bits)，平均每组到达速率为v。则：$L \ast v / R \longrightarrow 0 ​$时：平均排队延迟很小；$L \ast v / R \longrightarrow 1$时：平均排队延迟很大；$L \ast v / R &gt; 1​$时：超出服务能力，延迟 趋向于 无限大。时延带宽积$时延带宽积 = 传播时延 \ast 带宽$，单位：bit。实际意义是：从我们向某一信道上发送第一个bit，到这个bit被接收方接受这个时间里，发送方总共向信道上发送了多少bit。也可以称为以比特为单位的链路长度，比如某段链路长度为n比特。吞吐率/量（Throughput）发送端与接收端之间的传送数据率（b/s）。端到端的吞吐量取决于瓶颈链路。网络体系结构指通信系统的整体设计，它为网络硬件、软件、协议、存取控制和拓扑提供标准。计算机网络是一个非常复杂的系统，需要解决的问题很多并且性质各不相同。所以，在设计时，就使用了“分层”的思想，即将庞大而复杂的问题分为若干较小的易于处理的局部问题。各层之间是按照功能进行分层的，同时每层遵循相应的网络协议完成本层功能。OSI参考模型的通信过程七层结构：物理层、数据链路层、网络层、传输层、对话层、表示层和应用层。端系统需要完成七层的功能，中间系统完成三层功能。协议之间是对等的，比如应用层的协议对发送方来说是如何把信息传输到表示层，而对接收方来说，是如何把从表示层传来的信息还原到应用层。对于后四层，从逻辑上说不需要经过中间系统，所以被称为“端-端层”。OSI参考模型的数据封装后六层每层在把数据向下一层传输时都会加上控制信息。而物理层不再封装，因为到达它的数据已经时二进制数据，直接传输就行。数据链路层传送给物理层时一般加头加尾，其他层只加头。头是首部，尾是循环冗余校验。PDU协议数据单元。可能包括地址：标识发送端/接收端等；差错检测编码：用于差错检测或纠正；协议控制：一些如优先级、服务质量、安全控制等信息。TCP/IP参考模型四层结构：应用层、运输层、网际层和网络接口层。所有的应用都架构在IP上，在网络接口层只要能构建IP，能进行分组就可以算是网络的一部分，这是互联网发展迅速的一大原因。五层参考模型五层结构：物理层、链路层、网络层、传输层和应用层。此模型结合了OSI概念清晰，分工明确的优点和TCP/IP简单实用的优点。五层传输模型的数据封装三种模型对应物理层实现的功能概述核心功能：透明地传送比特流。解决的问题一般如下：接口特性：机械特性：接口的几何形状，位置等等；电气特性：使用电压的高低等等；功能特性：各个引脚的作用等等；规程特性：工作的过程是什么样的，如哪个引脚先发送数据，哪个后发送等。比特编码：用信号的什么特征表示信息，如什么时候用0，什么时候用1。数据率：在物理层上传输数据的速率。比特同步：解决时钟同步问题，发送端何时发送数据，接收端何时接受数据。传输模式：单工通信：一个为确定的发送端、一个为确定的接收端，不能互换。半双工：发送端和接收端可以互换，但是随时间交替的。双工：两端可以同时发送和接受数据。数据链路层功能概述核心功能：在两个相邻结点之间的链路上“透明”地传送数据。解决的问题如下：组帧：来自网络层的数据被加头加尾后形成的数据叫做帧。组帧问题包含：头和尾里包含什么信息等。物理寻址：物理层只进行比特流的传输，其他的都不做。物理寻址是在数据链路层做的，也就是数据链路层传输层给物理层的数据包含处理好的地址。流量控制：使数据的发送和数据的接收尽可能平衡，防止数据太多造成丢失等。差错处理：检测并重传损坏或丢失帧，并避免重复帧。访问（接入）控制：在任一时刻觉得哪个设备拥有链路使用权。网络层功能概述核心功能：负责为分组交换网上的不同主机提供通信服务。选择合适的路由，是源主机运输层所传下来的分组，能够通过网络中的路由器找到目的主机。解决的问题：逻辑寻址：全局唯一逻辑地址，确保数据分组被送达的主机，如IP地址。路由和分组转发：确保在网络中数据能从源主机到目的主机传输层功能核心功能：负责向两个主机中进程之间的通信提供服务。解决的问题：分段与重组：网络层传输的分组大小是有限制的。应用层的SAP寻址：确保将完整报文提交给正确进程，如端口号SAP：Service Access Point，在同一系统中相邻两层的实体进行交互的地方。连接控制：有两种协议，面向连接的TCP和无连接的UDP。流量控制：匹配发送方和接收方的速度。差错控制：如发送的报文接收方没有接受到或者接收方缓冲区由于满把报文丢弃该怎么处理。应用层核心功能：直接为用户的应用进程提供服务。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10-索引]]></title>
    <url>%2F2019%2F10-%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引基础使用索引是因为索引是查询性能优化最有效的手段。Mysql中的索引分为两种：B+树和Hash表，但是我们在这里只介绍基于B+树的索引。INNODB引擎也只支持B+树索引。Mysql的索引是在存储引擎级别设置的。索引匹配原则假如有如下表：1234567CREATE TABLE People( last_name varchar(50) not null, first_name varchar(50) not null, dob date not null, gender enum('m', 'f') not null, key(last_name, first_name, dob));对应的B+树如下：建立的索引对如下类型的查询有效：### 全值匹配和索引中定义的所有列进行匹配，如查找姓名为Cuba Allen，出生于1996-01-01的人。### 匹配最左前缀前面提到的索引可用于查找所有姓为Allen的人，即只使用索引的第一列。### 匹配列前缀也可以只匹配某一列的值的开头部分，例如前面提到的索引可用于查找所有以J开头的姓的人。这里使用了索引的第一列。### 匹配范围值例如前面提到的索引可用于查找姓在Allen和Barrymore之间的人。这里也只用了索引的第一列。### 精确匹配某一列并范围匹配另外一列前面提到的索引也可用于查找所有姓为Allen，并且名字是K开头的人。## 索引分类和创建### 分类#### 普通索引MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了查询数据更快一点。#### 唯一索引索引列中的值必须是唯一的，但是允许为空值，#### 主键索引是一种特殊的唯一索引，不允许有空值。后面会有介绍，在INNODB中，主键索引是聚簇索引。### 创建#### 建表时创建123456CREATE TABLE table_name ( [col_name data_type], ..., [UNIQUE] [INDEX | KEY] [index_name] (col_name[length], ...) [ASC | DESC]);#### 后期添加12ALTER TABLE table_name ADD [UNIQUE] [INDEX | KEY] [index_name](col_name[length], ...) [ASC | DESC]12CREATE [UNIQUE] [INDEX | KEY] index_name ON table_name(col_name[length], ...) [ASC | DESC]INDEX和KEY具有相同的效果。length是指该列在B+树中的关键字所占的长度。## 聚簇索引和非聚簇索引### 聚簇索引聚簇的意思是键值和数据行紧凑地存储在一起，因为无法把数据行放在两个不同的地方，所以一个表只有一个聚簇索引。而主键会被默认添加上聚簇索引，如果没有主键，INNODB会选择一个非空索引来替代，如果没有这样的索引，INNODB会隐式定义一个主键来作为聚簇索引。### 非聚簇索引非聚簇索引的叶子节点仍然是索引节点，只不过有指向对应数据块的指针。又被称为二级索引。INNODB的二级索引其叶子结点上保存的是KEY+PRIMARY COL。### INNODB索引注意：INNODB中主键索引就是聚簇索引。### MyISAM索引]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[B树]]></title>
    <url>%2F2019%2FB%E6%A0%91%2F</url>
    <content type="text"><![CDATA[磁盘访问时间磁盘构造当磁盘驱动器执行读/写功能时。盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头（又叫磁头）下通过，就可以进行数据的读/写了。一般磁盘分为固定头盘（磁头固定）和活动头盘。固定头盘的每一个磁道上都有独立的磁头，它是固定不动的，专门负责这一磁道上数据的读/写。活动头盘 （如上图）的磁头是可移动的。每一个盘面上只有一个磁头（磁头是双向的，因此正反盘面都能读写）。它可以从该面的一个磁道移动到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的（行动整齐划一）。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。### 访问时间典型的磁盘访问时间包括以下三个部分：1. 寻道时间$T_s$：$T_s = s$2. 旋转延迟时间$T_τ$：$T_t = \frac{1}{2r}$3. 磁盘访问时间 ：$T_t=\frac{b}{rN}$$s$是指磁头从当前位置定位到开始点的时间，$b$是传输的字节数，$r$是每秒的转数，$N$是一条磁道上的字节数。$总时间 = T_s + \frac{1}{2r} + \frac{b}{rN}$这其中，时间开销最大的是$s$，台式机的旋转速度一般是7200转/分钟（RPM），即旋转一周需要8.33ms，所以式子中的$s$平均为4.165ms，而且磁臂的移动也需要时间，通常磁盘的平均存储时间是$8-11ms$。而硅存储的常见存取时间是50ns，即$s$约为一次存取时间200000倍。通常一页的长度为$2^{11}-2^{14}$，即使磁盘一般是一次读取连续的几个页面，定位到信息的时间也比存取信息的时间多。所以当大量数据存储在外存磁盘中时，需要一种合理高效的数据结构来降低访问外存的时间：B树。需要说一下，B树的英文名是B-tree，所以有时候有人会把B树叫做B-树，这两个名词是同一个意思。B树的典型执行过程中，B树算法的运行时间取决于DISK-READ和DISK-WRITE。1234x = a pointer to some objectDISK-READ(x)operations of xDISK-WRITE(x)通常一个B树的结点和磁盘的一页一样大，这样一次读写操作能获取更多的信息。而每页能存储多少个数据和关键字大小有关。下图中的B树每个结点有1000个数据（B树中结点的度数为结点数据个数+1，见后面的定义），高度为2。所以它可以存储超过十亿个关键字，查找某个关键字至多进行两次磁盘访问。B树的定义B树的定义每个结点有如下属性：$x.n$：表示当前存储在结点$x$中的关键字个数。每个结点中的关键字以非降序方式存放：$x.key_1 \leq x.key_2 \leq \cdots \leq x.key_n$。$x.leaf$：一个布尔值，如果$x$是叶结点，则为$true$，否则为$false$。每个内部结点还包含包含$x.n+1$个指向其孩子的指针：$x.c_1, x.c_2, \cdots , x.c_n $，叶结点的$c_i$属性没有定义。关键字$x.key_i$对存储在各子树中的关键字范围加以分割：如果$k_i$为任意一个存储在以$x.c_i$为根的子树中的关键字，满足：$k_i \leq x.key_1 \leq k_2 \leq x.key_2 \leq \cdots \leq x.key_{x.n} \leq k_{x.n+1}$。每个叶结点具有相同的深度，即树的高度h。每个结点关键字所包含的关键字个数有上界和下界。用一个被称为B树的最小度数的固定整数$t$来表示这些界，$t \geq 2$。除了根结点外的每个结点都至少有$t-1$个关键字，因此，除了根结点以外的每个内部结点至少有$t$个孩子。如果树非空，根结点至少有一个关键字。每个结点至多可包含$2t-1$个关键字，因此一个内部结点至多可有$2t$个孩子，当一个结点恰好有$2t-1$个关键字时，该结点是满的。$t=2$的树是最简单的，每个内部结点有2个、3个或4个孩子。那么为什么最小度数不能取1呢？因为最小度数取1之后，内部结点（设指向其的指针为p）可以包含0个关键字，此时包含0个关键字的结点只有一个孩子（设为c），这个结点就被浪费了，我们其实可以直接让p指向c。B树的高度对任意一棵包含n（$n \geq 1$）个关键字、最小度数为t的B树来说，有：$h \leq log_t{\frac{n+1}{2}}$。证明：假设根所在的层高度为0，则高度为h的B树在高度为1的层至少包含2个结点，在高度为2的层至少包含$2t$个结点，在高度为3的层至少包含$2t^2$个结点…直到高度为h的层至少包含$2t^{h-1}$个结点。可得关于关键字个数n的关键字：$n \geq 1+(t-1)\sum_{i=1}^h2t^i-1 = 1+2(t-1)(\frac{t^h-1}{t-1})=2t^h-1$$\Longrightarrow t^h \leq (n+1)/2$$\Longrightarrow h \leq log_t{\frac{n+1}{2}}$B树的阶我们经常会遇到一个B数的术语：阶，假如树中的结点最多含有m个孩子，此B树的阶为m。当阶为偶数的时候，我们可以把定义中的$t$替换成$m/2$，但是当阶为奇数的时候就要考虑一个问题了，除根结点外的每个内部结点至少含有ceil(m/2)个结点还是floor(m/2)个结点？应该是ceil(m/2)，因为除了根结点每个结点的孩子个数满足：$t \leq keyNum \leq 2t$，如果取floor(m/2)会发现无法满足上式，所以一棵含有n个总关键字数的m阶的B树的最大高度是：$log_{ceil(m/2)}(n+1)/2$。B树的操作以下的操作都遵循两个规定：B树的根结点始终在主存中，这样就不用对根做DISK-READ操作。然而，当根结点被改变后需要对根结点做一次DISK-WRITE操作。任何被当做参数的结点在被传递之前，都要对它们先做一次DISK-READ操作。搜索设$x$是根结点，被搜索的关键字是$k$。需要说明一下，伪代码中$key$和$c$的起始下标都为1。NIL代表空。### 插入插入的时候会遇到两种情况：1. 将新的关键字插在一个已经存在但未满的结点上：直接插入；2. 将新的关键字插在一个已经存在但已满的结点上：分裂后插入；#### 分裂将一个满的结点$y$（有$2t-1$个关键字）按照中间关键字分裂成两个各含有$t-1$个关键字的结点，中间关键字被升到$y$的父结点。如果$y$的父结点也是满的，也需要分裂，最终满结点的分裂会向上传播。如果向上传播时全程都是满结点会把根结点分裂，使B树的高度增1。分裂是使B树增高的唯一办法。但是在实际操作中不是等到找出插入过程中实际要分裂的结点才做分裂，而是在沿着树向下查找时分裂所有遇到的满结点，这样就能保证在插入的时候节点一定非满。$x$是被分裂的结点的父节点，$y$是$x$的第$i$个孩子。#### 非满结点插入$x$是被插入的节点，$k$是插入的键。解释几行代码：- 12行：被操作的节点从磁盘中读入到内存中，然后在内存中进行操作。- 7行+17行：每次插入的都是叶节点。#### 完整插入过程此时对根的分裂需要创建两个节点，而且对根的分裂是B树长高的唯一办法。而且在分裂之后我们会发现根节点必然会有一个关键字，这也对应了定义中的B树的根至少有两个孩子。### 创建分配空节点：分配之后循环调用插入即可。### 删除在删除时需要注意两个部分：1. 除根节点外，被删除关键字的节点在删除后仍然要满足$keyNum \geq t-1$。2. 删除后需要重新安排这个结点的孩子。#### 操作1. 如果关键字$k$在结点$x$中，并且$x$是叶节点，从$x$中删除$k$2. 如果关键字$k$在结点$x$中，但$x$是内部非根节点：上移孩子结点中的某相近元素（“左孩子最右边的节点”或“右孩子最左边的节点”）到父节点中，并且递归被上移的孩子。删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于$ceil(m/2)-1$，则需要看其某相邻兄弟结点是否贫困（结点中元素个数等于$ceil(m/2)-1$）如果非贫困，则父节点下降一个元素来此节点，兄弟结点上升一个元素。如果其相邻兄弟都贫困，则该结点与其相邻的某一兄弟结点进行“合并“成一个结点。#### 举例- 刪除H：直接删除- 删除T：W上升到T的位置，4上升到W的位置- 删除R：删除导致只有1个元素，已经小于最小元素数目$ceil(5/2)-1=2$，由于右相邻兄弟结点不贫困，所以先向父节点借一个元素T下移到该叶子结点中，代替原来S的位置，S前移；然后W上移到父结点中，X、Y、Z依次前移。- 删除E：因为E所在的结点和相邻的兄弟结点的关键字都刚好达标，删除后不能再向父节点借元素，所以需要该节点与某相邻兄弟结点进行合并操作；首先移动父结点中的元素（该元素在两个需要合并的两个结点元素之间）下移到其子结点中，然后将这两个结点进行合并成一个结点。所以在该实例中，咱们首先将父节点中的元素D下移到已经删除E而只有F的结点中，然后将含有D和F的结点与含有A和C的相邻兄弟结点进行合并成一个结点。但是此时还没有结束，此时的情况如下图第一幅，此时父节点只包含一个元素G，没达标。如果这个问题结点的相邻兄弟比较丰满，则可以向父结点借一个元素。假设这时右兄弟结点（含有Q,X）含有的元素个数大于2，咱们可以将M下移到元素很少的子结点中，将Q上移到M的位置，但此时咱们没有办法去借一个元素，只能与兄弟结点进行合并成一个结点，而根结点中的唯一元素M下移到子结点，即树的高度减少一层。B+树在B树中，我们做操作的时候都默认了关键字和其对应的数据都存在一个页面中，但是实际上可以只存储关键字，而且仅存关键字可以让每页能存储更多的数据。基于此点和为了更好的在文件系统中存取数据，诞生了B+树。定义B+树可以被视为每个节点仅包含键（不是键值对），并且链接了各叶节点叶的B树。和B树的区别如下：所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 （而B树的叶子节点并没有包括全部需要查找的信息）。所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 （而B树的非终节点也包含需要查找的有效信息）### 为什么数据库使用B+树作为索引- B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。- B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。而B+树只要遍历叶子节点就可以实现整棵树的遍历。- B+树对range-query的支持很强大。比如要查5-10之间的，B+树一把到5这个标记，再一把到10，然后串起来就行了，B树就非常麻烦。### 分裂B+树的分裂和B树没有太大区别，只是分裂后注意叶子结点需要有链接到下个结点的指针。## B*树### 定义B*树是B+树的变体，在B+树的基础上（所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针）:- B*树中非根和非叶子结点再增加指向兄弟的指针；- B*树定义了非叶子结点关键字个数至少为$ceil((2/3) \ast m)$，即块的最低使用率为2/3（代替B+树的1/2）。分裂当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。总结B树及其变形可以非常好的处理一维空间存储的问题。它的思想就是把一维直线分为若干段线段，当我们查找满足某个要求的点的时候，只要去查找它所属的线段即可。也可以说要查找某一满足条件的点，先去找到满足条件的线段，然后遍历所在线段上的点，即可找到答案。对比B树：有序数组+平衡多叉树；B+树：有序数组链表+平衡多叉树；B*树：一棵丰满的B+树。参考https://blog.csdn.net/v_JULY_v/article/details/6530142https://en.wikipedia.org/wiki/B%2B_tree#Overviewhttps://en.wikipedia.org/wiki/B-tree算法导论]]></content>
      <categories>
        <category>DSA</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>DSA</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09-Mysql结构和存储引擎]]></title>
    <url>%2F2019%2F09-Mysql%E7%BB%93%E6%9E%84%E5%92%8C%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[MySQL体系结构Mysql大致可以被分为四层：第一层Connectors指的是不同语言中与SQL的交互第二层Management Serveices &amp; Utilities：系统管理和控制工具，例如备份恢复、Mysql复制、集群等Connection Pool: 连接池，管理缓冲用户连接、用户名、密码、权限校验、线程处理等需要缓存的需求SQL Interface: SQL接口，接受用户的SQL命令，并且返回用户需要查询的结果。比如select * from就是调用SQL Interface。Parser: 解析器，SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本， 主要功能：将SQL语句分解成数据结构，并将这个结构传递到后续步骤，以后SQL语句的传递和处理就是基于这个结构的如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的Optimizer：查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化。他使用的是“选取-投影-联接”策略进行查询。 用一个例子就可以理解：select uid,name from user where gender = 1;先根据where语句进行选取，而不是先将表全部查询出来以后再进行gender过滤再根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤再将这两个查询条件联接起来生成最终查询结果Cache和Buffer（高速缓存区）：查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。 通过LRU算法将数据的冷端溢出，未来得及时刷新到磁盘的数据页，叫脏页。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等。第三级Engine：存储引擎。存储引擎是MySql中具体的与文件打交道的子系统。现在有很多种存储引擎，各个存储引擎的优势各不一样，最常用的MyISAM，InnoDB，BDB。默认下MySql是使用InnoDB引擎。第四级外存中真正存储数据的物理空间。存储引擎Mysql中真正和外存打交道的是存储引擎。一般有两种最常见的引擎：INNODB是缓存层，由一个大的innodb buffer pool和很多个其他小的内存组件组成，用来缓冲数据的，innodb的数据读取写入不是直接操作文件，而是从文件加载到缓存，在缓冲里做操作，再flush到磁盘文件。所以INNODE可以支持事务。是各种后台线程，例如IO线程、日志线程、监控线程等；是各种数据文件层，例如INNODB的数据文件、redo log等；MYISAMMYISAM存储引擎的数据组织形式是一种堆表，和索引组织表相区别（INNODB的数据组织形式是索引组织表）。 例如插入一条数据id=2（d为主键，表里已经存在id=1和id=3数据）。MYISAM存储引擎：如果插入id=2，数据的插入位置和id=1 id=3无关系，也就是无序的； 堆表的插入特性是无序的。INNODB存储引擎：如果插入id=2，会插入到id=1和id=3之间，因为INNODB是索引组织表是有有序的；索引组织表的最大特点是根据主键去查询效率非常快。MYISAM存储引擎不支持事务；INNODB存储引擎的缓存不缓存数据，只缓存索引。数据缓存是交给操作系统的内存来缓存的。这种会有问题：如果查询一个大表，会消耗大量操作系统内存，如果表中碎片很大可能会浪费大量操作系统内存。锁粒度较大：使用的是读写锁（读的时候不允许写，写的时候不允许读，只有读的时候允许读）参考：https://www.cnblogs.com/zhoubaojian/articles/7866231.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08-Mysql的锁]]></title>
    <url>%2F2019%2F08-Mysql%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[数据库的锁按照不同的分类可以分成很多类，常见的分类如下：悲观锁 &amp; 乐观锁悲观锁悲观锁就是在操作数据时，总是认为操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中的synchronized很相似，所以悲观锁需要耗费较多的时间。悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。不用考虑悲观锁，它对于应用程序员是透明的。说到这里，由悲观锁涉及到的另外两个锁概念就出来了，它们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。参考：https://isjinhao.github.io/2019/06-%E4%BA%8B%E5%8A%A1/#more乐观锁首先先说一下，乐观锁不是锁，只是人们都习惯这样叫。对于乐观锁来说在操作数据时，总是认为操作不会出现数据冲突，所以不会上锁。那么如何控制并发问题呢？这其实是在应用程序级完成的功能，一般来说可以用数据版本（Version）记录机制实现。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的version字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。例数据库表设计，三个字段，分别是id，value，version。每次更新表中的value字段时，为了防止发生冲突，需要这样两步操作：1select id,value,version from TABLE where id=#&#123;id&#125;123update TABLEset value=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;;按加锁的粒度分表级锁是Mysql中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分ySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。特点是开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。行级锁行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。分为共享锁和排他锁。特点是开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。页级锁表级锁是Mysql中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。特点是开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。存储引擎参考：https://isjinhao.github.io/2019/09-Mysql%E7%BB%93%E6%9E%84%E5%92%8C%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/#more]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09-磁盘存储器的管理]]></title>
    <url>%2F2019%2F09-%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[文件管理的目标是管理文件的组织方式，管理文件的访问权等。而磁盘存储器的管理是管理存储器的使用，如何高效利用存储器。他俩是棋与棋盘的关系。连续组织方式文件的信息存放在若干连续的物理块中。优点简单支持顺序存取和随机存取顺序存取速度快，所需的磁盘寻道次数和寻道时间最少缺点文件不能动态增长（预留空间：浪费、重新分配和移动）不利于文件插入和删除外部碎片问题链接组织方式隐式链接在文件的目录中记录该文件的第一和最后一个盘块的指针，每一个盘块的指针指向文件的下一物理块号。优点文件可动态增长有利于文件的插入和删除提高了磁盘空间利用率,不存在外部碎片问题缺点存取速度慢，不适于随机存取可靠性问题，如指针出错更多的寻道次数和寻道时间链接指针占用一定的空间显示链接将链接文件各物理块的指针显示地放在内存的一张链接表（文件分配表，File Allocation Table）中。在FCB的物理地址中填写其首指针所对应的盘块号。由于文件分配表示存储在内存中的，可以大大减少访问磁盘的次数。FAT微软公司早、中期推出的操作系统一直都是采用的FAT技术，即利用文件分配表FAT来记录每个文件中所有盘块之间的链接。FAT中引入了“卷”的概念，支持将一个物理磁盘分成四个逻辑磁盘，每个逻辑磁盘就是一个卷（也称为分区），每个卷都可以被单独格式化和使用。把盘块作为基本分配单位，同时每个分区中都配有两张相同的文件分配表FAT1和FAT2。FAT技术的发展有三个阶段：FAT12、FAT16和FAT32FAT12FAT表的每个表项占用12个bit。所以最多有$2^{12}$个表项，每个盘块的大小是512B，则每个磁盘分区的容量是2MB，能处理的磁盘最大容量是8MB。为了增大FAT能管理的最大容量，引入了“簇”的概念，每个簇是一组相邻的扇区，这样如果分配时以簇为单位进行分配就能管理更大的磁盘容量，但是相应的簇内零头也会更大，降低磁盘的利用率。FAT16FAT表的每个表项占用16个bit。最多有$2^{16}$个表项。FAT32FAT表的每个表项占用16个bit。最多有$2^{32}$个表项。同时每个簇固定为4KB。所以最大可管理$4 \ast 2^{10} \ast 2^{32} = 2TB$大小的空间。NTFS索引组织方式单级索引组织方式一个文件的信息存放在若干不连续物理块中，系统为每个文件建立一个专用数据结构索引表，并将这些块的块号存放在一个索引表中。一个索引表就是磁盘块地址数组，其中第i个条目指向文件的第i块。·### 多级索引组织方式增量式索引组织方式可以更好的满足大、中、小文件的组织。文件存储空间的管理文件存储空间的管理包括空闲块的组织分配和回收。空闲表法把一个连续未分配区域称为“空闲文件”，系统为所有空闲文件单独建立一个目录。表目内容：序号，第一个空白块号，空白块个数。分配算法：内存管理中的首次适应算法、循环首次适应算法。合并：空闲区邻接合并空闲链表法空闲盘块链：所有空闲盘块拉成一条链，分配时从头分配，回收时链接在尾部。空闲盘区链：每个连续的盘块组成一个盘区，每个盘区包含本盘区的大小和下一个盘区的地址。位示图法用一串二进制位反映磁盘空间中分配使用情况，每个物理块对应一位，分配物理块为1，否则为0。申请物理块时，可以在位示图中查找为0的位，返回对应物理块号；归还时；将对应位转置0。成组链接法（重点）把所有的空闲盘块按每n个一组分成m个组。最后一个组放在内存的空闲盘块号栈中，其他组存在外存上。空闲盘块号栈是一个临界资源，只允许一个进程同时访问。数据结构，一个size为n+1的栈。图上是一个倒着的的栈（栈底在上方，栈顶在下方）一个n+1的栈实际可用盘块只有n（图上只有99个可用盘块），因为栈底是一个计数器，指示当前有多少个可用盘块，但是可用盘块中有一个是指向下一个组，即stack[1]指向下一个组。如果stack[1]==0表示此时是最后一组。分配时从栈顶开始向下分配，直至分配出n-1个盘块，此时如果再想分配一个块就需要把下一个组调入空闲盘块号栈。调入后新组覆盖旧组。然后把新组在外存中占用的盘块分配出去。回收时从栈底向上回收，如果计数器==100时还有空闲盘块（设这个盘块编号为p）要回收，就把空闲盘块号栈内的组取出来存在p中，在空闲盘块号栈内新开辟一个组，新组的stack[1]指向p。例此题题目及来源：https://blog.csdn.net/ajay666/article/details/73569654分配3个盘块后，回收它所占的5个盘块，回收的盘块号依次为700、711、703、788、701，画出分配回收过程。第一次分配第二次分配注意：300号盘块中存储的组信息调入空闲盘块号栈之后其自己也可以被分配。第三次分配第一次回收第二次回收第三次&amp;第四次&amp;第五次回收]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么硬链接不能作用于目录]]></title>
    <url>%2F2019%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E7%A1%AC%E9%93%BE%E6%8E%A5%E4%B8%8D%E8%83%BD%E4%BD%9C%E7%94%A8%E4%BA%8E%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[笔者最初遇见这个问题的时候是因为知道了在Linux系统中，目录其实也是一种文件，只不过是一种比较特殊的文件，既然都是文件，那为什么不能对它做硬链接呢？想弄明白这个，就需要知道两个知识，目录和文件共享。因为链接的目的就是要实现文件共享。通常可以定义为文件控制块（FCB）的有序集合。但是并不是说目录中的每一个目录项都是一个FCB，只能是每一个目录项都能唯一确定一个FCB。这是由于如果每个目录项都是FCB会引起文件共享问题。比如下图：对于文件F8，D5:p、D6:e、D3:p都保存了F8的物理地址，即从某个盘块开始，总长度多少等。此时如果D6:e对F8进行了删除操作，D5:p和D3:P都无法察觉，仍然会认为在它们存储的位置上有文件，即一个目录项对文件的操作对其他目录项来说是不可见的。为了解决这个问题，引入索引节点。将文件的物理地址和其他的属性放在索引结点中，只在目录项中存放文件名和指向索引结点的指针。任何用户对文件进行操作，引起相应索引结点内容的改变。此种方法即Linux中的硬链接。所以如果我们对文件做硬链接，比如对Test r做硬链接生成thirdHardLink，那么就是thirdHardLink的指针指向索引节点，索引节点的count修改为3。Linux限制了对目录做硬链接，那么假如我们是设计者，想对一个目录做硬链接可以怎么做呢？第一种方法是把对目录生成的硬链接单独作为一种文件类型，如果我们想使用目录中的某个文件时，操作系统的处理步骤是HardLinkDir-&gt;Dir-&gt;指向索引节点的指针指针-&gt;索引节点。可以看出此种方法的代价很大。第二种方法是把目录的每个目录项拷贝一份，但这样不就是拷贝cp了吗，没有必要再实现对目录的硬链接了。第三种方法是把每个目录项的文件名拷贝一份，HardLink的指针指向原目录项的指针位置。但是这种方法也需要把对目录生成的硬链接单独作为一种文件类型，代价很大。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08-文件管理]]></title>
    <url>%2F2019%2F08-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[文件管理概述计算机中有很多的程序和数据都是保存在外存中，在需要使用的时候才调入内存中。而如何保存这些信息是很重要的问题，因为不同类型的文件存储的数据格式不同，但这些格式却必须“迎合”硬件只能存储二进制数据的硬性条件。所以操作系统提供了文件管理的功能，让使用者能在不了解文件特性和外存特性的情况下完成文件的存储和查找等功能。同时还提供了文件共享和安全管理等功能。文件系统 &amp; 文件操作系统中负责管理和存储文件信息的软件称为文件管理系统，简称文件系统。包含：文件系统的接口，对对象操纵和管理的软件集合，对象及属性三部分。它负责对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。包含创建文件、删除文件等功能。文件是指具有文件名的若干相关元素的集合，可以分成有结构文件和无结构文件，无结构文件可以看成一个字符流。有结构文件是由一组记录的集合，记录又是一组数据项的集合。数据项：用来描述一个对象的某种属性的字符集。例如学生的学号、姓名等。记录：一组数据项的集合，用来描述一个对象在某方面的属性，例如学生的成绩。能唯一标识一个记录的一个或多个数据项叫做关键字。文件类型不同的文件类型由于本身存储的信息具有不同的结构，在管理的时候也是不同。所以文件会被分成很多类型，下面是常用的文件分类方法：按用途分类：系统文件、库文件、用户文件。按文件中数据的形式分类：源文件、目标文件、可执行文件。按存储控制属性分类：可读、可写、可执行文件。按组织形式和处理方法分类：普通文件、目录文件、特殊文件。剖析文件和目录我们刚才在定义中说道，文件是指具有文件名的若干相关元素的集合，在有结构文件中这些元素是数据项集合的集合，在无结构文件指的是字符流。所以文件的概念中本身是：文件系统的层次结构文件系统从底层到高层可分成三部分：对象及其属性、对对象操纵和管理的软件集合、文件系统接口：对象及其属性：文件管理系统管理的文件如下：文件：在文件管理系统中有着各种不同类型的文件，它们都作为文件管理的直接对象。目录：用于对文件的存储和检索，目录的每个目录项包含了一个文件或目录的信息。磁盘存储空间：文件和目录必定占用存储空间，对这部分空间的有效管理不仅能提高外存的利用率，而且能提高对文件的存取速度。对对象操纵和管理的软件集合：该层是文件管理系统的核心部分。文件系统的功能大多是在这一层实现的。如：文件存储的管理、文件目录的管理、将文件的逻辑地址转换为物理地址的机制、文件读写控制的管理、文件的共享和保护等功能。这些功能被可分为四层：I/O控制层：文件系统的最底层、主要由磁盘驱动程序等组成。基本文件系统层：主要用于处理内存和磁盘之间数据块的交换。基本I/O管理程序：完成与磁盘I/O有关的事务，如将文件的逻辑块号转换为物理块号、管理磁盘中的空闲盘块、I/O缓冲的指定等。逻辑文件系统：管控对文件的操作，如控制用户或应用程序对文件的读写等。文件系统的接口：操作系统提供给用户或应用程序用来使用文件系统的接口：命令接口：用户与文件系统直接交互的接口，如Shell命令。程序接口：应用程序可以通过一系列命令调用文件系统的服务。文件的打开和关闭当用户要求对一个文件实施多次读/写操作时，如果每次都检索目录效率较低，所以为了避免多次重复的检索目录，OS提供了“打开（Open）”操作，当此操作被执行时，OS会把被打开文件的信息存为“打开文件表”的一个条目，然后把这个条目编号返回用户，这样用户就可以通过这个编号和文件之间建立一个连接，也就可以进行文件的读写等操作。当用户再次向系统发出请求时，把这个编号提交给OS，OS通过这个编号在打开文件表中查找文件信息就可以减少检索时间。而关闭就是OS从“打开文件表”上删除此条目，这样断开了用户和文件之间的连接。文件的逻辑结构和物理结构逻辑结构：从用户的角度来看，文件是能被存取的基本单位。物理结构：文件在磁盘上存储时的组织形式。逻辑文件按结构分类有结构文件：每个文件用于描述实体集中的一个实体。每个记录的长度对OS来说都是可知的。但记录之间可以分为定长和变长两种。定长记录：所有记录的长度都是相同的、所有记录中的各数据项都处在记录中相同的位置具有相同的顺序和长度。变长记录：各记录的长度不相同。比如论文的摘要可能长度差距很大，不能在存储之前估计出所需要的空间。无结构文件：系统中运行的大量的源程序、可执行文件、文本文件等都是无结构文件，即流式文件。其文件长度是以字节为单位的。逻辑文件按组织方式分类组织方式指的是文件中记录的组织方式。只对有结构文件有效。可以分成：顺序文件、索引文件、索引顺序文件。顺序文件指由一系列记录按某种顺序排列所形成的的文件。串结构：按存入时间的先后顺序排列。所以检索时必须从头挨个查找，效率低。顺序结构：用户指定一个字段作为关键字，他可以是任意类型的变量。如sql文件。索引文件为变长记录文件创建一张索引表，索引表是定长记录文件，检索时，先查找索引表，再根据指针所指的地址读取记录。可以解决变长文件记录较难直接存取的问题。索引顺序文件将顺序文件的所有记录分成若干组，为顺序文件建立一张索引表，索引表中为每组的第一个记录建立一个索引项。检索时，先检索索引表，找到记录所在记录组的第一个记录的表项，再顺序查找主文件，得到要求的记录。文件目录文件控制块包含三类信息：基本信息类：文件名、文件物理位置、文件逻辑结构、文件物理结构控制信息类：各类用户的读、写、可执行文件等。使用信息类：文件的建立时间，当前的使用信息，上一次修改的时间，是否被进程锁住等。索引节点为了唯一确定外存中的一个文件，必须要把文件的FCB加载进内存，而每次加载的数据大小是一定的，所以为了一次能多加载进内存一个文件标识。将FCB分成两部分：磁盘索引节点文件主标识符文件类型文件存取权限文件物理地址文件长度文件连接计数：本人理解为硬链接计数文件存取时间内存索引节点。索引节点编号状态访问计数文件所属文件系统的逻辑设备号：不明白链接指针：不明白树形结构目录在树形结构目录中，目录应该保存文件的信息。同时目录的目录项要能既作为目录文件的FCB，又作为数据文件的FCB。文件共享基于有向无循环图实现文件共享此种方法存在问题：比如对于文件F8，D5:p、D6:e、D3:p都保存了F8的物理地址，即从某个盘块开始，总长度多少等。此时如果D6:e对F8进行了删除操作，D5:p和D3:P都无法察觉，仍然会认为在它们存储的位置上有文件，即一个目录项对文件的操作对其他目录项来说是不可见的。利用索引节点引入索引结点，将文件的物理地址和其他的属性放在索引结点中，只在目录项中存放文件名和指向索引结点的指针。由任何用户对文件进行Append操作或修改，引起相应索引结点内容的改变。此种方法即Linux中的硬链接。利用符号链接实现文件共享建立符号链接文件，它是一种特殊类型的文件，其内容是被链接文件的路径名。建立符号链接文件，并不影响原文件，实际上它们各是一个文件。可以建立任意的别名关系，甚至原文件是在其他计算机上。只有文件主才有指向索引结点的指针，而其他共享用户只有该文件的路径名。文件保护访问权&amp;保护域访问权：一个进程能对某对象执行操作的权利，用&lt;对象名，权集&gt;表示，如&lt;F1, {R/W}&gt;表示进程对F1有读和写的权利。保护域：进程对一组对象访问权的集合，进程只能在域内进行操作。进程和域的联系方式进程和域之间是一对多的关系，即一个进程可以联系多个域。此时进程的运行分为多个阶段，每个阶段联系一个域，这样就可以根据运行的实际需要规定进程每个阶段所能访问的对象。访问矩阵R：在域内运行的进程对文件具有读权限W：在域内运行的进程对文件具有写权限$R^\ast$：在域内运行的进程能把其对文件的读权限扩展到其他域中，但在其他域中是R权限，不再是$R^\ast$。$W^\ast$：在域内运行的进程能把其对文件的写权限扩展到其他域中，但在其他域中是W权限，不再是$W^\ast$。S：在域Di中运行的进程能转移到域Dj中运行，如图中在域D3运行的进程能转移到域D2中运行。O：在域中运行的进程能增加或删除对某文件的访问权。Control：在域Di中运行的进程能删除在域Dj中运行进程对各对象的访问权。如图中在D2中运行的进程能删除在D3中运行进程的访问权。访问矩阵的实现访问控制表将访问对象按列划分，为每一列建立一张访问控制表，在该表中把属于对象的所有空项都删除。此时表中的每一项都是一个有序对&lt;域，权集&gt;构成。访问权限表将访问矩阵按行划分，每一行是一个访问权限表，表中的每一项表示该域对某对象的访问权限。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07-输入输出系统]]></title>
    <url>%2F2019%2F07-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[输入输出系统和OS中的其他部分有很大区别，因为其他部分都是在说计算机接受任务后该怎么运行能又快又可靠的完成任务并把结果输出。而输入输出系统是怎么快速稳定的将任务的需求输入和任务的结果输出。又由于输入输出设备种类繁多，比如输入设备中的键盘、鼠标、网卡、摄像头，输出设备中的打印机、音频等。所以输入输出系统被划分很多层次来尽可能屏蔽物理细节。IO系统的基本功能隐藏物理设备的细节：只需要使用简单的命令就能操作各种具有不同实现的硬件完成相应需求。与设备的无关性：用户不需要指定哪些设备完成功能，只需要描述需求，OS会选择一个设备完成功能。提高处理机和IO设备的利用率：IO设备之间一般是相互独立的，因此设备之间能够并行操作，所以OS应让处理机和设备之间能并行操作。对IO设备进行控制：轮询的可编程IO方式。采用中断你的可编程IO方式。直接存储器访问方式。IO通道方式。确保对设备的正确共享。错误处理。IO软件的层次结构用户层软件：提供设备与用户交互的接口，用户可以使用该层提供的功能直接控制设备。设备独立性软件：设备分配，设备保护，设备分配，设备回收，数据缓存等。设备驱动软件：发出控制设备的命令。中断处理程序：保存被中断的进程的CPU环境，转入相应的中断处理程序仅需处理，处理完毕后再恢复被中断进程的现场，返回到被中断的进程。IO系统各模块层次视图块设备：输入输出以数据块为单位的设备。如磁盘。流设备：字符设备的输入输出，如键盘。网络通信接口：网卡。IO设备和设备控制器直接和IO设备对接的是设备控制器。作用接收和识别命令（控制寄存器、命令译码器）：设备控制器将CPU送来的命令写入控制器寄存器中，并进行译码。数据交换（数据寄存器）。设备状态的了解和报告（状态寄存器）。地址识别（地址译码器）：系统中的每个设备都有自己的地址段，设备接口电路中有多个寄存器，一个寄存器有唯一的一个地址，每个地址为I/O端口，该地址称为I/O端口地址。设备控制器必须能识别每个设备的地址。数据缓冲：缓冲器。差错控制：差错检测码。组成设备控制器和处理机的接口：用于实现CPU与设备控制器之间的通信。设备控制器和设备的接口。IO逻辑：在一个设备控制器上，可以连一个或多个设备。相应的，在控制器中就有一个或多个设备接口，一个接口连一台设备，控制器中的I/O逻辑根据处理机发来的地址信号，去选择一个设备接口。控制器中的I/O逻辑用来实现对设备的控制。通过接收CPU 发来的命令和地址信息，对所选设备进行控制CPU如何控制设备控制器CPU控制内存时需要指定指令地址、数据地址等。控制设备控制器亦如此，一般有两种控制方式：利用特定IO指令：利用特殊的IO指令控制设备控制器。内存映像IO：不再区分内存和控制器中的寄存器地址。假如有一个地址K，当0&lt;=K&lt;N时被认为是内存地址，K&gt;=N时被认为是寄存器地址。IO通道有了设备控制器之后，CPU便可以操作控制器完成对IO设备的控制，但是此时数据交换仍然需要CPU的全程参与，所以引入IO通道来使数据传送、IO设备的组织管理等都独立于CPU。通道是独立于CPU的专门负责数据输入/输出传输工作的处理机，对外部设备实现统一管理，代替CPU对输入/输出操作进行控制，从而使输入，输出操作可与CPU并行操作。通道执行通道程序来控制IO操作。与CPU的区别：通道程序指令类型单一通道没有自己的内存，通道程序在主机的内存中，即通道与CPU共享内存。字节多路通道主要连接以字节为单位的低速IO设备。如打印机，终端。按字节交叉方式工作的通道。通常含有许多非分配型子通道，其数量从几十个到数百个，每一个子通道连接一台I/O设备。这些子通道按时间片轮转方式共享主通道。字节多路通道以字节为单位传输信息，它可以分时地执行多个通道程序。当一个通道程序控制某台设备传送一个字节后，通道硬件就控制转去执行另一个通道程序，控制另一台设备传送信息。数组选择通道主要连接磁盘，磁带等高速I/O设备选择通道是按数组方式进行数据传送，每次传送一批数据，故传送速度很高。选择通道在一段时间内只能执行一个通道程序，只允许一台设备进行数据传输。当这台设备数据传输完成后，再选择与通道连接的另一台设备，执行它的相应的通道程序。这种独占性又使得通道利用率很低。数组多路通道主要连接高速设备。结合了数组选择通道传送速度高和字节多路通道能进行分时并行操作的优点。它先为一台设备执行一条通道指令，然后自动转接，为另一台设备执行一条通道指令。它含有多个非分配型的子通道，既有很高的数据传输率，又能获得令人满意的通道利用率对通道程序采用多道程序设计的硬件实现可以连接多台高速设备，数据传输按数组方式，一段时间内可以执行多道通道程序解决瓶颈通道执行通道程序，向控制器发出命令，并具有向CPU发中断信号的功能。一旦CPU发出指令，启动通道，则通道独立于CPU工作。但是，由于通道价格贵，通道数量少，往往使之成为IO的“瓶颈”。解决办法是在不增加通道的前提下，增加设备到主机间的通路，一个通道可连接多个控制器，一个控制器可连接多个设备，形成树形交叉连接。中断机构和中断处理程序https://isjinhao.github.io/2019/%E6%97%B6%E9%92%9F%E4%B8%AD%E6%96%AD/#more设备驱动程序功能接受设备独立性软件发来的命令和参数，将接收到的抽象要求转换为具体要求检查用户IO请求的合法性，了解IO设备的状态，传递有关参数，设置设备的工作方式发出IO命令，如果设备空闲，启动IO设备完成指定的IO操作；如果设备忙碌，则将请求挂在设备队列上等待及时响应由控制器或通道发来的中断请求，并根据其中断类型调用相应的中断处理程序进行处理。对于设置有通道的计算机系统，驱动程序还应能够根据用户的IO请求，自动地构成通道程序。特点驱动程序主要是在设备无关性软件和设备控制器之间的一个通信程序驱动程序与IO设备特性密切相关：通常由硬件厂商提供驱动程序与I/O控制方式密切相关:中断驱动和DMA方式驱动程序与硬件相关,部分代码需用汇编语言编写驱动程序应允许可重入处理过程将抽象要求转换为具体要求通常设备控制器中都有若干个寄存器，分别用于暂存命令、数据和参数等；用户及上层软件对设备控制器的具体情况毫无了解，因而只能向它们发出抽象的要求(命令)，但不能直接传送给设备控制器。需要将抽象要求转换为具体要求(命令码，数据，参数)。例如，将抽象要求中的盘块号转换为磁盘的盘面、磁道号及扇区。这一转换工作只能由驱动程序来完成；在OS中只有驱动程序才同时了解抽象要求和设备控制器中的寄存器情况；也只有它才知道命令、数据和参数应分别送往哪个寄存器。检查IO请求的合法性读出和检查设备的状态传送必要的参数，设置工作方式启动I/O设备在完成上述准备工作后，驱动程序可以向控制器中的命令寄存器传送相应的控制命令对于字符设备，若发出的是写命令，驱动程序将把一个数据传送给控制器；若发出的是读命令，则驱动程序等待接收数据，并通过从控制器中的状态寄存器读入状态字的方法，来确定数据是否到达。驱动程序发出IO命令后，基本的IO是在设备控制器的控制下进行的，通常IO操作所要完成的工作较多，需要一定的时间，如读/写一个盘块中的数据，此时，驱动程序进程把自己阻塞起来，直至中断到来时才将它唤醒。对IO设备的控制方式使用轮询的可编程I/O方式CPU发出启动外设的I/O指令，同时将忙/闲标志置为1。如果外设的工作没有完成，则标志一直为1，CPU不断循环检测该标志，直到标志为不忙为止。使用中断的可编程I/O方式CPU设定I/O设备的初始值，然后不再忙等待，运行其他进程，当前进程阻塞；I/O设备完成对当前数据的处理后，向CPU发出中断，I/O中断处理程序将负责传送剩余数据。直接存储器访问(DMA)方式采用中断驱动IO方式时的CPU，是以字为单位进行干预的。如果将这种方式用于块设备的I／O，是极其低效的。如：为了从磁盘中读出1KB的数据块；需要中断1K次CPU。而DMA方式使用独立的DMA控制器代替CPU的工作，I/O设备与DMA通信，DMA在传输完成一个数据缓冲区之后再向CPU发中断。数据传输的基本单位是数据块，即CPU与IO设备之间，每次传送至少是一个数据块，主要用在块设备的IO操作中。在DMA方式中，利用总线直接连接外设和内存，由DMA控制机构窃取总线占有权，完成外设与内存间的成批数据交换。所传送的数据是从设备直接送入内存的，或者相反。仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在控制器的控制下完成的，不再需要CPU进行干预。I/O通道控制方式使用DMA方式，CPU每发出一条I/O指令，只能读写一个连续的数据块。如果需要一次去读多个离散的数据块且将它们分别送到不同的内存区域，则需要CPU分别发出多条I/O指令及进行多次中断处理，才能完成。而IO通道可实现CPU、通道和I/O设备三者的并行操作，进一步提高CPU与外设之间的并行工作能力，使I/O操作形成独立于CPU的体系，减少CPU的负担，使外设与内存的数据交换更加灵活，从而更有效地提高整个系统的资源利用率。参见4.4。与设备无关的I/O软件为了便于对外设进行管理，系统对每台进入计算机系统中的设备都给定一个对应的编号，作为调用时识别和区分设备用。这种编号无任何重复，一般被称为设备的绝对号（或物理设备名）。早期操作系统，应用程序直接使用物理设备名称，非常不灵活。所以引入逻辑设备名，规定用户申请外设时，只需要向系统说明所需用的某类设备真正在实际中使用哪台设备，由系统根据这类设备的应用情况作出分配。设备分配在多道程序环境下，设备不允许用户自行使用，而必须由系统分配。对于进程的IO请求，只要是安全（无死锁），设备分配程序便按照一定的策略进行设备分配。数据结构：系统设备表SDT：System Device Table。整个系统中只有一张，全面反映了系统中的外设资源的类型、数量、占用情况等。在SDT表中，每个接入系统中的外围设备都占有一个表目项。登录了该设备的名称、标识、设备控制表DCT的入口地址、设备驱动程序的入口地址及占用设备的进程名称等相关信息。设备控制表DCT ：Device Control Table。每台设备都有一张设备控制表DCT，用于记录本设备的情况。Type：设备类型Deviceid:设备标识符设备队列队首指针设备状态：标识设备忙或者空闲；与设备连接的控制器表指针。重复执行次数控制器控制表COCT：Controller Control Table。每个控制器都有一张，用于记录某控制器的使用分配情况及与该控制器相连的通道的情况。控制器号：控制器的内部标识符。控制器状态：控制器忙/闲，好/坏的状态标志。通道指针：指向与该控制器相联的通道控制表CHCT，当控制器与若干通道连接时该项内含多个指针。等待队列指针：指向等待该控制器的I/O进程队列通道控制表CHCT：Channel Control Table。反映了通道的情况，系统中的每个通道一张CHCT。通道号：通道内部标识符通道状态：通道的各种状态（好/坏，已分/未分等）的反映等待队列指针：等待该通道的I/O进程队列的首位置设备分配算法用户层的I/O软件系统调用与库函数用户层软件必须使用一组系统调用来取得操作系统服务，在高级语言中都提供了相应的库函数来完成此功能。SPOOLing程序多道程序技术将一台CPU虚拟为多台CPU，从而可以提高CPU的利用率。而SPOOLing系统是模拟脱机输入输出系统来实现多个用户共享一台物理IO设备。脱机输入输出系统的IO处理机 对应 SPOOLing程序。脱机输入输出系统的高速缓冲 对应 内存。缓冲区单缓冲区双缓冲区为输入或输出分配两个缓冲区，让两个缓冲区交替工作，形成并行操作的方式。环形缓冲区空缓冲区R：用于存放数据（指针：Nexti）已装满数据的缓冲区G：其中的数据提供给进程使用。（指针：Nextg）现行工作缓冲区C：当前进程使用的缓冲区。（指针：Current）磁盘存储器的性能和调度当磁盘驱动器执行读/写功能时。盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头（又叫磁头）下通过，就可以进行数据的读/写了。一般磁盘分为固定头盘（磁头固定）和活动头盘。固定头盘的每一个磁道上都有独立的磁头，它是固定不动的，专门负责这一磁道上数据的读/写。活动头盘 （如上图）的磁头是可移动的。每一个盘面上只有一个磁头（磁头是双向的，因此正反盘面都能读写）。它可以从该面的一个磁道移动到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的（行动整齐划一）。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。磁盘访问时间寻道时间$T_s$：$T_s = s$旋转延迟时间$T_τ​$：$T_t = \frac{1}{2r}​$磁盘访问时间 ：$T_t=\frac{b}{rN}$$s$是指磁头从当前位置定位到开始点的时间，$b$是传输的字节数，$r$是每秒的转数，$N$是一条磁道上的字节数。$总时间 = T_s + \frac{1}{2r} + \frac{b}{rN}$磁盘调度算法假设磁盘访问序列：98，183，37，122，14，124，65，67，读写头起始位置：53。先来先服务按访问请求到达的先后次序服务。最短寻道时间优先扫描算法当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方向，并为经过的访问请求服务，如此反复。循环扫描算法CSCAN算法规定磁头单向移动，例如由里向外移动，当磁头移到最外的磁道并访问后磁头立即返回到最里的欲访问磁道，即最小磁道号紧接最大磁道号构成循环，进行循环扫描。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07-Mysql高级操作]]></title>
    <url>%2F2019%2F07-Mysql%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[数据这个是本人数据库课程设计中的表结构，数据库课程设计写的是学院成绩管理系统，就是可以通过excel把学生的绩点、竞赛情况、大创项目情况导入到系统中，然后学生、班长、辅导员三个级别的用户可以从三个层次看到成绩。表结构：studentinfos：学号、密码、姓名、专业、班级、绩点、级别（学生是第一级）courses：课号、姓名、类型（必修课、公共选修课、专业选修课等）、重要系数（理学院套餐、专业核心课程一般是1.2，选修课等一般是1.0）、学分、年度。scores：唯一标识（没吊用…）、学号、课号、成绩、年度、学期classdamins：班号、密码、班级名称、级别（班长是第二级别）candp：唯一标识、项目或比赛的名称、年度、级别、是否是负责人、学号、状态视图语法1234CREATE [OR REPLACE] [ALGORITHM = &#123;UNDEFINED | MERGE | TEMPTABLE&#125;]VIEW view_name [(column_list)]AS SELECT_statement[WITH [CASCADED | LOCAL] CHECK OPTION]把每个班学生的绩点、学分、通过率创建一个视图：classstudentscores12345678910111213141516171819CREATE OR REPLACE VIEW classstudentscores ASSELECT `scores`.`stu_id` AS `id`, `studentinfos`.`name` AS `name`, `studentinfos`.`pwd` AS `pwd`, `studentinfos`.`cclass` AS `cclass`, `studentinfos`.`gpa` AS `gpa`, sum(`courses`.`credit`) AS `allcre`, `getStudentPassRate` (`scores`.`stu_id`) AS `passrate`FROM `studentinfos`, `scores`, `courses`WHERE `studentinfos`.`id` = `scores`.`stu_id` AND `scores`.`cou_id` = `courses`.`id` AND `scores`.`score` &gt; 59GROUP BY `scores`.`stu_id`更新视图视图是可以更新的，对视图的更新最终会反应到基本表上，但是并非所有的视图都是可更新的。如果视图包含下述结构中的任何一种，那么它就是不可更新的：聚合函数（SUM(), MIN(), MAX(), COUNT()等）。DISTINCTGROUP BYHAVINGUNION或UNION ALL位于选择列表中的子查询JoinFROM子句中的不可更新视图WHERE子句中的子查询，引用FROM子句中的表。ALGORITHM = TEMPTABLE（使用临时表总会使视图成为不可更新的）。WITH CHECK OPTIONLOCAL参数表示更新视图时只要满足该视图本身定义的条件即可。CASCADED参数表示更新视图时需要满足所有相关视图和表的条件。没有指明时，该参数为默认值。总结使用with check option之后，通过视图进行的修改，必须也能通过该视图看到修改后的结果。总结如下：视图只操作它可以查询出来的数据，对于它查询不出的数据，即使基表有，也不可以通过视图来操作。对于update，有with check option，要保证update后，数据要被视图查询出来对于delete，有无with check option都一样对于insert，有with check option，要保证insert后，数据要被视图查询出来对于没有where子句的视图，使用with check option是多余的视图创建算法MERGE算法：MySQL首先将输入查询与定义视图的SELECT语句组合成单个查询。 然后MySQL执行组合查询返回结果集。 如果SELECT语句包含集合函数、DISTINCT、GROUP BY、HAVING、LIMIT、UNION、UNION ALL、子查询，则不允许使用MERGE算法。如果SELECT语句无引用表，则也不允许使用MERGE算法。 如果不允许MERGE算法，MySQL将算法更改为UNDEFINED。使用TEMPTABLE算法，MySQL首先根据定义视图的SELECT语句创建一个临时表，然后针对该临时表执行输入查询。因为MySQL必须创建临时表来存储结果集并将数据从基表移动到临时表，所以TEMPTABLE算法的效率比MERGE算法效率低。 另外，使用TEMPTABLE算法的视图是不可更新的。原文链接：https://www.yiibai.com/mysql/create-sql-views-mysql.html存储过程教程链接：https://www.yiibai.com/mysql/stored-procedure.html一定要注意，Mysql的游标只能用于存储过程和函数。例：获得班级的平均绩点123456789101112131415161718192021222324drop procedure IF EXISTS getClassGpa;create procedure getClassGpa(IN `classID` varchar(20), OUT `avgpa` double)BEGIN DECLARE cgpa DOUBLE; DECLARE sum DOUBLE DEFAULT 0.0; DECLARE done int DEFAULT 0; DECLARE num int; DECLARE cur cursor for select gpa from studentinfos where cclass = classID; DECLARE CONTINUE HANDLER for not found set done = TRUE; set sum=0.0; set num=0; open cur; read_loop:LOOP FETCH CUR INTO cgpa; if done then leave read_loop; end if; set sum = sum + cgpa; set num = num+1; end loop; close cur; set avgpa = sum/num; SELECT sum,avgpa;END函数本质上和存储过程没区别。只是函数只能返回一个变量的限制。而存储过程可以返回多个。而且函数是可以嵌入在sql中使用，可以在select中调用，而存储过程不行。通常如果返回值只有一个使用函数，其他情况使用存储过程。12345678910111213141516171819DROP FUNCTION IF EXISTS `getClassNotPassRate`;CREATE FUNCTION `getClassNotPassRate` (`classID` VARCHAR(20)) RETURNS DOUBLEBEGIN DECLARE sum DOUBLE; DECLARE notPassSum DOUBLE; SELECT COUNT(*) INTO sum FROM scores, studentinfos WHERE scores.stu_id = studentinfos.id AND studentinfos.cclass = classID; SELECT COUNT(*) INTO notPassSum FROM scores, studentinfos WHERE scores.stu_id = studentinfos.id AND studentinfos.cclass = classID AND scores.score &lt; 60; IF (sum = 0) THEN RETURN 0; END IF; RETURN notPassSum / sum;END触发器教程：https://www.yiibai.com/mysql/triggers.html例：在录入学生成绩时，触发器根据新录入的学生成绩的系统中已有的学生选课成绩计算出录入之后的学生GPA。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859DROP TRIGGER IF EXISTS `changeGpa`;CREATE TRIGGER `changeGpa` AFTER INSERT ON `scores` FOR EACH ROWBEGIN DECLARE myavg DOUBLE; DECLARE allcre DOUBLE; DECLARE temp DOUBLE; DECLARE sum DOUBLE DEFAULT 0.0; DECLARE t INTEGER; DECLARE t1 DOUBLE; DECLARE t2 DOUBLE; DECLARE done INT DEFAULT FALSE; DECLARE cur cursor for SELECT scores.score, courses.coefficient, courses.credit from studentinfos, scores, courses where studentinfos.id = scores.stu_id and scores.cou_id = courses.id and stu_id = new.stu_id; DECLARE CONTINUE HANDLER for not found set done = TRUE; SELECT SUM(courses.credit) into allcre from studentinfos, scores, courses where studentinfos.id = scores.stu_id and scores.cou_id = courses.id and stu_id = new.stu_id and score&gt;=60; open cur; read_loop:loop FETCH cur into t, t1, t2; IF done THEN LEAVE read_loop; END IF; if(t &lt; 60) THEN set temp = 0.0; end if; if(t &gt;= 60) THEN set temp = 1.0; end if; if(t &gt;= 64) THEN set temp = 1.6; end if; if(t &gt;= 66) THEN set temp = 1.7; end if; if(t &gt;= 68) THEN set temp = 2.0; end if; if(t &gt;= 72) THEN set temp = 2.3; end if; if(t &gt;= 75) THEN set temp = 2.7; end if; if(t &gt;= 78) THEN set temp = 3.0; end if; if(t &gt;= 82) THEN set temp = 3.3; end if; if(t &gt;= 85) THEN set temp = 3.7; end if; if(t &gt;= 90) THEN set temp = 4.0; end if; set sum=temp*t1*t2+sum; end loop; close cur; set myavg = sum/allcre; UPDATE studentinfos SET gpa = myavg where id = new.stu_id;END]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-事务]]></title>
    <url>%2F2019%2F06-%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[ACIDA原子性（Atomicity）：事务是数据库的逻辑工作单位事务中包括的诸操作要么都做，要么都不做。C一致性（Consistency）：事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。一致性状态：数据库中只包含成功事务提交的结果。不一致状态：数据库中包含失败事务的结果。I隔离性（Isolation）：一个事务内部的操作及使用的数据对其他并发事务是隔离的。也就是说一个事务在执行的时候不知道是否有其他事务和它一起在对相同的数据做操作，事务之间是相对不可见的。D持续性（Durability）：持续性也称永久性。一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其执行结果有任何影响。事务的并发问题由于事务的隔离性，不同事务若同时相同的数据做操作，可能会引发问题，即事务的并发问题。按照问题解决的难度由低至高可分为四类。丢失修改一个事务对数据对象的修改被另一个事务的修改所覆盖。分为两类：第一类：事务T1、T2同时读取A为10，T1将A减1后提交，T2将A也减1后提交，此时数据库中数据为9。T1的修改被T2覆盖。第一类：事务T1、T2同时读取A为10，T1将A减1后提交，T2将A也减1后回滚，此时数据库中数据为10。T1的修改被T2覆盖。脏读由于一个事物的回滚，使得另一个事务读到的数据无效。事务T1中读A为100，修改A未300，还未提交时事务T2读C为300，但由于T1因某原因进行事务回滚。A又被重置为100。T2读取到的是脏数据。不可重复读在一个事务的两次“读”同一数据之间，有另一个事务的“updata”发生。如在事务T1中第一次读A为100，读B为200，A+B为300，在事务T2中把A修改为200，事务T2第二次读A为200，读B为200，A+B为400。同一事务两次读取的数据不一致。幻读在一个事务的两次“读”同一数据之间，有另一个事务的“insert”发生。如在事务T1中第一次读count(*)为100，事务T2插入一条数据，事务T1中第二次读count(*)为101，同一事务两次读取的数据不一致。封锁类型加锁是解决事务并发问题的常见手段。数据库中的锁从读写的角度可分为两类：共享锁和排它锁。排它锁（X锁）：只允许当前事务T对数据进行“读”、“写”，其它事务对数据R的任何锁请求被拒绝直到T释放R上的X锁。共享锁（S锁）：允许当前事务T对数据R进行“读”，不允许“写“，而其它事务对R的S申请被允许，X请求拒绝。带来的效果是：X锁：数据对象当前只能由一个事务操作。S锁：多个事务允许同时“读”一个数据。封锁协议在运用X锁和S锁对数据对象加锁时，还需要约定一些规则 ，例如何时申请X锁或S锁、持锁时间、何时释放等。称这些规则为封锁协议。对封锁方式规定不同的规则，就形成了各种不同的封锁协议。一级封锁协议对T要“写”的R加X锁，直到T结束。此时可以解决丢失更新。此时仍然会发生：脏读：事务T2可以绕过X锁读取数据，且读取到的是T1回滚的数据。不可重复读：事务T2的两次读之间可以发生T1的”update“。幻读：事务T2的两次读之间可以发生T1的”insert“。二级封锁协议T发生“写”加X锁，直到T结束；（一级封锁协议）T发生“读”R加S锁，读完即释放。此时可以解决丢失修改和脏读。事务T1先对R进行写（加X锁），则事务T2在读时没法加S锁，直至T1结束。事务T2先对R进行读（加S锁），则事务T1在写时需要等待读结束（T1不一定结束）。此时仍然会发生：不可重复读：事务T1在第一次读之后（释放S锁），事务T2进行了”update”操作，事务T1再读得到的数据和上次不一致。幻读：事务T1在第一次读之后（释放S锁），事务T2进行了”insert”操作，事务T1再读得到的数据和上次不一致。三级封锁协议T发生“写”加X锁，直到T结束。T发生“读”加S锁，直到T结束。此时可以解决任何并发问题，因为无论对数据进行读还是写都要加锁：写：先加X锁，之后任何读写都被禁止。读：先加S锁，之后任何写操作都被被禁止。三级封锁协议仅允许不同的事务同时发生读操作。两段锁协议在对任何数据进行读、写操作之前，事务首先要获得对该数据的封锁。在释放一个封锁之后，事务不再获得任何其他封锁。满足所有遵守两段锁协议的事务，其并行执行的结果一定是正确的：先加X锁：X锁结束前（在两段锁协议中，不一定要事务结束才能释放X锁）任何锁都不能加上去，X锁结束后此事务不能再进行任何读写操作。先加S锁：S锁结束前，只能对其加S锁，即只允许多个事务同时读。一旦释放一个S锁，便任何锁都加不上去，只能完成为完成的读，不能再进行新的读写操作。满足三级封锁协议的一定满足两段锁协议：先加X锁，两种协议下事务结束之前任何读写都会被禁止。先加S锁，在两段锁协议中，若第一个锁的释放之后紧跟的事件就是事务的结束，此时就是三级封锁协议，即三级封锁协议是两段锁协议的一部分。事务的隔离级别读未提交READ UNCOMMITTED。对应一级封锁协议。读已提交READ COMMITTED。对应二级封锁协议。可重复读REPEATABLE READ。二级封锁协议加上不允许事务读取在该事务开始后新提交的数据。即防止了不可重复读的发生。可串行化SERIALIZABLE。对应三级封锁协议。MySql特点MySql默认的事务隔离级别是读已提交MySql的事务是自动提交，即即使未事务，MySql也会把每个SQL语句放在一个事务中运行，这个事务是MySql自动添加上去的。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet]]></title>
    <url>%2F2019%2FServlet%2F</url>
    <content type="text"><![CDATA[Servlet的创建简介Servlet是指任何实现了Servlet接口的类。一般情况下Servlet用来扩展基于HTTP协议的Web服务器，它可以接受响应通过HTTP协议从客户端发过来的信息。Servlet是一个类，但Servlet类的对象是由Web服务器创建的，不是由开发者创建的。并且多个客户端访问同一个Servlet时只会创建一个Servlet对象。即Servlet是单实例多线程的。图片来至：https://blog.csdn.net/qq_19782019/article/details/80292110Servlet接口void init(ServletConfig config)：在服务器创建 Servlet对象时执行。void destroy()：在服务器关闭时调用。ServletConfig getServletConfig()：返回一个ServletConfig对象。String getServletInfo()：得到Servlet的信息。如作者、版本等。void service(ServletRequest req, ServletResponse res) ：被服务器调用去获得和响应从服务器发来的请求。Servlet的生命周期Servlet何时创建：默认第一次访问Servlet时创建该对象。Servlet何时销毁：服务器关闭Servlet就销毁了。每次访问必然执行的方法：service(ServletRequest req, ServletResponse res)。实现Servlet接口12345678910111213141516171819202122232425262728293031323334353637383940package cn.isjinhao;import java.io.IOException;import javax.servlet.Servlet;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;public class MyServlet implements Servlet&#123; @Override public void destroy() &#123; // TODO Auto-generated method stub &#125; @Override public ServletConfig getServletConfig() &#123; // TODO Auto-generated method stub return null; &#125; @Override public String getServletInfo() &#123; // TODO Auto-generated method stub return null; &#125; @Override public void init(ServletConfig arg0) throws ServletException &#123; // TODO Auto-generated method stub &#125; @Override public void service(ServletRequest arg0, ServletResponse arg1) throws ServletException, IOException &#123; // 处理业务 &#125;&#125;继承HttpSerlvet类123456789101112131415161718192021package cn.isjinhao;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class MyServlet extends HttpServlet&#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; //处理业务 &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; this.doGet(req, resp); &#125;&#125;]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>Java Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汤姆猫和超文本传输协议]]></title>
    <url>%2F2019%2F%E6%B1%A4%E5%A7%86%E7%8C%AB%E5%92%8C%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[TomcatTomcat结构bin用来存放Tomcat的可执行文件：startup.bat是windows系统下启动Tomcat的可执行文件；shutdown.bat是windows系统下关闭Tomca的可执行文件。startup.sh是Linux下的启动Tomcat的可执行文件；shutdown.sh是linux下关闭Tomca的可执行文件。conf存放Tomcat服务器全局配置的各种文件。web.xml：给动态Web工程提供相应的配置，比如Session的过期时间，如果在工程的web.xml中覆盖了同种配置，以工程配置优先。server.xml：配置和服务器本身相关的信息，如用什么编码集解析URL，lib存放的是tomcat运行时和项目运行时必须的jar包。如果我们想把某个jar包让所有工程都能使用而不用每个工程都导入，直接将其放入lib文件夹下即可。logs存放的是日志文件webapps存放要发布的Web项目。将Web项目打包成War包，放在此目录下，在Tomcat启动时会将War解压并发布。work用来存放jsp文件文件在运行时产生的java文件和class文件。Dynamic Web项目结构Web项目结构12345678myweb(目录名:项目名) | |---资源文件 html img css js 可以存放到文件夹下 |---WEB-INF(目录:特点,通过浏览器直接访问不到) | | | |---lib(目录:项目运行的jar包) | |---classes(目录:存放的class文件) | |---web.xml(核心配置文件,在web2.5版本中必须有,web3.0版本不是必须的)手动创建一个Web项目并发布http://localhost:8080/test-web/test.htmlhttp://localhost:8080/test-web/WEB-INF/test.htmlHTTP协议请求行请求的方式 请求的资源 协议/版本。请求头key-value类型的数据。Accept：浏览器可接受的mime类型，如：text/html,image/*。Accept-Charset：浏览器解析所用哪个的字符集，如：ISO-8859-1。Accept-Encoding：浏览器能够进行解码的数据编码方式，比如gzip。Servlet能够向支持gzip的浏览器返回经gzip编码的HTML页面。Accept-Language：浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到。这个指的是中文、英语这种语言。Host：被访问的主机。If-Modified-Since：在发送HTTP请求时，把浏览器端缓存页面的最后修改时间一起发到服务器去，服务器会把这个时间与服务器上实际文件的最后修改时间进行比较。如果时间一致，那么返回HTTP状态码304（不返回文件内容），客户端接到之后，就直接把本地缓存文件显示到浏览器中。如果时间不一致，就返回HTTP状态码200和新的文件内容，客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示到浏览器中。Referer：告诉服务器我是从哪个页面链接过来的，服务器基此可以获得一些信息用于处理。User-Agent：浏览器内核。客户端浏览器的信息， 如。Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0)Cookie：客户端会话技术。请求体post请求的参数。只有表单提交或异步提交时明确指定method=&quot;post&quot;这时候是post请求，其他的都是get请求。格式：参数名称=值&amp;参数名称=值。响应行版本/协议 响应的状态码 状态码说明。常见的状态码：200：响应成功302：重定向304：读缓存404：用户访问的数据不存在500：服务器内部错误响应头Location：跳转方向，仅配合状态码302使用才有作用，如 https://www.baicu.com。Server：服务器型号Content-Encoding：Servlet应该通过查看Accept-Encoding头（即request.getHeader(&quot;Accept-Encoding&quot;)）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的HTML页面，为其他浏览器返回普通页面。Content-Length：数据长度Content-Type: text/html; charset=GB2312 –数据类型Last-Modified：客户可以通过If-Modified-Since请求头提供一个日期，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（Not Modified）状态。Last-Modified也可用setDateHeader方法来设置。Refresh：表示浏览器应该在多少时间之后刷新文档，以秒计。但只刷新一次。除了刷新当前文档之外，还可以通过setHeader(&quot;Refresh&quot;, &quot;5; URL=http://host/path&quot;)让浏览器读取指定的页面。Content-Disposition：指示浏览器不要解析文档，而是以附加形式下载。如attachment; filename=aaa.zip。Set-Cookie：设置cookie。响应体浏览器解析的内容。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>Java Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么分页存储管理页面大小是2的n次幂]]></title>
    <url>%2F2019%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E5%88%86%E9%A1%B5%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E9%A1%B5%E9%9D%A2%E5%A4%A7%E5%B0%8F%E6%98%AF2%E7%9A%84n%E6%AC%A1%E5%B9%82%2F</url>
    <content type="text"><![CDATA[在分页存储管理方式中，进程中存储的是逻辑地址，通过地址变换机构将逻辑地址转变为物理地址。逻辑地址形式为page: offset。页面大小为什么满足2的n次幂，原因有下：方便计算如果要将（线性）地址转换为page：offset，则需要将地址除以页面大小，并将整数答案作为页面，将余数作为偏移量。 这是使用编程语言中的整数除法和模数运算符完成的。 计算机将地址表示为数字，存储为二进制位。 这是一个示例地址：12是二进制1100。 如果页面大小为3，那么我们需要计算12/3和12%3来查找页面和偏移量（分别为4、0）。 但是，如果页面大小为4（2的幂），则二进制中的4为100，此时使用特殊的“快捷方式”计算整数除法和模数：右移进行除法，按位与进行取模。所以： 12/4 == 12&gt;&gt;2（右移两位） 12%4 == 12&amp;(4-1)（1100和11按位与）。同时页面大小转为2进制可以使用左移，可以减小时间开销。充分利用空间如果页面大小不满足2的n次幂，假如是5，则页内偏移地址，采用2位则每页有一个地址不能使用，采用3位则111、110、101未被使用。怎么做都不能完全利用地址空间。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-多表DQL]]></title>
    <url>%2F2019%2F05-%E5%A4%9A%E8%A1%A8DQL%2F</url>
    <content type="text"><![CDATA[数据准备12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/*功能：创建 scott 数据库中的 dept 表 */CREATE TABLE dept( deptno INT UNSIGNED AUTO_INCREMENT PRIMARY KEY COMMENT '部门编号', dname VARCHAR(15) COMMENT '部门名称', loc VARCHAR(50) COMMENT '部门所在位置')ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='部门表'; /*功能：创建 scott 数据库中的 emp 表 */CREATE TABLE emp( empno INT UNSIGNED AUTO_INCREMENT PRIMARY KEY COMMENT '雇员编号', ename VARCHAR(15) COMMENT '雇员姓名', job VARCHAR(10) COMMENT '雇员职位', mgr INT UNSIGNED COMMENT '雇员对应的领导的编号', hiredate DATE COMMENT '雇员的雇佣日期', sal DECIMAL(7,2) COMMENT '雇员的基本工资', comm DECIMAL(7,2) COMMENT '奖金', deptno INT UNSIGNED COMMENT '所在部门', FOREIGN KEY(deptno) REFERENCES dept(deptno))ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='雇员表'; /*功能：创建数据库 scott 中的 salgrade 表，工资等级表 */CREATE TABLE salgrade( grade INT UNSIGNED COMMENT '工资等级', losal INT UNSIGNED COMMENT '此等级的最低工资', hisal INT UNSIGNED COMMENT '此等级的最高工资' )ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='工资等级表'; /*功能：创建数据库 scott 的 bonus 表，工资表 */CREATE TABLE bonus( ename VARCHAR(10) COMMENT '雇员姓名', job VARCHAR(9) COMMENT '雇员职位', sal DECIMAL(7,2) COMMENT '雇员工资', comm DECIMAL(7,2) COMMENT '雇员资金' )ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT='工资表'; /*功能：插入数据库 scott 中表 dept 的初始化数据 */INSERT INTO dept VALUES (10,'ACCOUNTING','NEW YORK');INSERT INTO dept VALUES (20,'RESEARCH','DALLAS');INSERT INTO dept VALUES (30,'SALES','CHICAGO');INSERT INTO dept VALUES (40,'OPERATIONS','BOSTON'); /*功能：插入数据库 scott 中表 emp 的初始数据 */INSERT INTO emp VALUES (7369,'SMITH','CLERK',7902,'1980-12-17',800,NULL,20);INSERT INTO emp VALUES (7499,'ALLEN','SALESMAN',7698,'1981-2-20',1600,300,30);INSERT INTO emp VALUES (7521,'WARD','SALESMAN',7698,'1981-2-22',1250,500,30);INSERT INTO emp VALUES (7566,'JONES','MANAGER',7839,'1981-4-2',2975,NULL,20);INSERT INTO emp VALUES (7654,'MARTIN','SALESMAN',7698,'1981-9-28',1250,1400,30);INSERT INTO emp VALUES (7698,'BLAKE','MANAGER',7839,'1981-5-1',2850,NULL,30);INSERT INTO emp VALUES (7782,'CLARK','MANAGER',7839,'1981-6-9',2450,NULL,10);INSERT INTO emp VALUES (7788,'SCOTT','ANALYST',7566,'87-7-13',3000,NULL,20);INSERT INTO emp VALUES (7839,'KING','PRESIDENT',NULL,'1981-11-7',5000,NULL,10);INSERT INTO emp VALUES (7844,'TURNER','SALESMAN',7698,'1981-9-8',1500,0,30);INSERT INTO emp VALUES (7876,'ADAMS','CLERK',7788,'87-7-13',1100,NULL,20);INSERT INTO emp VALUES (7900,'JAMES','CLERK',7698,'1981-12-3',950,NULL,30);INSERT INTO emp VALUES (7902,'FORD','ANALYST',7566,'1981-12-3',3000,NULL,20);INSERT INTO emp VALUES (7934,'MILLER','CLERK',7782,'1982-1-23',1300,NULL,10); /*功能：插入数据库 scott 中表 salgrade 的初始数据 */INSERT INTO salgrade VALUES (1,700,1200);INSERT INTO salgrade VALUES (2,1201,1400);INSERT INTO salgrade VALUES (3,1401,2000);INSERT INTO salgrade VALUES (4,2001,3000);INSERT INTO salgrade VALUES (5,3001,9999);1234567891011121314151617181920212223242526272829dept( DEPTNO, //部门编号，由两位数字所组成 DNAME, //部门名称，最多由14个字符所组成, LOC //部门所在的位置);emp( EMPNO, //雇员的编号，由四位数字所组成 ENAME, //雇员的姓名，由10位字符所组成 JOB, //雇员的职位 MGR, //雇员对应的经理编号，经理也是雇员 HIREDATE, //雇员的雇佣日期 SAL, //基本工资，其中有两位小数，五倍整数，一共是七位 COMM, //奖金，佣金 DEPTNO //雇员所在的部门编号);salgrade( GRADE, //工资的等级 LOSAL, //此等级的最低工资 HISAL //此等级的最高工资);bonus( ENAME, //雇员姓名 JOB, //雇员职位 SAL, //雇员的工资 COMM //雇员的奖金);自连接自连接就是自己和自己连接，在使用时将一张表看做多张表使用。查询员工编号，员工姓名，经理的编号，经理的姓名KING没有经理，所以查询出来只有13条记录12345678910SELECT e1.empno, e1.ename, e1.mgr, m1.enameFROM emp e1, emp m1WHERE e1.mgr = m1.empno查询员工编号，员工姓名，员工的部门名称，经理的编号，经理的姓名12345678910111213SELECT e1.empno, e1.ename, d1.dname, e1.mgr, m1.enameFROM emp e1, emp m1, dept d1WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno查询员工编号，员工姓名，员工的部门名称，经理的编号，经理的姓名，经理的部门名称12345678910111213141516SELECT e1.empno, e1.ename, d1.dname, e1.mgr, m1.ename, d2.dnameFROM emp e1, emp m1, dept d1, dept d2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno这里有一个难点是为什么需要拓展出两张部门表？这里需要理解刚才说的一句话：在使用时将一张表看做多张表使用，想象一下，如果真实存在一张员工表和一张经理表，员工表.部门=部门.id，经理表.部门=部门.id，不就等于是经理和员工在一个部门才能要求吗？这个题意明显不符。- 查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称12345678910111213141516171819SELECT e1.empno, e1.ename, d1.dname, s1.grade, e1.mgr, m1.ename, d2.dnameFROM emp e1, emp m1, dept d1, dept d2, salgrade s1WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal- 查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称，员工所属经理的工资等级12345678910111213141516171819202122SELECT e1.empno, e1.ename, d1.dname, s1.grade, e1.mgr, m1.ename, d2.dname, s2.gradeFROM emp e1, emp m1, dept d1, dept d2, salgrade s1, salgrade s2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal AND m1.sal BETWEEN s2.losal AND s2.hisal查询员工编号，员工姓名，员工的部门名称，员工的工资等级，经理的编号，经理的姓名，经理的部门名称，经理的工资等级（将工资等级 1,2,3,4 显示成 中文的 一级 二级 三级…）1234567891011121314151617181920212223242526272829303132333435363738394041424344SELECT e1.empno, e1.ename, d1.dname, CASE s1.grade WHEN 1 THEN '一级' WHEN 2 THEN '二级' WHEN 3 THEN '三级' WHEN 4 THEN '四级' ELSE '五级' END "等级", e1.mgr, m1.ename, d2.dname, CASE s2.grade WHEN 1 THEN '一级' WHEN 2 THEN '二级' WHEN 3 THEN '三级' WHEN 4 THEN '四级' ELSE '五级' END "等级"FROM emp e1, emp m1, dept d1, dept d2, salgrade s1, salgrade s2WHERE e1.mgr = m1.empno AND e1.deptno = d1.deptno AND m1.deptno = d2.deptno AND e1.sal BETWEEN s1.losal AND s1.hisal AND m1.sal BETWEEN s2.losal AND s2.hisal外连接数据准备：insert into emp(empno,ename) values(9527,&#39;HUAAN&#39;);左外连接以左表为基准，右表能匹配上左表则匹配，右表没有一条记录匹配上左表，左表显示为空。右连接是以右表为基准，左表能匹配上右表则匹配，左表没有一条记录匹配上右表，右表显示为空。查询员工所在的部门12345SELECT *FROM emp e1LEFT OUTER JOIN dept d1 ON e1.deptno = d1.deptno;查询部门的员工12345SELECT *FROM emp e1 RIGHT OUTER JOIN dept d1 ON e1.deptno = d1.deptno;子查询查询最高工资的员工信息123456SELECT *FROM empWHERE sal = (SELECT max(sal) FROM emp);查询出比雇员7654的工资高,同时和7788从事相同工作的员工信息123456789101112131415161718192021SELECT *FROM empWHERE sal &gt; ( SELECT sal FROM emp WHERE empno = 7654 )AND job = ( SELECT job FROM emp WHERE empno = 7788 );查询每个部门最低工资的员工信息和他所在的部门信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 查询每个部门的最低工资,分组统计SELECT deptno, min(sal) minsalFROM empGROUP BY deptno; # 员工工资等于他所处部门的最低工资SELECT *FROM emp e1, ( SELECT deptno, min(sal) minsal FROM emp GROUP BY deptno ) t1WHERE e1.deptno = t1.deptno AND e1.sal = t1.minsal;# 查询部门相关信息SELECT *FROM emp e1, ( SELECT deptno, min(sal) minsal FROM emp GROUP BY deptno ) t1, dept d1WHERE e1.deptno = t1.deptno AND e1.sal = t1.minsal AND e1.deptno = d1.deptno;查询领导信息123456SELECT *FROM empWHERE empno IN (SELECT mgr FROM emp);查询不是领导的信息1234567891011121314151617181920212223242526272829# 错误的写法SELECT *FROM empWHERE empno NOT IN (SELECT mgr FROM emp);# &lt;&gt; ALL 等价于 NOT INSELECT *FROM empWHERE empno &lt;&gt; ALL (SELECT mgr FROM emp); # 正确的写法SELECT *FROM empWHERE empno NOT IN ( SELECT mgr FROM emp WHERE mgr IS NOT NULL );查询出比20号部门所有员工薪资高的员工信息 10 20 301234567891011121314151617181920212223242526272829# 写法1SELECT *FROM empWHERE sal &gt; ( SELECT max(sal) FROM emp WHERE deptno = 20 ); # 写法2SELECT *FROM empWHERE sal &gt; ALL ( SELECT sal FROM emp WHERE deptno = 20 );查询有员工的部门的信息12345678910111213SELECT *FROM dept d1WHERE EXISTS ( SELECT * FROM emp e1 WHERE e1.deptno = d1.deptno );补充EXISTS假设有三张表，学生、课程、选课表。查询选修了全部课程的同学。1234567891011121314151617181920212223242526/* 思路： 从上面的例子可以看到EXITSTS其实是对外部表的某个字段做循环。循环变量带入内部表后判断 从内部表能否查出来信息，能查出来表示真（留下），查不出来表示假（去除）。 所以这个题就是对每个学生做循环，把学生带入内部查询，查询学生是否有未选修的课，如果有 学生去除，否则学生留下，所以选用not exists： select * from student where not exists (学生未选修的课) 假设某次循环的学号是 110，此时需要拿course中的每个课号到sc表中做循环，查询在sc表的 学号为110且course.no = sc.cno的情况下，记录是否存在，记录存在course去除，记录不存 在course留下，所以选用not exists： select * from course where not exists select * from sc where 110 = sc.sno and sc.cno = course.no; 这样，可以查出学号为110的同学未选修的课程。 结果： 把两次分析的合并之后： select * from student where not exists( select * from course where not exists( select * from sc where student.no = sc.sno and sc.cno = course.no; ) )*/现在还是这三张表，我们换个题，查询被所有学生选修的课程信息123456789101112131415161718192021/* 思路： 对课程做循环，把课程带入内部查询，如果有学生未选此课，课程去除，否则课程留下， 所以选用not exists：： select * from course where not exists (未被选的课) 假设某次循环，课号为120，此时拿student中的每个学号到sc表做循环，查询在sc表的课号为 120且student.no = sc.sno的情况下，记录是否存在，记录存在student去除，记录不存在 student留下，所以选用not exists：： select * from student where not exists select * from sc where student.no = sc.sno and 120 = sc.no 结果： 两次分析合并 select * from course where not exists( select * from student where not exists( select * from sc where course.no = sc.cno and sc.sno = student.no ) )*/查询没有一个学生选择的课：123456789101112/* 对course做循环，如果存在学生选此课去除，没有学生选此课保留，选用not exists： 对内部循环，记录存在保留，记录不存在去除，选用exists：*/select * from course where not exists( select * from student where exists( select * from sc where course.no = sc.cno and sc.sno = student.no ))]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06-虚拟存储器]]></title>
    <url>%2F2019%2F06-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[传统存储器的问题传统的内存管理方式要求将一个作业全部装入内存才可以运行，由此造成了以下两种情况：大作业对内存的要求超出物理内存总容量，致使其无法运行。内存由于容量的限制，只能装入少量的作业使其运行，而其它大量作业留在外存。解决原理程序局部性原理程序执行时， 除了少部分的转移和过程调用指令外，在大多数情况下仍是顺序执行的。过程调用将会使程序的执行轨迹由一部分区域转至另一部分区域， 但经研究看出，过程调用的深度在大多数情况下都不超过5。程序中存在许多循环结构， 这些虽然只由少数指令构成， 但是它们将多次执行。程序中还包括许多对数据结构的处理， 如对数组进行操作， 它们往往都局限于很小的范围内。表现两个方面时间局限性。如果程序中的某条指令一旦执行， 则不久以后该指令可能再次执行；如果某数据被访问过， 则不久以后该数据可能再次被访问。产生时间局限性的典型原因，是由于在程序中存在着大量的循环。空间局限性。一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，其典型情况便是程序的顺序执行。基于局部性原理在程序装入时，不必将其全部读入到内存，而只需将当前需要执行的部分页或段读入到内存，就可让程序开始执行。在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统，将相应的页或段调入到内存，然后继续执行程序。虚拟存储器定义所谓虚拟存储器， 是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。可见，虚拟存储技术是一种性能非常优越的存储器管理技术，故被广泛地应用于大、 中、 小型机器和微型机中。实现虚拟存储器的条件由于一个作业被分成多次地调入内存运行，所以在内存分配时必须采用离散分配方式。同时需要解决以下问题：页表（段表）的设计（软件支持）程序不在内存时去外存调度需要中断（硬件支持）逻辑地址转换为物理地址（软件硬件支持）如何给每个进程分配物理块一个页（段）进入内存时，淘汰哪个页（段）请求分页存储管理方式页表机制用于将用户逻辑地址空间变换为内存的物理地址空间。在页表中增加若干项，以便于标志程序或数据的状态。- 状态位（存在位）P：表示该页是否调入内存。- 访问字段A：用于记录该页在某段时间内被访问的次数。- 修改位M：表示该页在调入内存后是否被修改过。未修改过不必写回外存，修改要写回外存。- 外存地址：该页在外存上的地址，通常是物理块号。### 缺页中断机构- 在地址映射过程中，在页表中发现所要访问的页不在内存，则产生缺页中断。操作系统接到此中断信号后，就调出缺页中断处理程序，根据页表中给出的外存地址，将该页调入内存，使进程继续运行下去。- 如果内存中有空闲块，则分配一页，将新调入页装入内存，并修改页表中相应页表项目的状态位及相应的内存块号。- 若此时内存中没有空闲块，则要淘汰某页，若该页在内存期间被修改过，则要将其写回外存。- 缺页中断发生在指令执行期间，而通常情况下，CPU是在一条指令执行完后，才检查是否有中断请求到达；一条指令在执行期间，可能产生多次缺页中断。所以硬件机构应能保存多次中断时的状态，并保证最后能返回到中断前产生缺页中断的指令处，继续执行。### 地址转换机构内存分配最小物理块数的确定最小物理块数：保证进程正常运行所需的最小物理块数。与计算机的硬件机构有关，取决于指令的格式、功能和寻址方式。内存分配策略在请求分页中，可采取两种分配策略，即固定和可变分配策略。在进行置换时，也可采取两种策略，即全局置换和局部置换（置换范围不同）。于是组合出三种适用的策略：固定分配局部置换：分配固定数目的内存空间，在整个运行期间都不改变。如果缺页，则先从该进程在内存的页面中选中一页，进行换出操作，然后再调入一页。可变分配全局置换：每个进程预先分配一定数目的物理块，同时OS也保持一个空闲物理块队列。当缺页时，首先将对OS所占有的空闲块进行分配，从而增加了各进程的物理块数。当OS的空闲块全部用完，将引起换出操作。可变分配局部置换：系统根据缺页率动态调整各进程占有的物理块数目，使其保持在一个比较低的缺页率状态下。物理块分配算法平均分配算法：将系统中所有可供分配的物理块，平均分配给各个进程。按比例分配算法：按照进程的大小比例分配物理块。考虑优先权的分配算法：为了对于紧迫的作业，能够尽快完成。可以将内存的物理块分成两部分，一部分按照比例分配给各进程，另一部分根据进程优先级，适当增加其相应的份额，分配给各进程。页面调入何时调入页面提前取页：预先装入主存一页或几页（提前页）。请求取页：当用到某页而不在主存时即缺页时取页。从何处调入页面外存有两个部分：文件区和对换区。对换区I/O操作速度比文件区相对快一些，因此一般应当尽量使用对换区来调入页面。对于不同情况，采用不同的策略：系统有足够的对换空间：全部从对换区调入。系统对换空间不足：未修改的从文件区调入，修改的从对换区调入。UNIX的调入方式：未运行过的从文件区调入，运行过的放在对换区，允许页面共享。页面调入过程进程需要的页面不在内存，引起缺页中断中断处理程序保留现场环境，转入缺页中断处理程序中断处理程序查找页表，得到对应的外存物理块号。如果内存有空闲，则启动磁盘操作，将所缺的页面读入，并修改页表。否则，到4。执行置换算法，选出要换出的页面，如果该页修改过，应将其写入磁盘，然后将所缺页调入内存，修改相应表项，将其存在位置为1，并放入快表。利用修改后的页表，形成物理地址，访问内存数据。缺页率假设进程逻辑空间为n页，系统为其分配物理块数为m。如果进程运行过程中，访问页面成功次数为S，访问页面失败次数为F，总页面访问次数A=S+F，则进程运行过程中 缺页率f=F/A。影响缺页率的主要因素：页面大小：页面越大，缺页率越小进程所分配物理块数：物理块越多，缺页率越小页面置换算法：合理的置换算法能更少将页面调入调出程序固有特性：比如做循环操作时，缺页率较低，因为执行的命令都是一系列大致相同的指令。页面置换算法最佳置换算法所选择的被淘汰页面，将是以后永不使用的， 或许是在最长（未来）时间内不再被访问的页面。采用最佳置换算法，通常可保证获得最低的缺页率。这是一种理想情况，是实际执行中无法预知的，因而不能实现。可用作性能评价的依据。例：假定系统为某进程分配了三个物理块， 并考虑有以下的页面号引用串17，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1进程运行时， 先将7，0，1三个页面装入内存。 以后， 当进程要访问页面2时， 将会产生缺页中断。此时OS根据最佳置换算法， 将选择页面7予以淘汰。先进先出页面置换算法选择装入最早的页面被置换。可以通过链表来表示各页的建立时间先后。最近最久未使用置换算法选择内存中最久未使用的页面被置换。这是局部性原理的合理近似，性能接近最佳算法。但由于需要记录页面使用时间的先后关系，硬件开销太大。硬件支持寄存器：每个页面设立移位寄存器：被访问时左边最高位置1，定期右移并且最高位补0，于是寄存器数值最小的是最久未使用页面。栈：一个特殊的栈，每当进程访问某页面时，便把被访问的页面移到栈顶，于是栈底的是最久未使用页面。最少使用置换算法选择到当前时间为止被访问次数最少的页面被置换。实现方法1：每个页面设立移位寄存器：被访问时左边最高位置1，定期右移并且最高位补0，这样，在最近一段时间内时用最少的页面将是$\sum_{R_i}$最小的页。实现方法2：每页设置访问计数器，每当页面被访问时，该页面的访问计数器加1；发生缺页中断时，淘汰计数值最小的页面，并将所有计数清零。Clock置换算法也称最近未使用算法（NRU, Not Recently Used），它是LRU（最近最久未使用算法）和FIFO的折衷。内存中所有页面通过链接指针形成一个循环队列，每页有一个使用访问位，若该页被访问则置1。置换时采用一个指针，从当前指针位置开始按地址先后检查各页，寻找访问位为0的页面作为被置换页。指针经过的访问位为1的页都修改0，最后指针停留在被置换页的下一个页。改进Clock置换算法由于Clock算法不考虑换出页面时，页面是否修改过的问题。这样在换出的页面如果被修改过的话，则必须做拷回磁盘处理，开销比较大。于是，改进型的Clock算法为每个页又增加了一个修改位。选择页面时，尽量选择既未使用又没有修改的页面。访问位A，修改位M有四种不同情形：1类(A=0，M=0）既未访问，又没有修改，最佳淘汰页2类(A=0，M=1）未访问，但是有修改，效率低的淘汰页3类(A=1，M=0）被访问，但没有修改4类(A=1，M=1）既被访问，又有修改算法：指针从当前位置开始，开始第一轮扫描循环队列，寻找A=0且M=0的页面，找到则可换出。如果找不到，则开始第二轮扫描，寻找A=0且M=1的页面，并且每经过一个页面时，将其访问位A设置为0。如果找到一个第2类页面，则可换出。如果仍旧未找到合适的换出页面，则此时指针回到初始位置，且所有页面其访问位A为0。再转回1继续工作。页面缓冲算法在请求分页系统中，进程在运行的时候经常会发生页面换进换出的情况。而影响换进换出效率的原因如下：页面置换算法：好的页面置换算法能使进程运行中具有较低的缺页率，从而可以减少换进换出的开销。写会磁盘的频率。读入内存的频率。而页面缓存算法就是降低读写磁盘的频率来降低开销。做法如下：空闲页面链表：当有一个未被修改的页要换出时，实际上并不将其换出到外存，而是把它们所在的物理块挂在空闲链表的末尾。如果以后某进程请求此页时，便将其从空闲页面链表上取下。修改页面链表：和空闲页面链表的功能一样，只是说此链表是存放已修改页面的。当链表上挂有足够多的页面时，将它们一齐写入磁盘，这样可以降低读写磁盘的频率。访问内存的有效时间被访问页在主存，且相应页表项在快表：$EAT= \lambda +t$查找快表+访问实际物理地址被访问页在主存，但相应页表项不在快表：$ EAT= \lambda +t + t + \lambda$查找快表+读取页表+读取数据+更新快表被访问页不在主存：$EAT= \lambda + t + \varepsilon + t + \lambda$查找快表+读取页表+缺页中断处理+读取数据+等新快表内存的有效访问时间为：$EAT= \lambda + t + (1 - a ) \ast [f \ast ( \varepsilon + \lambda + t)+(1-f) \ast(\lambda+t)]$a为命中率，f为缺页率。查找快表+访问内存一次+未命中不需要请求缺页访问快表+未命中时不需要请求缺页访问内存+未命中需要请求缺页访问快表+未命中时需要请求缺页访问内存+未命中时需要请求缺页开销。抖动与工作集抖动由于只装入一个进程的部分程序和数据便可开始运行，故希望运行更多进程，增加多道程序度。但在多道程序环境下，并不是多道程序的度越高，系统吞吐量越大。当CPU的利用率达到某一峰值后，若继续增加多道程度，将产生“抖动”。抖动是指同时运行进程太多，分配给每个进程物理块太少，进程在运行时频繁缺页，必须请求调页，等待页面调进调出的进程增多，磁盘访问时间急剧增加，进程大部分时间用于页面换进换出，处理机利用率急剧下降并趋于0。工作集基于程序运行的局部性原理，程序运行时，对页面的访问并不均匀，一段时间仅局限于较少的页面；另一段时间，有可能局限于另一些较少的页面，如果能预知这些页面，并提前调入，将大大减少缺页率工作集，是指在某段时间间隔内，进程实际要访问的页面的集合。为了降低缺页率，应将程序全部工作集装入主存。方法：用程序过去某段时间的行为作为程序将来某段时间行为的近似。定义：是指在某段时间间隔内，进程实际要访问的页面的集合。为了降低缺页率，应将程序全部工作集装入主存。方法：用程序过去某段时间的行为作为程序将来某段时间行为的近似。工作集$ \omega (t, \Delta) $是二元函数。某进程在时间t的工作集记为$ \omega (t, \Delta) $，其中，$\Delta$为工作集的窗口尺寸。例窗口大小$\Delta$选择得过小，频繁产生缺页中断。窗口大小$\Delta$选择得很大，失去了虚拟存储器的意义抖动的预防方法采取局部置换策略：仅允许进程在自身范围内进行置换，不影响其他进程在CPU调度程序中引入工作集算法：调入新作业时，应该检查每个进程在内存中的驻留集是否足够大L=S准则：产生缺页的平均时间L=系统处理进程缺页的平均时间S选择暂停的进程：使某些低优先级的进程进程挂起，从而腾出内存空间请求分段存储管理方式请求分页系统建立的虚拟存储器，是以页面为单位进行换入、换出操作的。在请求分段系统中实现的虚拟存储器，以分段为单位进行换入和换出。程序在运行之前，只需要装入必要的若干个分段即可运行。当访问的分段不在内存时，可由OS将所缺少的段调入内存。使用请求分段存储管理方式可以对动态链接有很好的支持。请求段表机制- 存取方式：标记本段存取属性。如读R，写W，执行X- 访问字段A：记录本段使用的频繁程度- 修改位：是否在调入内存后做过修改- 存在位：本段是否装入内存- 增补位：该段是否动态增长过### 缺段中断机构要有专门的缺段中断处理程序。特点：- 指令和操作数必定不会跨越在段边界上。- 由于段的长度是不固定的，处理比缺页系统复杂。- 调入一个段可能要淘汰几个内存中的段。### 请求中断处理地址中断机构分段的共享与保护共享段表共享进程计数：多少进程在使用此段。存取控制手段：每个共享段，应为不同进程赋予不同的存取权限。断号：同一个共享段在不同进程那有不同的断号。分配第一个请求的进程，由系统分配一物理块，调入共享段，设置相关表项信息，并置count=1； 以后的进程，在自己的段表中增加一项，填入共享段的信息，在共享段表项中做count=count+1，填写进程相关信息。回收做count=count-1；若count=0 ，则该共享段被回收。分段保护越界检查：在进行存储访问时，要将逻辑地址的段号与段表长度进行比较，如果超出则发生越界中断信号；其次，将段内地址与段表中该段的长度进行比较，如果有效才进行转换，否则产生越界中断信号。存取控制检查：用于规定对该段的访问权限。通常的访问方式有：读：允许用户对该段/页内任何信息或其副本进行读操作。写：允许用户修改该段/页内任何信息直至撤消整个段/页。执行：用户可以执行该段/页程序，数据段/页除外。增加：用户可在段/页的末尾添加信息，但不允许修改已存在于段/页中的信息。环保护检查：是一种功能较完善的保护机制。思想：将所有的程序分成不同的级别，分别放置在不同的环上。内环（编号小，在内侧）的程序具有高优先权，外环的程序优先权低。操作系统核心安排在0环内；重要程序和操作系统服务安排在中间环；一般应用程序安排在外环。一个程序可以直接访问在相同环或低优先级环（比自身相对靠外的环）上的数据。一个程序访问高优先级（比自己靠内的环）时，通过系统调用方式实现。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis入门]]></title>
    <url>%2F2019%2Fredis%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[环境安装本人使用的是redis-3.0.0和阿里云centos7服务器。上传redis-3.0.0到服务器。安装gcc环境：yum install gcc-g++解压redis-3.0.0：tar -zxvf ...进入解压后的redis文件夹执行：make安装：make PREFIX=/usr/local/redis install拷贝redis文件夹的redis.conf到/usr/local/redis下修改/usr/local/redis下的redis.conf，搜索以daemonize开头的行，将此行修改为daemonize yes。修改后redis以后台进程运行。开放端口：redis默认端口是6379。/sbin/iptables -I INPUT -p tcp --dport 6379 -j ACCEPT启动服务器：./xxx/redis-server xxx/redis.conf使用客户端连接服务器：./xxx/redis-cli -h ip地址 -p 6379连接测试：ping显示PONG表名成功关闭客户端：quit关闭服务器：./bin/redis-cli shutdown基础使用存储string设置：set key value取值：get key删除：del username- 数值相加减- 加一：incr key- 减一：decr key- 加x：incrby key x- 减x：decrby key x字符串拼接存储Map赋值：赋多值：取值：删除字段：删除map：判断字段存在：获取全部entry：获取全部key：获取全部value：存储list头部添加：尾部添加：查看列表：头部弹出：尾部弹出：lpushx key value：仅当key存在时才向头部插入rpush key value：仅当key存在时才向尾部插入删除：irem key count value：count&gt;0时从头部开始删除|count|个值为value的元素；count&lt;0时从尾部开始删除|count|个值为value的元素；count=0时删除全部的值为|value|的元素。设置：lset key index value：设置链表中索引值为index的元素，0是链表头，-1是链表尾。索引值不存在抛异常。lindex key index：通过索引获取列表中的元素linsert key before|after pivot value：在列表的元素前或者后插入元素rpoplpush source destination：移除列表的最后一个元素，并将该元素添加到另一个列表并返回存储setSADD key member1 member2...：向集合添加一个或多个成员SREM key member1 member2...：移除集合中一个或多个成员SISMEMBER key member：判断 member 元素是否是集合 key 的成员1：存在0：key不存在或member不存在sdiff key1 key2：返回集合key1-key2的数据sinter key1 key2 ...：返回集合key1,key2,...的交集sunion key1 key2 ...：返回集合key1,key2,...的并集scard key：返回集合的数量srandmember key：随机返回集合中的一个数据集合运算拓展存储sortedset有序集合和集合一样也是string类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。有序集合的成员是唯一的,但分数(score)却可以重复。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。ZADD key score1 member1 [score2 member2]：向有序集合添加一个或多个成员，或者更新已存在成员的分数。ZSCORE key member：返回有序集中，成员的分数值。ZREM key member1 member2 ...：移除有序集合中的一个或多个成员ZRANGE key start stop [WITHSCORES]：通过索引区间返回有序集合成指定区间内的成员。withscores表示返回的成员包含分数。ZREVRANGE key start stop [WITHSCORES]：返回有序集中指定区间内的成员，通过索引，分数从高到底。withscores表示返回的成员包含分数。ZREMRANGEBYRANK key start stop：移除有序集合中给定的排名区间的所有成员ZREMRANGEBYSCORE key min max：移除有序集合中给定的分数区间的所有成员keys的通用操作keys pattern：获取所有和pattern匹配的key。del key1, key2, ...：删除指定key。exists key：key是否存在。rename key newkey：为当前的key重命名。expire key：为key设置过期时间，单位：秒。ttl key：获取key所剩的时间，如果没有设置超时，返回-1，key不存在返回-2。type key：以字符串形式返回key的类型。key不存在返回none。Jedisjedis是Java操作redis的一套规范。使用jedis需要有两个包。commons-pool2-2.3.jar和jedis-2.7.0.jar。入门使用12345678910public class Demo1 &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis("59.110.143.226", 6379); jedis.set("name", "zhangsan"); String string = jedis.get("name"); System.out.println(string); jedis.close(); &#125;&#125;工具类连接1234maxTotal=20maxWaitMillis=7000host=59.110.143.226port=637912345678910111213141516171819202122232425262728public class JedisPoolUtils &#123; private static JedisPoolConfig jc = null; private static int maxTotal = 0; private static long maxWaitMillis = 0; private static String host = null; private static int port=0; private static JedisPool pool=null; static&#123; jc=new JedisPoolConfig(); //获取properties中的配置数据 ResourceBundle re = ResourceBundle.getBundle("jedis"); maxTotal=Integer.parseInt(re.getString("maxTotal")); maxWaitMillis=Long.parseLong(re.getString("maxWaitMillis")); jc.setMaxTotal(maxTotal); jc.setMaxWaitMillis(maxWaitMillis); host = re.getString("host"); port = Integer.parseInt(re.getString("port")); //创建Jedis池 pool=new JedisPool(jc, host, port); &#125; public static Jedis getJedis()&#123; return pool.getResource(); &#125;&#125;123456789public class TestUtils &#123; public static void main(String[] args) &#123; Jedis jedis=JedisPoolUtils.getJedis(); jedis.set("username2", "xiaowang"); String string = jedis.get("username2"); System.out.println(string); jedis.close(); &#125;&#125;多数据库redis的一个实例可以有多个数据库，就像一个mysql可以有多个数据库一样。一个redis实例最多可以提供16个数据库，下标从0到15，默认是0号数据库，连接其他数据库使用select num。移动key到指定数据库消息订阅与发布订阅就是一个客户端在某个频道里发消息，其它订阅到此频道的客户端接收消息。订阅：发布消息：批量订阅：发布消息：redis持久化RDB每隔指定时间自动把内存中数据写入一个文件，下次启动时加载文件，这样内存中就有上次的数据。redis默认的持久化方式。配置在redis.conf的140多行有如下配置是RDB配置。- save 900 1：每900秒至少有1个key发生变化，则备份内存快照。- save 300 10：每300秒至少有10个key发生变化，则备份内存快照。- save 60 10000：每60秒至少有10000个key发生变化，则备份内存快照。位置：AOF把对redis的操作存在一个文件中，下次开机时按照文件的记录再次将数据存在内存中。配置appendonly no改为appendonly yes。appendfsync always：每次有数据修改时，都会写入AOF文件appendfsync everysec：每秒同步一次，写入AOF文件appendfsynv no：从不同步。手动重写aof文件命令：bgrewriteaof。启动多个redis拷贝安装目录下的redis文件夹修改redis.conf文件的端口号启动redis时指定配置文件，保证端口号不同关闭时指定端口号，如：./bin/redis-cli -p 端口号 shutdown]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-内存管理]]></title>
    <url>%2F2019%2F05-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[存储器的层次我们都知道存储器的容量和速度是限制计算机发展的一大原因，人们对存储器的要求需要既快又大，但是这样带来的结果就是存储器的造价非常昂贵，所以不可能在计算机中全部配置既快又大的存储器。所以现代的计算机系统中都配置了多层结构的存储器系统来平衡速度差异问题。存储器一般被分成六层，不过在只有前四层属于内存，所以此篇只介绍前四层：主存储器用于保存进程运行时的程序和数据。对于微机系统和大中型机，容量为数十MB到数GB；对于嵌入式系统，容量为数十KB到数MB。CPU从主存读取指令和数据。CPU与外设交换信息要依托主存。为缓解CPU执行指令速度和主存访问速度的矛盾，引入寄存器和高速缓冲。寄存器访问速度做快，完全与CPU协调工作，价格十分昂贵，容量不可能很大。长度一般以字为单位。对于微机系统和大中型机，可能有几十个甚至上百个；对于嵌入式系统，仅有几个到几十个。高速缓冲容量大于或远大于寄存器，比内存小两到三个数量级左右，从几十KB到几MB。访问速度快于主存。将主存中经常访问的信息存放在高速缓冲，减少访问主存次数。磁盘缓冲将一部分频繁使用的磁盘数据和信息，暂时存放在磁盘缓冲中，减少访问磁盘次数。不是实际存在的存储介质，利用主存的存储空间，暂存从磁盘读出或写入的信息。总结一下：磁盘缓冲是为了解决内存和外存的速度差异而在内存中开辟的一块用于暂存磁盘数据的存储介质。主存储器是保存进程运行时的程序和数据的。寄存器是和CPU速度匹配的存储器，直接给CPU提供数据。虽然CPU是直接从寄存器去取指令和数据，但是寄存器的数据来源最终还是主存储器，所以为了减少访问CPU的次数，产生了高速缓冲来缓和寄存器和主存储器的矛盾。至于为什么能缓和呢？这是由于程序局部性原理。程序的装入和链接用户程序要在系统中运行，必须将它装入内存，其中有三个过程。编译：由编译程序（Complier）将用户源代码编译成若干个目标模块（Object Module）；链接：由链接程序（Linker）将编译后形成的目标模块以及它们所需要的库函数，链接在一起，形成一个装入模块（Load Module）；装入：由装入程序(Loader)将装入模块装入内存。链接链接程序的功能是将经过编译或汇编后得到的一组目标模块以及它们所需要的库函数，装配成一个完整的装入模块。静态链接方式生成可执行文件时进行链接。主要有两步。修改相对地址。变换外部调用符号。装入时动态链接目标模块是在装入内存时，边装入边链接的。装入时动态链接方式有以下优点：便于修改和更新。便于实现对目标模块的共享。运行时动态链接将对某些模块的链接推迟到执行时才执行，即在执行过程中，当发现一个被调用模块尚未装入内存时，立即由OS去找到该模块并将之装入内存， 把它链接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到装入模块上，这样不仅可加快程序的装入过程，而且可节省大量的内存空间。装入装入是将一个具有执行资格的模块加载进内存。绝对装入方式在可执行文件中指定内存地址，装入时直接定位在上述（即文件中记录的地址）内存地址。逻辑地址和物理地址完全相同。可重定位装入方式编译程序所生成的目标模块中采用逻辑地址，根据当前内存情况，将装入模块装入到适当位置。地址映射是在装入模块装入内存时一次性进行的，即是静态重定位。动态运行时装入方式静态重定位时程序装入内存后不能移动，而且通常需要占用连续的内存空间。所以与其对应的动态重定位是将地址映射工作推迟到程序真正执行时才进行。现代计算机运行过程预处理把存储在不同文件中的源程序聚合在一起。把被称为宏的缩写语句转换为原始语句。编译：将高级语言翻译成汇编语言或机器语言。链接将多个可重定位的机器代码文件（包括库文件）连接到一起。解决外部内存地址（一个文件中的代码会引用其他文件中的数据对象或过程，这些数据对象或过程的地址对于此文件来说就是外部地址）问题。装入确定程序在内中的绝对地址（即修改程序起始地址），将修改后的指令和数据放到内存中适当的位置。连续分配存储管理方式连续分配是指为一个用户程序分配空间的时候，将所有程序装入到一段连续的物理内存中。在早期（20世纪60-80年代）的操作系统中，这种分配内存的方式曾经被广泛的使用。单一连续分配这是最简单的一种存储管理方式，但只能用于单用户、单任务的操作系统中。内存分为以下两个分区：系统区和用户区。操作系统使用系统区；应用程序装入到用户区，可使用用户区全部空间。固定分区分配固定分区式分配，是最早使用的一种可运行多道程序的存储管理方式。它将内存空间划分为若干个固定大小的区域，每个分区大小可相同，也可不同。OS占一区，其余每个分区中可以装入一道作业。为了便于内存分配，系统需建立一张分区使用表。当有一用户程序要装入时，从表中找出一个能满足要求的、尚未分配的分区分配给该程序，然后修改分区使用表。动态分区分配数据结构空闲分区表每个空闲分区占用一个表项。分区表的表项中包含分区号、分区始址及分区大小等表目。表长不易确定。占用额外内存。空闲分区链表利用各空闲分区自身的单元组成双向链表。操作速度较慢。分区分配分区回收如果回收区的前后有空闲区，可分为图示三种情况。回收时将空闲区和回收区合并。如果回收区的前后无空闲区，新建一个表项，填写信息插入。分区检索算法顺序检索算法首次适应算法：按各空闲分区首址的升序的方法组织，分配时，按空闲分区表（或空闲分区链）的先后次序，从头查找，找到符合要求的第一个分区。循环首次适应算法：分配空闲空间时，不是从链首（或表头）开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找。最佳适应算法：按空闲区大小的升序方法组织，分配时，按空闲分区表（或空闲分区链）的先后次序，从头查找，找到符合要求的第一个分区。就说明它是最适合的（即最佳的）。最坏适应算法：按空闲区大小的降序方法组织，分配时总是取空闲分区表（或空闲分区链）中的第一项，若大小不能满足申请者的要求，则表示系统中无满足要求的空闲区，分配失败；否则分配。索引检索算法快速适应算法：将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，同时在内存中设立一张管理索引表，该表的每一个表项对应一种空闲分区类型，并记录其表头指针。空闲分区的分类是根据进程常用的空间大小进行划分，对于其他大小的分区，可以放在一个特殊的空闲区链表中。伙伴系统：分区大小均为2的K次幂。假设系统可利用空间容量为$2^m$个字，系统运行过程中，不断划分，将空闲分区根据大小分类。为长度为n的进程分配分区时，首先计算$i$值使得$2^{i-1}≦n≦2^i$。先找大小为$2^i$的分区分配，否则找大小为$2^{i+1}$的分区分配，把$2^{i+1}$分区分成两个$2^i$分区（互称伙伴），一个分配，另一个加入$2^i​$的空闲分区链表。分配可能经过多次分割，回收可能进行多次合并。哈希算法：根据空闲分区在可利用空闲区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算，即得到在哈希表中的位置，从中得到相应的空闲分区链表，实现最近分配策略。紧凑可变式分区也有零头问题。在系统不断地分配和回收中，必定会出现一些不连续的小的空闲区，称为外零头。虽然可能所有零头的总和超过某一个作业的要求，但是由于不连续而无法分配。解决零头的方法是拼接（或称紧凑），即向一个方向（例如向低地址端）移动已分配的作业，使那些零散的小空闲区在另一方向连成一片。分区的拼接技术，一方面是要求能够对作业进行重定位，另一方面系统在拼接时要耗费较多的时间。分页存储管理方式基本概念页面：将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页。物理块：把内存空间分成与页面相同大小的若干个存储块，称为（物理）块或页框（frame）。页面碎片：由于进程的最后一页经常装不满一块而形成了不可利用的碎片，称之为“页内碎片”。页面大小：每一页可进行编址的地址数目。页面大小应该满足2的n此幂。逻辑地址：页表：系统为每个进程建一张页表，其在内存的起始地址和长度记录在该进程的PCB中。页表项：页表的每一行。页表项长度：每个页表项占用的编址个数。从逻辑地址那里我们可以看到页号占用了20位，对应的块号也要占用20位，当然块号本身可能不止$2^{20}$个。又由于为了控制对物理块的读写等操作，会在页表项中加上控制字段。如果内存按字节编址，即每个编址可以存储8个二进制位，那么页表项占用的二进制位总数大于内存的字长度。我们需要把一个页表项拆开存放在多个编址后的空间中。地址变换$物理地址=块号+块内地址=F(逻辑地址的页号*页表项长度+页表始址)+业内地址$。每次进行地址变换需要访问两次内存，内存速度较慢，所以影响计算机整体性能。具有快表的地址变换根据程序局部性原理，把最近使用的页表项存放在快表中，下次再进行地址变换时先去快表中查找对应项，如果没找到再去内存中查找，然后把新找到的页表项存放在快表中，如果快表已满，采用某种算法淘汰一份。有效访问时间设t是访问内存的时间，a是快表命中率，λ是查找快表所需的时间。普通地址变换时间：t+t具有快表的地址变换时间：$ a \ast \lambda + (1-a) \ast (t+\lambda)$。两级页表对于两级页表，是将页表再进行分页，页面的大小与内存物理块的大小相同。逻辑地址结构可描述如下：两级页表地址变换可推广至N级页表。反置页表页表是按每个进程的页号排序，指示出物理块号的位置，反置页表是按物理块号排序，指示出每个页隶属的进程和页号。此方法需要为每个进程创建一个外部页表，即将页表建立在外存中。进程进行地址变换时先从反置页表里查找，如果查找不到则去外村中查找，再将查找到的页表项调入内存。分段存储管理方式之前的分区管理都是为了更好的利用内存。为了满足程序员在编程上的要求引入了分段管理方式。方便编程：通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都是从0开始编址，并有自己的名字和长度。因此，希望要访问的逻辑地址是由段名（段号）和段内偏移量（段内地址）决定的。例如，下述的两条指令便是使用段名和段内地址：其中，前一条指令的含义是将分段A中D单元内的值读入寄存器1；后一条指令的含义是将寄存器1的内容存入B分段的C单元中。12LOAD 1，[A] |〈D〉；STORE 1，[B] |〈C〉；信息共享：在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，共享某个例程和函数。分页系统中的“页”只是存放信息的物理单位（块），并无完整的意义，不便于实现共享；然而段却是信息的逻辑单位。由此可知，为了实现段的共享，希望存储管理能与用户程序分段的组织方式相适应。信息保护：信息保护同样是对信息的逻辑单位进行保护，因此，分段管理方式能更有效和方便地实现信息保护功能。动态增长：在实际应用中，往往有些段，特别是数据段，在使用过程中会不断地增长，而事先又无法确切地知道数据段会增长到多大。前述的其它几种存储管理方式，都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。动态链接：动态链接是指在作业运行之前，并不把几个目标程序段链接起来。要运行时，先将主程序所对应的目标程序装入内存并启动运行，当运行过程中又需要调用某段时，才将该段（目标程序）调入内存并进行链接。可见，动态链接也要求以段作为管理的单位。分段地址段表地址映射地址变换分页和分段的主要区别页是信息的物理单位，段则是信息的逻辑单位；页的的大小固定且由系统决定，而段的长度不固定，由用户所编写的程序决定；分页的地址空间是一维的，而分段的地址空间是二维的。分页是系统管理的需要；分段是为了更好满足用户的需要。段页式存储管理方式分段结构具有逻辑上清晰的优点，但它的一个致命弱点是每个段必须占据主存储器的连续区域，于是，要装入一个分段时可能要移动已在主存储器中的信息，为了克服这个缺点，可兼用分段和分页的方法，构成段页式存储管理。每个作业仍按逻辑分段，但对每一段不是按单一的连续整体存放到存储器中，而是把每个段再分成若干个页面，每一段不必占据连续的主存空间，可把它按页存放在不连续的主存块中。原理逻辑地址空间分段，段内分页，内存分块（页框），存储管理的分配单位是：物理块（页框）地址结构：段号，页号，页内偏移地址。每个作业一张段表，每段一张页表。地址变换：先查段表，再查该段的页表。映射地址变换机构]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-死锁及处理]]></title>
    <url>%2F2019%2F04-%E6%AD%BB%E9%94%81%E5%8F%8A%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[资源分类可重用资源和消耗性资源可重用性资源：可供用户重复使用多次的资源。特点：互斥访问系统中此资源数目相对固定系统中大多数资源属于此类可消耗性资源：临时性资源由进程动态创建和消耗，数目是可以不断变化的，比如信号量、进程通信的信息等。可抢占性资源和不可抢占性资源可抢占性资源：CPU和主存，不会引起死锁。不可抢占性资源：只能进程自行释放。如打印机，因为如果打印到一半，打印机被抢占，造成的结果只能是此次打印作废，所以它是不可抢占资源。死锁定义如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。死锁的起因竞争不可抢占性资源引起死锁一个资源只能同时被一个进程使用，但是下图P1在获得R1后还去申请R2，同时P2获得R2后还去申请R1，陷入僵局，引发死锁。竞争可消耗性资源引起死锁123P1：receive(p3,m3)； send(p2,m1)；P2：receive(p1,m1)； send(p3,m2)；P3：receive(p2,m2)； send(p1,m3)；如上代码，P1在等待P3给P1发消息，P2在等待P1给它P2发消息，P3在等待P2给P3发消息。造成一个死循环。进程推进顺序非法在下图中，X轴表示进程P1推进图，Y轴表示进程P2推进图。如果按照4号路线推进，可以看出P1在经过b、d段的执行之后，获得R1，P2在进过a、c、e段的执行之后获得R2。此时如果不加以处理，系统一定会进入死锁状态，因为接下来P1在拥有R1后又去申请R2，P2在拥有R2后又去申请R1。死锁产生的必要条件互斥条件：某段时间内，某资源只能由一个进程使用；请求和保持条件：进程因请求资源而阻塞时，对已分配给它的资源保持不放；不可抢占条件 ：资源在未使用完前，不能被剥夺，由使用进程释放；循环等待条件 ：发生死锁时，有向图必构成一环路。死锁处理共有三类做法：第一类是预防死锁，也就是破坏死锁产生的条件（破坏其中一个就可以），这样系统就永远不会产生死锁。第二类是死锁避免，死锁产生的根本原因是系统资源分配出现问题，如果能进行合理的资源分配就能避免死锁的发生。第三类是死锁发生后的检测和解除。预防死锁预防死锁是给系统施加一个条件使其永远不可能满足死锁产生的必要条件，但是互斥条件是不能被破坏的条件，所以预防死锁有三类做法：破坏“请求和保持”条件即进程在请求资源时，它不能持有不可抢占资源。有两种做法：所有进程在开始运行之前，一次性的申请其在整个运行过程中的全部资源，如果申请成功，进程便陷入等待。这样进程在运行的时候就不会再发出请求。进程在只获得运行初期所需的资源后便开始运行，但是进程在运行过程中需要逐步释放以分配给自己的资源，等初期获得所有资源都被释放后才能请求其他资源。破坏“不可抢占”条件当进程保持了某些不可被抢占资源，且提出的新需求又不能被满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这种预防策略的代价非常昂贵，比如进程请求的打印机被强制剥夺后，之前的工作等于作废。破坏“循环等待”条件常见的方法是“资源有序分配”。其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号升序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程，在拥有大编号资源再申请小编号资源时需要释放和小资源编号相等及以上的编号。避免死锁避免死锁讲道理是属于死锁的预防，但是它和预防死锁不同，预防死锁是破坏死锁产生的条件，避免死锁是防止系统进入不安全状态。所以我们就要明白什么是安全状态，它和死锁产生的必要条件有什么区别。安全状态安全状态指的是系统能按某种进程推进顺序(P1, P2, …, Pn)为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。此时，序列(P1, P2, …, Pn)为安全序列。如果系统无法找到这样一个序列，则称系统处于不安全状态。为什么能找到这样的序列系统就是安全的呢？其实它是一个递推的关系，假如系统在时刻i发起申请资源请求，其此时状态为a，系统会判断它申请成功后是否还能寻找到一个安全序列，如果能找到便可以分配，否则便是系统不安全状态。假如系统申请到了资源，还想发出申请请求，便会再次判断请求成功之后能否找到安全序列，由此递推下去可保证整个系统能避免死锁。安全状态和死锁必要条件的区别仍以此图为例。假如我们采用的是预防死锁策略中的破坏“请求和保持”条件里的第一个做法，那么推进顺序就不可能为4，因为进程P1在执行的时候需要获取全部资源才能执行。但对于避免死锁来说，系统可以按照4号推进顺序推进到e段和阴影区的交界处，然后进程P2在申请资源R2的时候会去判断分配R2给P2之后系统能否找到安全序列，事实上是找不到的，所以R2便不会分配给P2，这样系统就进入不了阴影区，从而可以避免死锁。所以预防死锁和避免死锁的区别是：预防死锁是每个进程在执行之前确保其自身不陷入死锁状态，如果每个进程都能不陷入死锁状态，系统便能永远安全。即从单个进程角度静态解决问题。但避免死锁是在每一次进行资源分配时判断分配之后是否系统处于安全状态，如果处于安全状态便可分配，否则便不能分配。即从系统整体角度动态解决问题。银行家算法数据结构可利用资源向量$Available$：是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果$Available[j]=K$，则表示系统中现有$R_j$类资源K个。最大需求矩阵$Max$：这是一个$n×m$的矩阵，它定义了系统中$n$个进程中的每一个进程对$m$类资源的最大需求。如果$Max[i, j]=K$，则表示进程$i$需要$R_j$类资源的最大数目为K。分配矩阵$Allocation$：这也是一个$n×m$的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果$Allocation[i,j]=K$，则表示进程i当前已分得$R_j$类资源的 数目为K。需求矩阵$Need$：这也是一个$n×m$的矩阵，用以表示每一个进程尚需的各类资源数。如果$Need[i,j]=K$，则表示进程$i$还需要$R_j$类资源K个，方能完成其任务。可得：$Need[i,j]=Max[i,j]-Allocation[i,j]​$算法设进程$cusneed$提出请求$REQUEST[i]$，则银行家算法按如下规则进行判断。如果$REQUEST[cusneed] [i]&lt;= Need[cusneed][i]​$，则转2；否则，出错。如果$REQUEST [cusneed] [i]&lt;= Available[i]$，则转3；否则，等待。系统试探分配资源，修改相关数据：$Available[i]-=REQUEST[cusneed][i]$;$Allocation[cusneed][i]+=REQUEST[cusneed][i]$;$Need[cusneed][i]-=REQUEST[cusneed][i]$;系统执行安全性检查算法，如安全，则分配成立；否则试探险性分配作废，系统恢复原状，进程等待。安全性算法设置两个工作向量$Work=Available​$、$Finish=false​$。从进程集合中找到一个满足下述条件的进程$i$，$Finish[i]==false;$$Need[i, j]&lt;=Work[j];$，如找到，执行3；否则，执行4。设进程获得资源，可顺利执行，直至完成，从而释放资源。$Work[i]=Work[i]+Allocation[i,j];​$，$Finish[i]=true;​$，循环2。如所有的进程$Finish= true​$，则表示安全；否则系统不安全。举例假定系统中有五个进程$\lbrace P0, P1, P2, P3, P4\rbrace$和三类资源$\lbrace A,B, C\rbrace$，各种资源的数量分别为10、5、7，在$T0$时刻的资源分配情况如图所示。$T0​$时刻的安全性$P1$请求资源：$P1$发出请求向量$Request1(1,0,2)​$，系统按银行家算法进行检查。$Request_1(1, 0, 2)≤Need_1(1, 2, 2)​$$Request_1(1, 0, 2)≤Available_1(3, 3, 2)$系统先假定可为$P1​$分配资源，并修改$Available,Allocation_1和Need_1​$向量。由此得到的资源变换情况如上上图括号所示。再利用安全性算法检查此时系统是否安全。$P4$请求资源：$P4$发出请求向量$Request_4(3,3,0)$，系统按银行家算法进行检查。$Request_4(3, 3, 0)≤Need_4(4, 3, 1);$。$Request_4(3, 3, 0)&gt;Available(2, 3, 0)​$，让$P4​$等待。$P0$请求资源：$P0$发出请求向量$Requst_0(0,2,0)$，系统按银行家算法进行检查。$Request_0(0, 2, 0)≤Need_0(7, 4, 3);$$Request_0(0, 2, 0)≤Available(2, 3, 0);$系统暂时先假定可为$P0$分配资源，并修改有关数据，如下图所示。进行安全性检查：此时可用资源$Available(2,1,0)$已经不能满足任何进程的需要，进入不安全状态，因此系统不分配资源。死锁的检测和解除死锁的检测在图中找一既非阻塞又非独立的进程节点$P_i$，如顺利，$P_i$可获得所有资源直至运行完毕。消去$P_i$所有的请求边和分配边，即释放占有的所有资源，同理再选下一进程节点$P_{i+1}, …, $若能消去所有的边，那么该图是可完全简化的，否则该图是不可完全简化的。具体做法如下：可利用资源向量$Available[]$，它表示了m类资源中每一类资源的可用数目。把不占用资源的进程（向量$Allocation[i]∶= 0$）记入L表中，即$L_i \bigcup L$。从进程集合中找到一个$Request_i≤Work$的进程，做如下处理：将其资源分配图简化，释放出资源，增加工作向量$Work∶ =Work+Allocation_i$。将它记入L表中。若不能把所有进程都记入L表中， 便表明系统状态S的资源分配图是不可完全简化的。 因此，该系统状态将发生死锁。死锁的解除死锁解除有多种做法，如下是按代价递减排序的几种。撤销所有死锁的进程。将每个进程回退到先前定义的某个检查点，再重新启动所有进程。逐个撤销死锁进程，直至死锁不存在。撤销进程的顺序应是基于某种最小代价原则，每次撤销后，死锁检测算法应该重新检测死锁是否依然存在。剥夺进程P的资源交给进程Q，P同时会退到获得此资源的节点上。对于3和4，选择的标准可以如下：以占用处理器的时间最小；以产生的输出少；所估计的剩余运行时间最长；所占用的资源最少；优先权最低。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时钟中断]]></title>
    <url>%2F2019%2F%E6%97%B6%E9%92%9F%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[中断的理解说到中断还不得不从现代操作系统的特性说起，无论是桌面PC操作系统还是嵌入式都是多任务的操作系统，而很遗憾，处理器往往是单个的，即使在硬件成本逐渐下降，但处理器的数量依然不可能做到每个任务一个CPU，所以CPU必须作为一种全局的资源让所有任务共享。即什么时候给任务A用，什么时候给任务B用……这就是进程调度，具体的安排就由调度算法决定了。进程如何去调度？现代操作系统一般都是采用基于时间片的优先级调度算法，把CPU的时间划分为很细粒度的时间片，一个任务每次只能时间这么多的时间，时间到了就必须交出使用权，即换其他的任务使用。这种要看操作系统的定时器机制了。那么时间片到之后，系统做了什么呢？这就要用到我们的中断了，时间片到了由定时器触发一个软中断，然后进入相应的处理历程。当然这一点不足以表明中断的重要，计算机操作系统自然离不开外部设备：鼠标、键盘、网卡、磁盘等等。就拿网卡来讲，我计算机并不知道时候数据包会来到，我能保证的就是数据来了我能正常接收就行了。但是我又不可能一直等着接收数据包，要是这样其他任务就死完了。所以合理的办法是，你数据包来到之后，通知我，然后我再对你处理，怎么通知呢？？答：中断！键盘、鼠标亦是如此！中断的定义指处理机处理程序运行中出现的紧急事件的整个过程.程序运行过程中，系统外部、系统内部或者现行程序本身若出现紧急事件，处理机立即中止现行程序的运行，自动转入相应的处理程序（中断服务程序），待处理完后，再返回原来的程序运行，这整个过程称为程序中断。可分为两类：硬中断（Hardware Interrupt）外部中断：一般是指由计算机外设发出的中断请求，如：键盘中断、打印机中断、定时器中断等。外部中断是可屏蔽的。内部中断是指因硬件出错（如突然掉电、奇偶校验错等）,或运算出错（除数为零、运算溢出、单步中断等）所引起的中断，内部中断是不可屏蔽的。软中断（Software Interrupt）软中断是利用硬中断的概念，用软件方式进行模拟，实现宏观上的异步执行效果。很多情况下，软中断和”信号”有些类似，同时，软中断又是和硬中断相对应的，硬中断是外部设备对CPU的中断，软中断通常是硬中断服务程序（模拟硬件发出中断的程序）对内核的中断，信号则是由内核（或其他进程）对某个进程的中断。时钟中断在Linux的0号中断是一个定时器中断。在固定的时间间隔都发生一次中断，也是说每秒发生该中断的频率都是固定的。该频率是常量HZ，该值一般是在100 ~ 1000之间。该中断的作用是为了定时更新系统日期和时间，使系统时间不断地得到跳转。另外该中断的中断处理函数除了更新系统时间外，还需要更新本地CPU统计数。若进程的时间片递减到0，进程则被调度出去而放弃CPU使用权。Linux的OS时钟的物理产生原因是可编程定时/计数器产生的输出脉冲，这个脉冲送入CPU，就可以引发一个中断请求信号，我们就把它叫做时钟中断。时钟中断是特别重要的一个中断，因为整个操作系统的活动都受到它的激励。系统利用时钟中断维持系统时间、促使环境的切换，以保证所有进程共享CPU；利用时钟中断进行记帐、监督系统工作以及确定未来的调度优先级等工作。可以说，时钟中断是整个操作系统的脉搏。参考：https://www.jb51.net/article/133782.htmhttps://blog.csdn.net/wlf_go/article/details/80237491]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>计算机组成原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c与cpp]]></title>
    <url>%2F2019%2Fc%E4%B8%8Ecpp%2F</url>
    <content type="text"><![CDATA[数据类型绝对值在$10^9$范围以内或者是32位的整数都可以定义成int型。绝对值在$10^{18}$范围以内或者是64位以内的整数可以定义为long long型。如果long long型赋大于$2^{31}-1$的初值，则需要在初值后面加上LL。遇到浮点型数据不要使用float，都应该使用double。小写字母的ASCII值开始于97，大写字母的ASCII值开始于65。小写字母比大写字母大32。\0表示NULL。运算符运算符含义语法效果&lt;&lt;左移a &lt;&lt; x整数a按二进制位左移x位&gt;&gt;右移a &gt;&gt; x整数a按二进制位右移x位&amp;位与a &amp; b整数a和b按二进制对齐，进行按位与运算$\mid$位或$a \mid b$整数a和b按二进制对齐，进行按位或运算^位异或a ^ b整数a和b按二进制对齐，进行按位或运算~位取反~a整数a在二进制下各位取反解释按位与：除了11为1，其他都是0；按位或：除了00为0，其他都是1；按位异或：相同为0，不同为1。无穷大const int INF = (1 &lt;&lt; 30) - 1;const int INF = 0x3fffffff;scanf数据类型格式符举例int%dscanf(&quot;%d&quot;, &amp;n)long long%lldscanf(&quot;%lld&quot;, &amp;ll)float%fscanf(&quot;%f&quot;, &amp;fl)double%lfscanf(&quot;%lf&quot;, &amp;db)char%cscanf(&quot;%d&quot;, &amp;c)字符串（char数组）%sscanf(&quot;%d&quot;, str)scanf双引号之内的字符串其实类似一个匹配模式，我们输入的参数只要能匹配这个模式其实都算对。比如在输入时间时：scanf(&quot;%d:%d:%d&quot;, &amp;hour, &amp;minute, &amp;second)。输入的参数只要是：h:m:d的形式就行。除了字符类型（%c），scanf对于其他类型都是默认以空白符（空格、换行等）判断结束标志的。但是在使用字符类型时可以读入空白符。如对于scanf(&quot;%d%c%s&quot;, &amp;a, %c, str)，我们输入1 a bad，得到的结果是a=1, c= , str=a。printf数据类型格式符举例int%dprintf(&quot;%d&quot;, n)long long%lldprintf(&quot;%lld&quot;, ll)float%fprintf(&quot;%f&quot;, fl)double%fprintf(&quot;%f&quot;, db)char%cptintf(&quot;%d&quot;, c)字符串（char数组）%sptintf(&quot;%d&quot;, str)输出%和\：printf(&quot;%%&quot;)，printf(&quot;\\&quot;)%md &amp; %0md &amp; %.md%md：使不足m位的int型变量以m位且右对齐输出，高位以空格补齐，若变量本身超过m位，则保持原样。%0md：使不足m位的int型变量以m位且右对齐输出，高位以0补齐，若变量本身超过m位，则保持原样。%.mf：让浮点数保留m位小数输出。如果题目要求保留xx位小数，使用这个格式便是正确的。这种格式不是四舍五入：它是四舍六入偶成双。getchar &amp; putchargetchar()输入单个字符，putchar(char c)输出单个字符。如char c = getchar();，getchar()可以读入换行符。typedef给复杂的数据类型定义一个别名。如：typedef long long ll。常用math函数double类型取绝对值：fabs(double x)double类型向上取整：floor(double x)double类型向下取整：ceil(double x)求$r^p$：pow(double r, double p)取double类型的算术平方根：sqrt(double x)得到以自然对数为底的对数：log(double x)得到以a为底b的对数：$log_ab$=log(b)/log(a)四舍五入：round (double x)三角函数：sin(double x)，cos(double x)，tan(double x)：参数是弧度制。asin(double x)，acos(double x)，atan(double x)。memsetmemset(数组名, 值, sizeof(数组名));。memset是按字节赋值，也就是说所有的字节都会被赋值为相同的数值，比如对于int a[10]，使用memset(a, 1, sizeof(a);，则四十个字节上的二进制结果都是00000001。由于0的二进制补码全为0，-1的二进制补码全为1，所以memset一般只用于赋值0和-1。字符数组仅在初始化的时候可以直接赋值字符串，如：char str[4] = &quot;PAT&quot;;gets(str)：读入一行字符串，以换行符作为输入结束。puts(str)：输出一行字符串，即输出字符串+换行符。gets()和scanf()在读入字符串时会自动添加结束符（\0）。string.h头文件strlen()：获得字符数组中第一个\0前的字符个数（不包含\0）。strcmp(str1, str2)：比较两个字符串的大小（字典序）：str1 &lt; str2：返回负整数；str1 == str2：返回0；str1 &gt; str2：返回正整数；strcpy(str1, str2)：把str2复制给str1，包含结束符\0。strcat(str1, str2)：把str2粘贴在str1后面（覆盖str1的\0）。sscanf &amp; sprintf用于处理字符串问题：sscanf(原位置，格式符，目的位置)：把原位置里的数据输入到目的位置中。sprintf(目的位置, 格式符, 原位置)：把原位置里的数据输出到目的位置中。12345678int main()&#123; int n; char str[100] = "123"; sscanf(str, "%d", &amp;n); //字符转int时不是强转为ASCII，是字面值相同。 printf("%d\n", n); //123 return 0;&#125;处理复杂的字符串：12345678910int main()&#123; int n; double db; char str1[100] = "2048:3.14,hello"; char str2[100]; sscanf(str1, "%d:%lf,%s", &amp;n, &amp;db, str2); printf("n=%d, db=%.2f, str2=%s\n", n, db, str2); //n=2048, db=3.14, str2=hello return 0;&#125;12345678910int main()&#123; int n = 12; double db = 3.1415926; char str1[100]; char str2[100] = "good"; sprintf(str1, "%d:%.2lf,%s", n, db, str2); printf("str2=%s\n", str1); //str2=12:3.14,good return 0;&#125;指针指针存储的地址的类型称为基类型。基类型必须和指针变量存储的地址类型相同。进行加减法得到的是其基类型偏移的位数。如，两个int型指针相减，等价于两个指针之间差了几个int。指针作为函数的参数，传递的是地址的拷贝123456789101112void testPointer(int *p1, int * p2)&#123; p1 = p1 + 1; cout &lt;&lt; *p1 &lt;&lt; endl; //3&#125;int main()&#123; int a[6] = &#123;1, 2, 3, 4, 5, 6 &#125;; testPointer(&amp;a[1], &amp;a[5]); cout &lt;&lt; a[1] &lt;&lt; endl; // 2 return 0;&#125;指针在创建的时候赋予初值。否则可能出现问题。如int *temp;，temp会被赋予一个随机空间，可能指向系统功能区，此时程序运行就会问题。结构体结构体限制：结构体内部不能定义本类型，但可以定义本类型的指针。结构体的构造函数：1234567891011121314struct studentInfo&#123; int id; char gender; studentInfo()&#123;&#125; studentInfo(char _gender): gender(_gender) &#123;&#125; studentInfo(int _id, char _gender): id(_id), gender(_gender) &#123;&#125;&#125;;int main()&#123; studentInfo stu = studentInfo(10086, 'M'); cout &lt;&lt; stu.id &lt;&lt; " " &lt;&lt; stu.gender &lt;&lt; endl; return 0;&#125;浮点数的比较计算机采用有限位的二进制代码，因此浮点数在计算机中的存储并不总是精确的，具体参考IEEE754规则。所以我们需要定义一个极小数eps（一般定义为$10^{-8}$）对这种误差进行修正。等于运算大于运算小于运算大于等于运算小于等于运算123456789101112const double eps = 1e-8;const double Pi = acos(-1.0);#define Equ(a, b) ((fabs((a) - (b))) &lt; (eps))#define More(a, b) ((a) &gt; (b + (eps)))#define Less(a, b) ((a) &lt; (b - (eps)))#define MoreEqu(a, b) ((a) &gt; (b - (eps)))#define LessEqu(a, b) ((a) &lt; (b + (eps)))单点测试提交的程序被执行多次，每次执行会输入一组数据，得到输出后和此组数据的结果做比较，如果相同则判断此测试点通过，总成绩等于N次执行的成绩之和。PAT采用的是单点测试的方案。多点测试提交的程序被执行一次，会把所有的测试数据都输入，如果其中一组输出出错，则此题错误。所以此时需要程序能有循环读入多组数据的能力。大多数OJ系统采用这种方案，如codeup。下面介绍三种读入方案：while ... EOF应用于没有给定输入的结束条件，默认读到文件末尾。123while(scanf("%d", &amp;n) != EOF)&#123; ...&#125;while ... break应用于题目要求输入的数据满足某个条件时停止输入12345while(scanf("%d", &amp;n) != EOF)&#123; if(n == 0) break; ...&#125;while(T--)当题目给出测试数据组数时采用这种方案。1234int T = 20；while(T--)&#123; ...&#125;]]></content>
      <categories>
        <category>算法笔记</category>
      </categories>
      <tags>
        <tag>C</tag>
        <tag>C++</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-Shell]]></title>
    <url>%2F2019%2F05-Shell%2F</url>
    <content type="text"><![CDATA[简介Shell是一个命令解释器，用户输入命令来获得自己想要的结果，但是终端中输入的命令很难进行高级语言的选择、循环等操作。不过Shell程序可以存放在文件上，称为Shell脚本（虽然Linux文件不以后缀名区分文件类型，但是一般编写Shell脚本时文件名会命名为以.sh结尾）。在脚本中可以较方便的进行类似高级语言的操作。最简单的Shell脚本我们都知道，直接在终端输入echo命令是回显参数，把echo命令放在shell脚本中有相同的效果。设置成可执行文件变量Shell脚本中的变量直接使用=便可创建，使用$解析变量名。{}是分组命令，表示H是一个变量，这里不加也可以。特殊变量$#：除脚本名外，命令行上参数的个数。$*：表示在命令行上实际给出的所有实参。如：exam3.sh A B C D E F G H I J K。$#是11。$*是： A B C D E F G H I J K$n：表示命令行上第n个参数$0表示文件名 $1表示第一个参数 …$@：表示在命令行上实际给出的所有实参。如：exam3.sh A B C D E F G H I J K。$@就是： “A” “B” “C” “D” “E” “F” “G” “H” “I” “J” “K”$$：当前进程的进程号$!：上一个后台命令对应的进程号。$?：上一条前台命令执行后的返回值。算术运算执行算术运算需要使用let，如let c=$a+$b。可以使用c=$(($a+$b))代替。其中算术运算符及优先级等同于C语言。同时多了个**表示幂运算。（运算符前后不要有空格）从命令行读入参数直接使用read，命令行中的参数会读到read后面跟的参数（相当于变量）里。读入时输出提示信息：引号双引号：由双引号引起来的字符（除$、`和`\`）都被当做普通字符对待。$表示变量替换； `表示命令替换；\之后的字符只有是$、 、双引号、`或换行符之一时会成为转义字符。其他情况都是\本身。单引号：单引号引起来的字符都是普通字符。特殊字符也失效。倒引号：被到引号引起来的字符被解释为命令。如上上图中所示。数组变量之间使用空格隔开各个元素。如果元素中有空格，使用双引号引起来。测试条件任何命令都可以作为条件，shell会执行这个命令并检查返回值，如果命令成功（返回值为0），表示真。test &lt;条件&gt;：如test n1 -eq n2[ 条件 ]：如[ n1 -eq n2 ]有关文件方面的测试-r 文件名：真 &lt;==&gt; 文件存在并且是用户可读-w 文件名：真 &lt;==&gt; 文件存在并且是用户可写-x 文件名：真 &lt;==&gt; 文件存在并且用户可执行-f 文件名：真 &lt;==&gt; 文件存在且是普通文件-d 文件名：真 &lt;==&gt; 文件存在且是目录文件-s 文件名：真 &lt;==&gt; 文件存在且长度大于0有关字符串方面的测试-z s1：真 &lt;==&gt; 字符串长度为0-n s1：真 &lt;==&gt; 字符串长度大于0s1：真 &lt;==&gt; 字符串不是空字符串s1 = s2（在“=”前后应有空格）：真 &lt;==&gt; 字符串相等s1 != s2：真 &lt;==&gt; 字符串不等s1 &lt; s2：真 &lt;==&gt; 按字典顺序s1在s2之后s1 &gt; s2：真 &lt;==&gt; 按字典顺序s1在s2之前数值方面的测试n1 -eq n2：真 &lt;==&gt; 数值相等n1 -ne n2：真 &lt;==&gt; 数值不等n1 -lt n2：真 &lt;==&gt; n1小于n2n1 -le n2：真 &lt;==&gt; n1小于或等于n2n1 -gt n2：真 &lt;==&gt; n1大于n2n1 -ge n2：真 &lt;==&gt; n1大于或等于n2逻辑运算符!：逻辑非-a：逻辑与-o：逻辑或(表达式)：圆括号括起来表示为一条语句选择结构循环结构break &amp; continue和C语言一致。shift参数跳转命令：不跟数组默认跳转1位，跟了跳转n位。命令行ex.shABCDEF原位置参数$0$1$2$3$4$5$6移位后参数$0$1$2$3$4$5还可以用于循环结构的done上面，表示每次选择指定参数。参数置换变量格式var1为空var1不空var2=${var1:-str}var2=str。var1不变var2=$var1。var1不变var2=${var1:=str}var2=var1=strvar2=$var1。var1不变var2=${var1:+str}var2为空。var1不变var2=str。var1不变var2=${var1:?str}输出：“shell 脚本名:var1:str”并退出shell。var2不变var2=$var1。var1不变ex1编写ex1.sh，参数为一个大于 20 的正整数。先检查参数是否符合要求。如果不符合要求，请给出提示；如果符合要求，输出这个参数的平方。ex2编写ex2.sh，首先显示当天日期，然后查找给定的用户是否在系统中工作（who 命令）。如果在系统中，就输出一条欢迎语句（例如 hello，xxxx！）；如果不在系统中，就输出一条语句（waiting for xxx！）ex3编写 ex3.sh，该脚本接受一个参数。若改参数不是目录，则给出提示信息；否则使用ll命令列出该目录下的内容，并输出有多少个子目录（d开头），多少个普通文件（-开头）。ex4编写 ex4.sh，将第一个参数指定的内容 copy 到第二个参数指定地点。若第一个参数是目录，自动添加-r选项（即把目录下的所有内容都 copy 过去）；若第一个参数是普通文件，则将其 copy 到指定地点；若第一个参数指定的文件或目录不存在，则报错；若第二个参数指定的文件或目录已经存在，则提示是否替换，若选择 yes，则先删除原来的文件或目录，然后再执行 copy 操作，否则放弃。ex5编写 ex5.sh。检查命令行的第一个参数是否是-b或者-s。如果是-b，则计算由第二个参数指定的文件中以 b 开头的行数。如果是-s，则计算由第二个参数指定的文件中以 s 开头的行数。否则显示选择有错的信息。ex6编写 ex6.sh。该脚本需要输入两个文件的名称，然后由用户选择相应的操作（若两个参数中任何一个不是普通文件，则报错）。cat：输出两个文件的内容statistic：统计两个文件分别有多少行merge：将第 1 个文件的内容合并到第 2 个文件后面copy：将第 1 个文件的内容 copy 到第 2 个文件（覆盖原文件）bye：退出1ex编写 1ex.sh，利用 for 循环将当前目录下的.c 文件移动到指定的目录下，完成后显示指定目录下的文件内容，并按文件从小到大排序。(ll -r -S）2ex编写 2ex.sh，显示 Fibonacci 数列的前 10 项及其总和。3ex编写 ex3.sh，判断给定的参数是否是素数。4ex编写 ex4.sh，将给定的参数转换成二进制表示。5exex5.sh假设存在一个/homework的文件夹，其中包含一个 studentlist.csv的文件，当中存放了若干学生的学号，每个一行。例如：150341101、150341102、150341105、150341106，编写 ex11.sh。查看/homework 文件夹下学生是否提交了作业，假设作业名的格式为：学号_homework.txt。最后输出没提交作业的学号名单。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-进程管理]]></title>
    <url>%2F2019%2F04-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux的进程状态psProcess Status。查看进程状态的最常用的命令，它可以提供关于进程的许多信息。直接用ps命令可以列出每个与你的当前Shell有关的进程的基本信息。ps -ef：显示系统中所有进程的全面信息。-e：显示所有进程-f：全格式用户ID、进程ID、父进程ID、CPU占用率、开始时间、开始此进程的终端设备、此进程运行的总时间、命令名。ps aux显示所有终端上所有用户的有关进程的所有信息。终结进程通常来说，终结一个前台进程可以使用Ctrl+C。终结一个后台进程得使用kill命令。kill &lt;进程号&gt;。如果想强制杀掉一个进程需要使用-9：kill -9 &lt;进程号&gt;sleep使进程暂停由时间值所指定的秒数。此命令大多用于shell程序设计中，使两条命令执行之间停顿指定的时间。如：sleep 100; who | grep &#39;root&#39;。waitwait是用来阻塞当前进程的执行，直至指定的子进程执行结束后，才继续执行。wait [进程号 或 作业号]：eg：wait 23 or wait %1如果wait后面不带任何的进程号或作业号，那么wait会阻塞当前进程的执行，直至当前进程的所有子进程都执行结束后，才继续执行。fork()fork()函数会创建一个和原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事。但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。一个进程调用fork()函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。fork()调用一次，分别向父子进程返回，它可能有三种不同的返回值：在父进程中，fork()返回新创建子进程的进程ID；在子进程中，fork()返回0；如果出现错误，fork()返回一个负值；所以我们可以通过fork返回的值来判断当前进程是子进程还是父进程。同时每个进程都有一个互不相同的进程标识符（process ID），可以通过getpid()函数获得，还有一个记录父进程pid的变量，可以通过getppid()函数获得变量的值。题1源代码运行结果分析程序运行到第7行，创建一个新的进程，克隆一份当前进程。向父进程返回子进程的pid，向子进程返回0。所以执行后父进程进入第3个分支，子进程进入第2个分支。题2源代码结果分析题3源代码结果分析题4题目分析执行第5行之后，向父进程返回真，向子进程返回假，但是没有任何影响，此时创建了一个进程，之后父子进程创建的进程个数相同，所以只分析一个再乘以2即可。第一个子进程分析结果如下图。注意，对于A &amp;&amp; B || C：表达式A为假，B不执行，C执行；表达式A为真，B执行：B为真：C不执行；B为假：C执行。所以答案是1+9*2=19个。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-vim]]></title>
    <url>%2F2019%2F03-vim%2F</url>
    <content type="text"><![CDATA[vi &amp; vim这俩都是文本编辑器。vi是Linux默认的编辑器，类似于windows的记事本。vim是vi的拓展，比vi更强大。可以用于在Linux中编辑文件内容。笔记中使用vim。它有两种模式，命令模式和编辑模式，在命令模式中可以做一些检索、筛选等操作。在编辑模式中可以对文档进行修改。进入 &amp; 退出进入命令模式方法：vim &lt;文件名&gt;。此时进入命令模式，不能对文件内容进行操作。对文档的检索是在这种模式下进行的。进入编辑模式：i：编辑位置在当前光标位置之前按下i再按_I：在光标所在行的行首插入新增文本按下I再按_a：在该命令之后输入的字符都插到光标之后按下a再按_A：在光标所在行的行尾添加文本按下A再按_o：在光标所在行的下面新开辟一行，随后输入的文本就插入在这一行按下o再按_O：在光标所在行的上面新开辟一行，随后输入的文本就插入在这一行上按下O再按_r：替换光标所在的哪一个字符按下r再按_R：一直替换光标所在的文字，直到按下ESC为止按下R再按三次_再按Esc退出编辑模式在编辑模式下按 Esc 键。退出命令模式需要使用转义字符::q：若未修改文件，此命令可以退出编辑器。:wq：把编辑缓冲区的内容写入文件中，退出编辑器，回到Shell下。:ZZ或:x：仅当作过修改时才将缓冲区内容写到文件上。:q!： 强行退出vi。告诉vi，无条件退出，丢弃缓冲区内容。vim流程图命令模式下的光标跳转方向键和Backspace键的使用和正常情况下相同。移动到上一行，列不变：k移动到上一行行头：-移动到下一行，列不变：j移动到下一行行头：+如果在相应命令的前面加上一个数字n，相应命令执行n次。如2k表示向上移动两行，列不变。移至行首：^或0移至行尾：$移至指定行：行号G。如2G，移动到第二行行首。移至指定列：列号|。如2|，移动到本行第2列。文本删除命令x（小写字母）删除光标所在的字符。命令X（大写字母）删除光标前面的那个字符命令dd删除光标所在的整行命令D从光标位置开始删除到行尾d&lt;光标移动命令&gt;删除从光标位置开始至光标移动命令之间的所有字符。如：d0：从光标位置（不包括光标位）删至行首。d3l：从光标位置（包括光标位）向右删3个字符。d$：从光标位置（包括光标位）删至行尾。与D相同。d5G：将光标所在行至第5行都删除。复原命令u：取消前面刚执行的插入或删除命令的效果，恢复到此前的情况。U：总是把当前行恢复成它被编辑之前的状态。重复命令.：在命令模式下，重复执行前一次插入命令或删除命令补充文本编辑命令方式下d0：删至行首d$：删至行尾ndd：删除当前行及其后的n-1行yy：复制当前行的文本10yy：复制包括当前行及其后面9行文本p：在当前行后面插入一个空行，把缓冲区的内容粘贴过来P：在当前行前面插入一个空行，把缓冲区的内容粘贴过来ex转移方式下:n1,n2 d：将n1行到n2行的内容删除:n1,n2 co n3：将n1行到n2行的内容复制到n3行下:n1,n2 m n3：将n1行到n2行的内容移到n3行下字符串检索向下检索：/模式〈Enter〉。例如：/int向上检索：?模式〈Enter〉。例如：?flout字符串替换:n1,n2s/word1/word2/g：n1和n2为数字。在n1与n2行之间寻找word1这个字符串，并将该字符串替换为word2。例如:100,200s/a/A在100行到200行之间搜索a并替换成A。:1,$s/word1/word2/gc：全局搜索word1，替换成word2。g改成gc表示要用户确认。:%s/$/s2/g：在整个行的末尾添加s2。全局替换命令g：:g/模式/命令表。:g/s1/p：打印文本中有s1的行。p命令表示打印。块选择ctrl+v，然后使用方向键选择块。y：复制反白的地方d：将反白的地方删除掉p：插入复制的内容参考：https://jingyan.baidu.com/article/84b4f565c6b9e560f6da3291.html。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-Linux常用命令]]></title>
    <url>%2F2019%2F02-Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[输入终端窗口中的命令以Enter键结束，且Shell命令区分大小写。如果命令太长，一行放不下时，在行尾输入\并按Enter键。这时Shell会返回一个大于号（&gt;）作为提示符，表示该命令行尚未结束，允许继续输入有关信息。echoecho命令把命令行中的参数全部显示到标准输出（终端）中。如果参数用引号引起来，会按原样输出。否则会把各个单词按字符串输出，字符串之间用空格隔开。单引号/双引号的区别请看Shell那一部分。输出重定向Linux的标准输出是屏幕，把结果输出到指定的文件叫做输出重定向。&gt;：目标文件不存在，系统将建立该文件；文件存在，重定向将会删除该文件，并重新建立一个新文件存放结果。&gt;&gt;：目标文件不存在，系统将建立该文件；如果目标文件存在，新的输出结果将会追加到文件末尾。pwd显示出当前所在目录的路径。历史命令history命令可以看到用户所有曾经输入过的命令。!!：执行上一个命令；`!n：执行第n个命令；!-n：执行倒数第n个命令；!xxx：执行以xxx开头的命令，如之前使用过clear，!cle会执行clear。~/.bash_history文件中会存储你近期使用过的命令。查看此文件：cat ~/.bash_historydatedate命令在屏幕上显示或设置系统的日期和时间：date [+格式控制字符串]格式控制字符串常用单引号引起来。年:Y 月:m 日:d 小时:H 分:M 秒:S有且只有超级用户能设置或修改系统时钟，语法如下：date -s “year-month-day hour:minute:second”系统在启动的时候是从CMOS（用来存储计算机某些参数的芯片）中加载时钟，为了保持系统时间与CMOS时间的一致性，Linux每隔一段时间会将系统时间写入CMOS。由于该同步是每隔一段时间进行的，在我们执行date -s后，如果马上重起机器，修改时间就有可能没有被写入CMOS，而hwclock –w强制把系统时间写入CMOS。cal列出日历信息。单独一个cal：列出当前月的日历信息。cal xxxx：列出xxxx年的日历信息。cal yy xxxx：列出xxxx年yy月的日历信息。cal dd yy xxxx：列出xxxx年yy月xx日所在月的日历信息。clearclear命令清除屏幕上的信息，清屏后，提示符移到屏幕左上角。关机 &amp; 重启shutdown -h now：立刻关机shutdown -h 15:30：15:30 关机shutdown -h +30：30 分钟后关机reboot：重启shutdown -k +2 &quot;一会要关机，抓紧保存&quot;：向所有用户输出关机通知，但不做真正操作。+2表示通知的关机时间是现在之后的两分钟。帮助命令如果我们忘记某些命令或其参数如何使用，需要使用帮助命令。whatis &lt;命令&gt;：显示命令的简短描述。&lt;命令&gt; -help：显示使用方法概述和参数列表。man &lt;命令&gt;：为命令提供相关帮助文档，页面分成章节。info &lt;命令&gt;：类似man命令，但是通常比它更详细。切换路径命令cd &lt;位置&gt;：切换到指定位置；cd ~：切换到用户家目录；cd -：切换到上一个所在目录；passwd修改密码。单独的passwd：修改使用该命令的用户的密码。passwd 用户名：root用户可以使用该命令修改其他用户的密码。Linux用户登录Linux系统时，必须通过指定的用户名和密码进行登录。不过所有的用户在Linux眼中都是一个数字，用userid（一个32位的二进制整数）来表示。可以通过id命令，查看自己的userid。userid为0的表示根用户。同时，在系统运行的每个进程、所创建的每个文件都有一个userid，这个userid代表运行这个程序的用户，或者文件的所有者。Linux系统中，用户被保存在/etc/passwd文件中。用户又分成三类：一般用户（userid&gt;=500）、超级用户（userid=0）和系统用户（userid&lt;500）。查看用户Linux是一个多用户系统，即很多个用户同时操作一个设备中的资源，但不同的用户有不同的权限。这些用户中有一个是超级用户（root），它是权限最高的用户。root用户在终端中的输入命令以#开头，其他的用户以$开头。- who：列出正在使用系统的所有用户、所用的终端名和注册到系统的时间。who am i：列出使用该命令的用户、所用的终端名和注册到系统的时间。用户组由于不同的用户有不同的权限。为了给不同的用户赋予相同的权限更加方便，诞生了用户组的概念。即同一个用户组里的人员可以有相同的某些权限。Linux中的用户或文件至少属于一个用户组。添加用户useradd或者adduser。执行后的具体操作（不同发行版有区别）：分配一个新的userid，数值等于之前所有userid中数值最大的加一。在/etc/passwd中添加一行。为用户在/home下建立一个新的目录（用户的家目录），目录名和用户名相同。在/etc/group中为用户建立一个新的个人组。在/var/spool/mail中创建用户的邮件文件。删除用户userdel &lt;用户&gt;。删除用户及部分相关信息，家目录和邮件文件还会存在。-r：包括家目录和邮件池等在内的所有用户信息都会被删除。添加/删除组groupadd &lt;组名&gt;。所有的组都保存在/etc/group文件中。groupdel &lt;组名&gt;。删除组。/etc/passwd &amp; /etc/shadow/etc/passwd有7列：用户名、密码、用户id、主要组id、备注信息、主目录、登录shell。各列之间使用:分割。同时密码一般都是x（被加密了），加密后的密码在/etc/shadow中。/etc/shadow有9列：用户名、加密密码、最近更改密码的日期、密码不可更改的天数、密码需要重新更改的天使、密码更改期限前的警告期限、密码过期的宽限时间、帐号失效日期、保留字段。但这里显示的密码是加密的。查看用户所属的组groups：查看使用此命令的用户所属组；groups &lt;用户&gt;：查看指定用户所属组。用户可多选，使用空格隔开。/etc/group &amp; /etc/gshadow/etc/group：组名、组密码、组id、组中附加用户。- /etc/gshadow：组名、密码、组管理者、组中附加用户。为用户添加备注在创建的时候添加：useradd -c &lt;备注&gt; 用户名。创建后修改：usermod -c &lt;备注&gt; 用户名。（会清除之前的备注信息）。usermod改变用户某些属性的命令。-l：改变用户的名称；-G：改变用户支持的用户组，会退出原来的附属组，配合-a不会删除之前组；-L：不让该用户登录；-e：设定用户失效日期。日期格式：“YYYY-MM-DD”。-s：改变Shell。新创建的用户默认使用bash，此选项修改登录Shell。如：usermod -aG 组名 用户gpasswdgpasswd -d userName groupName：从组中删除用户切换用户超级用户输入su 用户名可以不用输入密码切换到其他用户。普通用户切换到其他所有用户（su 用户名）需要输入密码。文件系统操作系统中负责管理和存储文件信息的软件机构称为文件管理系统，简称文件系统。文件：文件系统中存储数据的一个命名的对象。即使是空文件（不包含用户数据）也会为操作系统提供其他信息。目录：包含文件项目的一类特殊文件。Linux中在应用层上来看目录和文件是被区分开来的。查找文件find &lt;路径&gt; -name &#39;正则表达式&#39;：如find . -name &#39;*.so&#39;，查找当前目录下以.so结尾的文件。catcat &lt;文件&gt;：显示文件的内容。文件可以多选，之间用空格隔开。cat f1 &gt; f2：把f1文件的内容合并到f2文件中。touch文件不存在：则创建一个空的新文件；文件存在：把文件的时间标签更新为系统当前时间。grep命令的意思：global search regular expression and print out the line。部分选项如下：-a：将 binary 文件以 text 文件的方式搜寻数据-c：计算找到 ‘搜寻字符串’ 的次数-i：忽略大小写的不同，所以大小写视为相同-n：顺便输出行号-v：反向选择，亦即显示出没有 ‘搜寻字符串’ 内容的那一行！--color=auto：可以将找到的关键词部分加上颜色的显示喔！举例如下：管道命令管道命令是用来过滤信息的，比如我们之前grep -n root /etc/passwd之后显示带有root的行，如果想在结果中再按其他条件过滤就要使用管道命令：“|”。统计文件信息wc：统计指定文件的字节数（-c）、字数（-w）、行数（-l）例子：统计文件a中以b开头的行数：cat a | grep ^b | wc -l创建目录mkdir &lt;文件名&gt;。-p：父目录不存在时也可以创建。删除文件/目录rm -rf &lt;文件名&gt;。-r表示递归删除；-f表示强制删除，不询问。列出文件ls命令列出指定目录的内容。- -l：文件的详细信息。输出的信息分成多列，它们依次是：文件类型与权限、链接数、文件主、文件组、文件大小、建立或最近修改的时间、文件名。total的计算：https://yq.aliyun.com/ziliao/264744。-a：显示所有文件。之前显示的没有隐藏文件（以.开头）。-h：文件大小以人类可读的方式显示。需要配合-l使用。拷贝文件cp &lt;文件&gt; &lt;目录&gt;。剪切文件mv &lt;文件&gt; &lt;目录&gt;。修改文件名mv &lt;文件&gt; &lt;新文件名&gt;。文件结构Linux中所有的文件都由两部分构成。索引结点：包含此文件的信息，如文件权限、文件主、文件大小等。数据：文件的实际内容，有没有数据都可以。链接链接就是把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。硬链接：硬链接是多一个文件名和inode结点关联。由于它依赖于inode，所以不能在不同的文件系统之间做硬链接。硬链接不能用于目录。用法：ln &lt;被链接的文件&gt; &lt;新的文件名&gt;软连接：软连接是再拓展出一份inode，这个inode指向的区域保存如何找到真正数据的信息。用法：ln -s &lt;被链接的文件&gt; &lt;新的文件名&gt;用户和权限文件主：文件所有者，并赋予唯一的注册名。只有文件主或root才有权利用chown命令改变文件的所有关系（UID）。用户组：通常，组中包含了有相同需求的用户。文件主或超级用户（root）可以利用chgrp命令改变文件的GID。用户存取权限：Linux系统中规定了4种不同类型的用户：文件主、同组用户、其他用户、超级用户。3种访问文件或目录的方式：r（读）、w（写）、 x（可执行或查找）。chmod只有文件主或超级用户root才有权用chmod命令改变文件或目录的存取权限。使用格式：chmod [选项] MODE 文件。MODE可多选，之间用,隔开。MODE：&lt;who&gt;&lt;操作符号&gt;&lt;权限&gt;。who：u——user、g——group、o——others、a——all（可叠加）。操作符号：+ 添加、- 取消、= 赋予；权限：r 读、w 写、x 执行。（可叠加）举例以绝对方式改变权限置为1表示有相应权限，置为0表示没有相应权限。例如：r w x r - x r - -1 1 1 1 0 1 1 0 0转换成十进制是754。chmod 754 aa和chmod u=rwx,g=rx,o=r aa一致。umask官方的解释是掩码，其实就是用户创建文件或目录后它们的默认权限。不过和chomd有区别的是它把有权限设置为0，没权限设置为1，而且umask命令显示的是八进制数字。我的umask显示的是0022，转换成二进制就是000 010 010，转换成权限就是rwx r-x r-x。所以创建的目录的默认权限就是这个。但是Linux不允许新创建的文件有可执行权限，所以创建的文件的默认权限是rw- r-- r--。chown改变某个文件或目录的所有者。chown &lt;用户&gt; &lt;文件&gt;/&lt;目录&gt;chgrp改变文件或目录所属的用户组。chgrp &lt;用户组&gt; &lt;文件&gt;/&lt;目录&gt;文件权限的理解可读（r）：浏览文件中的内容；可写（w）：修改文件中的内容；可执行（x）：将文件作为命令使用。目录权限的理解可读：只能查看到目录下的子目录名和文件名；可执行：可以访问目录中的文件，包括子目录；可写：要在目录下添加删除目录和文件，必须有可执行的权利。压缩 &amp; 打包 &amp; 解压缩tar -zcvf：打包压缩后的文件名 要打包压缩的文件（多个之间用space分开）z：调用gzip压缩命令进行压缩c：create，打包文件v：显示运行过程f：指定文件名tar -xvf xxx.tar.gz -C 位置x：extract，解包v：显示允许过程f：指定文件名别名我们可以使用ll代替ls -l。但是对于ls -a，系统并没有提供la命令，不过我们可以使用alias定义la。取消别名使用unalias 别名## 定时任务cron工具允许用户配置要定期运行的任务，通过配置crontab的文件可以指定要运行哪些作业以及何时运行。配置crontab文件使用命令crontab。命令由6个用空白分隔的字段组成：| 字段 | minute | hour | day of month | month | day of week | command to run || —- | —— | —- | ———— | —– | ———– | —————— || 举例 | 45 | 16 | | | | date&gt;/tmp/date.txt || 范围 | 0-59 | 0-23 | 1-31 | 1-12 | 0-7 | |corntab命令的参数：- -e：编辑crontab的内容（会打开一个文件）；- 设置定期任务（16:45时把当前时间写入/tmp/date.txt文件中）：- 过一段时间之后查看/tmp文件夹：-u：只有root才能执行这个选项，帮助其他用户建立/删除crontab；-l：查看crontab的工作内容:-r：删除crontab的工作内容；成组命令被成组命令约束的命令被认为是一条命令。{ 命令; }：需要有空格和命令隔开，且命令后面需要“;”。不创建子进程。(命令)：不强制需要有空格和命令隔开，不强制需要“;”。创建子进程完成功能。例如下例把两条ls命令的值全部由管道输入给grep。sortsort lines of text files，将文本文件内容加以排序，以行为单位来排序，但不改变文件原始内容。默认排序规则：从第每行一个字符开始，依次按照ASCII码值进行比较。-n：按数字的大小排序，默认情况下把数字看成字符。-r：反转排序效果。uniq文件输出时，删除重复行或列。但如果重复的行不连续则不起作用。文件类型-：普通文件l：符号链接文件d：目录s：套接字文件（socket）b：块设备文件p：命名管道文件（pipe）c：字符设备文件ex1：用户管理在系统中添加三个用户：Blondie、Prince和Madonna他们都希望属于次要组music### Blondie要求在他的条目中添加特殊备注“heart of glass”Prince要求使用/bin/csh作为登录shellMadonna的使用期限为2020-12-1。Blondie决定加入摔跤俱乐部wrestle组。Prince要将他的用户名改为tafkap。Madonna开始对风水感兴趣，加入组fengshui，并要求将她的userid改为888。groupadd fengshuiusermod -a –G fengshui Madonnausermod –u 888 MadonnaPrince又要改名字了，我们觉得太麻烦，干脆锁住他的帐号。usermod –L PrinceBlondie最近表现不好，我们决定将他踢出去。userdel –r Blondie（想把该用户所有信息都一起删除可以使用-r）ex2：文件目录管理Ventura同时属于次要组governor和wrestle。Ventura撰写了自己的摔跤计划plans.txt，并将它放到目录/tmp下。Ventura希望将他的摔跤计划和用户Hogan以及其他摔跤组的成员共享，但他不希望组外的成员访问。用户Hogan想往用户Ventura的计划上添加内容，可以吗？怎么做？用户Hogan对他自己的贡献很满意，他希望将这个计划公开，让所有人都能读到这个文件，可以实现吗？不可以，只有root和文件主能修改文件访问权。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01-Linux入门]]></title>
    <url>%2F2019%2F01-Linux%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Linux介绍Linux是一套免费使用和自由传播的操作系统。严格来讲，Linux这个词本身只表示Linux内核，但一般来说使用Linux内核的操作系统都被称为Linux。而不同的厂家使用相同的Linux内核所构建的操作系统叫做Linux发行版。常见的Linux发行版有Ubuntu、Centos、Debian等。这些发行版的使用方法大同小异。但Linux不仅限于使用在PC机上，移动端（安卓系统是由Linux改写而来）、路由器（只保留少许功能的Linux系统）等终端都在使用Linux。Linux安装虚拟机安装：blog.csdn.net/qq_38206090/article/details/82559358双系统：笔者没有安装过，因为怕系统出问题导致文件损失。云服务器：云服务器系统配置Linux版本我认为是最简单的方式，所以以下实例均采用阿里云服务器。连接服务器工具SecureCRT：去 http://59.110.143.226/Sharing-Your-Story/ 搜索。Termius：https://www.microsoft.com/store/productId/9NK1GDVPX09V推荐使用Termius，好看也好用。SecureCRT是破解版，Termius是免费使用。Linux目录结构Linux的目录结构是一个树形结构，树根是一个/。直接子目录包括root、home等。如我的阿里云服务器根目录：ShellShell是指“为使用者提供操作界面”的软件（命令解析器）。Shell翻译过来叫做“壳”，用来区别于“核”，也就是说它把底层的东西封装成命令，使用者键入命令就能得到相应的结果。比如上面的这张图中，我在根目录下输入ll命令，就在终端上给我显示根目录下的文件信息。也就是说Shell解析了我输入的ll命令，返回我想要的信息（根目录文件信息）。Bash命令Shell是命令解释器，自然会有不同的分类，就类比于同是循环结构，Java和Python却有不同的语法。但是Bash（Bourne-Again SHell）是Linux默认的Shell交互类型，也就是说在Linux中打开一个终端，就启动一个Bash进程。Bash命令格式格式：命令名 [选项] [参数1] [参数2] … 有如下特点：命令名必须是小写英文字母。一般格式中，方括号括起来的部分是可选选项。选项是对命令的特别定义，以“-”开始。一个命令可以使用多个选项且多个选项连接起来同样有效（部分发行版不支持）。如：ls -al和ls -a -l效果相同。命令正常执行后返回一个0表示执行成功，返回非0值表示执行过程出错。在终端上很难体现出来，但在shell脚本（后续会介绍）中可作为控制逻辑流程的一部分（用$?查看）。Bash举例查看内核版本号：uname -a:uname是命令名，-a是选项，这个命令没有参数。uname解释]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv实现人脸识别、人脸打框、人脸剪切]]></title>
    <url>%2F2019%2Fopencv%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E3%80%81%E4%BA%BA%E8%84%B8%E6%89%93%E6%A1%86%E3%80%81%E4%BA%BA%E8%84%B8%E5%89%AA%E5%88%87%2F</url>
    <content type="text"><![CDATA[Opencv在各平台上的配置https://opencv-java-tutorials.readthedocs.io/en/latest/01-installing-opencv-for-java.html。测试图片人脸识别代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.Arrays;import java.util.List;import org.opencv.core.Core;import org.opencv.core.Mat;import org.opencv.core.MatOfRect;import org.opencv.core.Rect;import org.opencv.imgcodecs.Imgcodecs;import org.opencv.objdetect.CascadeClassifier;public class GetImgFace &#123; private static String classifier = "D:/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml"; static &#123; // 必须要加载Opencv的Library System.loadLibrary(Core.NATIVE_LIBRARY_NAME); &#125; public static void main(String[] args) &#123; //图片路径不能有中文... GetImgFace.getImgFace("C:\\Users\\ISJINHAO\\Desktop\\test.jpg"); &#125; public static List&lt;Rect&gt; getImgFace(String imgPath)&#123; /* * 加载分类器，选择已经训练好的opencv分类器，训练器路径：%OPENCV_HOME%/sources/data/haarcascades/ * 分类器包含眼睛，人脸，人体，微笑等等，其中对于仅仅识别人脸来说，最好的训练器是： * haarcascade_frontalface_default.xml * haarcascade_frontalface_alt.xml * haarcascade_frontalface_alt2.xml * */ // 分类器路径不要有中文... CascadeClassifier faceDetector = new CascadeClassifier(classifier); if (faceDetector.empty()) &#123; System.out.println("请选择正确的分类器！"); return null; &#125; // 创建Mat，Mat是用来保存图片信息的类。Imgcodecs是用来读取图片的工具类 Mat image = Imgcodecs.imread(imgPath); // 检测人脸，检测结果存在faceDetections中 MatOfRect faceDetections = new MatOfRect(); faceDetector.detectMultiScale(image, faceDetections); List&lt;Rect&gt; faceList = Arrays.asList(faceDetections.toArray()); System.out.println(faceList); return faceList; &#125; &#125;结果人脸打框代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.io.File;import java.util.Iterator;import java.util.List;import java.util.UUID;import org.opencv.core.Mat;import org.opencv.core.Point;import org.opencv.core.Rect;import org.opencv.core.Scalar;import org.opencv.imgcodecs.Imgcodecs;import org.opencv.imgproc.Imgproc;public class FaceRect &#123; public static void main(String[] args) &#123; String imgPath = "C:\\Users\\ISJINHAO\\Desktop\\test.jpg"; List&lt;Rect&gt; faceRects = GetImgFace.getImgFace(imgPath); //把识别出来的图片分别打框 Iterator&lt;Rect&gt; iterator1 = faceRects.iterator(); while(iterator1.hasNext()) &#123; Rect rect = iterator1.next(); FaceRect.imageMark(imgPath, "D:\\test\\" + UUID.randomUUID() + ".jpg", rect); &#125; //在一张图片中把所有识别出来的人脸都打框 Mat image = Imgcodecs.imread(imgPath); Iterator&lt;Rect&gt; iterator2 = faceRects.iterator(); while(iterator2.hasNext()) &#123; Rect rect = iterator2.next(); Imgproc.rectangle(image, new Point(rect.x, rect.y), // 左上点 new Point(rect.x + rect.width, rect.y + rect.height), // 右下点 new Scalar(0, 255, 0), 2); // 框的颜色和粗细 &#125; Imgcodecs.imwrite("D:\\test\\" + UUID.randomUUID() + ".jpg", image); &#125; public static File imageMark(String imagePath, String outFilePath, Rect rect) &#123; Mat image = Imgcodecs.imread(imagePath); // 原始图片 //Imgproc.rectangle的作用是在修改image中的数据，把相应的位置打上框 Imgproc.rectangle(image, new Point(rect.x, rect.y), // 左上点 new Point(rect.x + rect.width, rect.y + rect.height), // 右下点 new Scalar(0, 255, 0), 2); // 框的颜色和粗细 // 把mat写入图片 Imgcodecs.imwrite(outFilePath, image); return new File(outFilePath); &#125;&#125;结果人脸剪切代码1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.io.File;import java.util.Iterator;import java.util.List;import java.util.UUID;import org.opencv.core.Mat;import org.opencv.core.Rect;import org.opencv.core.Size;import org.opencv.imgcodecs.Imgcodecs;import org.opencv.imgproc.Imgproc;public class FaceCut &#123; public static void main(String[] args) &#123; String imgPath = "C:\\Users\\ISJINHAO\\Desktop\\test.jpg"; List&lt;Rect&gt; faceRects = GetImgFace.getImgFace(imgPath); //把识别出来的图片分别打框 Iterator&lt;Rect&gt; iterator1 = faceRects.iterator(); while(iterator1.hasNext()) &#123; Rect rect = iterator1.next(); FaceCut.imageCut(imgPath, "D:\\test\\" + UUID.randomUUID() + ".jpg", rect); &#125; &#125; public static File imageCut(String imagePath, String outFilePath, Rect rect) &#123; Mat image = Imgcodecs.imread(imagePath); // 按照原始图片中的人脸提取出来 Mat sub = image.submat(rect); Mat mat = new Mat(); Size size = new Size(rect.width, rect.height); // 修改提取出来的人脸信息sub在坐标轴的位置。 Imgproc.resize(sub, mat, size); // 将截图保存 Imgcodecs.imwrite(outFilePath, mat); return new File(outFilePath); &#125;&#125;结果]]></content>
      <categories>
        <category>大学生创新创业项目</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>人脸识别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-处理机调度]]></title>
    <url>%2F2019%2F03-%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[概述处理机调度是指通过对处理机资源进程的合理分配来提升系统资源的利用率、降低作业周转时间等。但是由于不同操作系统的目标不同，所以处理机调度的策略和目标也不相同。处理机调度的层次高级调度：又称作业调度或长程调度。它的主要功能是根据某种算法决定把外存上处于后备队列中的哪些作业调入内存，并为他们创建进程、分配资源等，然后放入就绪进程队列。主要用于批处理系统，分时系统的实时系统中不设置高级调度。低级调度：又称进程调度或断层调度。它的主要功能是根据某种算法决定让哪些就绪队列获得处理机，并由分配程序将处理机分配给被选中的进程。在批处理系统、实时系统和分时系统中都设置低级调度。中级调度：又称内存调度。它的主要功能是根据某种算法决定将哪些暂时不能运行的进程调至外存等待，当它们具备运行条件且内存又有空闲时再调入内存。这实际上是存储器管理中的对换功能，在下一章再展开介绍，处理机调度的目标共同目标：提升资源利用率：$CPU的利用率=\frac{CPU有效工作时间}{CPU有效工作时间+CPU空闲等待时间}$。公平：每个进程都应获得合理的CPU时间，不发生进程饥饿现象。平衡：进程可以分成多个类型，如计算型、I/O型等等。平衡是指系统中不同的设备都能处于忙碌状态。策略强制执行：指某些强制型任务，比如安全策略等，即使会造成其他工作的延迟。批处理系统的目标：平均周转时间短：周转时间：从作业进入系统到作业完成退出系统所用的时间。平均周转时间：同时参与系统运行的几个作业的周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NT_i]$带权周转时间：作业的周转时间（$T$）和系统为它提供服务的时间（$T_S$）。$W=\frac{T}{T_s}$平均带权周转时间：同时参与系统运行的几个作业的带权周转时间的平均值。$T=\frac{1}{n}[\sum_{i=1}^NW_i]$系统吞吐量高：单位时间内系统完成的作业数尽量多。处理机利用率高。分时系统的目标：响应时间快：指终端提交一个请求到主机返回结果至终端的时间短。均衡：不同请求的复杂度不同，所以响应时间必定不同，均衡是指响应时间应和请求复杂度相适应。实时系统的目标：截止时间的保证：对于HRT任务截止时间必须满足要求，SRT也要尽可能满足。可预测性：如在观看电影时一般都会连续播放帧，所以请求是可预测的，假如采用双缓冲实现第i帧和第i+1帧并行处理就能提高实时性。高级调度作业作业：比程序更为广泛的概念，不仅包含了通常的程序和数据，还有一份作业说明书。在批处理系统中，是以作业为基本单位从外存调入内存的。作业步：在作业运行期间，每个作业都必须经过若干个相对独立。又相互关联的顺序加工步骤才能得到结果。期中每一个加工步骤成为一个作业步。作业控制块Job Control Block，JCB。是作业在系统中存在的标志。保存了系统对作业进行管理和调度所需的全部信息。如：作业标识、用户名称、用户账号、作业类型（CPU繁忙型、I/O繁忙型、批量型、终端型等）、作业状态、调度信息（优先级、作业运行时间）、资源需求（预计运行时间、要求内存大小等）、已申请到资源的使用情况。作业运行的三个阶段收容阶段：每一个作业进入系统时（即输入到硬盘），便由“作业注册”程序为该作业建立一个作业控制块JCB并把它放入作业后备队列中。运行阶段：后备队列中的作业被选中后，系统会为其分配必要的资源和建立进程，然后将其放入就绪队列。一个作业从第一次进入就绪状态开始到它运行结束前都是处于运行阶段。完成阶段：当作业完成或发生异常而终止时，作业便处于完成阶段，此时系统会撤销进程和资源，并将运行结果通过某种方式输入，如输出到文件中。先来先服务算法First-Come First-served，FCFS。每次调度都是选择一个或多个最先进入队列的作业或进程，为它们分配资源，创建进程和分配CPU，使之投入运行。它是最简单的调度算法，同时也可用于进程调度。效率不高，所以一般不作为主调度算法。适用于CPU繁忙型而不适用于I/O繁忙型。因为CPU繁忙型长时间占用CPU很少有I/O操作，一旦获得CPU，就会运行很长时间，就是会长时间占用CPU，而I/O繁忙型由于要频繁访问IO端口，每次访问都要放弃CPU，等I/O访问完后要重新等待下一次调度（此时排到了就绪队列的队尾），所以要等待很久才能重新被调度。因此先来先服务有利于CPU繁忙型而不利于I/O繁忙型。短作业优先算法Short Job First，SJF。指对短作业优先调度的算法，它从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。此种算法对长作业非常不利而且实际使用上很难预估每个作业的运行时间。静态优先级调度算法为照顾紧迫性作业，使之进入系统后获得优先处理，引入优先级调度算法。按照进程的优先级大小来调度，使高优先级进程得到优先处理的策略称为优先权调度算法。静态优先级调度算法是指在输入前作业为其赋予优先级且一直保持不变。虽然可以照顾紧迫性作业，但是没有考虑到作业本身的运行时间和作业的等待时间等，所以产生了更好的动态优先级算法。高响应比算法高响应比算法是动态优先级算法的一种，其中$优先级 = \frac{响应时间}{要求服务时间} = \frac{等待时间+要求服务时间}{要求服务时间}$。这样可以得到：对于短作业：其要求服务时间短，优先级相对较高。对于长作业：在等待一段时间之后，其优先级会增长，直至够高而能获得服务。对于先来作业：假如在某一时刻其仍未获得服务，和后来的作业相比其优先级相对较高。相应时间与周转时间的对比，假如作业运行完了，两者相等，假如没有则 $响应时间&lt;周转时间$周转时间：从作业进入系统到作业完成退出系统所用的时间。响应时间：等待时间+要求服务时间。低级调度进程调度的任务和机制保存处理机的现场信息：比如程序计数器、通用寄存器里的内容。按某种算法选取进程。把处理机分配给进程：把选中进程的PCB中的有关处理机调度的信息装入处理器的寄存器中，把处理器的控制权交给进程使其能从上次的断点处恢复运行。进程调度机制排队器：每当有进程转入就绪状态时，排队器会将它插入到相应的就绪队列。分派器：分派器依据进程调度程序（更直接的说，进程调度算法）所选定的进程，将其从就绪队列中取出。上下文切换器：会产生两次上下文切换：旧进程和分配程序之间的切换；分配程序和新进程之间的切换。排队器、分派器、上下文切换器本身也是程序，但是它们是处于系统态的程序，而被调度的进程一般是用户态的程序，从系统态到用户态进行上下文切换需要很大的耗费，所以一般采用两组（或多组）寄存器，一组用于处理机在系统态时使用，一组用于系统在用户态时使用，这样在系统态和用户态之间切换时就可以只改变指针（用于从寄存器中存取数据和指令）使其指向指定寄存器就行。进程调度方式非抢占方式一旦某进程获得处理机，就会一直运行下去，直至该进程完成或者因发生某种事件而被阻塞其他进程才能获得处理机。此时引起进程调度的因素：正在执行的进程运行完毕。外部环境的改变使其不能再继续运行，如程序运行发生异常。进程通信或进程同步时执行了某种原语，如Block。正在执行的进程发出I/O请求。抢占方式允许调度程序根据某种原则去暂停某个正在执行的进程，将处理机分配给其他进程。这些原则一般有三种：高优先级原则；短进程优先原则；时间片原则。我们后面所提到的进程调度算法其实都是抢占方式下的策略。轮转调度算法将CPU的处理时间分成固定大小的时间片q， q的大小从几ms到几百ms。系统将所有就绪进程按先来先服务的原则排成队列。每次调度时，把CPU分配给队首进程，令其执行一个时间片，时间片用完后若进程未结束，则送回就需队列尾部重新调度，在一给定的时间内，就绪进程均能获得一时间片的执行时间。此时时间片大小是关键问题，一般来说时间片q正比于响应时间，反比于就绪进程数目。计算机的处理能力。速度快，q可小些。通常q值是这样决定的：批处理系统:80%的CPU周期在一个时间片内完成分时系统：$q=T/N_{max}$，（$T-响应时间上限，N_{max}-最大进程数$）优先级调度算法非抢占式优先级调度算法即一旦某个高优先级的进程占有了处理机，就一直运行下去，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件）才让另一高优先级进程运行。主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。抢占式优先级调度算法任何时刻都严格按照高优先级进程在处理机上运行的原则进行进程的调度。常用于要求比较严格的实时系统中， 以及对性能要求较高的批处理和分时系统中。静态优先权静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。一般地，优先权是利用某一范围内的一个整数来表示的，这些整数被称为优先数。确定优先权大小的依据：进程类型；进程对资源的需求；用户要求。动态优先权动态优先权是指，在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间的增加而改变的，以便获得更好的调度性能。例如，我们可以规定，在就绪队列中的进程，随其等待时间的增长，其优先权以速率a提高。若所有的进程都具有相同的优先权初值，则显然是最先进入就绪队列的进程，将因其动态优先权变得最高而优先获得处理机，此即FCFS算法。若所有的就绪进程具有各不相同的优先权初值，那么，对于优先权初值低的进程，在等待了足够的时间后，其优先权便可能升为最高，从而可以获得处理机。当采用抢占式优先权调度算法时，如果再规定当前进程的优先权以速率b下降，则可防止一个长作业长期地垄断处理机。多队列调度算法之前介绍的调度算法都是用一个算法来解决所有的进程调度，这样无法满足系统中不同用户对进程调度策略的不同要求。而多队列调度算法就是将就绪队列从一个分成多个，将不同性质或类型的进程放在不同的就绪队列，这样不同的队列之间设置优先级，和队列内部也可以设置优先级，能更好的满足用户的需求。同时在多处理机系统中，可以方便的给每个处理机设置单独的就绪队列。多级反馈队列调度算法设置多个就绪队列，每个队列赋予不同的优先级，一个队列的优先级最高，第二个队列次之，其余各队列的优先级逐个降低，各队列内部使用FCFS原则排列。优先级越高的进程时间片越短。当一个进程进入内存后，首先放在第一队列的尾部，按FCFS的原则调度，如果该时间片内未结束，进程调度时将此进程转入第二队列队尾，直至第N个对列，若进程仍未结束，在第N个对列上采用时间片轮转算法。仅当第i队列空闲时才调度第i+1队列，如果有新进程进入优先级较高的队列，剥夺CPU执行新进程，旧进程放入原队列尾部。此算法不必事先知道各进程执行的所需时间，可满足各种进程需要，是目前公认较好的进程调度算法。举例第i个对列的时间片为$2^{i-1}$。基于公平原则的调度算法保证调度算法保证每个进程都获得相同的处理机时间：跟踪计算每个进程自创建以来已经执行的时间。计算每个进程应该获得的处理机时间，即自创建以来的时间除以n。比较各进程获得处理机时间的比率，即实际执行时间除以应获得的处理机时间。比较各进程获得处理机时间的比率，如A：0.5；B：0.9；C：1.2。调度程序应选择比率最小的进程将处理机分配给它，并让该进程一直运行，直到超过最接近它的进程比率，然后把处理机让给此时比率最小的进程。公平调度算法在上个算法中，如果用户A有4个进程，用户B有1各进程，那用户A获得处理机的时间是用户B的四倍。而公平调度算法的目标是保证每个用户都获得相同的处理机时间。实时调度实时调度必须能满足实时任务对截止时间的要求。所以实时任务的算法和优先级算法有些区别。实时算法的分类非抢占式调度算法非抢占式轮转调度算法；非抢占式优先调度算法。抢占式调度算法基于时钟中断的抢占式优先级调度算法：在某实时任务到达后，如果它的优先级高于当前任务的优先级，这时并不立即抢占当前任务的处理机，而是等到时钟中断发生时，调度程序才剥夺当前任务的执行，将处理机分配给新到的高优先级任务。立即抢占式优先级调度算法：一旦出现外部中断，只要当前任务未处于临界区，便立即剥夺当前任务的执行，把处理机分配给请求中断的紧迫任务。最早截止时间优先算法Earliest Deadline First，EDF。可用于非抢占式算法，也可用于抢占式算法。非抢占式抢占式有两个周期任务，A、B的周期分别是20ms，50ms。A、B的执行时间分别是10ms和25ms。最低松弛度优先即算法Least Laxity First，LLF。$松弛度=截止时间-当前时间-任务执行时间$。主要用于抢占式调度。例有两个周期任务，A、B的周期分别是20ms，50ms。A、B的执行时间分别是10ms和25ms。优先级倒置即高优先级进程（或线程）被低优先级（或线程）延迟或阻塞。例，假如有三个完全独立的进程P1、P2和P3，优先级P1&gt;P2&gt;P3。P1和P3通过共享一个临界资源进行交互。123P1：...P(mutex); CS-1; V(mutex);... P2: ...Program2...;P3：...P(mutex); CS-3; V(mutex);...假如P3最先执行，在执行了P(mutex)操作后，进入临界区CS-3。在时刻a，P2就绪，因为它比P3的优先级高，P2抢占了P3的处理机而运行，在时刻b，P1就绪，因为它比P2的优先级高，抢占处理机执行，但P1执行P(mutex)之后被阻塞，处理机被P2获得，P2执行结束后，P1仍不能进入临界区，处理机被P3获得，等P3退出临界区，P1才能获得处理机。所以本应该高优先级的P1优先执行，但是由于存在临界资源而导致优先级倒置。优先级倒置的解决遵循动态优先级继承原则：当高优先级进程P1要进入临界区去使用临界资源，如果已经有一个低优先级进程P3正在使用该资源，此时一方面P1被阻塞，一方面P3继承P1的优先级并一直保持到P3退出临界区。这样做就能保证不会有比P3优先级高但比P1优先级低的进程插进来。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[仅使用Servlet3实现文件上传下载]]></title>
    <url>%2F2019%2F%E4%BB%85%E4%BD%BF%E7%94%A8Servlet3%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[上传文件的html界面123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="UTF-8"&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;单文件上传&lt;/h2&gt; &lt;form action="/servlet3-upload-and-download/uploadone" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="file"&gt; &lt;input type="submit" name="upload"&gt; &lt;/form&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt; &lt;h2&gt;多文件上传&lt;/h2&gt; &lt;form action="/servlet3-upload-and-download/uploadmany" method="post" enctype="multipart/form-data"&gt; &lt;input type="file" name="file1"&gt; &lt;input type="file" name="file2"&gt; &lt;input type="submit" name="upload"&gt; &lt;/form&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt; &lt;h2&gt;文件下载&lt;/h2&gt; &lt;a href="/servlet3-upload-and-download/download"&gt;点击下载&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;下载1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package download;import java.io.BufferedInputStream;import java.io.BufferedOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;@WebServlet("/download")public class download extends HttpServlet&#123; private static final long serialVersionUID = 1L; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.setContentType("text/html;charset=utf-8"); //filepath String filePath = "D:\\我.jpg"; try( BufferedInputStream bis = new BufferedInputStream(new FileInputStream(filePath)); BufferedOutputStream bos = new BufferedOutputStream(resp.getOutputStream()); ) &#123; long fileLength = new File(filePath).length(); resp.setHeader("Content-disposition", "attachment; filename=" + new String(new File(filePath).getName().getBytes("utf-8"), "ISO8859-1")); resp.setHeader("Content-Length", String.valueOf(fileLength)); byte[] buff = new byte[2048]; int bytesRead; while (-1 != (bytesRead = bis.read(buff, 0, buff.length))) &#123; bos.write(buff, 0, bytesRead); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; doGet(req, resp); &#125; &#125;上传单文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package upload;import java.io.File;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.MultipartConfig;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.Part;@WebServlet("/uploadone")@MultipartConfig //Servlet3中处理multipart/form-data类型请求的注解public class UploadOne extends HttpServlet&#123; private static final long serialVersionUID = 1L; protected void doGet(HttpServletRequest request,HttpServletResponse response) throws ServletException,IOException&#123; this.doPost(request, response); &#125; protected void doPost(HttpServletRequest request,HttpServletResponse response) throws ServletException,IOException&#123; //说明输入的请求信息采用UTF-8编码方式 request.setCharacterEncoding("utf-8"); response.setContentType("text/html; charset=UTF-8"); PrintWriter out = response.getWriter(); //Servlet3.0中新引入的方法，用来处理multipart/form-data类型编码的表单 Part part = request.getPart("file"); //获取HTTP头信息headerInfo=（form-data; name="file" filename="文件名"） String headerInfo = part.getHeader("content-disposition"); System.out.println("headinfo ==&gt; " + headerInfo); //从HTTP头信息中获取文件名fileName=（文件名） String fileName = headerInfo.substring(headerInfo.lastIndexOf("=") + 2, headerInfo.length() - 1); //获得存储上传文件的文件夹路径 String fileSavingFolder = this.getServletContext().getRealPath("/upload"); //获得存储上传文件的完整路径（文件夹路径+文件名） //文件夹位置固定，文件夹采用与上传文件的原始名字相同 String fileSavingPath = fileSavingFolder + File.separator + fileName; System.out.println("filePath ==&gt; " + fileSavingPath); //如果存储上传文件的文件夹不存在，则创建文件夹 File f = new File(fileSavingFolder + File.separator); if(!f.exists())&#123; f.mkdirs(); &#125; //将上传的文件内容写入服务器文件中 part.write(fileSavingPath); //输出上传成功信息 out.println("文件上传成功~！"); &#125;&#125;多文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package upload;import java.io.File;import java.io.IOException;import java.io.PrintWriter;import java.util.Collection;import java.util.Iterator;import javax.servlet.ServletException;import javax.servlet.annotation.MultipartConfig;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.Part;@WebServlet("/uploadmany")@MultipartConfig //Servlet3中处理multipart/form-data类型请求的注解public class UploadMany extends HttpServlet&#123; private static final long serialVersionUID = 1L; protected void doGet(HttpServletRequest request,HttpServletResponse response) throws ServletException,IOException&#123; this.doPost(request, response); &#125; protected void doPost(HttpServletRequest request,HttpServletResponse response) throws ServletException,IOException&#123; //说明输入的请求信息采用UTF-8编码方式 request.setCharacterEncoding("utf-8"); response.setContentType("text/html; charset=UTF-8"); PrintWriter out = response.getWriter(); //Servlet3.0中新引入的方法，用来处理multipart/form-data类型编码的表单 Collection&lt;Part&gt; parts = request.getParts(); Iterator&lt;Part&gt; iterator = parts.iterator(); //获得存储上传文件的文件夹路径 String fileSavingFolder = this.getServletContext().getRealPath("/upload"); while(iterator.hasNext()) &#123; Part next = iterator.next(); //获得文件大小 long size = next.getSize(); System.out.println(size); //获取HTTP头信息headerInfo=（form-data; name="file" filename="文件名"） String headerInfo = next.getHeader("content-disposition"); System.out.println("headinfo ==&gt; " + headerInfo); //从HTTP头信息中获取文件名fileName=（文件名） String fileName = headerInfo.substring(headerInfo.lastIndexOf("=") + 2, headerInfo.length() - 1); //获得存储上传文件的完整路径（文件夹路径+文件名） //文件夹位置固定，文件夹采用与上传文件的原始名字相同 String fileSavingPath = fileSavingFolder + File.separator + fileName; System.out.println("filePath ==&gt; " + fileSavingPath); //如果存储上传文件的文件夹不存在，则创建文件夹 File f = new File(fileSavingFolder + File.separator); if(!f.exists())&#123; f.mkdirs(); &#125; //将上传的文件内容写入服务器文件中 next.write(fileSavingPath); &#125; //输出上传成功信息 out.println("文件上传成功~！"); &#125;&#125;demo下载：https://github.com/isjinhao/servlet3-upload-and-download。]]></content>
      <categories>
        <category>Java Web</category>
      </categories>
      <tags>
        <tag>Java Web</tag>
        <tag>servlet3</tag>
        <tag>文件上传</tag>
        <tag>文件下载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Face++人脸识别系统项目结构]]></title>
    <url>%2F2019%2F%E5%9F%BA%E4%BA%8EFacepp%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[要求AngularJS+Bootstrap3+SSM+Opencv+Face++开发一套人脸签到系统，使用电脑摄像头获取人脸并进行签到。识别方式验证方式：人脸图片+保存人脸至服务器+到场离场时间。到场离场时间：第一次截取到的人脸是到场，最后一次截取到的人脸是离场。人脸图片、保存至服务器：使用Opencv 识别图片中的人脸得到所有的Rect，一个人脸在图片中的位置会储存在一个Rect（x轴、y轴、width、height）对象中。然后循环以下做法：剪切出每个Rect在图片中对应的子图片，调用Face++的接口搜索与子图片最相近的一个人，如果最相近的人置信度 &gt;= 80，认为是同一个人，复制一份原图片，然后把Rect对应的位置画上框，保存在指定文件夹（每个活动有唯一的存储文件夹）下，如果置信度 &lt; 80，处理下一个Rect。上传方式：客户端一秒截一张图上传。实体 &amp; 表结构组织创建活动，学生参与活动。活动分为两种，使用组的和不使用组的。使用组的应用场景是教学班签到，教学班的人数是固定的，不属于教学班的人即使识别成功也不算为签到。不使用组的应用场景是社团活动签到，只要识别成功，就算为签到。组织功能组织注册发布活动查看组信息查看举办的活动信息：查看每场活动用户：录入和导出记录签到用户用户注册###用户查看签到用户查看组管理员]]></content>
      <categories>
        <category>大学生创新创业项目</category>
      </categories>
      <tags>
        <tag>SSM</tag>
        <tag>Face++</tag>
        <tag>Opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown数学公式]]></title>
    <url>%2F2019%2Fmarkdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[符号代码符号代码$\sum$\sum$\sum_{i=0}^n$\sum_{i=0}^n$\pm$\pm$\div$\div$\cdot$\cdot$\times$\times$\mid$\mid$\circ$\circ$\ast$\ast$\bigotimes$\bigotimes$\bigoplus$\bigoplus$\leq$\leq$\geq$\geq$\neq$\neq$\approx$\approx$\prod$\prod$\coprod$\coprod$\cdots$\cdots$\int$\int$\iint$\iint$\oint$\oint$\infty$\infty$\nabla$\nabla$\because$\because$\therefore$\therefore$\forall$\forall$\exists$\exists$\not=$\not=$\not&gt;$\not&gt;$\leq$\leq$\geq$\geq$\not\subset$\not\subset$\emptyset$\emptyset$\in$\in$\notin$\notin$\subset$\subset$\subseteq$\subseteq$\bigcup$\bigcup$\bigcap$\bigcap$\bigvee$\bigvee$\bigwedge$\bigwedge$\biguplus$\biguplus$\bigsqcup$\bigsqcup$\hat{y}$\hat{y}$\check{y}$\check{y}$\breve{y}$\breve{y}$\overline{a+b+c+d}$\overline{a+b+c+d}$\underline{a+b+c+d}$\underline{a+b+c+d}$\overbrace{a+\underbrace{b+c}_{1.0}+d}^{2.0}$\overbrace{a+\underbrace{b+c}_{1.0}+d}^{2.0}$\uparrow$\uparrow$\downarrow$\downarrow$\Uparrow$\Uparrow$\Downarrow$\Downarrow$\rightarrow$\rightarrow$\leftarrow$\leftarrow$\Rightarrow$\Rightarrow$\Longleftarrow$\Longleftarrow$\longleftarrow$\longleftarrow$\longrightarrow$\longrightarrow$\Longrightarrow$\Longrightarrow$\alpha$\alpha$\beta$\beta$\gamma$\gamma$\Gamma$\Gamma$\delta$\delta$\Delta$\Delta$\epsilon$\epsilon$\varepsilon$\varepsilon$\zeta$\zeta$\eta$\eta$\theta$\theta$\Theta$\Theta$\vartheta$\vartheta$\iota$\iota$\pi$\pi$\phi$\phi$\Phi$\Phi$\psi$\psi$\Psi$\Psi$\omega$\omega$\Omega$\Omega$\chi$\chi$\rho$\rho$\omicron$\omicron$\sigma$\sigma$\Sigma$\Sigma$\nu$\nu$\xi$\xi$\tau$\tau$\lambda$\lambda$\Lambda$\Lambda$\mu$\mu$\partial$\partial$\lbrace$\lbrace$\rbrace$\rbrace$\overline{a}$\overline{a}$\frac{7x+5}{1+y^2}$\frac{7x+5}{1+y^2}$\int ^2_3 x^2 {\rm d}x$\int ^2_3 x^2 {\rm d}x$\sqrt[n]{3}$\sqrt[n]{3}$\vec{a} \cdot \vec{b}=0$\vec{a} \cdot \vec{b}=0$\iiint$\iiint$\oint$\oint$\lim$\lim$\infty$\infty$\partial$\partial$\ln15$\ln15$\log_2^{10}$\log_2^{10}]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>Latex</tag>
      </tags>
  </entry>
</search>
